{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"QKxfGTnfq2Sn","outputId":"ba242b6e-36ad-40f5-f19a-d5648449dea3","executionInfo":{"status":"ok","timestamp":1734468183932,"user_tz":300,"elapsed":256226,"user":{"displayName":"Danying Xu","userId":"05764054896178344561"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: transformers 4.46.3\n","Uninstalling transformers-4.46.3:\n","  Successfully uninstalled transformers-4.46.3\n","Found existing installation: accelerate 1.1.1\n","Uninstalling accelerate-1.1.1:\n","  Successfully uninstalled accelerate-1.1.1\n","\u001b[33mWARNING: Skipping unsloth as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mFound existing installation: torch 2.5.1+cu121\n","Uninstalling torch-2.5.1+cu121:\n","  Successfully uninstalled torch-2.5.1+cu121\n","Found existing installation: torchvision 0.20.1+cu121\n","Uninstalling torchvision-0.20.1+cu121:\n","  Successfully uninstalled torchvision-0.20.1+cu121\n","Found existing installation: torchaudio 2.5.1+cu121\n","Uninstalling torchaudio-2.5.1+cu121:\n","  Successfully uninstalled torchaudio-2.5.1+cu121\n","Collecting unsloth\n","  Downloading unsloth-2024.12.4-py3-none-any.whl.metadata (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting unsloth_zoo>=2024.11.8 (from unsloth)\n","  Downloading unsloth_zoo-2024.12.1-py3-none-any.whl.metadata (16 kB)\n","Collecting torch>=2.4.0 (from unsloth)\n","  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n","Collecting xformers>=0.0.27.post2 (from unsloth)\n","  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n","Collecting bitsandbytes (from unsloth)\n","  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n","Collecting triton>=3.0.0 (from unsloth)\n","  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.2)\n","Collecting tyro (from unsloth)\n","  Downloading tyro-0.9.2-py3-none-any.whl.metadata (9.4 kB)\n","Collecting transformers>=4.46.1 (from unsloth)\n","  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets>=2.16.0 (from unsloth)\n","  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.45.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.26.4)\n","Collecting accelerate>=0.34.1 (from unsloth)\n","  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\n","Collecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n","  Downloading trl-0.13.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.13.2)\n","Collecting protobuf<4.0.0 (from unsloth)\n","  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.26.5)\n","Collecting hf_transfer (from unsloth)\n","  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n","Collecting xxhash (from datasets>=2.16.0->unsloth)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets>=2.16.0->unsloth)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.11.10)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->unsloth) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth) (2024.9.11)\n","Collecting tokenizers<0.22,>=0.21 (from transformers>=4.46.1->unsloth)\n","  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.9.4)\n","Collecting cut_cross_entropy (from unsloth_zoo>=2024.11.8->unsloth)\n","  Downloading cut_cross_entropy-24.12.2-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth) (11.0.0)\n","Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\n","Collecting shtab>=1.5.6 (from tyro->unsloth)\n","  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (4.4.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.18.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2024.8.30)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.18.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.17.0)\n","Downloading unsloth-2024.12.4-py3-none-any.whl (174 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.2/174.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading accelerate-1.2.1-py3-none-any.whl (336 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trl-0.13.0-py3-none-any.whl (293 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.4/293.4 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading unsloth_zoo-2024.12.1-py3-none-any.whl (60 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.9.2-py3-none-any.whl (112 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.1/112.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n","Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cut_cross_entropy-24.12.2-py3-none-any.whl (22 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, triton, shtab, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf_transfer, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, tyro, tokenizers, nvidia-cusolver-cu12, transformers, torch, xformers, datasets, cut_cross_entropy, bitsandbytes, accelerate, trl, unsloth_zoo, unsloth\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 4.25.5\n","    Uninstalling protobuf-4.25.5:\n","      Successfully uninstalled protobuf-4.25.5\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n","    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.23.4\n","    Uninstalling nvidia-nccl-cu12-2.23.4:\n","      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.7.77\n","    Uninstalling nvidia-curand-cu12-10.3.7.77:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n","    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n","    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.20.3\n","    Uninstalling tokenizers-0.20.3:\n","      Successfully uninstalled tokenizers-0.20.3\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.18 requires torchvision>=0.11, which is not installed.\n","timm 1.0.12 requires torchvision, which is not installed.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n","grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-1.2.1 bitsandbytes-0.45.0 cut_cross_entropy-24.12.2 datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 hf_transfer-0.1.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 protobuf-3.20.3 shtab-1.7.1 tokenizers-0.21.0 torch-2.5.1 transformers-4.47.1 triton-3.1.0 trl-0.13.0 tyro-0.9.2 unsloth-2024.12.4 unsloth_zoo-2024.12.1 xformers-0.0.28.post3 xxhash-3.5.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"bdf99d88ff774db98947e11dce55bb88"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hFound existing installation: unsloth 2024.12.4\n","Uninstalling unsloth-2024.12.4:\n","  Successfully uninstalled unsloth-2024.12.4\n","Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-upu9twkj/unsloth_4818aed743354c95b2d9de1c7e50bd44\n","  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-upu9twkj/unsloth_4818aed743354c95b2d9de1c7e50bd44\n","  Resolved https://github.com/unslothai/unsloth.git to commit 85f1fa096afde5efe2fb8521d8ceec8d13a00715\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: unsloth_zoo>=2024.11.8 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.12.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2)\n","Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.9.2)\n","Requirement already satisfied: transformers>=4.46.1 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.47.1)\n","Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.2.0)\n","Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n","Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.26.5)\n","Requirement already satisfied: hf_transfer in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.8)\n","Requirement already satisfied: bitsandbytes>=0.43.3 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.1)\n","Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11.10)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.5)\n","Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.0)\n","Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.2.1)\n","Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.13.0)\n","Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.13.2)\n","Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.12.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.0.0)\n","Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.4)\n","Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n","Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.18.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.8.30)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\n","Building wheels for collected packages: unsloth\n","  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unsloth: filename=unsloth-2024.12.4-py3-none-any.whl size=173746 sha256=cb8cc23fbbe0c1ab12e287863b16fac1c37e46c5c1efdbc8174ef3c862a74132\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-hl3qgpw7/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n","Successfully built unsloth\n","Installing collected packages: unsloth\n","Successfully installed unsloth-2024.12.4\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n","Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# Uninstall potentially conflicting packages\n","!pip uninstall -y transformers accelerate unsloth torch torchvision torchaudio\n","\n","# Install base packages\n","!pip install unsloth\n","\n","# Install dependencies\n","!pip install -q transformers accelerate peft\n","!pip install -q datasets evaluate bitsandbytes trl\n","!pip install -q torch torchvision torchaudio\n","\n","# Install Colab-optimized unsloth\n","!pip uninstall unsloth -y\n","!pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","\n","# Install other tools\n","!pip install pandas scikit-learn\n","!pip install -q ipywidgets"]},{"cell_type":"markdown","metadata":{"id":"uIWN2AazbCtN"},"source":["Preparations\n","------"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"q2ADdar0bCBw","outputId":"a72888ce-3009-4bec-f703-79cc0469e16e","executionInfo":{"status":"ok","timestamp":1734468654200,"user_tz":300,"elapsed":36382,"user":{"displayName":"Danying Xu","userId":"05764054896178344561"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n","PyTorch version: 2.5.1+cu124\n","Transformers version: 4.47.1\n","Accelerate version: 1.2.1\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Environment setup\n","import os\n","import warnings\n","import random\n","import numpy as np\n","import torch\n","from datasets import load_dataset, Dataset\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import gc\n","from unsloth import FastLanguageModel\n","from trl import SFTTrainer\n","from transformers import TrainingArguments, TrainerCallback\n","import transformers\n","import accelerate\n","import json\n","import openpyxl\n","from datasets import Dataset\n","import gdown\n","\n","# Print versions\n","print(f\"PyTorch version: {torch.__version__}\")\n","print(f\"Transformers version: {transformers.__version__}\")\n","print(f\"Accelerate version: {accelerate.__version__}\")\n","\n","# Configure environment\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","warnings.filterwarnings('ignore')\n","torch.set_float32_matmul_precision('high')\n","\n","# Set random seeds\n","def set_seeds(seed=3407):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","# Memory management utilities\n","def clear_memory():\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","def print_gpu_utilization():\n","    print(\"\\nGPU Memory Usage:\")\n","    !nvidia-smi | grep -E \"Memory|Volatile\"\n","\n","def print_detailed_gpu_info():\n","    print(\"\\nDetailed GPU Memory Info:\")\n","    print(f\"Allocated: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n","    print(f\"Cached: {torch.cuda.memory_reserved()/1024**2:.2f} MB\")\n","    print(f\"Max Allocated: {torch.cuda.max_memory_allocated()/1024**2:.2f} MB\")"]},{"cell_type":"markdown","metadata":{"id":"bBRNJ9cqJqjP"},"source":["set up wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"IuwYk1ySIpp8","executionInfo":{"status":"aborted","timestamp":1734468280011,"user_tz":300,"elapsed":13,"user":{"displayName":"Danying Xu","userId":"05764054896178344561"}}},"outputs":[],"source":["!pip install wandb --upgrade\n","\n","import wandb\n","wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"nXDBvaR3JuKH"},"source":["define the sweep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YkUe7Y3FJwjE","executionInfo":{"status":"aborted","timestamp":1734468280012,"user_tz":300,"elapsed":12,"user":{"displayName":"Danying Xu","userId":"05764054896178344561"}}},"outputs":[],"source":["sweep_config = {\n","    'method': 'random'\n","    }\n","\n","metric = {\n","    'name': 'loss',\n","    'goal': 'minimize'\n","    }\n","\n","sweep_config['metric'] = metric\n","\n","parameters_dict = {\n","    'learning_rate': {\n","        'distribution': 'log_uniform_values',\n","        'min': 1e-5,\n","        'max': 1e-3\n","        },\n","    'warmup_ratio': {\n","        'values': [0.05, 0.1, 0.2]\n","        },\n","    'weight_decay': {\n","        'values': [0.01, 0.03, 0.05]\n","        },\n","    'per_device_train_batch_size': {\n","        'values': [2, 4]\n","        },\n","    'gradient_accumulation_steps': {\n","        'values': [2, 4, 8]\n","        },\n","    'epochs': {\n","        'value': 1\n","        }\n","}\n","\n","sweep_config['parameters'] = parameters_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cE0zTn7sRRHj","executionInfo":{"status":"aborted","timestamp":1734468280012,"user_tz":300,"elapsed":11,"user":{"displayName":"Danying Xu","userId":"05764054896178344561"}}},"outputs":[],"source":["import pprint\n","\n","pprint.pprint(sweep_config)"]},{"cell_type":"markdown","metadata":{"id":"Z6hC7qnObJHV"},"source":["Define class\n","---"]},{"cell_type":"code","execution_count":12,"metadata":{"collapsed":true,"id":"XZk6B1XqqQkM","executionInfo":{"status":"ok","timestamp":1734470823995,"user_tz":300,"elapsed":226,"user":{"displayName":"Danying Xu","userId":"05764054896178344561"}}},"outputs":[],"source":["class MemoryCallback(TrainerCallback):\n","    def on_step_end(self, args, state, control, **kwargs):\n","        if state.global_step % 50 == 0:  # 每50步清理一次\n","            clear_memory()\n","            print_detailed_gpu_info()\n","\n","class AIGenerationDetector:\n","    def __init__(self, max_seq_length=2048, save_dir='/content/drive/MyDrive/ai_detection_model', data_dir='/content/drive/MyDrive/ai_dataset'):\n","        \"\"\"\n","        Initializes the AIGenerationDetector class.\n","        Args:\n","            max_seq_length (int): Maximum sequence length for the model.\n","            save_dir (str): Directory to save the model and checkpoints.\n","            data_dir (str): Directory to save the dataset.\n","        \"\"\"\n","        self.max_seq_length = max_seq_length\n","        self.save_dir = save_dir\n","        self.data_dir = data_dir\n","        self.model = None\n","        self.tokenizer = None\n","        self.train_dataset = None\n","        self.eval_dataset = None\n","        self.test_dataset = None\n","        os.makedirs(self.save_dir, exist_ok=True)\n","        os.makedirs(self.data_dir, exist_ok=True)\n","\n","\n","    def download_data(self):\n","        \"\"\"\n","        Downloads the dataset from Google Drive only if the files don't exist.\n","        \"\"\"\n","        # Download target folder path\n","        download_dir = self.data_dir\n","\n","        # human.xlsx and ai.xlsx Google Drive download links\n","        human_xlsx_url = \"https://drive.google.com/uc?export=download&id=1EXEs6bDZ8KYWN6wei17QTOFKT8TOHVbq\"\n","        ai_xlsx_url = \"https://drive.google.com/uc?export=download&id=1fGU3P_xAfqHZeYQiwE382YmKiQZoWmFi\"\n","\n","        # File names\n","        human_xlsx_filename = \"human.xlsx\"\n","        ai_xlsx_filename = \"ai.xlsx\"\n","\n","        # Check if human.xlsx exists\n","        human_xlsx_output_path = os.path.join(download_dir, human_xlsx_filename)\n","        if not os.path.exists(human_xlsx_output_path):\n","            print(f\"Downloading {human_xlsx_filename} from Google Drive to {download_dir}...\")\n","            gdown.download(human_xlsx_url, human_xlsx_output_path, quiet=False)\n","        else:\n","            print(f\"{human_xlsx_filename} already exists in {download_dir}. Skipping download.\")\n","\n","        # Check if ai.xlsx exists\n","        ai_xlsx_output_path = os.path.join(download_dir, ai_xlsx_filename)\n","        if not os.path.exists(ai_xlsx_output_path):\n","            print(f\"Downloading {ai_xlsx_filename} from Google Drive to {download_dir}...\")\n","            gdown.download(ai_xlsx_url, ai_xlsx_output_path, quiet=False)\n","        else:\n","            print(f\"{ai_xlsx_filename} already exists in {download_dir}. Skipping download.\")\n","\n","        print(\"Data download check complete!\")\n","\n","    def setup_model(self):\n","        \"\"\"\n","        Loads the pre-trained model and tokenizer and configures the PEFT model.\n","        \"\"\"\n","        clear_memory()\n","        print(\"Loading model...\")\n","\n","        try:\n","            model, tokenizer = FastLanguageModel.from_pretrained(\n","                model_name=\"unsloth/Meta-Llama-3.1-8B\",\n","                max_seq_length=self.max_seq_length,\n","                load_in_4bit=True,\n","            )\n","\n","            model = FastLanguageModel.get_peft_model(\n","                model,\n","                r=16,\n","                target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n","                lora_alpha=16,\n","                lora_dropout=0.1,\n","                bias=\"none\",\n","                use_gradient_checkpointing=True,\n","                random_state=3407,\n","                use_rslora=True,\n","            )\n","\n","            self.model = model\n","            self.tokenizer = tokenizer\n","            print(\"Model loaded successfully!\")\n","\n","        except Exception as e:\n","            print(f\"Error loading model: {str(e)}\")\n","            raise\n","\n","    def prepare_datasets(self, max_samples=1000):\n","        \"\"\"\n","        Prepares the training, evaluation, and test datasets.\n","        Args:\n","            max_samples (int): Maximum number of training samples to use.\n","        \"\"\"\n","        clear_memory()\n","        print(\"Preparing datasets...\")\n","        try:\n","            human_xlsx_path = os.path.join(self.data_dir, \"human.xlsx\")\n","            ai_xlsx_path = os.path.join(self.data_dir, \"ai.xlsx\")\n","\n","            if not os.path.exists(human_xlsx_path) or not os.path.exists(ai_xlsx_path):\n","                self.download_data()\n","\n","            print(f\"Loading data from {human_xlsx_path} and {ai_xlsx_path}...\")\n","\n","            df_human = pd.read_excel(human_xlsx_path)\n","            df_human = df_human[['abstract']]\n","            df_human['is_ai_generated'] = 'False'\n","\n","            df_ai = pd.read_excel(ai_xlsx_path)\n","            df_ai = df_ai[['abstract']]\n","            df_ai['is_ai_generated'] = 'True'\n","\n","            # merge\n","            df = pd.concat([df_human, df_ai], ignore_index=True)\n","\n","            dataset = Dataset.from_pandas(df)\n","            print(f\"Data loaded. Total samples: {len(dataset)}\")\n","\n","            # Take required number of samples, if specified\n","            if max_samples > 0:\n","                dataset = dataset.shuffle(seed=3407).select(range(min(max_samples, len(dataset))))\n","\n","            # Split train, val and test set\n","            train_val_idx, test_idx = train_test_split(\n","                range(len(dataset)),\n","                test_size=0.2,\n","                random_state=3407\n","            )\n","\n","            train_idx, val_idx = train_test_split(\n","                train_val_idx,\n","                test_size=0.125,\n","                random_state=3407\n","            )\n","\n","            train_examples = [self.process_training_example(dataset[i]) for i in train_idx]\n","            eval_examples = [self.process_training_example(dataset[i]) for i in val_idx]\n","            test_examples = [dataset[i] for i in test_idx]\n","\n","            self.train_dataset = Dataset.from_list(train_examples)\n","            self.eval_dataset = Dataset.from_list(eval_examples)\n","            self.test_dataset = Dataset.from_list([{'text': item['abstract']} for item in test_examples])\n","\n","            del train_examples, eval_examples, dataset\n","            clear_memory()\n","            print(f\"Datasets prepared! Train size: {len(self.train_dataset)}, Eval size: {len(self.eval_dataset)}, Test size: {len(self.test_dataset)}\")\n","\n","        except Exception as e:\n","            print(f\"Error preparing datasets: {str(e)}\")\n","            raise\n","\n","\n","    def process_training_example(self, example):\n","         \"\"\"\n","         Processes a single training example to create the prompt.\n","         Args:\n","            example (dict): A dictionary containing the 'text' and 'is_ai_generated' fields.\n","         Returns:\n","            dict: A dictionary containing the processed text.\n","         \"\"\"\n","         text = example['abstract']\n","         is_ai_generated = example['is_ai_generated']  # Get the field from the dataset\n","\n","         prompt = (\n","            \"You are an expert in distinguishing between text written by humans and text generated by AI.\\n\\n\"\n","            f\"Given Text: {text}\\n\\n\"\n","            \"Based on careful analysis, is the text generated by an AI? Respond with EXACTLY 'True' or 'False'.\\n\"\n","            f\"Answer: {str(is_ai_generated)}\"\n","         ) + self.tokenizer.eos_token\n","\n","         return {\"text\": prompt}\n","\n","\n","    def process_test_example(self, example):\n","        \"\"\"\n","        Processes a single test example to create the prompt.\n","        Args:\n","            example (dict): A dictionary containing the 'text' field.\n","        Returns:\n","            str: The generated prompt for testing.\n","        \"\"\"\n","        #text = example['abstract']\n","        print(example)\n","        text=example\n","\n","        prompt = (\n","           \"You are an expert in distinguishing between text written by humans and text generated by AI.\\n\\n\"\n","           f\"Given Text: {text}\\n\\n\"\n","           \"Based on careful analysis, is the text generated by an AI? Respond with EXACTLY 'True' or 'False'.\\n\"\n","        )\n","        return prompt\n","\n","    def setup_training_args(self, config=None):\n","        \"\"\"\n","        Sets up training arguments, either default or for hyperparameter sweeping.\n","        Args:\n","           config (dict, optional): Configuration for hyperparameter sweep. Defaults to None.\n","        Returns:\n","           TrainingArguments: Training arguments based on the given configuration.\n","        \"\"\"\n","        if config is None:\n","            # Default training arguments\n","            return TrainingArguments(\n","                output_dir=os.path.join(self.save_dir, \"checkpoints\"),\n","                per_device_train_batch_size=2,\n","                gradient_accumulation_steps=8,\n","                warmup_ratio=0.1,\n","                num_train_epochs=3,\n","                learning_rate=0.0006026,\n","                fp16=True,\n","                logging_steps=10,\n","                optim=\"adamw_torch\",\n","                weight_decay=0.05,\n","                lr_scheduler_type=\"cosine\",\n","                seed=3407,\n","                evaluation_strategy=\"steps\",\n","                eval_steps=50,\n","                save_strategy=\"steps\",\n","                save_steps=50,\n","                load_best_model_at_end=True,\n","                metric_for_best_model=\"eval_loss\",\n","                gradient_checkpointing=True,\n","                max_grad_norm=0.3,\n","                report_to=\"none\",\n","                remove_unused_columns=True,\n","                dataloader_pin_memory=False\n","            )\n","        else:\n","            # Training arguments for hyperparameter sweep\n","            return TrainingArguments(\n","                output_dir=os.path.join(self.save_dir, \"checkpoints\"),\n","                per_device_train_batch_size=config.per_device_train_batch_size,\n","                gradient_accumulation_steps=config.gradient_accumulation_steps,\n","                warmup_ratio=config.warmup_ratio,\n","                num_train_epochs=config.epochs,\n","                learning_rate=config.learning_rate,\n","                fp16=True,\n","                logging_steps=10,\n","                optim=\"adamw_torch\",\n","                weight_decay=config.weight_decay,\n","                lr_scheduler_type=\"cosine\",\n","                seed=3407,\n","                evaluation_strategy=\"steps\",\n","                eval_steps=50,\n","                save_strategy=\"steps\",\n","                save_steps=50,\n","                load_best_model_at_end=True,\n","                metric_for_best_model=\"eval_loss\",\n","                gradient_checkpointing=True,\n","                max_grad_norm=0.3,\n","                report_to=\"wandb\",\n","                remove_unused_columns=True,\n","                dataloader_pin_memory=False,\n","            )\n","\n","    def train(self):\n","        \"\"\"\n","        Trains the model using the SFTTrainer.\n","        \"\"\"\n","        clear_memory()\n","        print(\"Starting training...\")\n","\n","        try:\n","            trainer = SFTTrainer(\n","                model=self.model,\n","                tokenizer=self.tokenizer,\n","                train_dataset=self.train_dataset,\n","                eval_dataset=self.eval_dataset,\n","                dataset_text_field=\"text\",\n","                max_seq_length=self.max_seq_length,\n","                dataset_num_proc=2,\n","                packing=False,\n","                args=self.setup_training_args(),\n","                callbacks=[MemoryCallback()]\n","            )\n","\n","            trainer.train()\n","\n","            final_save_path = os.path.join(self.save_dir, \"final_model\")\n","            self.model.save_pretrained(final_save_path)\n","            self.tokenizer.save_pretrained(final_save_path)\n","            print(f\"Training completed! Model saved to {final_save_path}\")\n","\n","        except Exception as e:\n","            print(f\"Error during training: {str(e)}\")\n","            raise\n","\n","\n","    def sweep(self):\n","       \"\"\"\n","        Conducts a hyperparameter sweep using Weights & Biases.\n","        \"\"\"\n","       print(\"Starting sweeping...\")\n","\n","       with wandb.init():\n","            config = wandb.config\n","            training_args = self.setup_training_args(config)\n","\n","            try:\n","                trainer = SFTTrainer(\n","                    model=self.model,\n","                    tokenizer=self.tokenizer,\n","                    train_dataset=self.train_dataset,\n","                    eval_dataset=self.eval_dataset,\n","                    dataset_text_field=\"text\",\n","                    max_seq_length=self.max_seq_length,\n","                    dataset_num_proc=2,\n","                    packing=False,\n","                    args=training_args\n","                    )\n","                trainer.train()\n","\n","                final_save_path = os.path.join(self.save_dir, \"final_model\")\n","                self.model.save_pretrained(final_save_path)\n","                self.tokenizer.save_pretrained(final_save_path)\n","                print(f\"Training completed! Model saved to {final_save_path}\")\n","\n","            except Exception as e:\n","                  print(f\"Error during training: {str(e)}\")\n","                  raise\n","\n","\n","    def generate_predictions(self, batch_size=16):\n","         \"\"\"\n","        Generates predictions on the test dataset.\n","        Args:\n","           batch_size (int): Batch size for generating predictions.\n","        Returns:\n","           list: List of prediction values.\n","        \"\"\"\n","         clear_memory()\n","         print(\"Generating predictions...\")\n","\n","         try:\n","            FastLanguageModel.for_inference(self.model)\n","            predictions = []\n","            # Convert test data to a list to support batch processing\n","            test_examples = list(self.test_dataset)\n","            total_batches = (len(test_examples) + batch_size - 1) // batch_size\n","            all_predictions = []\n","\n","            # Process in batches\n","            for i in range(0, len(test_examples), batch_size):\n","                if i % (batch_size * 10) == 0:\n","                    print(f\"Processing batch {i//batch_size}/{total_batches}\")\n","\n","                # Get current batch samples\n","                batch = test_examples[i:i + batch_size]\n","                prompts = [self.process_test_example(example) for example in batch]\n","\n","                # Batch encoding\n","                inputs = self.tokenizer(\n","                    prompts,\n","                    return_tensors=\"pt\",\n","                    padding=True,\n","                    truncation=True,\n","                    max_length=self.max_seq_length\n","                ).to(\"cuda\")\n","\n","                # Batch generation\n","                with torch.inference_mode():\n","                    outputs = self.model.generate(\n","                        **inputs,\n","                        max_new_tokens=8,  # Reduce the number of generated tokens as we only need True/False\n","                        temperature=0.1,\n","                        top_p=0.9,\n","                        do_sample=False,    # Disable sampling for faster generation\n","                        use_cache=True,\n","                        pad_token_id=self.tokenizer.pad_token_id,\n","                    )\n","\n","                input_length = inputs['input_ids'].shape[1]\n","                responses = self.tokenizer.batch_decode(\n","                    [output[input_length:] for output in outputs],\n","                    skip_special_tokens=True\n","                )\n","\n","                # Batch processing prediction results\n","                batch_predictions = [\"true\" in response.lower() for response in responses]\n","                all_predictions.extend(batch_predictions)\n","\n","                # Periodically clear memory\n","                if i % (batch_size * 50) == 0:\n","                    clear_memory()\n","\n","            print(f\"Total predictions: {len(all_predictions)}\")\n","            assert len(all_predictions) == len(test_examples)\n","\n","            return all_predictions\n","\n","         except Exception as e:\n","            print(f\"Error generating predictions: {str(e)}\")\n","            raise\n","\n","\n","    def create_submission(self):\n","        \"\"\"\n","        Creates the submission file in CSV format using the generated predictions.\n","        \"\"\"\n","        print(\"Creating submission file...\")\n","        try:\n","            predictions = self.generate_predictions(batch_size=16)\n","            print(f\"Generated predictions: {len(predictions)}\")\n","\n","            assert len(predictions) == len(self.test_dataset), \\\n","                f\"Prediction count mismatch! Expected {len(self.test_dataset)}, got {len(predictions)}\"\n","\n","            submission_df = pd.DataFrame({\n","                'ID': range(len(predictions)),\n","                'is_ai_generated': predictions\n","            })\n","\n","            print(f\"Submission DataFrame shape: {submission_df.shape}\")\n","\n","            submission_path = os.path.join(self.save_dir, 'submission.csv')\n","            submission_df.to_csv(submission_path, index=False)\n","            print(f\"Submission saved to {submission_path}\")\n","\n","            saved_df = pd.read_csv(submission_path)\n","            print(f\"Saved file shape: {saved_df.shape}\")\n","\n","        except Exception as e:\n","            print(f\"Error creating submission: {str(e)}\")\n","            raise"]},{"cell_type":"markdown","metadata":{"id":"6MyPxv-EImbL"},"source":["# Hyper Parameters sweeping"]},{"cell_type":"markdown","metadata":{"id":"Zrbq99E0Redc"},"source":["## 1. Initial the sweep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Q0-DB4jRggc"},"outputs":[],"source":["sweep_id = wandb.sweep(sweep_config, project=\"ai_detection\")"]},{"cell_type":"markdown","metadata":{"id":"-eWethtVSJrV"},"source":["## 2. Run sweep agent"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kjIDgdFtXnbP"},"outputs":[],"source":["def run_sweep(data_dir):\n","    \"\"\"\n","    Runs the hyperparameter sweep.\n","    Args:\n","      data_dir(str): Path to the data directory.\n","    \"\"\"\n","    trainer = AIGenerationDetector(data_dir = data_dir) # set data directory path\n","    trainer.download_data()\n","    trainer.setup_model()\n","    trainer.prepare_datasets(max_samples=1000)\n","    trainer.sweep()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vkp4-r3U39H5"},"outputs":[],"source":["wandb.agent(sweep_id, run_sweep, count = 50)"]},{"cell_type":"markdown","metadata":{"id":"DSV3PgSEZzXZ"},"source":["# Get final result"]},{"cell_type":"markdown","metadata":{"id":"kDmQ-L8OC4DQ"},"source":["Before running the main function, hyper parameter in trainer.train() should be changed."]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f68e1b61bd304214b6a52f80fc37faf3","ef03292b2a2142d1b37c01e1684258a1","bd945d8684e94a9db712f7cd5291c89c","3cfd3ba6e0bf41c0adb6c7f649a3f1d1","b951e46369324e80bc0a501ed8c383dd","39416d60de274bd8b269ab71a2de6c25","2a528ef78b1b453283ed9b7c8dbb1810","f6f7e5b33c4a43e787f8234da7f73913","29ab1fe4f92c4c83adfb624031d064bf","6ce850ea4fe645d3ace5361f452077d2","1a8f9c9abb574e15bc182c7f4276f56e","6944b9463ec64dfe96f51569adfd6c4b","a1154a7e9d02419d82b097955360c73d","a1c75d42776342f4a7b6fe5c4ffd292c","45e9be17b1e449e5b86e3d276ea25c13","e20ff4b6dd154cc39536f99d485d22cb","fd2d1b75abc34531b92d24a37d374d1b","8cb8654249854752adffc8c11becb002","075678c9c4714a2fbc9b4f1f9d3ff78d","3b89f172e16c489eb477755b1c83a24c","414330f0171f4a3abb56a52e3eb92412","bd17beae41094bab89ed49df440ab7f9"]},"id":"TFcIHpQQaEv4","outputId":"9fcdf613-b7d1-4d05-df47-19c369a0af45","executionInfo":{"status":"ok","timestamp":1734486015540,"user_tz":300,"elapsed":15187231,"user":{"displayName":"Danying Xu","userId":"05764054896178344561"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting training pipeline...\n","human.xlsx already exists in /content/drive/MyDrive/ai_dataset. Skipping download.\n","ai.xlsx already exists in /content/drive/MyDrive/ai_dataset. Skipping download.\n","Data download check complete!\n","Loading model...\n","==((====))==  Unsloth 2024.12.4: Fast Llama patching. Transformers:4.47.1.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","Model loaded successfully!\n","Preparing datasets...\n","Loading data from /content/drive/MyDrive/ai_dataset/human.xlsx and /content/drive/MyDrive/ai_dataset/ai.xlsx...\n","Data loaded. Total samples: 50670\n","Datasets prepared! Train size: 3500, Eval size: 500, Test size: 1000\n","Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/3500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f68e1b61bd304214b6a52f80fc37faf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6944b9463ec64dfe96f51569adfd6c4b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 3,500 | Num Epochs = 3\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 8\n","\\        /    Total batch size = 16 | Total steps = 654\n"," \"-____-\"     Number of trainable parameters = 13,631,488\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [654/654 4:06:05, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>1.739000</td>\n","      <td>1.728870</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.767000</td>\n","      <td>1.735386</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.772300</td>\n","      <td>1.750454</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.738000</td>\n","      <td>1.742761</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.568300</td>\n","      <td>1.756627</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.585400</td>\n","      <td>1.757929</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.638200</td>\n","      <td>1.746924</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.616800</td>\n","      <td>1.739211</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.352900</td>\n","      <td>1.787875</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.339300</td>\n","      <td>1.811091</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>1.350000</td>\n","      <td>1.815925</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.289000</td>\n","      <td>1.819873</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>1.308300</td>\n","      <td>1.812395</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Detailed GPU Memory Info:\n","Allocated: 6151.94 MB\n","Cached: 6172.00 MB\n","Max Allocated: 7534.30 MB\n","\n","Detailed GPU Memory Info:\n","Allocated: 6151.94 MB\n","Cached: 6174.00 MB\n","Max Allocated: 7534.30 MB\n","\n","Detailed GPU Memory Info:\n","Allocated: 6151.93 MB\n","Cached: 6172.00 MB\n","Max Allocated: 7534.30 MB\n","\n","Detailed GPU Memory Info:\n","Allocated: 6151.93 MB\n","Cached: 6172.00 MB\n","Max Allocated: 7534.30 MB\n","\n","Detailed GPU Memory Info:\n","Allocated: 6151.94 MB\n","Cached: 6172.00 MB\n","Max Allocated: 7534.30 MB\n","\n","Detailed GPU Memory Info:\n","Allocated: 6151.94 MB\n","Cached: 6174.00 MB\n","Max Allocated: 7534.30 MB\n","\n","Detailed GPU Memory Info:\n","Allocated: 6151.94 MB\n","Cached: 6172.00 MB\n","Max Allocated: 7534.30 MB\n","\n","Detailed GPU Memory Info:\n","Allocated: 6151.94 MB\n","Cached: 6172.00 MB\n","Max Allocated: 7534.30 MB\n","\n","Detailed GPU Memory Info:\n","Allocated: 6151.95 MB\n","Cached: 6174.00 MB\n","Max Allocated: 7534.30 MB\n","\n","Detailed GPU Memory Info:\n","Allocated: 6151.94 MB\n","Cached: 6172.00 MB\n","Max Allocated: 7534.30 MB\n","\n","Detailed GPU Memory Info:\n","Allocated: 6151.93 MB\n","Cached: 6172.00 MB\n","Max Allocated: 7534.30 MB\n","\n","Detailed GPU Memory Info:\n","Allocated: 6151.94 MB\n","Cached: 6172.00 MB\n","Max Allocated: 7534.30 MB\n","\n","Detailed GPU Memory Info:\n","Allocated: 6151.93 MB\n","Cached: 6172.00 MB\n","Max Allocated: 7534.30 MB\n","Training completed! Model saved to /content/drive/MyDrive/ai_detection_model/final_model\n","Creating submission file...\n","Generating predictions...\n","Processing batch 0/63\n","{'text': \"We propose a type-driven approach to building verified safe and correct IoT applications. Today's IoT applications are plagued with bugs that can cause physical damage. This is largely because developers account for physical constraints using ad-hoc techniques. Accounting for such constrains in a more principled fashion demands reasoning about the composition of all the software and hardware components of the application. Our proposed framework takes a step in this direction by (1) using refinement types to make make physical constraints explicit and (2) imposing an event-driven programing discipline to simplify the reasoning of system-wide properties to that of an event queue. In taking this approach, our framework makes it possible for developers to build verified IoT application by making it a type error for code to violate physical constraints.\"}\n","{'text': 'This paper studies multi-antenna covert communications coexisting with randomly located wardens and interferers. We analyze and optimize the covert throughput under a stochastic geometry framework. We first introduce covert outage probability and connectivity probability to respectively characterize covertness and reliability, and derive analytically tractable expressions for them. We then consider a worst-case covert communication, where the wardens can invariably maximize the covert outage probability by adjusting the detection thresholds of their detectors. Afterwards, we jointly design the optimal transmit power and transmission rate to maximize the covert throughput while satisfying the covertness requirement. Interestingly, it is found that the maximal covert throughput is invariant to either the density of interferers or the interfering power, regardless of the number of transmit antennas.'}\n","{'text': 'In this paper, we propose a simple neural net that requires only O(n log_2k) number of qubits and O(nk) quantum gates: Here, N is the number of input parameters, and k is the number of weights applied to these parameters in the proposed neural net. We describe the network in terms of a quantum circuit, and then draw its equivalent classical neural net which involves O(k^n) nodes in the hidden layer. Then, we show that the network uses a periodic activation function of cosine values of the linear combinations of the inputs and weights. The backpropagation is described through the gradient descent, and then iris and breast cancer datasets are used for the simulations. The numerical results indicate the network can be used in machine learning problems and it may provide exponential speedup over the same structured classical neural net.'}\n","{'text': 'Multi-channel physical random bit generator (RBG) based on a chaotic semiconductor lasers (SLs) network is proposed and experimentally demonstrated. In experiments, a small ring network consisting of three SLs mutually coupled with heterogeneous delays is constructed to obtain chaotic temporal waveforms. The results show that the time-delay signature of chaotic intensities in all the three SLs can be well concealed over wide range of parameters. Through linear combination of the three chaotic outputs, seven channels of chaotic entropy sources can be obtained. Furthermore, by introducing a minimal post-processing technique and directly extracting four least significant bits at 80-GS/s sampling rate, seven channel random bit sequences with verified randomness can be simultaneously achieved, and the total bit rate is 2.24 Tb/s. The proposed RBGs enabling such high generation rate have potential applications in the one-time pad encryption for the high-speed optical communication networks.'}\n","{'text': 'This paper presents the creation of a smartphone-captured ear and voice database in degraded conditions. The objective of this project is to develop a biometric authentication system capable of functioning in adverse situations. Hidden Markov models were applied to feature extraction in order to identify and verify individuals. The database was created through recordings of individuals in various environments, including noisy locations and areas with poor lighting conditions. The resulting dataset provided valuable information for the development of smart homes and other applications related to biomedical imaging. The use of a smartphone as a capture device allowed for easy accessibility and convenience for users. The ear and voice biometric system developed through this project has the potential for use across a range of industries needing secure and reliable authentication.'}\n","{'text': 'Hydroponics is the practice of growing plants and crops in soilless culture. It is becoming more prevalent nowadays because of decreasing available land due to urbanization, and the various advantages it has as compared to soil-based farming. To study and optimize the various factors that affect plant growth in hydroponics set-ups (such as ambient temperature, light intensity, humidity, etc.), a hybrid sensor network system, with both wireless (6LoWPAN) and wired (CAN Bus) components, was proposed. The proposed system was then implemented using off-the-shelf devices such as the CC2650 MCU, MSP432 launchpad, Digilent PMOD CAN, and the Raspberry Pi 2. The total number of 6LoWPAN nodes in the intended application setup was shown to be reduced by 87.26% compared to fully-wireless setup. The system was shown to be functional and the packet drop rate when time interval between messages is 800ms drops to almost 0%. An initial design for the visualization of the web application was also presented.'}\n","{'text': 'With the rapid development of technology and the increasing demand for sustainable development, the concept of \"Smart Cities\" has become an important issue. In this context, GPON (Gigabit Passive Optical Network) technology can play a significant role in the construction of Smart Cities. By providing high-speed and reliable access to information systems, GPON enables the integration of different systems such as energy, transportation, and security. Moreover, GPON can also facilitate the deployment of wireless fidelity (WiFi) hotspots, enhancing the connectivity of the city. Computational modeling can also be applied to GPON networks to optimize their performance and improve their efficiency. In conclusion, GPON is a crucial contribution to the realization of Smart Cities, supporting sustainable development and improving the quality of life through efficient and interconnected infrastructures.'}\n","{'text': 'Eye diagram and its parameters measurement are very important to represent and analyze the high-speed digital signal. In this paper, K-means algorithm, which is popular in data mine, is introduced into the eye diagram parameters measurement. By utilizing this algorithm, the proposed method presented in this paper operates with automation and effectiveness. A differential line is measured by vector network analyzer (VNA) and several eye diagrams at different data rates are generated by the measured S parameters. The method is used to measure these eye diagrams. Experiment results show that this method works very well.'}\n","{'text': 'This study introduces a novel approach for classifying and recognizing images of grape leaf disease using a 2-Level Simplified Fuzzy ARTMAP (2L-SFAM). The 2L-SFAM has been developed to extend the Simplified-Fuzzy ARTMAP (SFAM) to make it more suitable in particular applications. This proposed 2L-SFAM network uses multi - vigilance parameters which can be applied for classifying on data with 2 different patterns within the same category, for example grape diseases with multiple stages of each disease. Both color imagery and gray level co-occurrence matrix (GLCM) are used to classify the data attributes. Moreover, the Self-Organizing Feature Map (SOFM) is applied to extract the disease region of grape leaves. The classification and recognition of grape leaf disease area are performed by 2L-SF AM. The main advantage of the 2L-SF AM is its ability to learn brand new categories of data without retraining the entire network and incrementally update the learned category data, which can significantly reduce the time for learning and classifying effectively. The results demonstrate that the proposed algorithm shows excellent accuracy, and the 2L-SF AM can efficiently classify and recognize different diseases of grape leaf based on their stages.'}\n","{'text': 'In this paper, we introduce a 3D convolutional neural network (CNN)-based method to segment point clouds obtained by mobile laser scanning (MLS) sensors into nine different semantic classes, which can be used for high definition city map generation. The main purpose of semantic point labeling is to provide a detailed and reliable background map for self-driving vehicles (SDV), which indicates the roads and various landmark objects for navigation and decision support of SDVs. Our approach considers several practical aspects of raw MLS sensor data processing, including the presence of diverse urban objects, varying point density, and strong measurement noise of phantom effects caused by objects moving concurrently with the scanning platform. We also provide a new manually annotated MLS benchmark set called SZTAKI CityMLS, which is used to evaluate the proposed approach, and to compare our solution to various reference techniques proposed for semantic point cloud segmentation. Apart from point level validation we also present a case study on Lidar-based accurate self-localization of SDVs in the segmented MLS map.'}\n","{'text': 'Machine Readable Codes have been used for several purposes. Approaches like UPC and QR Code can be seen everywhere. Recently, it has emerged a new MRC able to combine the communication power of classical methods to a meaningful improvement on aesthetics and data capacity. This method is named Graphic Code. Although it has been used in previous researches, this name was firstly used publicly at Security Document World Conference and Exhibition, 2018. Graphic Code has two major advantages over classical MRCs: aesthetics and larger coding capacity. It opens new possibilities for several purposes such as identification, tracking (using a specific border), and transferring of content to the application. This paper focuses on presenting how graphic code can be used for industry applications, emphasizing its uses on Augmented Reality (AR). In the first context, it is still being used for creating labels and validation stamps. In the second one, it can be used as a marker (identification and tracking), and to code parameters for an AR application such as large texts, meshes of a 3D model, an image, a drawing, or other complex controls.'}\n","{'text': \"The fault diagnosis of the gearbox is a complex and important work. In this paper, a multilayer gated recurrent unit (MGRU) method is proposed for spur gear fault diagnosis, that is, three-layer gated recurrent unit (GRU). The vibration signals are firstly monitored on the test bench, and then extracted in both time domain and time-frequency domain. Finally, MGRU is used to learn representation and classification. The MGRU can improve the representation of information and identify the features of fault types more precisely with the increasing number of layers. The proposed method was tested by two spur gears with 10 state modes. To evaluate the method's classification accuracy, four methods were utilized for comparison, i.e., the GRU, long short-term memory (LSTM), multilayer LSTM (MLSTM), and support vector machine (SVM), respectively. In addition, the separability and robustness analysis are also discussed for the proposed MGRU performance. All of the results exhibited that the proposed MGRU approach is effective for spur gear fault diagnosis.\"}\n","{'text': 'This standard covers the rating structure for high-voltage circuit breakers, which include all voltage ratings above 1000 V ac and both indoor and outdoor types. Preferred ratings are also provided. Typical circuit breakers covered by these standards have maximum voltage ratings ranging from 4.76 kV through 800 kV, and continuous current ratings of 600 A, 1200 A, 2000 A, 3000 A, and 4000 A associated with the various maximum voltage ratings. The rating structure establishes the basis for all assigned ratings, including continuous current, insulation capability (formerly dielectric withstand voltages), short-circuit current, transient recovery voltage, and capacitor switching, plus associated capabilities such as mechanical endurance, load current, and out-of-phase switching. It is important to note that generator circuit breakers are subject to regulations covered in IEC/IEEE Std 62271-37-013.'}\n","{'text': 'In this paper, we propose a novel singing-voice enhancement system that makes the singing voice of amateurs similar to that of professional opera singers, where the singing voice of amateurs is emphasized by using a singing voice of a professional opera singer on a frequency band that represents the remarkable characteristic of the professional singer. Moreover, our proposed singing-voice enhancement based on highway networks is able to convert any song (that a professional opera singer does not sing). As a result of our experiments, the singing voice of the amateur singer at the middle-high frequency range which contains a lot of frequency components that affect glossiness was emphasized while maintaining speaker characteristics.'}\n","{'text': 'Validation of highly automated or autonomous vehicles remains a significant challenge. One of the primary obstacles is the identification of the countless potential situations in which the vehicle must be evaluated. Even when they are completely identified, the full-coverage of all these situations is not possible in real-world tests. Virtual validation however can be used to generate infinitesimally changing cases for testing. The key challenge then becomes the collection and description of practical test scenarios. This paper proposes an end-to-end approach for scenario generation using various sources. A flexible database structure enables fast and efficient querying that is used to generate an extensive set of test cases. The proposed schema is evaluated end-to-end-from scenario to test case generation to automated simulation and data gathering-populated by a data source based on the experience gained through real world tests. This approach is an additional step towards efficient testing of autonomous functions.'}\n","{'text': \"To Design and develop a low cost real-time monitoring, alert to workers, notified data of polluted area has been checked for the immediate surroundings. A various parameter such as Air Quality, Temperature & Humidity, and Sound intensity sensors with PIC controller which collects and upload data into the cloud using ESP8266 Wi-Fi module. Then transmit to the cloud platform using MQTT protocol to perform Digital Dashboard on Smartphone checks anomaly notification and alert to the user through a web page. If the industry doesn't take any step to reduce the pollution within a certain period, the pollution control board will shut down the industrial electricity power until they pay a penalty amount of polluting the city according to the government rules and regulation.\"}\n","{'text': \"The prospects of achieving a trillion connected internet of things (IoT) devices by 2020 has created the urgency for effective intrusion detection systems (IDS) for these devices. Although it has been argued that the most effective technique used in such systems is anomaly detection, there exist no mechanisms to determine their performance in real-life deployment. In this paper, we report the results of applying asymptotic analysis to evaluate the performance of an anomaly detection algorithm which is designed using logic reasoning through fuzzy logic methodologies. In order to achieve this, the IDS was included as part of intrusion detection software for ZigBee Wireless Sensor Networks (WSNs). In particular, the solution is targeted to address the ZigBee protocol's vulnerability to flood attacks during node discovery and association to the network. The intrusion detection software is hosted external to the WSNs in pursue of a light solution mindful of resource preservation in sensor nodes.\"}\n","{'text': 'Analysis and interpretation of stained histopathology sections is one of the main tools in cancer diagnosis and prognosis. In addition to the information which is typically extracted by trained pathologists, there is also information that is not yet exploited, simply because we do not yet understand the impact of all cellular and tissular features that could be predictive of outcome. In this paper, we address a question that can currently not be solved by pathologists: the prediction of treatment efficiency for Triple Negative Breast Cancer (TNBC) patients from biopsy data.'}\n","{'text': 'Community detection has become a hot topic in complex networks. It plays an important role in information recommendation and public opinion control. Bipartite network, as a special complex network, reflects the characteristics of a kind of network in our life truly and objectively. Therefore, detecting community structure in bipartite networks is of great significance and has practical value. In this paper, we first introduce two concepts: a) a micro-bipartite network model Bi-EgoNet which can be used to analyze bipartite network from a micro view to reduce the complexity of structure in bipartite networks, and b) a complete bipartite graph that is a special bipartite graph with the indivisible property. Then, we propose a novel overlapping community detection algorithm based on a complete bipartite graph in micro-bipartite network Bi-EgoNet (CBG&BEN), which combines advantages of both a complete bipartite graph and Bi-EgoNet to get an optimal community structure. The CBG&BEN is evaluated on accuracy and effectiveness in several synthetic and real-world bipartite networks. The CBG&BEN is compared with other excellent existing algorithms, and our experimental results demonstrated that CBG&BEN is better at detecting overlapping community structure in bipartite networks.'}\n","{'text': 'The roughness of surface walls, a source of additional and often significant path loss, can play an important role in the accurate modeling of wave propagation in tunnel environments. Despite the long history of tunnel propagation studies, the relevant literature on accounting for surface roughness is rather limited. This paper presents a rigorous approach to incorporate surface roughness into vector parabolic equation based models. The validity of the approach is demonstrated through comparisons to experimental data.'}\n","{'text': 'Time series (TSs) are usually represented numerically; however, there are many situations where a linguistic description is preferable. Granular linguistic model of phenomena (GLMP) is a paradigm used in the generation of linguistic descriptions of static situations without considering the temporal relationship of data present, for example, in TSs. This paper presents a new method to generate linguistic descriptions of TSs with an operation similar to petri nets (PNs) and inspired by GLMP. The presented approach maintains the operation of PNs, adding a mechanism to generate linguistic descriptions based on GLMP. The main components of GLMP are added to places and transitions of PNs. This extension is called linguistic PNs (LPNs) and is a language that can be used to generate linguistic descriptions of systems. GLMP is a method that can be used by experts to design how the linguistic descriptions are synthesized and generated. So, LPNs also allow incorporating expert knowledge and combining descriptions in an appropriate way. The experimental part is focused on showing how LPNs can be used to linguistically describe TSs, including the occurrence of maxima or minima, and trends.'}\n","{'text': 'In response to the escalating air pollution problem, monitoring air quality has become an increasingly important area of focus in both academic research and practical applications. In this paper, we present the implementation and optimization of our own air quality sensing system, which provides real-time and fine-grained air quality map of the monitored area. The objective of our optimization problem is to minimize the average joint error of the established real-time air quality map, which involves data inference for the unmeasured data values. To tackle this challenge, a deep Q-learning solution has been proposed for power control to effectively plan the sensing tasks of the power-limited sensing devices online. A genetic algorithm has been designed for the location selection problem to efficiently find the suitable locations to deploy a limited number of sensing devices. Simulation results demonstrate that the proposed solutions significantly improve system performance.'}\n","{'text': 'This paper deals with a PV array fed water pumping system operated by a mechanical sensorless induction motor drive. The recurrence of PV power outage causes the disturbance in water pumping. One possible solution is to use a utility grid as a backup source. The power is delivered by the grid in case the PV array is unable to meet the required power demand. A current multiplier approach is developed for unidirectional power flow control through a power factor improved boost converter. The utilization of reduced number of sensors makes the system cheap. The proposed system enables a consumer to get a rated quantity of water regardless of duration or the climatic condition. Simulated and test results justify the suitability of the system under different operating conditions.'}\n","{'text': 'Archwire bending is an important step of orthodontic treatment as the bending accuracy would directly affect the treatment outcomes. In the process of archwire bending using a robot, parameter extraction of archwire is needed for both online feedback of bending control and offline validation of bending results. This study developed a vision inspection method for the parameter extraction of orthodontic archwire. The method uses a single camera to capture an image of the archwire. The image is processed to extract the locations of bending points, and bending parameters are then calculated automatically from the image. Experimental results validated that the developed method is effective to accurately extract the parameters of archwire.'}\n","{'text': 'Millions of alarms in the optical layer may appear in optical transport networks every month, which brings great challenges to network operation, administration and maintenance. In this paper, we deal with this problem and propose a method of alarm pre-processing and correlation analysis for this network. During the alarm pre-processing, we use the method of combined time series segmentation and time sliding window to extract the alarm transactions, and then we use the algorithm of combined $K$ -means and back propagation neural network to evaluate the alarm importance quantitatively. During the alarm correlation analysis, we modify a classic rule mining algorithm, i.e., Apriori algorithm, into a Weighted Apriori to find the high-frequency chain alarm sets among the alarm transactions. Through the actual alarm data from the record in the optical layer of a provincial backbone of China Telecom, we conducted experiments and the results show that our method is able to perform effectively the alarm compressing, alarm correlating, and chain alarm mining. By parameter adjustment, the alarm compression rate is able to vary from 60% to 90% and the average fidelity of chain alarm mining keeps around 84%. The results show our approach and method is promising for trivial alarm identifying, chain alarm mining, and root fault locating in existing optical networks.'}\n","{'text': 'Effective storage, processing and analyzing of power device condition monitoring data faces enormous challenges. A framework is proposed that can support both MapReduce and Graph for massive monitoring data analysis at the same time based on Aliyun DTplus platform. First, power device condition monitoring data storage based on MaxCompute table and parallel permutation entropy feature extraction based on MaxCompute MapReduce are designed and implemented on DTplus platform. Then, Graph based k-means algorithm is implemented and used for massive condition monitoring data clustering analysis. Finally, performance tests are performed to compare the execution time between serial program and parallel program. Performance is analyzed from CPU cores consumption, memory utilization and parallel granularity. Experimental results show that the designed framework and parallel algorithms can efficiently process massive power device condition monitoring data.'}\n","{'text': 'This paper gives a co-dynamic simulation of a permanent magnet synchronous generator (PMSG)-based wind turbine implemented on field programmable gate array (FPGA) board. The proposed wind energy conversion system (WECS) includes the wind turbine model, pitch angle and maximum power point tracking (MPPT) controllers, generator model, and the control schemes of power converters for the machine and grid sides. The use of FPGA as a computational board offers a significant high simulation speed comparing to a typical computer, especially for a parallelized operations.'}\n","{'text': 'Breast cancer is now considered as one of the leading causes of deaths among women all over the world. Aiming to assist clinicians in improving the accuracy of diagnostic decisions, computer-aided diagnosis (CAD) system is of increasing interest in breast cancer detection and analysis nowadays. In this paper, a novel computer-aided diagnosis scheme with human-in-the-loop is proposed to help clinicians identify the benign and malignant breast tumors in ultrasound. In this framework, feature acquisition is performed by a user-participated feature scoring scheme that is based on Breast Imaging Reporting and Data System (BI-RADS) lexicon and experience of doctors. Biclustering mining is then used as a useful tool to discover the column consistency patterns on the training data. The patterns frequently appearing in the tumors with the same label can be regarded as a potential diagnostic rule. Subsequently, the diagnostic rules are utilized to construct component classifiers of the Adaboost algorithm via a novel rules combination strategy which resolves the problem of classification in different feature spaces (PC-DFS). Finally, the AdaBoost learning is performed to discover effective combinations and integrate them into a strong classifier. The proposed approach has been validated using a large ultrasounic dataset of 1,062 breast tumor instances (including 418 benign cases and 644 malignant cases) and its performance was compared with several conventional approaches. The experimental results show that the proposed method yielded the best prediction performance, indicating a good potential in clinical applications.'}\n","{'text': \"This paper presents the research methodology to develop neuro-fuzzy logic expert advising system, starting from determining the sample size and potential instruments to the development of integrated use of personality model and crowd-vote in recommending university program. This research is conducted using qualitative and quantitative methods, including experiment analysis, interview and neural network training. Questionnaire survey is also included along with the experiment analysis in series of research investigation. Starting from the semi-structured interviews with advisors and introducers from four different universities in Kuala Lumpur, Malaysia, questionnaire survey is then conducted to analyze the results statistically on influential factors, advising system practice and students' personality, relatively in six different universities. From these results, the development of neuro-fuzzy logic is implemented, which requires some methods to be performed for system evaluation. Rules are developed to create classification in fuzzy logic toolbox, in which they are used in a web-based prototype developed using Microsoft Visual Studio 2017 incorporated with SQL 2014. Neural network toolbox is chosen to generate multi-layer hidden neurons that are involved in evaluation that would be significantly useful on neural network training and system testing.\"}\n","{'text': 'Small bowel mucosa segmentation plays an important role in the characterization of frames in videos of endoscopic capsules. This technique involves the precise separation of small bowel mucosa from adjacent structures in video frames captured by wireless endoscopes. Image segmentation techniques have been utilized to improve the accuracy of small bowel mucosa segmentation. The training of deep learning models has also shown promising results in this area, allowing for automated and efficient segmentation of the small bowel mucosa in endoscopic capsule videos. Additionally, wireless communication and decoding protocols have been developed to ensure timely and accurate transmission of video frames for analysis. The combination of these techniques and advancements in the field of small bowel mucosa segmentation will continue to drive improvements in understanding and diagnosis of gastrointestinal diseases.'}\n","{'text': 'This paper proposes an Adaptive Null Steering Circular Parallel Plate Capacitor Array Antenna (ANSCPPCAA) that can adaptively control the antenna radiation patterns and reduce interference. This antenna uses adaptive arrays and is equipped with parallel plate capacitors to achieve null steering and improve the directivity of the antenna. The proposed antenna is optimized through genetic algorithms to improve its performance. The use of this antenna offers several advantages over traditional directive antennas, such as more flexibility in beam shaping and better adaptability to complex interference environments. In addition, the ANSCPPCAA also provides a cost-effective solution as it does not require complex and costly external components. The results of the simulations show that this antenna has excellent radiation pattern characteristics, high directivity, and efficient null steering capabilities, making it a promising candidate for various wireless communication applications.'}\n","{'text': 'Currently there are many elderly people who have walking problems. This paper aims to develop and solve these problems by introducing walking assistance system which can recognize 3 types of gestures, include walking, sitting and standing. Our system is divided into 3 main parts including Feature extraction which consists of Time domain and Frequency domain, Classification and Exoskeleton suit system. Conjugate Gradient Backpropagation Neural Network is used to classify sEMG signal of lower limb posture after extracted the features. Then the output of classification is used to command the Exoskeleton suit to perform the gesture according to the results of the recognition. In addition, our paper uses PID controller to control DC motor of Four Bar Linkages Mechanisms of Lower Limb Exoskeleton suit in order to reduce the number of motors and increase stability during the Stance Phase. The results from the experiment have concluded that all feature in time domain has the most recognition rate which up to 99.39%.'}\n","{'text': 'This paper discusses the research on classification and recognition of driving styles based on feature engineering. Vehicles, roads, and acceleration are the primary focus of analysis in this study, with support vector machines, hidden Markov models, classification algorithms, and data mining serving as the main methodologies. With the prevalence of the Internet of Things and the rise of autonomous and self-driving cars, understanding driving styles is becoming increasingly important for road safety and traffic management. Through feature engineering, this research aims to identify and classify driving styles based on vehicle data and road conditions. The results of this study can be used to improve traffic safety, predict potential accidents, and enhance transportation and traffic management.'}\n","{'text': 'Just noticeable difference (JND) for stereoscopic 3D content reflects the maximum tolerable distortion; it corresponds to the visibility threshold of the asymmetric distortions in the left and right contents. The 3D-JND models can be used to improve the efficiency of the 3D compression or the 3D quality assessment. Compared to 2D-JND models, the 3D-JND models appeared recently and the related literature is rather limited. In this paper, we give a deep and comprehensive study of the pixel-based 3D-JND models. To our best knowledge, this is the first review on 3D-JND models. Each model is briefly described by giving its rationale and main components in addition to providing exhaustive information about the targeted application, the pros, and cons. Moreover, we present the characteristics of the human visual system presented in these models. In addition, we analyze and compare the 3D-JND models thoroughly using qualitative and quantitative performance evaluation based on Middlebury stereo datasets. Besides, we measure the JND thresholds of the asymmetric distortion based on psychophysical experiments and compare these experimental results to the estimates from the 3D-JND models in order to evaluate the accuracy of each model.'}\n","{'text': 'The memory physics induced unknown offset of the channel is a critical and difficult issue to be tackled for many non-volatile memories (NVMs). In this paper, we first propose novel neural network (NN) detectors by using the multilayer perceptron (MLP) network and the recurrent neural network (RNN), which can effectively tackle the unknown offset of the channel. However, compared with the conventional threshold detector, the NN detectors will incur a significant delay of the read latency and more power consumption. To address this issue, we further propose a novel dynamic threshold detector (DTD) that derives its detection threshold based on the outputs of the proposed NN detectors. This approach enables the NN-based detection to only be invoked when the error correction code (ECC) decoder fails or periodically when the system is in the idle state. Thereafter, the threshold detector will still be adopted by using the adjusted detection threshold derived base on the outputs of the NN detector, until a further adjustment of the detection threshold is needed. Results obtained from simulations show that the proposed DTD based on RNN detection achieves error performance comparable to that of the optimum detector even without prior knowledge of the channel.'}\n","{'text': 'Nowadays, proactive error prediction, using ma-chine learning methods, has been proposed to improve storage system reliability by increasing the scrubbing rate for drives with higher error rates. Unfortunately, the majority of works incur non-trivial scrubbing cost and ignore the periodic characteristic of scrubbing. In this paper, we aim to make the prediction guided scrubbing more suitable for practical use. In particular, we design a scrub unleveling technique that enforces a lower rate scrubbing to healthy disks and a higher rate scrubbing to disks subject to latent sector errors (LSEs). Moreover, a voting-based method is introduced to ensure prediction accuracy. Experimental results on a real-world field dataset have demonstrated that our proposed approach can achieve lower scrubbing cost together with higher data reliability than traditional fixed-rate scrubbing methods. Compared with the state-of-the-art, our method can achieve the same level of Mean-Time-To-Detection (MTTD) with almost 32% less scrubbing.'}\n","{'text': \"Networking is one of the key enablers of cloud computing and its security is essential for multi-tenant clouds. As a widely used open source solution to cloud computing, OpenStack allows computing resources to connect to the physical network infrastructure through provider networks for performance and reliability considerations. However, OpenStack users are stuck with either VLAN provider networks that are complex to configure and manage or flat networks that are not isolated and have the limitation on interface multiplexing. To address this problem, in this paper, we propose a new mechanism called Isoflat, which extends OpenStack's ability for creating flat provider networks with both configuration simplicity and flexible isolation capability. Our evaluation results show that a provider network with Isoflat can achieve similar network performance as a flat or VLAN provider network. Our results also show that the Isoflat firewall has much less impact on throughput performance than security group.\"}\n","{'text': 'Simultaneously determining the 3-dimensional (3-D) position and orientation of a rigid object is termed rigid body localization (RBL). The RBL has potential applications in the systems of virtual reality, spacecraft docking, and so on. In this letter, a new RBL scheme based on Direction of Arrival (DoA) measurements is proposed, which needs only a single base station (BS) and has no requirement for time synchronization between the target of interest and BS. For determining the position and orientation, the rigid object of interest has wireless sensors mounted on its surface, which are distributed with known topology. We first build a geometrical model fusing the measured DoAs from the wireless sensors and their known topology to determine the 3-D coordinates of these sensors. Then, using the obtained coordinate information, we achieve the RBL via rigid body transform methodologies. The constrained Cramer-Rao bound is derived to evaluate the performance of the developed method with respect to the DoA noise level and rigid body size.'}\n","{'text': 'This paper proposes a robust scheme for optimizing the power flow in a photovoltaic system. The scheme utilizes distributed saddle point dynamics and a decentralized approach to solve the power flow problem. It converts the convex optimization problem of the dynamic system control into the asymptotically stable dynamic systems and employs a linear approximation of power flow equations; specifically, a quadratic programming model is deployed with the aim of minimizing real-power losses to guarantee a globally optimal solution. Then, the photovoltaic inverters and electric networks are analyzed independently in a decentralized manner to exchange injection power among nodes while maintaining their independence to support the plug-and-play feature. A case study and the experimental results show that the proposed scheme achieves higher optimization accuracy and are more economical than the existing state-of-the-art schemes.'}\n","{'text': 'This paper presents a study on collaborative affective computing by exploring the concept of ambiance signal processing. The aim is to better understand human emotions through computational modeling and intelligent sensors. The focus is on emotion recognition, with special attention paid to brain modeling as this is seen as a key factor in understanding the emotions of others. The field of affective computing is an emerging area, and this paper makes a valuable contribution to the literature by providing insights into how collaborative efforts can be used to achieve greater understanding of the human emotional experience. In particular, the use of mice as a model for studying emotions is discussed, and the potential benefits of this approach are highlighted. Overall, this paper provides a valuable foundation for future research in the field of affective computing, and demonstrates the potential for collaborative efforts to unlock important insights into the nature of human emotions.'}\n","{'text': \"New information and communication technologies have contributed to the development of the smart city concept. On a physical level, this paradigm is characterized by deploying a substantial number of different devices that can sense their surroundings and generate a large amount of data. The most typical case is image and video acquisition sensors. Recently, these types of sensors are found in abundance in urban spaces and are responsible for producing a large volume of multimedia data. The advanced computer vision methods for this type of multimedia information means that many aspects can be dynamically monitored, which can help implement value-added applications in the city. However, obtaining more elaborate semantic information from these data poses significant challenges related to a large amount of data generated and the processing capabilities required. This paper aims to address these issues by using a combination of cloud computing technologies and mobile computing techniques to design a three-layer distributed architecture for intensive urban computing. The approach consists of distributing the processing tasks among a city's multimedia acquisition devices, a middle computing layer, known as a cloudlet, and a cloud-computing infrastructure. As a result, each part of the architecture can now focus on a small number of tasks for which they are specially designed, and data transmission communication needs are significantly reduced. To this end, the cloud server can hold and centralize the multimedia analysis of the processed results from the lower layers. Finally, a case study on smart lighting is described to illustrate the benefits of using the proposed model in smart city environments.\"}\n","{'text': 'The integration of wearable wireless devices and cloud computing has greatly enhanced the effectiveness and accessibility of e-health systems. Patients can upload their personal health information (PHI) files to the cloud, from where the health service providers (HSPs) can obtain appropriate information to determine the health state. This system not only reduces the costs associated to healthcare but also provides timely diagnosis to save lives. However, a number of privacy concerns arise while sharing sensitive information. In this study, we suggest a unique privacy-preserving patient health information sharing scheme that facilitates secure and efficient access to PHI files by HSPs. We have introduced the searchable encryption technique with keyword range search and multikeyword search to ensure data protection. Moreover, the proposed privacy-preserving equality test protocol enables various numeric comparison searches on encrypted data. We also use a variant of bloom filter and message authentication code to classify PHI files, filter false data, and check integrity of search results. The simulations on real-world and synthetic data show the feasibility and efficiency of the system, and security analysis proves the privacy-preservation properties.'}\n","{'text': 'This special issue explores the challenges posed by the design of very-large-scale integration (VLSI) nodes for the Internet-of-Things (IoT) systems. These systems use wireless communication to link together physical devices into distributed real-time embedded systems. IoT systems are used in a wide range of applications, including industrial control, vehicles, smart grids, and medical and health care systems.'}\n","{'text': 'Lung volume segmentation is a key step in the design of Computer-Aided Diagnosis systems for automated lung pathology analysis. However, isolating the lung from CT volumes can be a challenging process due to considerable deformations and the potential presence of pathologies. Convolutional Neural Networks (CNN) are effective tools for modeling the spatial relationship between lung voxels. Unfortunately, they typically require large quantities of annotated data, and manually delineating the lung from volumetric CT scans can be a cumbersome process. We propose to train a 3D CNN to solve this task based on semi-automatically generated annotations. For this, we introduce an extension of the well-known V-Net architecture that can handle higher-dimensional input data. Even if the training set labels are noisy and contain errors, our experiments show that it is possible to learn to accurately segment the lung relying on them. Numerical comparisons on an external test set containing lung segmentations provided by a medical expert demonstrate that the proposed model generalizes well to new data, reaching an average 98.7% Dice coefficient. The proposed approach results in a superior performance with respect to the standard V-Net model, particularly on the lung boundary.'}\n","{'text': \"This paper proposes a Spatial-Temporal Visual Attention Model for Video Quality Assessment. The model leverages computational modeling and optical imaging to assess video quality by taking into account the viewer's attention patterns over time and space. By analyzing the viewer's visual attention in real-time, the proposed model identifies any potential optical distortions and indexes them against the original video. This approach offers a more accurate method of video quality assessment, especially in instances where conventional methods are insufficient due to issues such as observer bias or a lack of quality metrics. With the increasing popularity of video recording and visualization in various fields, the need for reliable quality assessment models is paramount. The proposed Spatial-Temporal Visual Attention Model thus provides a solution that can be adapted to different scenarios, thereby improving video quality assessment for a broad range of applications.\"}\n","{'text': 'In-band full-duplex wireless communication systems have received considerable attention because of their potential to double the capacity of existing wireless networks. However, one of the biggest challenges in achieving this goal is the residual self-interference (RSI) which occurs when the transmitted signal leaks into the receiving antenna. To address this problem, interference cancellation and channel estimation techniques have been proposed. In addition, radio frequency (RF) impairments such as phase noise can further degrade the performance of these systems. In this paper, the authors investigate the distribution of the RSI power in in-band full-duplex wireless systems. They propose a Monte Carlo method to model the RSI power distribution and analyze the impact of phase noise on the system performance. The simulation results show that the proposed method accurately captures the behavior of the RSI power distribution and can be used for evaluating the performance of in-band full-duplex wireless systems under different RF impairments. This work has important implications for the design and optimization of future wireless communication systems.'}\n","{'text': 'This paper focuses on the development of a scalable tattoo image search system that utilizes joint detection and compact representation learning. Specifically, the authors propose a feature extraction method that is able to accurately detect and recognize tattoos in images, particularly those on the face. The potential applications for such a system are vast, ranging from law enforcement and identity verification to image retrieval and task analysis. By improving the accuracy and efficiency of image recognition, this system could have a significant impact on various industries and fields. Overall, the authors highlight the importance of developing effective and scalable image recognition systems in the increasingly digital age.'}\n","{'text': \"Consider a multiplayer game, and assume a system level objective function, which the system wants to optimize, is given. This paper aims at accomplishing this goal via potential game theory when players can only get part of other players' information. The technique is designing a set of local information based utility functions, which guarantee that the designed game is potential, with the system level objective function its potential function. First, the existence of local information based utility functions can be verified by checking whether the corresponding linear equations have a solution. Then an algorithm is proposed to calculate the local information based utility functions when the utility design equations have solutions. Finally, consensus problem of multiagent system is considered to demonstrate the effectiveness of the proposed design procedure.\"}\n","{'text': 'This paper presents a rough set-based approximation method for empirically comparing distances for agglomerative hierarchical clustering. When a set of target is given, a level of clustering tree where one branch includes all the targets can be traced with the number of elements included. The resulting pair consisting of the number of clusters at a certain level and the number of elements in a cluster can be used as indices for comparison.'}\n","{'text': 'Deep learning has successfully shown excellent performance in learning joint representations between different data modalities. Unfortunately, little research focuses on cross-modal correlation learning where temporal structures of different data modalities, such as audio and video, should be taken into account. Music video retrieval by a given musical audio is a natural way to search and interact with music contents. In this work, we study cross-modal music video retrieval in terms of emotion similarity. Particularly, an audio of an arbitrary length is used to retrieve a longer or full-length music video. To this end, we propose a novel audio-visual embedding algorithm by Supervised Deep Canonical Correlation Analysis (S-DCCA) that projects audio and video into a shared space to bridge the semantic gap between audio and video. This also preserves the similarity among audio and visual contents from different videos with the same class label and the temporal structure. The contribution of our approach is mainly manifested in the two aspects: i) We propose to select top k audio chunks by attention-based Long Short-Term Memory (LSTM) model, which can represent good audio summarization with local properties. ii) We propose an end-to-end deep model for crossmodal audio-visual learning where S-DCCA is trained to learn the semantic correlation between audio and visual modalities. Due to the lack of music video dataset, we construct 10K music video dataset from YouTube 8M dataset. Some promising results such as MAP and precision-recall show that our proposed model can be applied to music video retrieval.'}\n","{'text': 'This paper presents an advanced cooperative positioning algorithm for multiple autonomous underwater vehicles (AUVs) that combines the improved factor graph and sum-product theory. By using a combination of signals from various sensors such as compass and velocity measurements, the algorithm is able to estimate the location of each AUV with greater accuracy. Traditional Kalman filters often assume a linear relationship between sensors and measurements, but the improved factor graph algorithm takes into account non-linearity in sensor measurements to improve the estimation. The use of sum-product theory also allows for efficient calculation of position estimates. Simulation results demonstrate that the proposed algorithm significantly reduces position error compared to traditional methods, making it a promising solution for improving navigation capabilities of multiple AUVs.'}\n","{'text': 'Short-term electricity demand or load forecasting is the way of estimating future demand for short time horizon, an hour to one week ahead. Short horizon forecasting helps to maintain secure power system, avoids blackout risk and provides adequate electricity supply. Therefore, accurate forecasting is prime concern for day to day planing and ensuring the stability of electricity system. Many literature show their mean absolute percentage error (MAPE) for short term load forecasting as less than 2%, which is very competitive performance. The methodology behind good performance is that the model should address the driving factors that effect electricity load and employs appropriate estimation techniques. In our work, multiple linear regression model are developed and Bayesian estimation technique is used. Assuming historical load, temperature, daily, and weekly seasonal patterns as the main effecting factors for electricity load consumption, two models Model A, and Model B are constructed. Model A consist historical load and deterministic terms. However, model B consist all variables of Model A plus temperature variables. These models are analyzed based on their forecasting performance for three years out of sample prediction. Our results showed that when temperature variable is included in model, it can improve the overall performance at least by 20%. Performance improvement was higher during morning and evening hours than day hours. Interestingly, evening hours (17 to 22) are statistically not significant.'}\n","{'text': 'Deep learning exploits large volumes of labeled data to learn powerful models. When the target dataset is small, it is a common practice to perform transfer learning using pretrained models to learn new task specific representations. However, pretrained CNNs for image recognition are provided with limited information about the image during training, which is label alone. Tasks such as scene retrieval suffer from features learned from this weak supervision and require stronger supervision to better understand the contents of the image. In this paper, we exploit the features learned from caption generating models to learn novel task specific image representations. In particular, we consider the state-of-the-art captioning system Show and Tell [1] and the dense region description model DenseCap [2]. We demonstrate that, owing to richer supervision provided during the process of training, the features learned by the captioning system perform better than those of CNNs. Further, we train a siamese network with a modified pair-wise loss to fuse the features learned by [1] and [2] and learn image representations suitable for retrieval. Experiments show that the proposed fusion exploits the complementary nature of the individual features and yields state-of-the art retrieval results on benchmark datasets.'}\n","{'text': 'In this paper, we propose a deep instance segmentation method for teeth in panoramic X-ray images in the field of dentistry. Our approach is based on a combination of image segmentation, X-ray imaging, training, image restoration, and feature extraction. We present a novel architecture for deep learning that uses a joint segmentation and detection scheme to accurately identify individual teeth in panoramic X-ray images. We also propose a feature extraction method based on a convolutional neural network (CNN) to help improve the accuracy of the segmentation. Our method achieves state-of-the-art performance on several benchmark datasets, demonstrating its effectiveness in real-world applications. Overall, our work contributes to the development of more reliable and accurate dental diagnosis and treatment.'}\n","{'text': \"In recent years, the identification of fruit flies has become increasingly important for agricultural applications and ecological studies. This paper proposes a deep feature-based classifier for fruit fly identification, focusing on the dipteran family Tephritidae. The proposed approach involves the extraction of features, task analysis, convolution, and machine learning techniques, specifically neural networks. Correlation analysis, using kernel functions, is employed to determine relevant features and improve the classifier's accuracy. The proposed method outperforms existing methods in terms of identification accuracy and robustness, showing a promising path for future fruit fly identification studies.\"}\n","{'text': 'This paper surveys research on the Resource Space Model (RSM). RSM is a multi-dimensional, classification-based, content-based and high-level semantic space model for organizing and managing various resources through multi-dimensional abstraction and specialization. RSM has more powerful resource representation ability than traditional resource management model. It has applications not only in resource management and retrieval, but also in other areas, such as automatic text summarization and question answering system.'}\n","{'text': 'A space-mapping inspired scattering construction method is proposed based on sparse representation for extended targets. Differing from the conventional space mapping technique of which the goal is to optimize the design parameters given an optimization target, the space mapping technique is modified to build a surrogate model by mapping the sparse representation of scattering response from the coarse model and the fine model. A robust and accurate method based on the particle swarm optimization is designed to extract the parameters of the basis function of the sparse representation of both the coarse model and the fine model. After that, a space-mapping optimization is run to extract the mapping matrix between the two sparse models. The simulation result shows that the extracted model not only has a much better accuracy than the conventional asymptotic model but also works effectively over a considerable range of the scatterer parameter space.'}\n","{'text': 'Vibration and acoustics emission based methods are commonly used in condition monitoring and fault diagnosis of rotating machinery. However, condition monitoring of low-speed bearings may be more difficult than that of high-speed bearings due to its low signal-to-noise ratio. A detailed discussion on vibration and acoustic emission based methods implemented in recent years for fault detection and health condition monitoring of low-speed bearings is presented in this paper. The comparison of these two methods is given, and some suggestions and considerations are included as well.'}\n","{'text': \"The article covers the theme of Smart Watches applied to high competition nautical sports, with a focus on the surf market for athletes within the context of competition and training. The underlying surfing competitions are related to the two most known championships from the World Surf League (WSL): World Circuit Tour (WCT) and World Qualifying Series (WQS). At this level of competition, the athlete needs to have a direct communication with the trainer in order to obtain technical guidance or information about his/her performance, including scores obtained during the competition (e.g., wave, competing athletes), technical instructions for correcting maneuvers, urgent messages (e.g., change of board or momentary injuries). The proposed model is extensible to training contexts, where the athlete has to comply with training plans and can receive technical instructions from the coach. The proposed solution was designed for two views: Athlete's view for smartwatch-type equipment and Coach's view for tablet-type equipment. The coach, at land, has the role of an observer of the athlete's performance at sea. The methodology for development of this undergoing research project is based on the Design Science Research Methodology (DSRM) together with the User Centered Design (UCD) and Design Thinking (DT).\"}\n","{'text': 'Real-time systems require timely and predictable scheduling of tasks that are executed by program processors. Many scheduling algorithms have been proposed for various application domains, such as multimedia and control, but challenge remains when it comes to streaming applications modeled as cyclic CSDF graphs. In this paper, we present a scheduling algorithm for hard real-time systems executing streaming applications modeled as cyclic CSDF graphs. Our algorithm uses task analysis to obtain the execution time of tasks and generate schedules that meet the required deadlines. Experimental results show that our algorithm outperforms other state-of-the-art scheduling algorithms in terms of meeting hard real-time constraints while reducing the overall execution time. This research contributes to the field of computational modeling and scheduling algorithms for hard real-time systems executing streaming applications modeled as cyclic CSDF graphs.'}\n","{'text': 'With the development of RGB-D sensors, the highquality color point cloud can be obtained conveniently. Besides the geometrical information of point cloud, the color has great potential to assist the point cloud registration. In this paper, we propose a registration method by adaptively combining with color moment information to improve the registration accuracy. Firstly, three kinds of central moments are used to characterize the color distribution of two point clouds. And then, we build the correspondence between point clouds by dynamically combining the geometric feature and color moment feature of each point, hence the corresponding points satisfy both geometric similarity and color similarity. Finally, for the partial registration problem in practice, we apply the trimmed ICP algorithm framework to calculate the rigid transformation. Experimental results demonstrate that our algorithm is more robust and accurate in dealing with point cloud geometry defects, missing data and poor initial position.'}\n","{'text': 'This paper proposes a novel approach to supporting the momentum training algorithm using a memristor-based synapse in order to improve the training of artificial neural networks. The study explores the use of synapses and neurons to achieve higher levels of convergence and better performance in training. The authors emphasize the importance of hardware support in the training of artificial neural networks and propose the use of memristors as a viable solution. The paper discusses the underlying structure and function of memristors, highlighting their potential as a key component in the development of hardware that emulates biological neural networks. The authors provide evidence to support their claim that memristors can effectively support the momentum training algorithm through simulations and experiments. This study contributes to the ongoing research in neural network development and provides a promising avenue for implementing memristor-based hardware for the training of artificial neural networks.'}\n","{'text': 'Freeform surfaces exist widely in the stock cutting process of clinical prosthesis preparation, aviation, ship, and other manufacturing industries. The free-form contours of surfaces need to be packed before they are machined from raw materials. The existing methods search a contour position by rotating the contour and translating it to connect other contours for packing. The relative position between two contours will be changed after the rotation as the contour description is lack of geometric invariance. These methods easily miss the best layout position resulting in interspaces in the raw material. Moreover, this result seriously reduces the performance and efficiency of an automatic packing system. Therefore, a new packing algorithm is proposed in this paper by combining the geometric invariant description and coding matching for contours to solve the contour rotating and position connecting problems. The optimal position of a contour can be found directly and then connected by the extracted similar complement features of the contour. The experimental results show that the proposed method can greatly improve quality and efficiency of the layout, especially in the material utilization.'}\n","{'text': \"Linear consensus protocol is an iterative distributed algorithm with asymptotic convergence guarantees. This paper develops and analyzes an algorithm for agents running linear consensus iterations to detect convergence to consensus within a specified error tolerance in a distributed manner. The distributed stopping criterion allows for time-varying bounded delays in information transmission and reception between agents. The algorithm relies on distributively determining the maximum and minimum values held by the agents. This paper further develops an algorithm for average consensus that utilizes a distributive stopping criterion, based on maximum and minimum consensus, where no centralized coordination is needed on how each agent weights its neighbor's values. Here, the doubly stochastic assumption on the weight matrix is relaxed and only column stochasticity is needed. The effectiveness of the algorithms is demonstrated by simulations and a comparison with prior work in the literature. Moreover, the demonstration of the proposed algorithms on an experimental test bed of Raspberry-Pi agents communicating wirelessly validates its applicability and utility.\"}\n","{'text': 'This paper presents a novel surface registration technique using the spectrum of the shapes, which can facilitate accurate localization and visualization of non-isometric deformations of the surfaces. In order to register two surfaces, we map both eigenvalues and eigenvectors of the Laplace-Beltrami of the shapes through optimizing an energy function. The function is defined by the integration of a smoothness term to align the eigenvalues and a distance term between the eigenvectors at feature points to align the eigenvectors. The feature points are generated using the static points of certain eigenvectors of the surfaces. By using both the eigenvalues and the eigenvectors on these feature points, the computational efficiency is improved considerably without losing the accuracy in comparison to the approaches that use the eigenvectors for all vertices. In our technique, the variation of the shape is expressed using a scale function defined at each vertex. Consequently, the total energy function to align the two given surfaces can be defined using the linear interpolation of the scale function derivatives. Through the optimization of the energy function, the scale function can be solved and the alignment is achieved. After the alignment, the eigenvectors can be employed to calculate the point-to-point correspondence of the surfaces. Therefore, the proposed method can accurately define the displacement of the vertices. We evaluate our method by conducting experiments on synthetic and real data using hippocampus, heart, and hand models. We also compare our method with non-rigid Iterative Closest Point (ICP) and a similar spectrum-based methods. These experiments demonstrate the advantages and accuracy of our method.'}\n","{'text': \"With the advancement of technology, Internet of Things (IoT) has become a promising field in the world of Electrical Engineering. This research paper proposes a method of integrating IoT with CCTV monitoring by using Raspberry Pi. The aim of this project is to improve the efficiency and effectiveness of security systems in various applications such as homes, businesses, and public spaces. By implementing streaming media, cameras can capture high-quality and real-time footage that can be remotely accessed through the internet. However, delays and throughput issues may arise due to the limitation of the device's hardware. Thus, this project investigates the potential of Raspberry Pi in overcoming these challenges, as well as its reliability and cost-effectiveness when compared to traditional CCTV monitoring systems. Overall, this project presents a practical approach to improve the security systems by integrating IoT technology, and can be utilized in various applications for better monitoring and control.\"}\n","{'text': 'Fifth generation (5G) core network is serviceoriented. To build upon this approach, we propose a service-oriented radio access network (RAN) that focuses on the handover process. By designing small-sized Next Generation Application Protocol (NGAP) functions as services that are easily testable and debuggable, handover control can be exposed as a service. In order to achieve this, we define service resources and their corresponding methods using the Representational State Transfer (REST) style. In addition, we model the handover state as seen by the core network, source, and target radio nodes. These models are formally described, and it is proven that they expose equivalent behavior. The models are formally described and it is proved that they expose equivalent behavior.'}\n","{'text': 'In this study, we develop a nonlinear mixed modeling for the luminance degradation of flexible OLED, enabling precise lifetime prediction even with a limited data obtained from 48h of aging tests. A 4-parameter exponential model is employed, and its parameter is estimated by NLME (nonlinear mixed effect model)and NLS (nonlinear least square)method respectively. Considering time-dependent random behaviors of an emissive layer deterioration, NLME is better fitted to empirical data set than NLS and stretched exponential decay (SED), examined by the goodness-of-fit test. In fact, NLME method provides a precise lifetime prediction within of the mean absolute error percentage for the estimation of long-term reliability at 1,000h, which is benefit for technical feasibility judgement particularly with fast turnaround feedback in the earlier stage development.'}\n","{'text': 'Traditional recognitions of the MNIST hand-written-digits need vast amounts of datasets to assure high accuracy based on artificial neural networks (ANNs). In this paper, we present a simple preprocessing method for image classification. Firstly, the image pixels are converted into spike streams by using the Poisson distribution method. Similar as the integration of synaptic current in brain, spike or binary streams are integrated into continuous signals which are used to feed into the input layer of the conceptor network. The conceptor network is a recurrent neural network used to generate high-dimensional dynamic information. We use the MNIST database to investigate the computational performance of this model. Our results show that this method can achieve high recognition accuracy with much smaller training samples (6000 in this model V.S. 60000 in traditional other methods). Note that in this model, information for each image is decoded into a continuous sequence and fully analyzed through the conceptor network. Therefore, the number of training samples can be remarkably reduced.'}\n","{'text': 'This paper proposes a methodology for identifying groups based on spatio-temporal semantic trajectory mining. The research focuses on the integration of semantics and trajectories for better accuracy in clustering algorithms. The methodology employs data mining techniques such as inference algorithms and indexes to facilitate efficient data analysis. The proposed approach is applicable to various domains such as transportation, healthcare and social networks. Our results show that our methodology outperforms existing trajectory clustering algorithms in terms of accuracy and scalability, making it a promising tool for group identification in large-scale datasets.'}\n","{'text': \"Sudden start of an IM load and frequent change of nonlinear load in a standalone distributed generation system (DGS) cause the dip in ac voltage and frequency. Moreover, these loads distort DGS currents. Hence, this paper proposes an improved-reweighted zero-attracting quaternion-valued least mean square (I-RZA-LMS) based voltage source converter (VSG) control to regulate voltage and frequency, and improve power quality in DGS systems. Moreover, the control algorithm of dcâ\\x80\\x93dc bidirectional converter (BDC) is used for dc link voltage regulation and MPPT of the solar photovoltaic array at IM starting and nonlinear loading. In this DGS system, the I-RZA-LMS-based control algorithm estimates the active and reactive component currents of distorted load currents, facilitating effective harmonics mitigation, reactive power compensation, and regulation of point of common coupling voltages. The proposed control algorithm rejects the dc-offset component from load currents and gives the fundamental load component. The BDC regulates the DC link voltage of VSC using a solar feedforward term, enhancing the DC link voltage control capability under solar power variation, IM starting, and unbalanced loading. Through simulations and experiments on a developed prototype of DGS, the proposed system's effectiveness is validated.\"}\n","{'text': 'With the development of the Internet of Things (IoT) technology, its application in the medical field becomes more and more extensive. However, with a dramatic increase in medical data obtained from the IoT-based health service system, labeling a large number of medical data requires high cost and relevant domain knowledge. Therefore, how to use a small number of labeled medical data reasonably to build an efficient and high-quality clinical decision support model in the IoT-based platform has been an urgent research topic. In this paper, we propose a novel semi-supervised learning approach in association with generative adversarial networks (GANs) for supporting clinical decision making in the IoT-based health service system. In our approach, GAN is adopted to not only increase the number of labeled data but also to compensate the imbalanced labeled classes with additional artificial data in order to improve the semi-supervised learning performance. Extensive evaluations on a collection of benchmarks and real-world medical datasets show that the proposed technique outperforms the others and provides a potential solution for practical applications.'}\n","{'text': 'This paper proposes a DDoS attack detection scheme based on the combination of entropy and PSO-BP neural network in an SDN environment. The scheme is aimed at detecting and mitigating the threats of computer crimes such as DDoS attacks in IP networks. The proposed scheme uses entropy to reduce the dimension of feature extraction and PSO-BP neural network to classify malicious and benign traffic. The switches deployed in the SDN environment are used for monitoring the network and forwarding packets to the controller for analysis. The feature vectors are extracted from the monitoring data and are then processed by the proposed scheme to detect the potential DDoS attacks. The results of the experiments on a simulated environment show that the proposed scheme is effective in detecting DDoS attacks in a timely and accurate manner. The use of entropy reduces the time and complexity of feature extraction, and the PSO-BP neural network enhances the accuracy and robustness of the detection system. Overall, the proposed scheme provides a promising solution for detecting DDoS attacks in SDN environments.'}\n","{'text': 'With the rise of social media, Twitter has become a popular platform for communication and information sharing. However, the sheer volume of tweets generated can be overwhelming, making it difficult to process and analyze the data. The emergence of big data has highlighted the need for efficient tools to handle and analyze such voluminous data. In this paper, we propose a method for handling voluminous tweets and analyzing the sentiment of tweets using biological neural networks. We apply sentiment analysis techniques to the tweets and use a communication system to transfer the data to a biological neural network for processing. The results show that our method is effective in handling large volumes of tweets and analyzing the sentiment of the tweets. Text analysis is an important tool for understanding the sentiment of individuals and groups on Twitter, and our method can provide valuable insights for businesses, marketers, and researchers.'}\n","{'text': 'Human tracking in video feeds has been a popular research area, which consists of different state of the art approaches including tracking-by-detection, feature tracking and tracking by recognition/re-identification. Dlib correlation tracker is a state-of-the-art tracking-by-detection implementation, which can be used for human tracking except under occlusions. That is, it fails to continuously track a person if that person disappears due to occlusions and reappears immediately. In order to overcome this challenge, we propose a state estimation approach to extend the capabilities of Dlib correlation tracker under occlusions along with the use of human detection. The proposed approach has proven to give better results than directly using Dlib correlation tracker with human detection and was evaluated in real-world experiment scenarios. The approach can further be improved for wider use cases and a wider variety of trackers for human tracking.'}\n","{'text': 'In wireless sensor networks, path planning plays an important role in achieving accurate localization. This paper proposes an enhanced path planning model for anchor-free localization. The mathematical model is based on analytical models that take into account the characteristics of optical scattering and optical sensors. The model considers measurement by laser beam and optimizes the path planning algorithm to reduce the localization error. Simulation tests have shown that the proposed model can achieve higher localization accuracy compared to traditional path planning models. The results indicate the feasibility and advantages of the proposed enhanced path planning model for anchor-free localization in wireless sensor networks.'}\n","{'text': \"The complexity of supply chains increase, especially due to the geographical spread of supplier and customer networks. In the connected and automated supply chains of the industry 4.0, even more nodes are incorporated in supply chains. This paper discusses the possible improvement of process quality in the industry 4.0 through the different blockchain and distributed ledger technologies. We derived hypotheses from a literature review and asked German blockchain experts from the industry to validate and discuss the hypotheses. We find that the different blockchain technologies and consensus algorithms have different strength with regard to quality improvement. One central finding is that IOTA, developed especially for the IoT and deemed the 'next evolutionary step' is scalable and hence may increases the process efficiency, but at the same time is more vulnerable than other blockchain implementations, which again may reduce the overall process quality.\"}\n","{'text': 'We consider the design of wideband multiple-input multiple-output (MIMO) radar waveforms to approximate a desired beampattern and achieve prescribed space-frequency nulling in a space-frequency region of interest. A general design model involving modulus, power, and energy constraints on the probing waveforms is introduced. To deal with the resulting non-convex design, a novel iterative algorithm with low computational complexity is proposed. In each iteration, the non-convex design is approximated successively through a series of convex subproblems. Then, each convex subproblem is reformulated in a new alternating direction method of multipliers form, with small-sized subproblems solved in parallel with closed-form solutions via utilizing the Karush-Kuhn-Tucker conditions. Numerical results are provided to demonstrate the effectiveness of the proposed algorithm.'}\n","{'text': \"Collaborative filtering is one of the most effective and adequate technique used in recommendation. The fundamental aim of the recommendation is to provide prediction of the different items in which a user would be interested in based on their preferences. Recommendation systems based on collaborative filtering techniques are able to provide approximately accurate prediction when there is enough data. User based collaborative filtering taechniques have been very powerful and success in the past to recommend the items based on user's preferences. But, there are also some certain challenges such as scalability and sparsity of data which increases as the number of users and items increases. In a large website, it is difficult to find the interested information in a certain time. But the recommendation system filter out information and items that are best suitable for us. Although there are different recommendation approaches, yet collaborative filtering technique is very popular because of the effectiveness. In this work, movie recommender system has been described, which basically uses item-based technique of collaborative filtering to provide the recommendations of items, which is dynamic and will learn from the positive feedback.\"}\n","{'text': 'In this paper, we propose a novel relative camera motion estimation algorithm that can provide accurate results even in challenging visual odometry scenarios. Our approach utilizes an efficient cost function that is well-suited for the classification algorithms. The algorithm offers robust estimation performance while leveraging computational efficiency. We demonstrate the effectiveness of our approach by conducting extensive experiments on various datasets. Our results show that our algorithm can achieve highly accurate estimates of relative camera motion, while maintaining a low computational cost. Our algorithm is therefore suitable for real-time visual odometry applications and can be a valuable addition to the existing methods in this field.'}\n","{'text': 'The cost-effective management of spare parts is an important objective for all manufacturing and service companies. One of the most difficult challenges, for this objective, is accurate demand forecasting and optimized supply planning decisions to achieve best availability level for the spare parts. The main objective of this paper is to propose a predictive approach to identify the best forecasting method with least error cost. Moreover, in business aircraft industry the best forecasting method for a part can change due to the high-level uncertainty in demand. To this purpose, a methodology to select the best forecasting method based on binary classifier machine learning is developed. Proposed methodology is applied in a real case for a well-known business aircraft. The results indicate that neural network is the best machine learning method for 98% of demand and random forest is the best machine learning method for only 2% of parts.'}\n","{'text': 'To improve the deficiency of previous reliability evaluation methods of CNC machine tools, an evaluation method based on function monotonicity is proposed to evaluate the reliability of CNC machine tools. First, residual correlation method is used to eliminate abnormal data. Second, an empirical distribution function of CNC machine tools is established through mean rank method. Furthermore, reliability models of CNC machine tools are developed, and model parameters are estimated through maximum likelihood method. A comprehensive evaluation method is adopted to select the optimal distribution function, which is the model used in our study. Finally, the interval of mean time between failures is estimated on the basis of function monotonicity. The proposed method is also used to evaluate the reliability of a certain CNC lathe. Results verify the feasibility and effectiveness of the proposed method.'}\n","{'text': 'In this paper, an approach to model the impedance characteristic of a generic smartphone antenna with lumped circuit elements based on characteristic modes is shown. In contrast to a pure fit of simple RLC resonator circuits, a model based on characteristic modes can deliver an enhanced insight into the real physical behavior of the modeled antenna. To obtain such a model, each dominant mode is modeled with a separate circuit. The superposition of all these circuits yields the whole model. To obtain the circuit models, we use an approach based on high pass circuits of even order, which is extended so that it is valid for inductive modes, too.'}\n","{'text': 'In this paper, the machine learning algorithms have been applied on distinct features of Keystroke Dynamics. The Machine learning is important to correctly authenticate an individual. In this work, the complex models and algorithms help to determine when the person is a genuine user or an imposter through learning. The algorithms that has been studied and deployed,are the Fuzzy Expert System (FESs), NeuroEvolution of the augmenting topology (NEAT), Proposed NeuroEvolution of the augmenting topology, Support Vector Machine (SVM) and Chaotic Neural Network. From the algorithms applied, the proposed NEAT algorithms performs better in terms of recognition rate on both databases used where the recognition rate achieved above 95.6%.'}\n","{'text': 'Fifth-generation and beyond (5G+) systems will support novel cases, and hence, require new network architecture. In this paper, network flying platforms (NFPs) as aerial hubs are considered in future 5G+ networks to provide fronthaul connectivity to small cells (SCs). We aim to find the optimal association between the NFPs and SCs to maximize the total sum rate subject for quality of service, bandwidth, and supported number of link constraints. The formulated optimization problem is an integer linear program and the optimal association between the NFPs and SCs is found using numerical solvers at the expense of high computational complexity. We propose two algorithms (centralized and distributed) to reach a sub-optimal association at reduced complexity. Simulation results show that the performance of the proposed algorithms approaches the counterpart of its optimal solution and outperforms the state-of-the-art techniques from the literature.'}\n","{'text': 'Generative adversarial networks (GANs) have shown great promise in various application fields such as image and speech recognition. However, training GANs remains a challenging task, especially when it comes to generating hard samples to improve classification networks. To overcome this limitation, a three-player GAN has been proposed, where two generators compete with each other in a game against a discriminator. One of the generators tries to produce difficult examples, while the other aims to generate easy samples. The generated samples are then used to train a classification network, resulting in better overall performance. This approach has been applied to different fields such as meteorology and computational modeling, but in this study, the focus is put on gallium nitride material classification. Experimental results have shown that the proposed method can significantly enhance the classification accuracy compared to traditional GANs.'}\n","{'text': 'The vision-based foreground (FG) identification approaches are in great demand to intelligent transportation applications. Here, the convolutional neural network (CNN)-based image-to-image models have shown impressive performance in saliency detection and semantic segmentation. Inspired by their advancement in computer vision (CV), we introduce a strategy, named double encoding - slow decoding to improve a basic encoder-decoder (EnDec) CNN for precise FG masking. Wherein, at every stage of down-sampling, a feature map is encoded twice and every stage of up-sampling is enhanced by two residual feature concatenations (cat) and interspersed batch normalization (BN). Such continuous forward feature pulling process in the encoding and decoding sub-networks results delineated FG identification. We carry out a thorough analysis to validate the effectiveness of the proposed model in terms of figure of merit (f-measure). We also investigate four different methods of FG binary mask creation from the probability saliency map generated by the model. The experimental study on benchmark datasets proves that the proposed architecture achieves better/competitive results than/against state-of-the-art methods.'}\n","{'text': 'This manuscript discusses the changing roles of Semiconductors for the development of Autonomous Driving within the scope of Vehicle IoT and Deep Learning. Also the development of Autonomous Driving will change the outlook of transportation industries with shorter product life cycle and different modes of business profitability. Along with these changes of technologies and market, the semiconductor business model will also require changes.'}\n","{'text': 'The era of the Internet of Things already started to be a part of daily lives. During these early years of development, the biggest barrier on the IoT solutions is the limited connection ranges and the desire for longer isolated working without connection to the grid. Low Power Wide Area Networks (LPWAN) is one of the most important key solutions for these two major issues due to its ability to connect very low power devices distributed in very large areas. This need does make the LP-WAN technologies become widely used in different fields of various applications of smart cities. In this paper, the current LP-WAN technologies are categorized into two groups, those unlicensed and licensed. Explored from both technical and non-technical requirements for applications, they are also compared to each other regarding their technological and commercial aspects. Also, as the need for technologies that would apply asset location is quickly becoming a requirement for the enterprise and industrial IoT, so the geolocation feature of LPWAN is also discussed as a major requirement.'}\n","{'text': 'Contextual information can be learned at the mobile devices, such as smartphones, in real-time from the sensors to provide better services to the user. The sensor data collection process, where the data is collected by various internal sensors or autonomous external sensors, incurs greater power consumption, depending upon the type of sensor and data capturing rate in the mobile devices. On the other hand, the learning process itself drains the battery and at the same time affects the accuracy of the learning due to the limited computational power of the mobile devices. These problems can be addressed by shifting the learning process to the cloud, which is however achieved at the cost of reducing the accuracy of the real-time solutions and incurs heavy bandwidth usage depending upon the context of the user. Therefore, we propose a cloud-based real-time context-learning system where the user of the system will get the predetermined service in real-time according to the userdetermined context, which is learned from the related sensors while conserving a maximum amount of power compared to the standalone system or the cloud-based system. We have produced experimental results using a smartphone that illustrates that our system conserves 96.36% of power compared to the mobilelearning system while at the same time, the network data usage is 80% lower when compared to the cloud-based system. We have also showed that the proposed system works 76.17% and 94.81% faster compared to the mobile-learning and cloud-based system respectively.'}\n","{'text': 'Strong teams do not happen by chance. Putting together a group of highly skilled individuals will not necessarily result in a top performing team. Team building can have lasting, positive, and measurable effects on team performance. However, it is important that you keep the activities project-focused and avoid situations that feel awkward or artificial. This paper describes how to build motivated and cohesive technical teams using a â\\x80\\x9cdeliberate team buildingâ\\x80?approach, which is a different way for technical managers to think about team building and describe techniques successfully employed that differ from the classic, sometimes less successful, team bonding exercises used with technical professionals.'}\n","{'text': \"Affective state recognition has recently attracted a notable amount of attention in the research community, as it can be directly linked to a student's performance during learning. Consequently, being able to retrieve the affect of a student can lead to more personalized education, targeting higher degrees of engagement and, thus, optimizing the learning experience and its outcomes. In this paper, we apply Machine Learning (ML) and present a novel approach for affect recognition in Technology-Enhanced Learning (TEL) by understanding learners' experience through tracking their interactions with a serious game as a learning platform. We utilize a variety of interaction parameters to examine their potential to be used as an indicator of the learner's affective state. Driven by the Theory of Flow model, we investigate the correspondence between the prediction of users' self-reported affective states and the interaction features. Cross-subject evaluation using Support Vector Machines (SVMs) on a dataset of 32 participants interacting with the platform demonstrated that the proposed framework could achieve a significant precision in affect recognition. The subject-based evaluation highlighted the benefits of an adaptive personalized learning experience, contributing to achieving optimized levels of engagement.\"}\n","{'text': 'Cardiac autonomic regulation is affected by respiratory training, which has been demonstrated in the linear analysis of heart rate variability (HRV). The two most important bands in frequency domain analysis of HRV, the low frequency (LF) and high frequency (HF) analysis, which respectively represent parasympathetic and sympathetic activity, have been widely used in deep breathing research. However, the interaction between the LF and HF in deep breathing has not been well studied. In this sense, we recruited 12 healthy young subjects (7 males and 5 females) for deep breathing experiment. Transfer entropy (TE) of HRV was applied to analyze the changes in information transmission between HF and LF at baseline and deep breathing. The results demonstrated that the mean TE(LFâ\\x86?HF) value was significantly lower during deep breathing than at baseline. Compared with the mean TE(HFâ\\x86?LF) value, the mean TE(LFâ\\x86?HF) value was significantly higher at baseline. The results also showed a significant increase in the LF/HF ratio in deep breathing. Our results demonstrated that deep breathing attenuates the information transmission from the sympathetic nervous system (SNS) to the parasympathetic nervous system (PNS).'}\n","{'text': \"Indoor localization has become a hot topic in recent years because of its wide applications. Map matching is a popular method used to improve the localization accuracy without adding hardware. However, the existing map matching methods are usually computationally expensive, leading to the unsuitability of running on resource-limited devices such as smartphones. In this paper, we present an efficient map matching system for indoor localization, called HTrack, which uses a hidden Markov model, considering the user's heading and spatial information. By considering user's heading information, we significantly reduce the number of candidate states for each step, and hence improve the computational efficiency. The experimental results show that the HTrack outperforms the state-of-the-art methods (more than 25% localization accuracy improvement), and consumes about five times less energy than the state-of-the-art methods.\"}\n","{'text': 'High-Level Synthesis (HLS) allows designers to create a register transfer level (RTL) description of a digital circuit starting from its high-level specification (e.g., C/C++/SystemC). HLS reduces engineering effort and design-time errors, allowing the integration of additional features. This study introduces an approach to generate benevolent Hardware Trojans (HT) using HLS. Benevolent HTs are Intellectual Property (IP) watermarks that borrow concepts from well-known malicious HTs to ward off piracy and counterfeiting either during the design flow or in fielded integrated circuits. Benevolent HTs are difficult to detect and remove because they are intertwined with the functional units used to implement the IP. Experimental results testify to the suitability of the approach and the limited overhead.'}\n","{'text': 'In the current practice, locational marginal prices (LMPs) are computed every few minutes by solving an optimization problem with continuous variables only. Generator on/off statuses are decided by the day-ahead unit commitment scheduling procedure. Thus, unit commitment and locational marginal price computing are two separate steps. This paper presents a model that substitutes the traditional two-step method. It is based on bilevel programming. The proposed problem determines generator on/off status and locational marginal prices simultaneously. The efficiency of the model is demonstrated on the 5- and 30-bus systems.'}\n","{'text': 'This paper proposes a nonlinear optimal control strategy for steam-turbine power generation in order to enhance power system stability. The control model utilizes mathematical models of both the generators and turbines coupled with Jacobian matrices to effectively model the multi-variable system. Computational modeling techniques are employed to simulate the power generation system and simulate the control strategy. The proposed nonlinear optimal control scheme is shown to significantly improve the stability of the system in comparison to traditional linear control methods. This research contributes to the ongoing effort to enhance the efficiency and reliability of power generation systems through advanced control techniques.'}\n","{'text': 'This paper proposes a methodology for minimizing the high-level fault model for microprocessor control parts. With the increasing complexity of microprocessors, the need for efficient testing and fault identification methods has become crucial. The paper highlights the importance of identifying circuit faults and utilizing test pattern generators for fault simulation. Integrated circuit modeling and computation modeling techniques are also explored as effective tools for high-level fault minimization. The proposed methodology is shown to be effective in reducing the number of faults in instruction sets for the microprocessor control parts. Overall, the research presented in this paper provides valuable insights into the development of efficient strategies for minimizing high-level fault models in microprocessors, which can lead to more reliable and robust systems.'}\n","{'text': 'This paper proposes a novel method for outlier accommodation in nonlinear state estimation for GNSS aided INS, by incorporating risk-averse performance specification techniques. The approach takes advantage of time measurement, optimization and covariance matrices to estimate the true state of the system, while minimizing the impact of outlier measurements. The use of Global Navigation Satellite System (GNSS) and sensors provide accurate data, which is suitable for the nonlinear state estimation process. The proposed method aims to overcome the challenges of dealing with unreliable measurements and offers a more robust solution for state estimation. The performance evaluation of the proposed method is carried out by comparing it with the existing methods in terms of estimation error and time complexity. The results indicate that the proposed method offers a more accurate and reliable solution, and it outperforms the existing techniques in terms of the estimation time. This work is expected to contribute to the development of more effective methods for nonlinear state estimation, which can be used in various applications that require accurate and reliable state estimation, such as robotics, navigation and control systems.'}\n","{'text': \"In this research we explore the effect of a virtual avatar that is non-human like and can express basic distinguishable emotions on users' level of engagement and interest. Virtual reality (VR) environments are able to render realistic representations. However, not all virtual environments require life-like representations of their characters-in our research a 'life-like' human character means that it resembles very closely to an actual person in real life. It is very common for games to use simple non-human characters. Cartoon-like characters can actually have a greater impact on users' affinity towards these games. The aim of this research is to examine if interactions with a cartoon-like character that has the capacity to express simple but common emotional expressions is sufficient to bring forth a change in the behavior and level of engagement of users with the character. This research seeks to find out if adding simple emotions to virtual characters is beneficial to increasing users' interest. To explore these questions, we have conducted a study with a human-like cartoon character in a VR environment that can express simple, basic human emotions based on users' input. The results of our experiment show that a cartoon-like character can benefit from displaying emotional traits or responses when interacting with humans in a VR environment.\"}\n","{'text': 'A computational study of heat transfer augmentation in a rectangular channel having rectangular ribs on the upper wall and triangular baffles/fins on the opposite wall by using Computational Fluid Dynamics (CFD) software (ANSYS FLUENT R18.2) is presented in the paper. Effects of Reynolds number on both the flow variables (velocity, pressure, turbulent kinetic energy) and heat transfer variables (temperature and heat transfer coefficient) for three different types of ribs/fins configurations were investigated. The three cases of study are: 1. Ribs Top Smooth Bottom Channel; (RTSBC), 2. Smooth Top Fin Bottom Wall (STFBC) and 3. Ribs Top Fin Bottom Channel (RTFBC). The computation based on finite volume with SIMPLE algorithm have been conducted for air flow in terms of Reynolds number ranging from 4000-20000 has been carried out with SST k- turbulence model. It has been found that for the Case 1, ribs have negligible effect on heat transfer augmentation and pressure drop, unlike Case 2 where a moderate effect is observed. Maximum values for Nusselt number and friction factor are obtained for Ribs Top Fin Bottom Channel (RTFBC).'}\n","{'text': 'How can we accurately predict the performance of a Personal Computer (PC) configuration without time consuming simulation? In this work, we predict the performance of a computer hardware configuration using Multiple Neural Networks (MNN). We use Principal Component Analysis (PCA) during data preprocessing as guidance for model creation. The input data includes the internal component characteristics of a computer. A deep learning model is used to infer a benchmark score given a hardware configuration. The finished model takes input data such as Central Processing Unit (CPU) type, frequency, number of cores, memory size and speed, flash or disk architecture, network configuration and correlates it against the corresponding performance benchmark value and system response to a benchmark workload. We demonstrate the accuracy and effectiveness of the MNN and PCA machine learning models using the Standard Performance Evaluation Corporation (SPEC) benchmarks (SPEC CPU2006 and SPEC CPU2017), and a set of approximately 50,000 commercial machines configurations. Our MNN model is able to achieve an average accuracy rate of 97.5% for all benchmarks. Our results provide both personal and enterprise users a tool that can accurately estimate system configuration performance without lengthy and resource intensive benchmarking sessions.'}\n","{'text': 'The TanDEM-X mission (TDM) is a spaceborne radar interferometer which delivers a global digital surface model (DSM) with a spatial resolution of 0.4 arcsec. In this letter, we propose an automatic workflow for digital terrain model (DTM) generation from TDM DSM data through additional consideration of Sentinel-2 imagery and open-source geospatial vector data. The method includes the automatic and robust compilation of training samples by imposing dedicated criteria on the multisource geodata for subsequent learning of a classification model. The model is capable of supporting the accurate distinction of elevated objects (OBJ) and bare earth (BE) measurements in the TDM DSM. Finally, a DTM is interpolated from identified BE measurements. Experimental results obtained from a test site which covers a complex and heterogeneous built environment of Santiago de Chile, Chile, underline the usefulness of the proposed workflow, since it allows for substantially increased accuracies compared to a morphological filter-based method.'}\n","{'text': 'Fundamental approaches in motion tracking are based on registration of pixel patches from one frame to another. To ensure invariance to some changes in the image and improve the speed of discovering a match, a pyramidal approach is used to steer the process faster to optima. However, registration of the patches in high resolution is still computationally expensive. Because we require the algorithm to process Ultra HD video content in real time on commonly available hardware, especially on mid-tier graphics processing units, approaches using matching of pixel patches are not feasible. In this paper, we present and evaluate an approach inspired by motion tracking on an image pyramid. However, instead of comparing pixel patches one to another, we utilise binary image descriptors that are much shorter and inherently use a Hamming distance for their direct comparison. Evaluation of our implementation, which is available on GitHub, was carried out on the Multiple Object Tracking challenge dataset.'}\n","{'text': 'Pedestrian detection is a crucial component for intelligent transport system and advanced driver assistance system. In recent years, pedestrian detection methods have achieved higher accuracy. However, the existing algorithms are insufficient for small-scale pedestrian detection that is relatively far from cameras in practical applications. In this paper, we propose a novel deep small-scale sense network (termed SSN) for small-scale pedestrian detection. The proposed architecture could generate some proposal regions which are more effective to detect small-scale pedestrians. Furthermore, we design a novel loss function based on cross entropy loss to increase the loss contribution from hard-to-detect small-scale pedestrians. In addition, a novel evaluation metric is introduced, which can measure the location precision of the pedestrian detection methods. In addition an Asian pedestrian detection dataset named VIP pedestrian dataset is constructed from various road condition data. Our method achieves good detection performance on Caltech pedestrian dataset and our VIP pedestrian dataset.'}\n","{'text': 'Network operators are under pressure to offer efficient network-based services while keeping service deployment costs to a minimum. Network functions virtualization (NFV) can potentially revolutionize network-based services bringing low-deployment costs for network operators. The NFV has been introduced to ultimately extend the non-proprietary and open-standard-based model to network and service deployments, significant improvements to todayâ\\x80\\x99s proprietary locked implementations. Notwithstanding the continuous efforts of both academia and industry to support the NFV paradigm, the current NFV solutions offered are still in its infancy. In this survey, we provide a detailed background of NFV to establish a comprehensive understanding of the subject, ranging from the basics to more advanced topics. Moreover, we offer a comprehensive overview of the NFV main concepts, standardization efforts, the benefits of NFV, and discussions of the NFV architecture as defined by the European telecommunications standardization institute (ETSI). Furthermore, we discuss the NFV applicability and current open source projects. We then highlight NFV requirements, design considerations, and developmental architectural impairments and barriers to commercial NFV deployments. Finally, we conclude enumerating future directions for NFV development.'}\n","{'text': 'Mobile cloud computing (MCC) has emerged as a promising technology to extend the capabilities of mobile handsets such as smartphones, tablets, and wearable devices. MCC provides an elastic, scalable and reliable infrastructure to support resource-intensive applications running on resource-constrained mobile devices. This paper proposes a taxonomy to classify the existing MCC systems based on their architecture, deployment model, provisioning scheme, and service model. We also identify some open challenges in the area of MCC such as task analysis, optimization, performance evaluation, energy consumption, and security. We highlight the importance of these challenges and how they affect the performance and correctness of MCC systems. Furthermore, we discuss some solutions proposed in the literature to tackle these challenges and improve the quality of service provided by MCC systems. This paper aims to provide guidelines for researchers and practitioners to design, implement, and evaluate efficient and secure MCC systems.'}\n","{'text': 'In this paper, a force sensorless control scheme based on neural networks (NNs) is developed for interaction between robot manipulators and human arms in physical collision. In this scheme, the trajectory is generated by using geometry vector method with Kinect sensor. To comply with the external torque from the environment, this paper presents a sensorless admittance control approach in joint space based on an observer approach, which is used to estimate external torques applied by the operator. To deal with the tracking problem of the uncertain manipulator, an adaptive controller combined with the radial basis function NN (RBFNN) is designed. The RBFNN is used to compensate for uncertainties in the system. In order to achieve the prescribed tracking precision, an error transformation algorithm is integrated into the controller. The Lyapunov functions are used to analyze the stability of the control system. The experiments on the Baxter robot are carried out to demonstrate the effectiveness and correctness of the proposed control scheme.'}\n","{'text': 'This paper focuses on the customized-wireless sensor node implementation of the classical least mean square (LMS) algorithm for the reduction in data-transmissions from the sensor nodes to the sink in internet of things (IoT) networks. This reduction, in turn, increases the battery life of the sensor node. The system was deployed in outdoor and indoor environments to read the ambient temperature and then perform the prediction of the sensed data in order to minimize the number of data-transmissions to the sink node. The utility of the proposed concept has been demonstrated using the measured data and the battery life is increased 2.64 and 2.53 times in indoor and outdoor environments, respectively.'}\n","{'text': 'Most existing algorithms for depth estimation from single monocular images need large quantities of metric ground-truth depths for supervised learning. We show that relative depth can be an informative cue for metric depth estimation and can be easily obtained from vast stereo videos. Acquiring metric depths from stereo videos are sometimes impracticable due to the absence of camera parameters. In this paper, we propose to improve the performance of metric depth estimation with relative depths collected from stereo movie videos using existing stereo matching algorithm. We introduce a new â\\x80\\x9crelative depth in stereoâ\\x80?(RDIS) dataset densely labeled with relative depths. We first pretrain a ResNet model on our RDIS dataset. Then, we finetune the model on RGB-D datasets with metric ground-truth depths. During our finetuning, we formulate depth estimation as a classification task. This re-formulation scheme enables us to obtain the confidence of a depth prediction in the form of probability distribution. With this confidence, we propose an information gain loss to make use of the predictions that are close to ground-truth. We evaluate our approach on both indoor and outdoor benchmark RGB-D datasets and achieve the state-of-the-art performance.'}\n","{'text': \"This paper deals with the problem of discrete time sliding mode control with an external trajectory generator. We consider a disturbed discrete time dynamical system and present a new reference trajectory based sliding mode control strategy. We adopt the nonswitching type definition of the quasi-sliding mode and, following the main stream of research on the topic, we use the reaching law approach to design the control. We propose generating the desired trajectory of the system externally, using a new nonswitching type reaching law. Then, we define a new desired trajectory following reaching law for the disturbed plant. We demonstrate that the trajectory following reaching law limits the impact of external disturbances and model uncertainties on the system to one step, whereas in the existing control methods the performance of the system is influenced by all disturbance values from the beginning of the control process. Therefore, our control strategy guarantees a reduction of the width of the ultimate band and increases the system's robustness. The results of our study are verified with a simulation example.\"}\n","{'text': 'The study explores the use of multicore processing to parallelize deep learning inference on chip multiprocessor architecture. To achieve faster and efficient processing of relatively complex neural networks, parallel processing is employed through kernel execution acceleration. Using a learned-to-scale approach, training the neural networks involves optimizing the weights of the neural networks in parallel to minimize the overall processing time. Results show that using parallel processing significantly improves the overall performance of the neural network, reducing the processing time by up to 75%.'}\n","{'text': 'This study designs a two-wheeled mobile platform with autonomous movement and face following functionality. The autonomous movement mechanism uses the change of the center of gravity to make the two-wheeled mobile platform move forward or backward, and utilizes simultaneously the PID controller to keep its balance. The face following functionality uses a tablet with an image sensor and an image processing to perform face recognition, and finds a tracking direction. Experimental results show that the two-wheeled mobile platform can perform autonomous balance, the movement and face tracking functionality.'}\n","{'text': \"In this paper, we propose a novel and efficient approach for semi-supervised anomaly detection using a combination of the CVAE-GAN framework and informative manifolds. The proposed method utilizes the training data to generate informative manifolds that enable the reconstruction of anomalous images. The trained generators in the framework operate within a Gaussian distribution and are utilized for image reconstruction, reducing the number of training parameters required. Further, we evaluate our proposed method's effectiveness on a dataset of Gallium nitride (GaN) materials and demonstrate superior performance compared to state-of-the-art methods. Overall, our approach provides an efficient and effective solution for anomaly detection in a semi-supervised setting.\"}\n","{'text': 'This paper delves into the fundamentals of signal design for wireless power transfer (WPT) and simultaneous wireless information and power transfer (SWIPT). The wireless communication system plays a crucial role in the successful design of WPT and SWIPT, which requires careful consideration of both the radio frequency and signal design. One of the key components in WPT and SWIPT are rectennas, which are used to convert the received radio frequency signal into DC power. Furthermore, wireless sensor networks require efficient transmitters and receivers for signal transmission and reception. Therefore, signal design is essential for successful WPT and SWIPT, as it impacts the performance of rectennas, wireless sensor networks, transmitters, and receivers. This paper discusses how signal design can be optimized to enhance wireless power and information transfer, leading to more efficient and sustainable wireless communication systems.'}\n","{'text': 'Due to rapid changes in the environment, vehicular communication channels no longer satisfy the assumption of wide-sense stationary uncorrelated scattering. The non-stationary fading process can be characterized by assuming local stationarity regions with finite extent in time and frequency. The local scattering function (LSF) and channel correlation function (CCF) provide a framework to characterize the mean power and correlation of the non-stationary channel scatterers, respectively. In this paper, we estimate the LSF and CCF from measurements collected in a vehicle-to-infrastructure radio channel sounding campaign in a suburban environment in Lille, France. Based on the CCF, the stationarity region is evaluated in time as 567 ms and used to capture the non-stationary fading parameters. We obtain the time-varying delay and Doppler power profiles from the LSF, and we analyze the corresponding root-mean-square delay and Doppler spreads. We show that the distribution of these parameters follows a lognormal model. Finally, application relevance in terms of channel capacity and diversity techniques is discussed. Results show that the assumption of ergodic capacity and the performance of various diversity techniques depend on the stationarity and coherence parameters of the channel. The evaluation and statistical modeling of such parameters can provide a way of tracking channel variation, hence, increasing the performance of adaptive schemes.'}\n","{'text': 'ElectroEncephaloGram (EEG) spectral power has been extensively used to classify Mental Imagery (MI) of movements involving different body parts. However, there is an increasing need to enable classification of MI of movements within the same limb. In this work, EEG spectral power was recorded in seven subjects while they performed MI of closing (grip) and opening (extension of fingers) the hand. The EEG data was analyzed and the feasibility of classifying MI of the two movements were investigated using two different classification algorithms, a linear regression and a Convolutional Neural Network (CNN). Results show that only the CNN is able to significantly classify MI of opening and closing of the hand with an average classification accuracy of 60.4%. This indicates the presence of higher-order non-linear discriminatory information and demonstrates the potential of using CNN in classifying MI of same-limb movements.'}\n","{'text': 'Artificial Intelligence (AI) is one of the current emerging technologies. In the history of computing AI has been in the similar role earlier - almost every decade since the 1950s, when the programming language Lisp was invented and used to implement self-modifying applications. The second time that AI was described as one of the frontier technologies was in the 1970s, when Expert Systems (ES) were developed. A decade later AI was again at the forefront when the Japanese government initiated its research and development effort to develop an AI-based computer architecture called the Fifth Generation Computer System (FGCS). Currently in the 2010s, AI is again on the frontier in the form of (self-)learning systems manifesting in robot applications, smart hubs, intelligent data analytics, etc. What is the reason for the cyclic reincarnation of AI? This paper gives a brief description of the history of AI and also answers the question above. The current AI â\\x80\\x9ccycleâ\\x80?has the capability to change the world in many ways. In the context of the CE conference, it is important to understand the changes it will cause in education, the skills expected in different professions, and in society at large.'}\n","{'text': 'Anomaly detection has become a crucial research area in the field of image reconstruction and inspection. This paper proposes a novel approach for anomaly detection using deep learning based image completion. Specifically, the proposed method utilizes convolutional neural networks for surface reconstruction, which enables accurate and efficient task analysis. The training process involves the use of large datasets to ensure robustness and adaptability. The proposed algorithm achieves high accuracy in the detection of anomalous regions, allowing it to be utilized for various applications in image reconstruction and inspection. Overall, the utilization of deep learning based image completion for anomaly detection presents exciting opportunities for the advancement of image analysis and machine learning.'}\n","{'text': 'The purpose of this study is to propose a new benefit segmentation method based on customer reviews existing on the web. With the diversification in customer needs, it is difficult to accurately identify the needs of customers with market segmentation using demographic information. Therefore, it is of utmost importance to segment the customer base according to the benefits they derive from a product or service. Utilizing the random forest algorithm for this purpose is advantageous as it accurately identifies training data despite the existence of noise and outliers, and is widely utilized for analysis of text data. Our experiment focuses on the segmentation of hotels based on customer reviews, with the reason for hotel usage considered as the benefit derived from the product/service. We utilized the frequency of words in textual data as explanatory variables to identify the topics discussed by customers. We extracted factors that influenced each benefit to determine customer needs.'}\n","{'text': 'In this paper, we propose a novel singing-voice enhancement system that makes the singing voice of amateurs similar to that of professional opera singers, where the singing voice of amateurs is emphasized by using a singing voice of a professional opera singer on a frequency band that represents the remarkable characteristic of the professional singer. Moreover, our proposed singing-voice enhancement based on highway networks is able to convert any song (that a professional opera singer does not sing). As a result of our experiments, the singing voice of the amateur singer at the middle-high frequency range which contains a lot of frequency components that affect glossiness was emphasized while maintaining speaker characteristics.'}\n","{'text': 'Person re-identification is a challenging task due to variations in appearance, lighting, and pose. In this paper, we propose a method for person re-identification using group symmetry theory. We first perform task analysis to identify the key components and tasks required for effective re-identification. We then apply deep learning techniques for feature extraction and measurement. Specifically, we use convolutional neural networks to extract discriminative features from images, and transforms to reduce the dimensionality of the feature space. Finally, we use group symmetry theory to match images and improve the accuracy of person re-identification. Our experimental results demonstrate that our method achieves state-of-the-art performance on several benchmark datasets, and is robust to variations in appearance, lighting, and pose.'}\n","{'text': 'Internet of Things (IoT) is ubiquitous because of its broad applications and the advance in communication technologies. The capabilities of IoT also enable its important role in homeland security and tactical missions, including Reconnaissance, Intelligence, Surveillance, and Target Acquisition (RISTA). IoT security becomes the most critical issue before its extensive use in military operations. While the majority of research focuses on smart IoT devices, treatments for legacy dumb network-ready devices are lacking; moreover, IoT devices deployed in a hostile environment are often required to be dumb due to the strict hardware constraints, making them highly vulnerable to cyber attacks. To mitigate the problem, we propose a light-weight authentication scheme for dumb IoT devices, in a case study of the UAV-sensor collaborative RISTA missions. Our scheme utilizes the covert channels in the physical layer for authentications and does not request conventional key deployments, key generations which may cause security risks and large overhead that a dumb sensor cannot afford. Our scheme operates on the physical layer, and thus it is highly portable and generalizable to most commercial and military communication protocols. We demonstrate the viability of our scheme by building a prototype system and conducting experiments to emulate the behaviors of UAVs and sensors in real scenarios.'}\n","{'text': 'Compared to frequent sequence mining that is a computationally challenging task with many intermediate subsequences, frequent closed and generator sequence mining provides several benefits because it results in increased efficiency and concise representations while preserving all the information of all traditional patterns recovered from the representations. Besides, frequent closed sequences can be combined with generators to generate non-redundant sequential rules and to recover all sequential patterns as well as their frequencies quickly. However, most algorithms that have been proposed to discover either closed sequences or generators at a time and for large databases containing many long sequences are still too long to complete the work or run out of memory. Therefore, this paper, by exploiting the advantage of multi-core processor architectures, proposes a novel parallel algorithm called Par-GenCloSM for simultaneously mining both frequent closed and generator sequences in the same process. Par-GenCloSM is based on efficient techniques to quickly eliminate unpromising candidate branches and two novel strategies named EPUCloGen and GPPCloGen to reduce the global synchronization cost of the parallel model and speed up the mining process. Par-GenCloSM is the first parallel algorithm for mining frequent closed sequences and generators concurrently. Experimental results on many real-life and synthetic databases show that Par-GenCloSM outperforms state-of-the-art algorithms in terms of runtime and memory consumption, especially for long sequence databases with low minimum support thresholds.'}\n","{'text': \"Smart home gateways have to forward multi-sourced network traffic generated with different distributions and with different quality-of-service (QoS) requirements. The state-of-the-art QoS-aware scheduling methods consider only the conventional priority metrics based on the IP type of service (ToS) field to make a decision for bandwidth allocation. Such priority-based scheduling methods are not optimal to provide both QoS and quality of experience (QoE), since higher priority traffic may not require lower delay than lower priority traffic (for example, traffic generated from medical sensors has a higher priority than traffic from streaming devices, but the latter one requires lower maximum delay). To solve the gaps between QoS and QoE, we propose a new queuing model for QoS-level Pair traffic with mixed arrival distributions in the smart home network (QP-SH) to make dynamic QoS-aware scheduling decisions meeting delay requirements of all traffic while preserving their degrees of criticality. A new metric that combines the ToS field and the maximum number of packets that can be processed by the system' s service during the maximum required delay is defined. Our experiments show that the proposed solution increases 15% of packets that meet their priorities and 40% of packets that meet their maximum delays as well as 25% of the total number of packets in the system.\"}\n","{'text': 'The data of the multi-objective job shop production process in intelligent manufacturing has the characteristics of diversity, ambiguity, heterogeneity and stochastic dynamics. Combined with the complex network theory, the network modeling algorithm is used to build a multi-objective job based on data information to dynamically weigh the complex network model. Taking the data information as a node, taking the relationship between data as the edge, and taking the intensity between relationships as the weight of the edge, the model introduces dynamic changes in time. In consideration of the dynamic evolution of internal nodes, edges and weights at different times, the process optimization model for the multi-objective job shop problem is transformed into the data optimization model. After the analysis of the characteristics parameters of the model, the simulation experiments verify that the model has the characteristics of network without scale, which proves that the model can perfectly describe the actual workshop production.'}\n","{'text': 'Based on word embedding method, this paper presents a word vector based review vector method for sentiment analysis of movie reviews. As a result, it is achieved that 86.18% classification accuracy using the method. Meanwhile, the method is applicable to multiple languages such as Chinese and English, and it is extensible for larger scale contents as well. Whatâ\\x80\\x99s more, the influence of word vector dimensions on the sentiment analysis accuracy and the methodâ\\x80\\x99s applicability on sentences of varied lengths are also discussed in this paper. The experimental result proved that the word vector based review method for sentiment analysis is not only an efficient and simple way to analyze emotional expression, but also has extensibility and applicability for comments in varied lengths and multiple languages.'}\n","{'text': 'Cyber physical assets are being widely deployed. An asset could be a device or object in Cyber physical system (CPS). Many of them are subjected to compromise due to insecure implementations and configuration. Existing authentication techniques are not effective in detecting compromised assets given the massive scale of deployment. In this paper, we present a system for detecting compromised CPS assets effectively. In contrast to prior work, we propose an asset authentication framework that uses device-specific and network information with weight vectors, called slanted fingerprints, to validate assets. In particular, we perform asset fingerprinting with environmental effects to detect the cyber-physical emulation attacks on authentication. The framework tracks the effect of changes in the physical environment on fingerprints and uses unique CPS environmental effects features to detect both cyber-physical emulation and advanced stealthy attacks.'}\n","{'text': 'This paper discusses the development of an Electromechanical Force Compensation System for the Weight Removal of Patients during Rehabilitation using a Medical Simulator. The system involves the use of oscillators, gears, damping, synchronous motors, torque, electric motors, and training. The aim of the system is to improve the rehabilitation process for patients and reduce the physical strain on medical professionals. The system is able to accurately remove the weight of the patient during exercises and movements to promote effective rehabilitation. The use of synchronous motors and electric motors help to provide a high degree of precision and control. Overall, the Electromechanical Force Compensation System is an innovative solution for improving the rehabilitation process for patients and making it easier for medical professionals.'}\n","{'text': 'Computer vision technology can now aid in the measurement of sugar content for diabetic patients through modified sustenance affirmation techniques. This paper proposes a method for modified sustenance affirmation, in perspective of the Bag of Features (BoF) appear. Specifically, this paper aims to improve the performance of BoF by optimizing its construction and associated parameters. For the arrangement and appraisal of the model system, a visual dataset with around 5000 sustenance pictures was made and dealt with into 11 classes. The proposed system generates dense adjacent features using Scale Invariant Feature Transformation on the hsv color space, forms a visual vocabulary of 10000 visual words using hierarchical k-means clustering, and classifies food images utilizing a Support Vector Machine classifier. The resulting model achieved an impressive classification accuracy of 78%.'}\n","{'text': \"Recognizing lies in human interaction is one of the most important and challenging tasks in artificial intelligence. For example, it leads to the development of a human-computer interaction system that detects a liar in a conversation. In another example, some systems in the future might occasionally need to tell a lie for not hurting user's feelings, namely a white lie for trouble-free conversations. In this paper, we construct a video corpus for developing a system that detects lies in conversations. The corpus consists of 540 question-answer pairs by 9 persons; 270 true answers and 270 lies. We manually analyze the images in the corpus for recognizing lies. In addition, we apply machine learning techniques, support vector machines with local binary pattern features and geometric features, to our corpus. We discuss the results of the analysis of the corpus and the machine learning approaches to our corpus.\"}\n","{'text': 'In this paper, vehicle counting is investigated using various machine methods on four datasets. Vehicle counting is needed to complete the data required for short term predictions using highway traffic model, which is in turn, applicable for road design and usage planning. The goal of this research is to show that automatic car counting using machine methods, can be obtained from utilizing existing CCTV image data or from better cameras. Then by applying quantitative evaluation, F1 and precision scores are obtained, so that a few recommendations can be given. Through numerous simulations, F1 scores ranging from 0.32 to 0.75 have been successfully obtained for one low resolution dataset, using Background Subtraction and Viola Jones methods, on existing CCTV data. It has been found also that Viola Jones method can improve F1 score, by about 39% to 56%, over Back Subtraction method. Furthermore, the use of Deep Learning especially YOLO has provided good results, with F1 scores ranging from 0.94 to 1 and its precision ranges from 97.37% to 100% involving three datasets of higher resolution.'}\n","{'text': \"Humanoid robots are seen as perfect education partners for students these days. Many researchers are working on educational humanoid robots to make them more effective in educating students. One of many approaches to realize it is to make the robots educate children in two-way communication. In this case, robots can recognize students' progress and provide suitable learning materials according to their progress. In a simple scenario for basic mathematics learning, the robot educates a student on how to solve mathematical expressions. As the student understand the concepts, the robot gives some simple exercises to further improve student's ability. While completing the exercise, the partner robot supervises each mathematical expression solved by the student, acknowledges mistakes and provides correct solutions. Thus, the robot must be equipped with a system which can recognize mathematical expressions and give the solutions. Such system is an inherent foundation to build much smarter robots in delivering education to students. This paper covers detail design and implementation of the system which recognizes handwritten mathematical equations and provides the corresponding solutions. Testing results show that the system performs quite well with 97.4% accuracy with slight errors for characters with similar shapes.\"}\n","{'text': 'Light emitting diode (LED) is widely used in the field of optical communications because of its low power consumption and high flicker frequency. Due to the advantages of low power consumption, many LEDs can be integrated into one array and provide higher luminous intensity. In addition, combining light intensity with space coordinates can be utilized for positioning by unmanned aerial vehicle (UAV)-ground communication based on visible light communication link. The precise positioning of the LED array is an important factor for UAV-ground communication. In this paper, we propose and implement a two-step positioning method for precise positioning which can be used for UAV-ground communication. The method uses the OpenCV library and it corrects possible tilting defects in the image and achieves effective positioning of specific points in the array. This method could provide a positioning method for safe landing for UAV.'}\n","{'text': 'Web-form spamming is a constant challenge for cloud-based applications. To prevent this, a proposed model combining the use of cloud computing, intrusion detection, computational modeling, malware detection, authorization, and collaboration is presented in this paper. The model utilizes cloud-based solutions that integrate with existing intrusion detection systems and computational modeling techniques to monitor and detect spamming attempts. In addition, malware detection techniques are employed to identify and prevent any potential threats. Authorization mechanisms are incorporated to prevent unauthorized access, while collaboration between users and administrators enhances overall security measures. The proposed model offers an effective approach to prevent web-form spamming for cloud-based applications, providing solutions to the persistent challenge faced by organizations in securing their web-based operations. Further research can focus on exploring the practical implementation of the proposed model and its potential impact on securing web-based operations.'}\n","{'text': \"In chapter 4, I posed the question why the type of artificial intelligence methods we have seen so many examples of in this book are not used more in games. I outlined a couple of potential reasons for this. One of the reasons I mentioned is that game development is a surprisingly risk-averse industry because of the hit-driven nature of the business and that the technology may not be mature enough yet. Now, after spending the past few chapters on AI methods for playing games, modeling players, and generating content, we'll revisit the question. This time we focus on the role of game design in enabling AI and, conversely, AI in enabling game design.\"}\n","{'text': 'The increasing demand for small unmanned aerial vehicles (UAVs) in logistics and rescue fields has brought with it an increased risk of collision with people and property in urban environments. However, safety regulations for small UAVs in urban areas have not been well established, and few studies have explored the potential collisions between UAVs and building structures in urban areas. In this study, experimental and numerical investigations are conducted to evaluate the damage resulting from a UAV collision with heat-strengthened glass, a widely used building exterior cladding. Commercially available UAVs were impacted into a series of glass panels at various speeds and angles. The collision processes were recorded with a high-speed camera, and the impact forces of the UAVs were measured using dynamic force sensors. A numerical model of the UAV was then developed to simulate the impacts using the finite element method and verified by comparison with the experimental results. The collision tests performed in this study are expected to provide primary data for establishing UAV safety regulations, and the verified numerical model can be applied to evaluate various collision scenarios for the different UAVs.'}\n","{'text': 'Heterogeneous Internet of Things (IoT) and multi-access mobile edge computing (MA-MEC) are believed as supporting technologies for building a smart city. The advancement and flourish of IoT are facilitating the entry of human society into the Internet of Everything era, which lay the foundation of the smart city. To address the conflict between computation capability and low-cost mobile devices in IoT, the MA-MEC is available for supporting the resource-limited and computation-sensitive services and applications by computation offloading and distributed content delivery/caching. However, deploying cloud computing capability within the radio access network may face serious security threats, which stem from not only the existing technologies and networks but also the MA-MEC-based IoT itself. Therefore, in this paper, the solutions to address the security threats are investigated from physical layer perspectives, since physical layer security technologies have the advantages of achieving perfect secrecy, low-computational complexity, and resource consumption, and good adaptation for channel changes. Specifically, we investigate the secure wiretap coding, resource allocation, signal processing, and multi-node cooperation, along with physical layer key generation and authentication, to cope with the emerging security challenges. Finally, the paper is concluded with some possible future research directions.'}\n","{'text': 'We consider an orthogonal frequency division multiple access (OFDMA)-based Multi-access Edge Computing (MEC) system, consisting of one serving node and multiple users each with an inelastic computation task of a non-negligible task processing duration and a non-negligible computation result size. A joint uplink/downlink sub-channel, bit and time allocation problem is investigated to minimize the energy consumption, which happens to be a very challenging non-convex mixed integer nonlinear programming (MINLP) problem. We equivalently convert it into a convex MINLP problem by using the McCormick envelope, and develop two low-complexity algorithms to obtain two suboptimal solutions. Specifically, one is based on continuous relaxation with greedy rounding and the other one bases on penalty convex-concave procedure. Simulation results show the advantages of our suboptimal solutions.'}\n","{'text': 'This paper presents an assessment of e-Social activity in psychiatric patients utilizing Fourier series, informatics, data models, and various tools. The proposed method involves feature extraction and analysis of circadian rhythm to identify patterns and irregularities in e-Social activity. Furthermore, mixture models are utilized to cluster patients with similar social behavior patterns. The results demonstrate the potential for utilizing e-Social activity as a tool for psychiatric assessment and treatment. The study highlights the importance of data modeling and informatics in psychiatry and emphasizes the need for new tools and methods for analyzing complex data. Overall, this research provides insights into the potential of utilizing e-Social activity as a non-invasive and objective approach towards understanding psychiatric conditions.'}\n","{'text': 'With the rapid development of technology and the widespread use of social networking, location-based social network (LBSN) has become an essential tool in the tourism industry for conducting market research and examining tourist activities. This study aims to explore the sequential activity pattern of tourists through LBSN using trajectory and data mining tools. The results showed that tourists tend to visit landmarks within urban areas during the day and engage in social activities at night. The study highlights the importance of leveraging LBSN to gain insights into tourist behaviors, which can be used for a better understanding of the tourist market and to improve tourism products and services. The findings of this study could also offer practical implications for industries to create personalized tourism products and to promote sustainable tourism development.'}\n","{'text': 'Unmanned aerial vehicle (UAV) millimeter-wave (mmWave) communication is emerging as a promising technique for future networks with flexible network topology and ultra-high data transmission rate. Within such full-dimensionally dynamic mmWave network, beam-tracking is challenging and critical, especially when all the UAVs are in motion for some collaborative tasks that require high-quality communications. In this paper, we propose a fast beam tracking scheme, which is built on an efficient position prediction of multiple moving UAVs. In particular, a Gaussian process based machine learning scheme is proposed to achieve fast and accurate UAV position prediction with quantifiable positional uncertainty. Based on the prediction results, the beam-tracking can be confined within some specific spatial regions centered on the predicted UAV positions. In contrast to the full-space searching based scheme, our proposed position prediction based beam tracking requires little system overhead and thus achieves high net spectrum efficiency. Moreover, we also propose a practical communication protocol embedding our beam-tracking scheme, which monitors the channel evolution and triggers the UAV position prediction for beam-tracking, transmit-receive beam pair selection and data transmission. Simulation results validate the advantages of our scheme over the existing works.'}\n","{'text': \"Recently, in addition to autonomous vehicle technology research and development, machine learning methods have been used to predict a driver's condition and emotions in order to provide information that will improve road safety. A driver's condition can be estimated not only by basic characteristics such as gender, age, and driving experience, but also by a driver's facial expressions, bio-signals, and driving behaviours. Recent developments in video processing using machine learning have enabled images obtained from cameras to be analysed with high accuracy. Therefore, based on the relationship between facial features and a driver's drowsy state, variables that reflect facial features have been established. In this paper, we proposed a method for extracting detailed features of the eyes, the mouth, and positions of the head using OpenCV and Dlib library in order to estimate a driver's level of drowsiness.\"}\n","{'text': 'In this paper, a novel direction-of-arrival (DOA) estimation algorithm is proposed for noncircular signals with nonuniform noise by using the unitary matrix completion (UMC) technique. First, the proposed method utilizes the noncircular property of signals to design a virtual array for approximately doubling the array aperture. Then, the virtual complex-valued covariance matrix with the unknown nonuniform noise is transformed into the real-valued one by utilizing the unitary transformation to improve the computational efficiency. Next, a novel UMC method is formulated for the DOA estimation to remove the influence of nonuniform noise. Finally, the DOA without the influence of the unknown noncircularity phase is obtained by using the modified estimation of signal parameters via rotational invariance technique (ESPRIT). Especially, for handling the coherent sources, the forward-backward spatial smoothing technique is utilized to reconstruct a full-rank covariance matrix so that the signal subspace and the noise subspace can be correctly separated. Due to utilizing the extended array aperture and the unitary transformation, the proposed method can identify more sources than the number of physical sensors and provides higher angular resolution and better estimation performance. Compared with the existing DOA estimation algorithms for noncircular signals, the proposed one can effectively suppress the influence of the nonuniform noise. The simulation results are provided to verify the effectiveness and superiority of the proposed method.'}\n","{'text': \"This paper describes fast versions of model predictive control (MPC) algorithms and their practical implementation using the STM32 ARM microcontroller. Two MPC algorithms are considered: Dynamic Matrix Control (DMC) and Generalized Predictive Control (GPC). Computationally efficient Fast DMC (FDMC) and Fast GPC (FGPC) algorithms are derived in which the values of the manipulated variables are calculated from uncomplicated explicit formulas. To demonstrate effectiveness of the discussed algorithms, two emulated benchmark processes and a laboratory servo are considered. The influence of some tuning parameters on algorithms' calculation time is studied. It is shown that for short sampling periods the classical DMC and GPC algorithms fail to work since calculations last longer than the sampling period, which is unacceptable. Conversely, the FDMC and FGPC algorithms require only hundreds or tens of microseconds and single microseconds, respectively. Hence, proposed algorithms may be used for very fast processes, with very short sampling time.\"}\n","{'text': 'The Internet of Things (IoT) and Cyber-Physical Systems (CPS), are generating wide spread data. The success of these trio depends on a well performed cyber-communication infrastructure. This necessitates improving the performance of the cyber-communication internetwork; this performance improvement includes optimization of network techniques as well as the security of the cyber-network. Internet infrastructure has been upgraded to higher level ever than before, where we are enjoying technologies like fibre, 10-gig ethernet and even 100-gig ethernet, but there is no guarantee of communication in the cyber space, internet still providing packet delivery on \"best effort\" basis. On the other side, cyber hackers are targeting big physical infrastructures, industrial hardware in addition to the financial institutions. Therefore, it has become vital to address secure and faster data communications, in order to improve the Performance of the Internetwork.'}\n","{'text': 'Cloud robot technology is to transfer the computing power of the robot to the cloud. The tasks are distributed to computing nodes for execution, but the previous scheduling algorithms have large task execution makespan, load imbalancing for scheduling, and low QoS, resulting in low execution efficiency. In order to efficiently allocate tasks and improve the performance of cloud robot systems, this paper proposes a multi-task scheduling algorithm based on Min-Min algorithm in cloud computing. Through multi-task simulation experiments, the algorithm can deal with complex multi-task scenarios of cloud robots, effectively improve the performance and QoS of cloud robots, solve the problem of load imbalancing in cloud robot systems, and realize the demand for priority processing tasks.'}\n","{'text': 'Fractional amplitude of low-frequency fluctuation (fALFF) can reflect the intensity of spontaneous neuronal activity. Feature selection on functional magnetic resonance imaging (fMRI) data combined with fALFF can be well used to study the pathology of attention deficit hyperactivity disorder (ADHD) and assist in its diagnosis. However, the unsatisfactory effect of feature selection limits the study of ADHD. In this study, a novel method is proposed to classify ADHD individuals and neurotypicals. This work introduces multiple linear regressions for reduction of confounding effects. After that, fALFF combined with principal component analysis (PCA), Shannon entropy (ShEn), and sample entropy (SampEn) are used to construct features, and a reliable RELIEF (R-RELIEF) algorithm is proposed to find the most prominent features. Public ADHD-200 dataset is used in this study to evaluate our method. The results in this study suggest that fALFF is a reliable fMRI marker for investigation of ADHD, and R-RELIEF shows good performance compared with RELIEF algorithm. Moreover, fALFF of many brain regions are found to differ between ADHD and neurotypicals, thus coinciding with the results of previous studies.'}\n","{'text': 'The study of silence localization in the brain is an important area of research in the field of neurosciences. The ultimate goal of this research is to develop a mathematical model that can accurately estimate the location of silent regions in the brain using non-invasive techniques such as electroencephalography (EEG) and magnetic resonance imaging (MRI). The scalp is a crucial region for the estimation of silence localizations in the brain, as it contains a wealth of information that can be used to detect the underlying neuron activity. By analyzing the brain activity, researchers aim to create a model that can accurately detect and locate silent regions in the brain. The development of such a model could have important implications for the diagnosis and treatment of various neurological disorders. Advances in the field of \"brain modeling\" are critical for improving our understanding of the human brain and identifying new therapeutic targets for neurological diseases.'}\n","{'text': 'The last decade has seen an explosion of research in network controllability. The present article reviews some basic concepts, significant progress, important results and recent advances in the studies of the controllability of networked linear dynamical systems, regarding the relationship of the network topology, node-system dynamics, external control inputs and inner dynamical interactions with the controllability of such complex networked dynamical systems. Different approaches to analyzing the network controllability are evaluated. Some advanced topics on the selection of driver nodes, optimization of network controllability and control energy are discussed. Potential applications to real-world networked systems are also described. Finally, a near-future research outlook is highlighted.'}\n","{'text': \"With abundant spectrum resources, the millimeter-wave (mmWave) band has emerged as a leading candidate for fulfilling the requirements of faster data rates and lower latency for future automotive networks. However, the incorporation of mmWave directional transmission and diversely vehicular mobility triggers frequent beam realignment, thus largely increasing the beamforming overhead and leaving less time for data transmission. In this paper, an energy-angle domain access and transmission frame structure is investigated for mmWave vehicle-to-everything communications, which consists of two phases, initial access and data transmission. Considering the transmission interruption issue caused by blockage, we propose an energy-angle domain initial access scheme, by which the signals are labeled by different directions with multi-power level. Several performance metrics are subsequently obtained to evaluate the proposed scheme. Subsequently, the access time-throughput tradeoff problem is mathematically formulated, and it is demonstrated that optimal access time exists, yielding the highest throughput for data transmission. Moreover, a binary-decision beam tracking scheme is designed to maintain the directional link connection in the data transmission phase. To verify our stance's accuracy and our proposed strategies' superiority, numerical evaluations and simulations were conducted.\"}\n","{'text': 'This paper presents a methodology for detecting work zones in SHRP 2 NDS videos using deep learning based computer vision. The proposed approach utilizes a combination of data models, deep learning techniques, and task analysis to accurately identify work zones in videos captured by cameras on roadways. The training phase involves collecting and annotating a large dataset of SHRP 2 NDS videos, which is used to develop a deep learning model capable of accurately detecting the presence of a work zone. The model is then evaluated on a separate test set to measure its performance. The results of this study show that it is possible to accurately detect work zones in SHRP 2 NDS videos using deep learning, achieving a high level of accuracy in the task of identifying these zones. This approach can be used to automate the detection of work zones on roadways, and pave the way for more efficient and effective management of these zones in the future.'}\n","{'text': 'This paper proposes a combination of color and texture features along with an adaptive boosting classifier for identifying pedestrian image attributes. The feature extraction method used is the color histogram and Multi Block Local Binary Pattern (MB-LBP). This is suitable with the dataset that is trained and tested in this research, PETA dataset since this dataset has various size, a point of view, resolution, etc. Color histogram and MB-LBP capture two kinds of information in the pedestrian images, i.e., color and texture information. The Adaboost is used as a classifier for the attribute identification, and for the weak classifier, the decision stump is applied. The performance accuracy of texture, color, and the combination of both features is compared in the attribute identification process. For the experiments conducted, the number of bins for the color histogram and MBLBP are 8, 16, and 32. The results of the experiments showed that the combination of both features, color histogram and MB-LBP, achieved the highest accuracy in attribute identification.'}\n","{'text': 'The article focuses on enhancing the performance of direct model reference adaptive control (MRAC) for linear time-invariant (LTI) plants. Three new solutions to the problem are proposed and involve the recently introduced dynamic regressor extension and mixing (DREM) estimator modified and aggregated with standard gradient-based adaptation algorithm driven by augmented error. It is shown that dynamic extension of regressor dramatically improves tracking and parametric error convergence and generalizes existing results of MRAC. Comparatively, the proposed adaptive control algorithms demonstrate superior performance in simulated scenarios.'}\n","{'text': 'With the increasing predominance of Internet of Things (IoT) applications, a considerable amount of geospatial information has been accumulating from various sources. In addition to the common features of big data, the unique characteristics of spatial data make the treatment of big spatial data even more complicated. To facilitate developers creating big spatial data applications, it is imperative to develop new technologies to efficiently handle the massive amount of big spatial data. Given this impetus, the Korean government launched a five-year national project involving businesses, government, and the research community. The goal is to develop a platform for efficiently storing, extracting, processing, and analyzing geospatial big data. This paper explains the expected outcome from the project including the overall architecture of the platform, along with its current status and future direction.'}\n","{'text': 'This paper proposes an adaptive traffic signal control mechanism for intelligent transportation based on a consortium blockchain. The use of blockchain technology allows for secure and transparent communication between different entities involved in the transportation system, while ensuring the privacy of the users. Encryption techniques are also used to ensure the confidentiality of the data transmitted through the network. The proposed mechanism focuses on optimizing traffic flow by adjusting traffic signals in real-time. It leverages vehicular ad hoc networks to collect data on traffic patterns, which are then analyzed to make intelligent decisions on traffic signal control. The adoption of a consortium blockchain ensures the collaborative and secure management of the road network. The proposed mechanism presents a scalable and efficient way of managing traffic, improving transportation efficiency and reducing congestion on roads.'}\n","{'text': 'Energy harvesting wireless communication is one of the most recent advances in communications techniques. The main benefits of energy harvesting are the increased convenience and the improved energy efficiency in communications. Energy harvesting communications and green communications are related to each other but do not belong to each other. Energy harvesting wireless communication has a lot of interesting applications. One main application is wireless sensor networks. These applications mainly use energy harvested from the ambient energy sources, such as the sun and the wind. In other applications, wireless energy harvesting from a dedicated wireless power transmitter can also be used, such as cellular communications. Among these applications, the fifthâ\\x80\\x90generation (5G) mobile communications system is a good use case. Finally, the chapter presents an overview of this book. The book investigates the effect of energy harvesting and new designs based on energy harvesting for both legacy systems and recently proposed systems.'}\n","{'text': 'In this brief, the coordinated path-following control for multiple nonlinear autonomous vehicles connected by digital networks is studied. To compensate for the time delays of the network actively, a novel networked predictive control strategy is proposed. Compared with existing networked control strategies, the control strategy proposed in this brief admits advantages such as high computational efficiency, robustness to disturbances, and relaxed restriction on the communication topology. The theoretical analysis of the proposed method is given and the conditions to achieve the control objectives are derived. Finally, the experiments are implemented to validate the effectiveness of the proposed method.'}\n","{'text': \"We investigate the design of a Mobile Edge Computing (MEC) system in which self-interested users minimize their own costs and a MEC service provider attempts to maximize its revenue. We introduce a third-party platform that works as an intermediary to facilitate the service transaction between the users and the provider. The platform collects MEC server information and discloses that to users; users rely on their user agent apps to place their application jobs on edge computing servers during their stay in the system. We propose a dynamic programming algorithm for a user to minimize his/her own cost and an efficient heuristic algorithm for the platform to minimize the cost of all users by optimally scheduling the admission of users' jobs and still allowing users to make independent optimal decisions. We have demonstrated the effectiveness of these algorithms via extensive simulations based on an empirical Google cloud dataset and a Web file dataset. Furthermore we model the interaction between users and a provider as a game, referred to as User-Provider Game. We find that when the provider always attempts to maximize its own revenue by adjusting the prices of edge servers, the interaction will lead to an unstable system with severe oscillation and degraded performance. To address the issue, we propose a better response algorithm for the provider which stabilizes the system and results in high performance. This paper sheds light on this important area of MEC, and points a promising direction to further investigate and design an effective MEC system of independent self-optimizing mobile users.\"}\n","{'text': \"This study aimed to investigate the effects of irreversible olivary system lesion on the gain adaptation of optokinetic response eye movement through a mouse model-based study. The research utilized adaptation models to simulate the gain adaptation process and explored the role of synapses in this process. The cerebellum, which is responsible for the fine-tuning of motor movements, was also investigated in relation to the optokinetic response. The study focused on the effect of lesions on the gain adaptation process, and results showed that irreversible olivary system lesions negatively impacted the gain adaptation process. These findings suggest that the olivary system plays a crucial role in the gain adaptation of optokinetic response eye movement, and its impairment can hinder the learning and training process. Overall, this study provides insights into the mechanisms and processes involved in optokinetic response eye movement and their relation to the brain's olivary system.\"}\n","Processing batch 10/63\n","{'text': \"The Internet of Things (IoT) is a newly emerging field with a vision of connecting `things', human and machines together making them an integral part of internet. The entire world is moving towards modernization and automation which may result in excessive pollution of environment. Determining the air quality is a prime need of the hour. This paper deals with the development of pollution monitoring system with deployment of intelligent sensors. Monitoring the gas leakage level from any part of the globe can be achieved by integration of big data to the Google Cloud via web servers. Analysis of the data is simplified thereby enabling ease of monitoring. Alerts can be triggered in case of drastic deterioration of air quality. The proposed method finds application in industry and also in monitoring of pollution caused by vehicles.\"}\n","{'text': 'Several effective methods of traffic-sign recognition have been around for a lot of time now, starting with recognition using conventional Image Processing techniques which are very generic and sluggish. However, majority of state-of-the-art detectors are based on Convolutional Neural Networks (CNNs) which have been evidenced to be de facto leader in image processing and computer vision research over the past decade. This has been made possible by datasets being easily available, organized and maintained with German Traffic Sign Recognition Benchmark being of relevance. CNNs require colossal amounts of data to work well; unfortunately, no traffic-sign dataset exists in Pakistan to enable any detector based on CNNs. This paper presents an approach revolving around transfer learning whereby, a model is pre-trained using German Traffic-sign Dataset and is then fine-tuned over Pakistani Dataset: which is collected across Pakistan and amounts to 359 images. Preprocessing and regularization are used to improve overall performance of the model. The fine-tuned model reached training accuracies of around 41% with minimal overfitting. This presents an encouraging outcome as even with a dataset which is comparatively meager, we have achieved a respectable accuracy, something which can be built upon and bettered by boosting number of images collected.'}\n","{'text': \"With the rapid advances of wireless technologies and popularization of mobile devices, edge computing boosts mobile social networks (MSNs) to allow mobile users to deliver, share, and exchange contents with each other. In particular, with edge caching, various content services can be provided to mobile users with improved Quality-of-Experience (QoE). However, edge caching is vulnerable to cache pollution attack (CPAttack), degrading content delivery. To tackle these problems, in this paper, we propose a hidden Markov model (HMM) based detection scheme against CPAttack in edge computing enabled MSNs. Specifically, we first present the CPAttack model with the observations of malicious behaviors. According to the CPAttack model, the caching state of each edge device is characterized in terms of request rate and cache hit rate. The HMM is exploited to detect the CPAttack with observation sequence of caching states. The simulation results demonstrate that the proposed scheme can efficiently improve edge devices' capability to detect CPAttack.\"}\n","{'text': 'Prior research has used reinforcement-learning (RL) models like Expectancy-Valence-Learning (EVL) and Prospect-Valence-Learning (PVL) to investigate human decisions in choice games. However, currently little is known on how RL models would account for human decisions in games where people face a collective risk social dilemma (CRSD) against societal problems like climate change. In CRSD game, a group of players invested some part of their private incomes to a public fund over several rounds with the goal of collectively reaching a climate target, failing which climate change would occur with a certain probability and players would lose their remaining incomes. Next EVL and PVL models were calibrated to human decisions across two between-subject conditions in CRSD (Info-all: N=120; No-Info: N=120), where half of the players in each condition possessed lesser wealth (poor) compared to the other half (rich). A symmetric Nash model was also run in both conditions as a benchmark. In Info-all condition, players possessed complete information on investments of other players after every round; whereas, in the No-info condition, players did not possess this information. Our results showed that for both rich and poor players, the EVL model performed better than the PVL model in No-info condition; however, the PVL model performed better than the EVL model in the Info condition. Both the EVL and PVL models outperformed the symmetric Nash model. Model parameters showed reliance on recency, reward-seeking, and exploitative behaviours. We highlight the implications of our model results for situations involving a collective risk social dilemma.'}\n","{'text': 'Unmanned Aerial Vehicles (UAVs) have recently been proposed as flying base stations, called UAV-BSs, to provide reliable connections and extend the coverage of the existing wireless networks. The mobility of UAV-BSs leads to a dynamic network environment, in which the global network information is hard to be obtained. Since frequent information exchanges cause huge signaling overheads, it is difficult to deploy centralized algorithms in UAV networks. Hence, we propose a distributed deep reinforcement learning (DRL) framework for multi-user access control in UAV networks. In particular, each user makes its own access decisions independently based on the local network information, and maximizes the long-term throughput while avoiding frequent handovers. Simulation results have validated the effectiveness of the proposed algorithm and shown the superiority of the proposed DRL framework over the state of arts.'}\n","{'text': 'In this work, we consider the problem of inferring links in a communication network, using limited, passive observations of network traffic. Our approach leverages transfer entropy (TE) as a metric for quantifying the strength of the automatic repeat request (ARQ) mechanisms present in next-hop routing links. In contrast with existing approaches, TE provides an information-theoretic, model-free approach that operates on externally available packet arrival times. We show, using discrete event simulation of a wireless sensor network, that the TE based topology inference approach described here is robust to varying degrees of connection quality in the underlying network. Compared to an existing approach which uses the linear regression based formulation of Granger Causality for network topology inference, our approach has better asymptotic time complexity, and shows significant improvement in network topology reconstruction performance. Our approach, though sub-optimal, also has better time complexity, while still retaining reasonable performance, compared to a causation entropy based optimal algorithm proposed in the literature.'}\n","{'text': 'The Internet of Things (IoT) is about connecting dynamically billion of devices to the Internet. This large-scale and dynamic topology is very challenging for IoT deployment and management. Software-Defined Networking (SDN) has been applied more and more in recent years as a solution for IoT challenges. The SDN concept of decoupling the control plane from the data plane promotes logically centralized visibility of the entire network and enables the applications to innovate through network programmability. At the same time, there are still some open issues, such as scalability in large IoT environments that include several devices. To face scalability challenges, SDN proposes distributed controllers as a solution to decentralize the control plane while maintaining the logically centralized network view. However, SDN-based architecture, that provides the flexibility and scalability, still lacks the smart or intelligent management to self-adapt to possible dynamic network topology changes. To over-come such issues, we propose a framework that answers automatically the business demands and makes the network self-adaptive. The topology deployment decision is made based on information that the controller gives. So for making sure that our proposed framework gives the best results, we have to study first the topology discovery mechanism in a distributed controller. In this paper, we introduce a self-adaptive management framework of SDN controllers for highly dynamic IoT networks. We evaluate performances of the two most popular distributed SDN controllers (i.e. ONOS and ODL) in a realistic scenario where the network topology changes dynamically. Results show the outperforming of ONOS compared to ODL in discovering the highly dynamic IoT network.'}\n","{'text': 'This paper explores the theme of transparency in connected objects, such as those found in the fields of virtual reality, the Internet of Things, ubiquitous computing, computers, and smart phones. Specifically, it discusses the importance of transparency as a means of building trust and increasing user engagement. The authors argue that, while these technologies have the potential to transform our lives in positive ways, transparency is often overlooked, leading to user skepticism and disengagement. To combat this, the article proposes a series of strategies for building transparency into these technologies, with a particular focus on the ways in which companies like Google can be proactive in this regard. The authors also discuss the challenges associated with implementing these strategies, including the difficulty of designing interfaces that are both transparent and user-friendly. Overall, this paper is an important contribution to the ongoing conversation about how we can create more trustworthy and engaging connected objects that are respectful of user privacy and agency.'}\n","{'text': 'A novel hybrid method of spatially filtered finite-difference time-domain (SF-FDTD) scheme and subgridding technique is presented to analyze the multiscale objects. Because of the controllable stability of the SF-FDTD scheme, which is applied in the subgrid region, the uniform temporal increment can be employed in the whole simulation region. Hence, the need for temporal interpolation of the field components is eliminated at the coarse-dense grids connecting boundary. In addition, by selecting the appropriate spatial interpolation field points in the Yee cells and only eliminating the unstable frequency domain magnetic fields, the influence of the filtering operation at the connecting boundary is removed. The simulation results are presented to validate the accuracy and efficiency of the hybrid method.'}\n","{'text': \"In terms of the accumulation of historical data of the power system, China's power grids have accumulated a great number of dispatching and operating data which contains different voltage levels. Online safety and stability analysis conduct a comprehensive system assessment every 15 minutes, including power flow, short circuit, static safety analysis, voltage stability, transient stability, small disturbance stability, limit transmission power, and scheduling assistance decision-making, and the calculation data and result data are about 1G. Based on the six-month online historical data accumulated by a provincial power grid, this paper studies the characteristics of the actual power grid security and stability, and proposes a system stability analysis method based on the online security analysis of historical resources. At the same time, Considering the time-varying characteristics of the power system, an operation rule extracting method was proposed. Firstly, based on the correlation analysis methods, the corresponding features are selected for each type on the hierarchical grid. Then, a power grid security risk assessment system is established based on load ratio, and line limitation. Finally, this article automatically discovers the characteristics and rules of grid dispatching operations from numerous online data, provides a theoretical basis for operational mode and scheduling decisions, further improves the ability of large-scale grid dispatching and online safety analysis, and enhances the ability of power grids to resist the influence of external factors on safe and stable operations ability and has important practical application value.\"}\n","{'text': 'We propose an ID/Locator resolution system for super wide area wireless mesh networks constructed using Delaunay overlay networks. Unlike conventional mobile ad-hoc network protocols, the proposed system does not use flooding to spread the locator notification messages of each node. The proposed method sends one-hop locator notifications on skip links such as skip graphs. The proposed system realized scalability by controlling the route, frequency, and storing locations of the locator notification message. Specifically, when the number of nodes increases, the average load on communication links and the message database of each node are approximately O(log n), where n is the total number of nodes. The scalability of the proposed method is confirmed through simulations.'}\n","{'text': 'In a typical Internet of Things (IoT) application where a central controller collects status updates from multiple terminals, e.g., sensors and monitors, through a wireless multiaccess uplink, an important problem is how to attain timely status updates autonomously. In this paper, the timeliness of the status is measured by the recently proposed age-of-information (AoI) metric; both the theoretical and practical aspects of the problem are investigated: we aim to obtain a scheduling policy with minimum AoI and, meanwhile, requires little signaling exchange overhead. Toward this end, we first consider the set of arrival-independent and renewal policies; the optimal policy thereof to minimize the time-average AoI is proved to be a round-robin policy with one-packet (latest packet only and others are dropped) buffers (RR-ONE). The optimality is established based on a generalized Poisson-arrival-see-time-average theorem. It is further proved that RR-ONE is asymptotically optimal among all policies in the massive IoT regime. The AoI steady-state stationary distribution under RR-ONE is also derived. An implementation scheme of RR-ONE is proposed which can accommodate dynamic terminal appearances with little overhead. In addition, considering scenarios where packets cannot be dropped, a Lyapunov optimization-based max-AoI-weight policy is proposed which achieves better performance compared with state-of-the-art.'}\n","{'text': \"This paper deals with near magnetic field characterization of power electronic modules. The purpose is to relate near-field (NF) measurement to switching behavioral characteristics. An elementary magnetic sensor is presented and its characterization is detailed. Isolated antenna simulations are computed, thanks to an equivalent lumped parameter model of the antenna. Experimental characterizations are also provided to be compared to simulations. Following that, the characterized antenna is integrated into a specific power electronic device. Measurements of the near-field allow us to establish magnetic field maps of the device under test. The paper discusses time and frequency analysis of the sensor's output data, based on current measurements and magnetic simulations of the power electronic device. Finally, NF measurement enables access to switching details, disturbance propagation paths, and radiation distribution of a power electronic module.\"}\n","{'text': 'Wireless Sensor Networks (WSNs) have been recognized as a promising communication technology for the Internet of Things (IoT). In particular, smart grid applications rely on WSNs for enabling pervasive monitoring and control of the electric grid. However, these applications are commonly deployed in harsh environments that adversely impact the reliability of low-power wireless links in WSNs. Efficient link quality estimation has been shown as a prerequisite to overcome link unreliability. Several WSN Link Quality Estimators (LQEs) have been proposed in the literature. However, there is a lack of real world experimentations that investigate their adequacy to assess low-power links in smart grid environments. To fill this gap, this paper presents a thorough experimental study of representative LQEs in a smart grid distribution substation. Both single and composite LQEs are evaluated in terms of reliability, stability and reactivity, by analyzing their statistical behavior. This study would help system designers choose the most appropriate estimators for smart grid environments. Especially, it shows that composite LQEs, such as Opt-FLQE, F-LQE, and four-bit, are more reliable than single LQEs, including PRR, WMEWMA, and RNP. Further, experimental results show that Opt-FLQE is found to be the most reliable estimator, F-LQE, PRR, and WMEWMA are the most stable estimators, while Opt-FLQE, RNP, and four-bit are the most reactive LQEs.'}\n","{'text': \"There has been a shift to technology-enhanced learning. New technology enables English teachers to expand learning with more ample resources and dynamic activities. Technology-enhanced learning has diversified learning activities in classroom or outside of classroom (van der Zwaard & Bannink, 2016). Scholars found drama to be an effective pedagogical tool to enhance children's language learning, communication, and personal development (Brouillette, 2010). The integration of drama and digital technology provides situational and experiential learning which can improve students' learning attainment. The researchers conducted a digital theater project and attempted to examine the effect of this integration approach on English acquisition and learning attitudes. The pre- and post-language tests and survey were devised for this investigation. A repeated measure was performed to see the effect and retention of the language. The results showed that the digital drama theater project had a significant impact on English learning. Children were able to retain the majority of the previously learned language. Their motivation, confidence, and attitudes toward the digital technology were also significantly increased.\"}\n","{'text': 'Poor efficiency and long running time of existent optimization algorithms in dealing with multi-objective multi-variable community microgrid optimization have always been a concern. To address this issue, a novel layered optimization algorithm based on NSGA-II is proposed. The proposed algorithm integrates the structural feature of community microgrid and the concept of multi-agent system into the optimization process and decomposes the complex microgrid optimization into several household optimizations of smaller scale and one central microgrid optimization. The household operation is optimized first and the central microgrid optimization is solved subsequently based on the Pareto solution set of household operation problems to obtain the optimal operation mode. Simulation results demonstrate that the proposed strategy is effective in improving optimization efficiency.'}\n","{'text': 'In this paper, we investigate the trajectory tracking problem of underactuated autonomous underwater vehicles (AUVs) with input saturation. Our proposed model-free algorithm can realize high-level tracking control and stable learning by employing a novel actors-critics architecture, where a critic and multiple actors are learned to estimate the action-value function and deterministic policy, respectively. For the critic, Pseudo Averaged Q-learning, which is a simple extension to Q-learning, is proposed to calculate the target value, specifically, the action-value of next state is obtained by maximizing the average over the last multiple previous learned action-value estimates among all actors. As for the actors, deterministic policy gradient is applied to update the weights. The effectiveness and performance of the proposed Pseudo Averaged Q-learning based deterministic policy gradient (PAQ-DPG) algorithm is verified by implementation to an underactuated AUV. And the results demonstrate high-level tracking control accuracy and stability of learning of PAQ-DPG algorithm. Besides, under our proposed actors-critics framework, increasing the number of actors will further improve the performance.'}\n","{'text': 'This paper discusses the modeling and design of a dynamic exoskeleton system that can accommodate various speeds for hemiplegic patients. The system uses a combination of torque, mathematical model, computational modeling, kinematics, gears, and DC motors. The overall goal is to provide an efficient and safe exoskeleton system that can assist hemiplegic patients in their daily activities. A mathematical model is developed to simulate the movements of the exoskeleton, including the angle of joints, torque, and velocity of the DC motors. Results show that the system can successfully compensate for the reduced function of the hemiplegic limbs, allowing patients to move with greater ease and reducing the risk of secondary injuries. The overall design of the system is optimized for efficiency, safety, and patient comfort, with particular attention paid to reducing weight and increasing flexibility. Future work will involve testing the prototype exoskeleton in a clinical setting to assess its effectiveness and refine its design.'}\n","{'text': 'The Internet of Things (IoT) supports a wide range of applications including smart cities, traffic congestion, waste management, structural health, security, emergency services, logistics, retails, industrial control, and health care. IoT is mega-technology that can establish connection with anything, anyone, at any time, place, service on a platform and any network. It has a great impact on the whole block chain of businesses, smart objects and devices, systems and services that are enabled by heterogeneous network connectivity and is developed as a smart pervasive framework of smart devices. IoT devices are in use in many fields, they connect to complex devices, interface with hostile environments and are deployed on various uncontrolled platforms, therefore faces many security issues and challenges. Since the IoT offers a potential platform for integrating any type of network and complex system it could encounter vulnerabilities inherent to the individual systems which are available within the integrated network. This research paper is a study of the security issues of the individual systems responsible for IoT interconnection and their impact towards the integrated IoT system.'}\n","{'text': 'Local matching approaches remain prevalent tools in real-time applications. Mismatch is a common situation in stereo vision, especially in local approaches. In this paper, we propose a truncated majority voting method (TMVM) to discriminate and reduce mismatches for local matching approaches in stereo. Our experiments using the Middlebury benchmark demonstrate that the proposed method can effectively identify and decrease mismatches while maintaining real-time capabilities.'}\n","{'text': 'Motor imagery brain-computer interfaces (BCIs) can control external machines with neurophysiological signals during limb movement imagination without real movements. An electroencephalography (EEG)-based motor imagery task has notable characteristics of event-related (de) synchronization (ERD/ERS) in specific frequency bands, including alpha and beta rhythms in the sensorimotor area. Based on this phenomenon, motor imagery features are extracted typically using common spatial patterns (CSPs). However, some researchers have reported that ERD features have severe inter-subject variation. In this study, we investigated the correlation between various ERD features and classification accuracy during a motor imagery task. We found that ERDs may not be useful in estimating classification accuracy, although they are representative features of a motor imagery task.'}\n","{'text': 'The brain-computer interface establishes a direct communication pathway between the human brain and an external device by recognizing specific patterns in cortical activities. The principle of hybridization stands for combining at least two different BCI modalities into a single interface with the aim of improving the information transfer rate by increasing the recognition accuracy and number of choices available for the user. This study proposes a simultaneous hybrid BCI system that recognizes the motor imagery (MI) and the steady-state visually evoked potentials (SSVEP) using the EEG signals from a dual-channel EEG setting with sensors placed over the central area (C3 and C4 channels). The data processing implements a supervised optimization algorithm for the feature extraction, named the common frequency pattern, which finds the optimal spectral filter that maximizes the separability of the data by classes. The experiment compares the classification accuracy in a two-class task using the MI, SSVEP and hybrid approaches on seventeen healthy 18-29 years old subjects with various dual-channel setups and complete set of thirty EEG electrodes. The designed system reaches a high accuracy of 97.4 Â± 1.1% in the hybrid task using the C3-C4 channel configuration, which is marginally lower than the 98.8 Â± 0.5% accuracy achieved with the complete set of channels while applying the support vector classifier; in the plain SSVEP task the accuracy drops from 91.3 Â± 3.9% to 86.0 Â± 2.5% while moving from the occipital to central area under the dual-channel condition. The results demonstrate that by combining the principles of hybridization and data-driven spectral filtering for the feature selection it is feasible to compensate a lack of spatial information and implement the proposed BCI using a portable few channel EEG device even under sub-optimal conditions for the sensors placement.'}\n","{'text': 'This study improves the performance of neural named entity recognition by a margin of up to 11% in terms of F-score on the example of a low-resource language like German, thereby outperforming existing baselines and establishing a new state-of-the-art on each single open-source dataset (CoNLL 2003, GermEval 2014 and TÃ¼bingen Treebank 2018). Rather than designing deeper and wider hybrid neural architectures, we gather all available resources and perform a detailed optimization and grammar-dependent morphological processing consisting of lemmatization and part-of-speech tagging prior to exposing the raw data to any training process. We test our approach in a threefold monolingual experimental setup of a) single, b) joint, and c) optimized training and shed light on the dependency of downstream-tasks on the size of corpora used to compute word embeddings.'}\n","{'text': 'Wound closure in plant stems (after either fire or mechanical damage) is a complex, multi-scale process that involves the formation of a callous tissue (callus lips) responsible for cell proliferation and overgrowth at the injury edges, resulting in coverage of the scarred tissue. Investigating such phenomena, it is difficult to discriminate between cell-specific growth responses, associated with physiological adaptations, and cell proliferation reactions emerging from specific cambium dynamics due to changes in mechanical constrains. In particular, the effects of cell-cell mechanical interactions on the wound closure process have never been investigated. To understand to what extent callus lip formation depends on the intra-tissue mechanical balance of forces, we built a simplified individual-based model (IBM) of cell division and differentiation in a generic woody tissue. Despite its simplified physiological assumptions, the model was capable to simulate callus hyperproliferation and wound healing as an emergent property of the mechanical interactions between individual cells. The model output suggests that the existence of a scar alone does constrain the growth trajectories of the remaining proliferating cells around the injury, thus resulting in the wound closure, ultimately engulfing the damaged tissue in the growing stem.'}\n","{'text': 'MANET is a type of Ad-hoc network that has frequently changing topology due to mobility of nodes. Routing protocols that are developed for traditional wired and wireless networks does not suitable for MANET, therefore several routing protocols have been developed for MANETs. Routing protocols that have been developed for MANETs are categorized in to proactive, reactive and hybrid protocols, among those protocols Ad-hoc On-Demand Distance Vector (AODV) protocol and Dynamic Source Routing (DSR) protocol are the popular reactive routing protocols used in MANET.AODV performs better than DSR protocol. Even though AODV performs better than DSR, AODV need improvements. Researchers have identified that in order to discover routes AODV use broadcasting RREQ packets. This broadcasting process is costly in terms of delay, bandwidth. Whenever route failure occurs need to done this route discover process again. Due to this process lot of delay and overhead will occur to the data transmission. In order to minimize the effect of this RREQ broadcasting process researchers have implemented a route caching mechanism for AODV protocol by providing nodes with extra cache space, make necessary changes to the RREQ packet to carry node address and sequence number, make necessary changes to extract information and use that information whenever needed. In this modified protocol whenever route failure has occurred, node which detects a route failure try to repair route using cached routes. Simulation have been done using NS2 against AODV protocol and DSR protocol in terms of throughput, delay and packet delivery ratio, simulation results show that the modified AODV protocol performs better than the current on demand routing protocol which are AODV and DSR protocol.'}\n","{'text': 'The extra quantities of wastewater entering the pipes can cause backups that result in sanitary sewer overflows. Urban underground infrastructure monitoring is important for controlling the flow of extraneous water into the pipelines. This paper presents a path loss analysis of wireless underground communications for wastewater monitoring in urban underground IoT. In this paper, the path loss analysis of wireless underground communications in urban underground IoT for wastewater monitoring has been presented. It has been shown that the communication range of up to 4 kilometers can be achieved from an underground transmitter when communicating through 10cm thick asphalt layer.'}\n","{'text': \"This paper proposes an efficient generalized surrogate-assisted evolutionary algorithm for high-dimensional expensive problems. The main objective of this research is to optimize expensive problems using genetic algorithms and other evolutionary computation techniques. The computational modeling of this algorithm is based on prediction and partitioning algorithms, which efficiently handle large amounts of data. The algorithm's search methods aim at finding the optimal solution for these high-dimensional problems. The results of the study demonstrate the validity of this algorithm in solving a range of high-dimensional problems. The proposed algorithm presents an alternative approach to costly and time-consuming numerical simulations.\"}\n","{'text': 'In this paper, an attempt is made to develop a MATLAB based Hardware-In-Loop compatible model of a three phase cage induction motor with a provision to accommodate eccentricity fault. The major benefits of the attempted work include compatibility with commercially available real-time simulators, facilitation of testing motor control units of electric vehicles when the motor is subjected to eccentricity fault, and ability to simulate in real-time varying severities of eccentricity fault. Modeling of the eccentricity fault is made by using the widely adopted modified winding function approach. Real-time simulation of the developed model is attempted by building a MATLAB model that utilizes pre-computed inductances for real-time execution. Finally, the major challenges encountered in this attempt are presented and discussed to pave way for further research.'}\n","{'text': 'With datasets from the domestic medium blast furnace (BF) as a sample place, the contributions of multivariable features of BF system to temperature tendency prediction are analyzed based on the support vector machine and recursive feature elimination (SVM-RFE), and then prediction model of BF temperature is built. First, the initial feature sets are trained to obtain the optimal feature nested subset based on SVM-RFE. Then, the optimal feature nested subset and the current BF temperature tendency are taken as input and output respectively to build support vector machine (SVM) model, which is applied to the independent test set. Third, the optimal feature set and tendency prediction rate are obtained. The simulation results show that the complexity of high dimension data is reduced. In addition, the model can provide an accuracy of 86% in temperature tendency prediction in BF and have some practical use in online monitoring the BF temperature, and thus it has remarkable advantages in feature selection and BF temperature tendency prediction in hot metal.'}\n","{'text': 'Ultrasound (US) localization microscopy offers new radiation-free diagnostic tools for vascular imaging deep within the tissue. Sequential localization of echoes returned from inert microbubbles (MBs) with low concentration within the bloodstream reveals the vasculature with capillary resolution. Despite its high spatial resolution, low MB concentrations dictate the acquisition of tens of thousands of images, over the course of several seconds to tens of seconds, to produce a single superresolved image. Such long acquisition times and stringent constraints on MB concentration are undesirable in many clinical scenarios. To address these restrictions, sparsity-based approaches have recently been developed. These methods reduce the total acquisition time dramatically, while maintaining good spatial resolution in settings with considerable MB overlap. Here, we further improve the spatial resolution and visual vascular reconstruction quality of sparsity-based superresolution US imaging from low-frame rate acquisitions, by exploiting the inherent flow of MBs and utilize their motion kinematics. We also provide quantitative measurements of MB velocities and show that our approach achieves higher MB recall rate than the state-of-the-art techniques, while increasing contrast agents concentration. Our method relies on simultaneous tracking and sparsity-based detection of individual MBs in a frame-by-frame manner, and as such, may be suitable for real-time implementation. The effectiveness of the proposed approach is demonstrated on both simulations and an in vivo contrast-enhanced human prostate scan, acquired with a clinically approved scanner operating at a 10-Hz frame rate.'}\n","{'text': 'This paper proposes an efficient channel estimation algorithm for a PDM CO-OFDM WDM system. In wavelength division multiplexing (WDM) systems, the use of optical fibers can cause polarization mode dispersion (PMD) which is detrimental to system performance. The proposed algorithm takes into account the effects of PMD and provides a means to estimate the channel under such conditions. The algorithm has been tested and validated in simulations. The ability to accurately estimate the channel is a critical aspect of WDM systems as it allows for effective compensation of impairments in optical transmitters and receivers. This algorithm adds to the growing body of work on channel estimation in WDM systems and has the potential to improve the performance of such systems.'}\n","{'text': 'In recent years, wireless communication has become a popular technology in the field of body area networks (BANs). To increase the energy efficiency of BANs, a Media Access Protocol (MAC) named Time Division Multiple Access (TDMA) has been proposed. This protocol divides the available time into time slots and assigns each time slot to a specific node, thus reducing the chances of collisions and maximizing energy efficiency. This paper presents an innovative approach for energy-efficient communication in wireless sensor networks through an efficient TDMA-based MAC protocol for BANs. This protocol is designed to optimize the usage of energy by allowing the nodes to sleep during the idle periods, saving battery life and improving the network lifetime. The proposed protocol can effectively reduce energy consumption, enhance network performance, and improve reliability.'}\n","{'text': \"In reality, the learning effect is a phenomenon which occurs almost every where in which, the employees executing a new task will perform better eventually after fluent reiterations. The learning effect acts as a considerable function for cost reduction and maximizing the profit. The basic concept of the EOQ model is that 100% of the articles in an ordered lot are of good quality but this concept is not practically justifiable for the production process owing to product deterioration and related factors. The objective of this paper is to exhibit as to what will be the influence of trade credit financing on the ordered quantity as well as on the corresponding profit derived from the deteriorating items with imperfect quality under the learning effect. Trade-credit financing is an efficacious policy for industrial businesses to formulate selling strategies and increase their sales in order to earn more profits within the specified limits. Keeping in mind such a concept, this paper investigates the inventory model for retailers dealing with imperfect quality and deteriorating items with credit financing under the learning effect. This model optimizes the ordered quantity by maximizing the total profit and in order to exhibit as to what will be the trade credit financing's influence on the ordered quantity as well as on the corresponding profit, it deals with imperfect quality deteriorating items too under the learning effect. Mathematical models for the same have been verified with the help of numerical examples. Conclusively, sensitive analysis has been presented.\"}\n","{'text': 'The performance of salient object segmentation has been significantly advanced by using the deep convolutional networks. However, these networks often produce blob-like saliency maps without accurate object boundaries. This is caused by the limited spatial resolution of their feature maps after multiple pooling operations and might hinder downstream applications that require precise object shapes. To address this issue, we propose a novel deep modelâ\\x80\\x94Focal Boundary Guided (Focal-BG) network. Our model is designed to jointly learn to segment salient object masks and detect salient object boundaries. Our key idea is that additional knowledge about object boundaries can help to precisely identify the shape of the object. Moreover, our model incorporates a refinement pathway to refine the mask prediction and makes use of the focal loss to facilitate the learning of the hard boundary pixels. To evaluate our model, we conduct extensive experiments. Our Focal-BG network consistently outperforms the state-of-the-art methods on five major benchmarks. We provide a detailed analysis of these results and demonstrate that our joint modeling of salient object boundary and mask helps to better capture the shape details, especially in the vicinity of object boundaries.'}\n","{'text': 'This research paper proposes the development of a decision support system (DSS) for parents in Surabaya City to choose the best daycare facility for their children. The proposed DSS will be based on the Analytical Hierarchy Process (AHP) methodology and will incorporate web services to provide convenient and accessible information to users. The integration of AHP will enable parents to evaluate different daycare facilities based on a set of criteria such as safety, location, program quality and affordability. Moreover, the DSS will also employ Google Maps to assist users in locating daycare facilities within their vicinity. The proposed DSS has been designed keeping in mind the advancements in the field of informatics and the widespread use of smart phones, hence it will be compatible with mobile devices. Overall, the proposed system will be a valuable tool for parents in Surabaya City to make informed decisions about the best daycare facilities for their children.'}\n","{'text': 'In recent years, the integration of Space and Ground networks has become an important topic in the field of communication networks. However, due to the complex nature of these networks, developing a secure and efficient integration algorithm has been a challenge. This paper proposes an association analysis algorithm based on a knowledge graph that incorporates ontologies, calculus, and cognition. The algorithm focuses on addressing the security concerns that arise during the integration of Space and Ground networks, and aims to improve the overall efficiency of these networks. Satellites are the primary component of these networks, and their use requires a proactive approach to security. The proposed algorithm can help reduce the occurrences of security breaches and improve the overall security of the networks. The use of a knowledge graph provides a structured and organized approach to the integration of these networks, and can help identify potential integration issues before they arise. The results of this study show that the proposed algorithm is effective in improving the security and efficiency of Space-Ground integrated networks, and has the potential to be applied in practical settings.'}\n","{'text': 'The quasi-maximum likelihood estimator used instantaneous frequency estimates based on short time Fourier transform for polynomial phase signal parameter estimation. In this work, we are interesting in the selection of minimum number of the best instantaneous frequency estimates to use them for polynomial interpolation in the quasi-maximum likelihood estimator. Simulation results show that judicious choice of instantaneous frequency estimates improves impressively the estimator performances.'}\n","{'text': 'This paper proposes a maximum likelihood approach to masking-based speech enhancement using a deep neural network. The aim of speech enhancement is to improve speech quality in noisy environments. The proposed approach focuses on the shape of the noise distribution and is based on a maximum likelihood estimation framework. To accomplish this, a deep neural network is used to model the distribution of the clean speech signal conditioned on the noisy speech signal, and the noise distribution is estimated through noise measurement. This approach aims to minimize distortion of the clean speech signal while maximizing the signal to noise ratio. Results show that the proposed approach outperforms traditional methods in terms of speech quality and intelligibility in various noisy environments. The approach also achieves better performance with less training data, indicating its potential for practical applications.'}\n","{'text': 'Mobile Edge Computing (MEC) is a technology that provides cloud computing services with ultra-low latency and large bandwidth by placing distributed cloud computing server near each wireless base stations so that various services and caching contents are deployed close to user mobile devices. However, if a network failure occurs at a point in a wireless base station or many mobile devices are crowded at a point, the task failure rate of applications that offloaded the tasks here is increased. Therefore, users experience a low quality of experience (QoE). In this paper, we propose an optimal node selection method based on ACO (Ant Colony Optimization) to solve this problem. In the MEC environment, when mobile devices are crowded around a certain base station or when network congestion occurs, tasks are autonomously offloaded to the optimal node among the nearby nodes monitored in real time through the ACO. This provides users with low task failure rate and low latency delay despite of a lack of resources or of network congestion in a specific base station. Therefore, it provides improved QoE by lowering network delay time and task failure rate. In order to prove this, performance analysis was performed by using EdgeCloudsim. We can confirm that the proposed ACO based optimal node selection algorithm obtained better performance through lower task failure rate and delay time compared to other scenarios.'}\n","{'text': 'Ground penetrating radar (GPR) has been widely used in the field of buried object detection due to its non-destructive and high-resolution imaging capabilities. However, the interpretation of GPR images for object identification remains a challenge. This paper proposes a deep learning approach for object identification from GPR images. The proposed method utilizes time-domain analysis and finite difference methods to preprocess GPR data and extract features. Then, a neural network model is trained using a large dataset of GPR images for object identification. The proposed method achieved high accuracy in identifying buried objects from GPR images, and it was able to distinguish between objects with different permittivity values. The results suggest that deep learning can be a powerful tool for improving the accuracy and efficiency of buried object detection using GPR technology.'}\n","{'text': 'Security assurance in a computer system can be viewed as distinguishing between self and non-self. Artificial Immune Systems (AIS) are a class of machine learning (ML) techniques inspired by the behavior of innate biological immune systems, which have evolved to accurately classify self-behavior from non-self-behavior. This work aims to leverage AIS-based ML techniques for identifying certain behavioral traits in high level hardware descriptions, including unsafe or undesirable behaviors, whether such behavior exists due to human error during development, or due to intentional, malicious circuit modifications, known as hardware Trojans, without the need for a golden reference model. We explore the use of Negative Selection and Clonal Selection, which have historically been applied to malware detection on software binaries, to detect potentially unsafe or malicious behavior in hardware. We present a software tool which analyzes Trojan-inserted benchmarks, extracts their control and data-flow graphs (CDFGs), and uses this to train an AIS behavior model, against which new hardware descriptions may be tested. The proposed model is capable of detecting the specified (Trojan or Trojan-like) behavior with an accuracy of ~85% and an average false negative rate of 12.6% for Negative Selection and 12.8% for Clonal Selection.'}\n","{'text': \"Managing waste in a sustainable way is a challenge in our symbiotic society. This study focuses on developing a sustainable solution for the waste management of disposable food packaging. For the proposed solution, the designed model is an amalgam of the Internet of Things technologies together with alternative methodologies for managing in a sustainable manner the disposable food containers. Meanwhile, the solution promotes the development of localized socio-economic ecosystems for a circular economy. A blueprint has been developed based on systematic analysis of the acquired qualitative and quantitative data in addition to a pilot run in the city of Uppsala, Sweden for verifying its viability. It is found that the proposed model although tested on small scale is feasible upon consideration of the local society's habitual gestures and peculiarities.\"}\n","{'text': 'In cellular Internet of things (IoT) systems, massive low-power terminals update information status to cellular base stations to support diverse IoT applications. In this circumstance, information freshness and energy efficiency become two fundamental concerns. Except data transmissions, information updates consume additional energy for radio activation. To improve the energy efficiency, it is reasonable to aggregate the dynamically generated data. However, the reduced updates will severely deteriorate the information freshness, especially for time-critical IoT applications. To address this issue, we propose an upload scheduling scheme in this paper. Considering dynamic packet arrivals and channel conditions, the upload scheduling problem is formulated from a long-term perspective. To solve this problem, a practical online upload scheduler, named as FReshness-aware Energy efficient ScHeduler (FRESH), is proposed to minimize the update energy consumption subject to information freshness constraints. We theoretically show that FRESH can make the energy saving arbitrarily close to that of the optimal scheduling decision. Simulation results demonstrate the necessity and effectiveness of implementing FRESH for cellular IoT systems.'}\n","{'text': 'We aim for a robot capable to learn sequences of motor policies to achieve a field of complex tasks. In this paper, we consider a set of interrelated complex tasks hierarchically organized. To address this high-dimensional mapping between a continuous high-dimensional space of tasks and an infinite dimensional space of sequences of policies, we introduce a framework called \"procedure\", which enables the creation of sequences of policies by combining previously learned skills. We propose an active learning algorithmic architecture, capable of organizing its learning process in order to achieve a field of complex tasks by learning sequences of primitive motor policies. Based on heuristics of goal-babbling, social guidance, strategic learning guided by intrinsic motivation, and the \"procedure\" framework, our algorithm can actively decide on which outcome to focus and which exploration strategy to apply. We show that a simulation industrial robot can tackle the learning of complex motor policies and adapt this complexity to that of the task at hand. Owing to its exploration strategies, it can discover the levels of difficulty of the tasks, and learn the hierarchy between tasks so as to combine simple tasks to complete a complex task.'}\n","{'text': 'In the last decade, energy consumption has significantly risen within the manufacturing industry. This issue has not only considerably increased energy costs but has also posed an environmental concern among society. Consequently, many researchers have designed and developed methods so as to reduce energy consumption. From this vantage point, the aim of this research is to design a fuzzy controller to turn-off the machine when it tends to be idle for energy saving purposes. A one buffer one machine manufacturing system with random part arrival is considered in this paper. The decision of the controller is based on the real-time status of the machine, the upstream buffer level and the required production rate. The controller was tested through simulation experiments and it was observed that large amount of energy can be saved without affecting the throughput significantly. The warm-up energy which results from turning off and on machine is also considered.'}\n","{'text': \"In order to solve the problem that the accuracy of time synchronization in power consumption information collection system is insufficient, a method of clock synchronization of power users' power information acquisition terminal based on a new timing algorithm is proposed. This paper first analyzes the traditional NTP time synchronization algorithm. In view of the shortcomings of the algorithm in clock synchronization, the channel asymmetry is fully considered and the algorithm is optimized in this paper. Also, a synchronization calculation method based on minimal round trip difference of NTP is proposed. By implementing this method in the synchronized structure of electricity info-collecting acquisition terminal clock, it can be seen that the new synchronization calculation method is largely improved in both accuracy and convergence compared with older one.\"}\n","{'text': 'Deep Convolutional Neural Network has shown significant improvements in many fields of computer vision, and a series of researches are proposed to explore advanced model structures to attenuate the problem of over-fitting. In this paper, two data driven techniques are designed including SwitchNode and SwitchConnect, which employ the sparsity of deterministic data to regularize convolutional neural network models. Specifically, the proposed SwitchNode method switches from the redundant nodes which have similar activations and spatial information to new initialization nodes, while the SwitchConnect method retrains replaceable convolutional kernels. The effectiveness of the proposed data driven regularization methods has been verified by the performance gain experimented on several benchmark image classification datasets.'}\n","{'text': 'A Memory Augmented Neural Network (MANN) is an extension to an RNN which enables it to save large amount of data to a memory object which is dimensionally separated from the Neural Network. This paper introduces a new Python library based on TensorFlow to define MANNs as Python objects. In addition to the standard implementation of the MANN, this contribution proposes a modification to the head calculation which decreases the noise while searching through the memory. The paper presents two experiments concerning the proposed implementation.FirsttheMANNistrainedtobeabletostoreand reproduce a piece of data (a task with linear data connectivity), and second the MANN is trained to find a Minimum Vertex Cover of a Graph (MVCG). This task was chosen because the connectivity of the vertex in the graph, that would pose a challenge to the MANN. The tests show that he MANN has no problem learning the first task, and that it is able to find an optimal solution for the MVCG problem in most cases.'}\n","{'text': 'The deramping scheme for frequency-modulated continuous-wave (FMCW) radars provides them with a high range resolution while using a low-end analog-to-digital converter (ADC). This manuscript reviews the operation principle of FMCW radars with emphasis on the inexpensive recently-achieved phase coherence, which leads to the robust determination of the range and the radial velocities of all illuminated targets. In addition, a novel coherent deramping-based multi-FMCW radar scheme that inexpensively hybridizes several FMCW modes is mathematically analyzed. Simulations are shown to verify the theoretical framework and the suitability of the proposed minimum-hardware radar architecture to enhance the performance of cost-effective short-range radar systems.'}\n","{'text': \"In this paper, we study the offloading problem in a mobile edge computing (MEC) network consisting of two-tier UAV. The high-altitude platform unmanned aerial vehicle (HAP-UAV) is equipped with a MEC server to complete the computing tasks of the low altitude platform unmanned aerial vehicle (LAP-UAV). We propose a multi-leader multi-follower Stackelberg game to formulate the two-tier UAV MEC offloading problem. As the leaders of the game, the HAP-UAVs optimize their pricing by considering the behavior of their competitors to maximize their revenue. Each LAP-UAV selects the best computing tasks offload strategy to minimize latency. From this perspective, the stochastic equilibrium problem of equilibrium program with equilibrium constraints (EPEC) model is proposed to develop the optimal supply strategies for HAP-UAVs to maximize their profits and minimize LAP-UAVs' cost. Simulation results show that the offloading delay of LAP-UAVs can be reduced by the proposed scheme.\"}\n","{'text': 'We address the problem of security for general partially observed linear stochastic systems, where some of the sensors and actuators may be malicious. We consider multiple-input-multiple-output linear stochastic systems that are under attack, where an arbitrary subset of its sensors and actuators are â\\x80\\x9cmalicious.â\\x80?A malicious sensor need not report its measurements truthfully, and a malicious actuator need not apply inputs in accordance with the prescribed control policy. For any such system, we show that there exists a decomposition of the state space into two orthogonal subspaces, called the securable and the unsecurable subspaces, and design a test that can be used by the honest sensors and actuators, such that if the malicious activity is to remain undetected by this test, then the covariance of the projection of the state estimation error of the honest nodes on the securable subspace remains at its designed value regardless of what attack strategy the malicious sensors and actuators choose to employ. This test therefore guarantees that the malicious nodes can degrade the state estimation performance only along the unsecurable subspace of the linear dynamical system.'}\n","{'text': 'This paper investigates the relationship between the Cyclic Wiener Filter (CWF) and Fractionally Spaced Equalizers (FSEs) in linear systems. Both CWF and FSEs are adaptive algorithms used for channel estimation and equalization in communication systems. The focus is on the effectiveness of CWF and FSEs in Phase Shift Keying (PSK) and Quadrature Amplitude Modulation (QAM) systems. The performance of these algorithms is analyzed based on estimation accuracy and bit error rate (BER). The results show that CWF outperforms FSEs in terms of estimation accuracy, especially in the presence of strong interference. However, FSEs perform better in terms of BER, particularly in low interference environments. This research contributes to a better understanding of the strengths and weaknesses of these two popular adaptive algorithms in communication systems.'}\n","{'text': 'From its early days the Internet of Things (IoT) has evolved into a decentralized system of cooperating smart objects with the requirement, among others, of achieving distributed consensus. Yet, current IoT platform solutions are centralized cloud based computing infrastructures, manifesting a number of significant disadvantages, such as, among others, high cloud server maintenance costs, weakness for supporting time-critical IoT applications, security and trust issues. Enabling blockchain technology into IoT can help to achieve a proper distributed consensus based IoT system that overcomes those disadvantages. While this is an ideal match, it is still a challenging endeavor. In this paper we take a first step towards that goal by designing Hybrid-IoT, a hybrid blockchain architecture for IoT. In Hybrid-IoT, subgroups of IoT devices form PoW blockchains, referred to as PoW sub-blockchains. Then, the connection among the PoW sub-blockchains employs a BFT inter-connector framework, such as Polkadot or Cosmos. In this paper, we focus on the PoW sub-blockchains formation, guided by a set of guidelines based on a set of dimensions, metrics and bounds. In order to prove the validity of the approach we carry on a performance and security evaluation.'}\n","{'text': \"Deep learning has become a popular technology in various applications such as natural language processing and computer vision. End devices, such as smartphones and Internet-of-Things sensors, are generating data that need to be analyzed in real time using deep learning or used to train deep learning models. However, deep learning inference and training require significant computation resources, making edge computing a feasible solution to meet the high computation and low-latency demand of deep learning in edge devices. Edge computing's benefits include privacy, scalability, and bandwidth efficiency, and this paper aims to provide a comprehensive review of the current state of the art at the intersection of deep learning and edge computing. This paper aims to provide a comprehensive review of the current state of the art at the intersection of deep learning and edge computing. Specifically, it will provide an overview of applications where deep learning is used at the network edge, discuss various approaches for quickly executing deep learning inference across a combination of end devices, edge servers, and the cloud, and describe the methods for training deep learning models across multiple edge devices. Ultimately, readers will gain insights into scenarios where deep learning is useful at the network edge, common techniques for speeding up deep learning inference, and distributed training across edge devices. They will also gain a better understanding of recent trends and opportunities in this field.\"}\n","{'text': 'The idea is to provide a smart package for restaurants using machine learning techniques. The techniques we have used are image processing, association rule generation and sentiment analysis . Main objective is to provide an interface for the customer where he can get complete information about the restaurant. Customer has to click and upload a picture of the restaurant. The system will perform image processing and as a response it will identify the restaurant (just by the picture). Along with identification of the restaurant it will also give the customer the previous reviews about the restaurant. These reviews will help the customer in order to decide whether the restaurant is of his choice or not. Our solution for smart restaurants also includes smart menu card for each restaurant. Here we are performing association rule mining on the previous yearâ\\x80\\x99s transaction of each restaurant and hence obtain a list of most frequently ordered dishes according to customerâ\\x80\\x99s choice and then form combos of the same in order to attract the customers. In the end we have an automated mail generating system which sends an e-mail to all the customers in the restaurants database about the offers they can avail in the restaurants. This will help in getting more customers to the restaurants.'}\n","{'text': 'In recent years, serverless architecture has gained popularity in the field of cloud computing. It provides an efficient solution for workflow scheduling with an unconstrained execution environment. This paper explores the benefits of serverless architecture for workflow scheduling and proposes its application in the context of computer architecture. The Federal Aviation Administration (FAA) is a key case study in this paper, with a focus on the use of containers in a serverless environment. The advantages of monitoring and managing servers through this architecture are also discussed. The use of middleware and cloud computing in a serverless environment is evaluated, with a view to providing a more effective workflow scheduling solution. Overall, this paper highlights the immense potential of serverless architecture in computer architecture and its applicability in diverse contexts.'}\n","{'text': 'This paper proposes a method for detecting face pigment regions based on improved Local Binary Fitting (LBF). The proposed algorithm focuses on detecting pigmented areas in facial images, which may be indicative of certain skin conditions. The method involves image segmentation to isolate the skin region, followed by feature extraction using the improved LBF algorithm. Additionally, a fitting process is employed to refine the segmentation result and improve accuracy in the detection of pigment regions. The proposed algorithm is evaluated using a dataset of facial images and compared to existing methods. Results show that the proposed method achieves higher accuracy in detecting pigment regions compared to traditional methods. The proposed method has potential for use in clinical diagnosis of skin conditions and cosmetic applications. Overall, this paper highlights the potential of improved LBF for detecting pigment regions in facial images using a combination of image segmentation, feature extraction, fitting, and level set methods.'}\n","{'text': 'Accurately classifying images using few-shot samples have been widely explored by researchers. However, these methods have two drawbacks. First, images are often used independently. Second, class imbalance is ignored and hinders the classification accuracy with the increment of classes. To tackle these two drawbacks, in this paper, we propose a novel visual classification method using image pairs with binary transformation (IPBT). For one image, we bundle it with each training image into an image pair by concatenating the representations of the two images along with their similarity. The class consistency of two images is used to split the image pairs into binary groups. One group contains image pairs of the same class, while the other group consists of images pairs belonging to different classes. We train classifiers to separate the binary groups apart. To classify a testing image, we first bundle it with all the training images that are then predicted using the learned binary classifier. The image pair with the largest response is selected, and the testing image is assigned to the same class of the paired image. We conduct few-shot visual classification experiments on three public image datasets. The experimental results and analysis show the effectiveness of the proposed IPBT method.'}\n","{'text': 'Trust management is an essential factor for the security of IP networks, especially in the context of the Internet of Things (IoT). In this paper, we propose a fast and efficient trust management scheme called FETMS for Information-Centric Networking in IoT. The scheme aims to provide secure communication and routing between IoT devices, while also preserving the privacy of users. Our scheme employs a centralized architecture with a trusted authority, which manages and verifies trust certificates for IoT devices. The certificates are used to authenticate devices and authorize data transmission in the network. FETMS achieves fast and efficient communication by using a novel method for trust certificate distribution, which reduces the overhead of communication and storage. Additionally, we evaluate the performance of FETMS through simulation and compare its efficiency and security to existing schemes. The results show that FETMS performs better in terms of communication overhead and security, making it a promising choice for trust management in Information-Centric Networking in IoT.'}\n","{'text': 'Accurate speed predictions for urban roads are highly important for traffic monitoring and route planning, and also help relieve the pressure of traffic congestion. Many existing studies on traffic speed prediction are based on convolutional neural networks, and these have primarily focused on capturing the spatial proximity among different road segments. However, the real cause of the spread of traffic congestion is the connectivity of these road segments, rather than their spatial proximity. This makes it very challenging to improve prediction accuracy. Using graph neural networks (GNNs), the connectivity of these road segments can be modeled as a graph in which the properties of road segments and the connections between them are embedded as the properties of the nodes and edges, respectively. This paper describes a novel approach that combines the advantages of sequence-to-sequence (Seq2Seq) models and GNNs. Specifically, the evolution of traffic conditions on road networks is modeled as a sequence of graphs. Thus, the proposed SeqGNN model represents both the inputs and outputs as graph sequences. Finally, the extensive experiments using real-world datasets demonstrate the effectiveness of our approach and its advantages over the state-of-the-art methods.'}\n","{'text': 'By sensing wirelessly the radio propagation environment and analyzing the channel state information (CSI), one can extend human senses beyond our traditional reach and enrich the insight into the surrounding environment and activities, with or without line-of-sight. On one hand, different indoor activities bring distinctive perturbations to wireless radio propagations. On the other hand, thanks to the nature of multipaths, indoor environmental information is contained and embedded in the wireless CSI. Since the occurrence of an indoor event lasts for a certain period of duration and repeats a similar transition pattern among different realizations, information is embedded not only in each instantaneous CSI sample, but also in how CSI changes along time, e.g., the CSI time series. Inspired by that, this paper proposes an indoor monitoring system that monitors the occurrence of different indoor events in real time with commercial WiFi devices, by exploiting the temporal information embedded in the CSI time series. Through extensive experiments, this paper studies the robustness of the proposed system to variabilities in event instances and human motion interference, and its long-term performance in a one-month test.'}\n","{'text': \"The article analyzes the issue of choosing geoinformation systems (GIS) software to implement essential professional educational programs at university. As a basis for the choice, the sufficiency of software characteristics to develop professional expertise in the scope of geoinformation systems in graduates has been adopted. The following choice procedure has been offered: 1) specification of the requirements to graduates' professional expertise based on the analysis of the Federal State Education Standards (FSES), professional standards and requirements of potential employers; 2) analysis of the GIS software characteristics in terms of possibility to implement the requirements to expertise; 3) establishment of compliance between the requirements to expertise and software characteristics and the software options on offer; 4) the choice of the software. The procedure has been tested during the implementation of essential professional educational programs in the scope of Geology, Information Systems and Technologies, and Applied Geodesy in the Institute of Geology and Petroleum Engineering of Industrial University of Tyumen. A conclusion about the viability of joint use of proprietary and open-source software in educational process has been made. The proposed approach to the choice can be extended to applied information technologies of any thematic focus.\"}\n","{'text': 'In this paper, we propose a novel approach to simplify and enhance the performance of multiple level nested arrays using high-order difference co-arrays. Specifically, we focus on the application of this technique in the context of sensor arrays and direction-of-arrival estimation. Our method leverages the unique properties of high-order difference co-arrays to improve the accuracy of estimation and reduce the computational complexity of array signal processing. We also explore various smoothing methods to further improve the estimation quality. Our experiments demonstrate that the proposed approach yields significant improvements in both estimation accuracy and computational efficiency compared to traditional techniques. These findings have important implications for the design and implementation of sensor arrays and other related applications where accurate and efficient direction-of-arrival estimation is critical.'}\n","{'text': 'This paper presents a method for the detection and isolation of false data injection attacks in smart grids by utilizing nonlinear interval observers. Smart grids are becoming increasingly commonplace, and as such, their security is of paramount importance. These grids rely on intelligent sensors and the internet of things (IoT) to monitor and control the flow of energy. However, this dependence on technology also makes them vulnerable to cyber-attacks, such as false data injections. The proposed method utilizes observers to identify any discrepancies between the measured and estimated values of the system state variables, thus allowing for the detection and isolation of any false data injections that may have occurred. The effectiveness of the method is demonstrated through simulation results, which show that the proposed method is capable of detecting and isolating false data injections with high accuracy. Overall, the findings of this paper provide valuable insight into the security of smart grids and highlight the importance of utilizing advanced techniques, such as nonlinear interval observers, to detect and mitigate attacks.'}\n","{'text': 'This paper presents a novel approach for Continuous Pedestrian Orientation Estimation using Human Keypoints. The proposed method is based on the extracting features, such as legged locomotion, semantics, and pose estimation, from the human keypoints. Specifically, the hip keypoints are analyzed in order to estimate the orientation of pedestrians. The proposed method also utilizes interpolation techniques to improve the accuracy of the orientation estimation. The results demonstrate that the proposed approach has a high accuracy and robustness in estimating pedestrian orientation. The approach has potential applications in various fields, such as robotics, surveillance systems, and autonomous vehicles.'}\n","{'text': 'In this paper, we study the sparse signal reconstruction with nonconvex regularization, mainly focusing on two popular nonconvex regularization methods, minimax concave penalty (MCP) and smoothly clipped absolute deviation (SCAD). An approximate message passing (AMP) algorithm is an effective method for signal reconstruction. Based on the AMP algorithm, we propose an improved MCP iterative thresholding algorithm and an improved SCAD iterative thresholding algorithm. Furthermore, we analyze the convergence of the new algorithms and provide a series of experiments to assess the performance of the new algorithms. The experiments show that the new algorithms based on AMP have stronger reconstruction capabilities, higher phase transition for sparse signal reconstruction, and better variable selection ability than the original MCP iterative thresholding algorithm and the original SCAD iterative thresholding algorithm.'}\n","{'text': 'In recent years, with the rapid development of the Internet of Things (IoT), sensors have been widely deployed in various scenarios to collect enormous data. However, data processing and analysis have become increasingly challenging due to limited computing power and delays caused by network transmission. To tackle these issues, the concept of \"Short-Dot\" computing large linear transforms distributedly using coded short dot products has been proposed. By encoding data with linear transforms, Short-Dot can speed up the data processing and analysis tasks. Moreover, integreating machine learning algorithms into Short-Dot further enhance the data processing efficiency. With the help of distributed processing, Short-Dot can efficiently utilize computing resources and reduce the delays caused by network transmission. In this paper, we analyze the task of processing large amounts of distributed sensor data using Short-Dot, and demonstrate the effectiveness of the proposed approach for handling these challenges.'}\n","{'text': \"Artificial intelligence evolved as a powerful tool in condition monitoring of the induction motor for early diagnosis of bearing faults. This paper attempted to identify the features to improve the accuracy of diagnosis using the benchmark database of the Case Western Reserve University (CWRU) and the Machinery Fault Prevention Technology (MFPT). In this paper, 18 time-domain features are extracted constituting six proposed time-dependent spectral features (TDSFs) and 12 statistical time-domain features. For the first time, a set of six TDSFs are extracted to diagnose the bearing faults. This involves extracting frequency-domain features using the relationship between Parseval's theorem and the Fourier transform directly from the time domain. Particle swarm optimization (PSO) and wheel-based differential evolution (WBDE) feature selection algorithms are also implemented to identify four prominent features. It is found that three of the four selected features are TDSF features, and results of selected features revealed the attainment of 90.92% for 48 class identifications of CWRU database and 100% for 17 class identifications of the MFPT database, respectively.\"}\n","{'text': 'This paper proposes a Key Engineering Characteristics (KEC) extraction technology based on Quality Function Deployment (QFD) for Mechatronics production. The aim of this technology is to improve customer satisfaction by ensuring that the production process meets their quality expectations. QFD is used as a tool for customer-driven quality control, allowing for the effective identification of key attributes that determine overall product quality. The KECs are then extracted using a neural network algorithm, which considers various factors such as production capabilities, technical feasibility and market demand. The proposed technology has great potential for application in Mechatronics production and provides a structured approach to quality management, enabling companies to achieve success in the highly competitive global market.'}\n","{'text': 'Detection and identification of military vehicles from aerial images is of great practical interest particularly for defense sector as it aids in predicting enemys move and hence, build early precautionary measures. Although due to advancement in the domain of self-driving cars, a vast literature of published algorithms exists that use the terrestrial data to solve the problem of vehicle detection in natural scenes. Directly translating these algorithms towards detection of both military and non-military vehicles in aerial images is not straight forward owing to high variability in scale, illumination and orientation together with articulations both in shape and structure. Moreover, unlike availability of terrestrial benchmark datasets such as Baidu Research Open-Access Dataset etc., there does not exist well-annotated datasets encompassing both military and non-military vehicles in aerial images which as a consequence limit the applicability of the state-of-the-art deep learning based object detection algorithms that have shown great success in the recent years. To this end, we have prepared a dataset of low-altitude aerial images that comprises of both real data (taken from military shows videos) and toy data (downloaded from YouTube videos). The dataset has been categorized into three main types, i.e., military vehicle, non-military vehicle and other non-vehicular objects. In total, there are 15,086 (11,733 toy and 3,353 real) vehicle images exhibiting a variety of different shapes, scales and orientations. To analyze the adequacy of the prepared dataset, we employed the state-of-the-art object detection algorithms to distinguish military and non-military vehicles. The experimental results show that the training of deep architectures using the customized/prepared dataset allows to recognize seven types of military and four types of non-military vehicles.'}\n","{'text': 'The article is devoted to the aspects of smaller information systems, their modern features and the possibility of working with limited resources allocated for information protection. The article analyzes the security of the system prior to the implementation of the proposed security policy based on the methodology for analyzing threats and vulnerabilities. The authors propose an approach to reduce the risks associated with the probability of loss, distortion, and data compromise. On the basis of the research, the benefits associated with the implementation of the proposed measures are shown.'}\n","{'text': 'Online auctions created a very attractive environment for dishonest moneymakers who can commit different types of fraud. Shill Bidding (SB) is the most predominant auction fraud and also the most difficult to detect because of its similarity to usual bidding behavior. Based on a newly produced SB dataset, in this study, we devise a fraud classification model that is able to efficiently differentiate between honest and malicious bidders. First, we label the SB data by combining a hierarchical clustering technique and a semi-automated labeling approach. To solve the imbalanced learning problem, we apply several advanced data sampling methods and compare their performance using the SVM model. As a result, we develop an optimal SB classifier that exhibits very satisfactory detection and low misclassification rates.'}\n","{'text': 'Dynamic state estimation, enabled by phasor measurement units (PMUs), opens new opportunities to improve detection of cyber-physical attacks in power networks. Distributed approaches to estimation and attack detection have many advantages, such as reduced processing times and increased security, and are arguably necessary for large size networks. In this work, we present a fully-distributed dynamic state estimation algorithm using PMU measurement data. The dynamic state estimation is jointly designed with an innovation-based attack detection scheme to limit communication overhead. An attractive feature of our work is that each control area utilizes a local model of reduced dimension. The design of our algorithm uses an approximation to the state covariance matrix, which allows for a trade-off between computation, communication, and accuracy. In numerical experiments, we demonstrate the effectiveness of this approach.'}\n","{'text': 'Long Short-Term Memory (LSTM) is a special class of recurrent neural network, which has shown remarkable successes in processing sequential data. The typical architecture of an LSTM involves a set of states and gates: the states retain information over arbitrary time intervals and the gates regulate the flow of information. Due to the recursive nature of LSTMs, they are computationally intensive to deploy on edge devices with limited hardware resources. To reduce the computational complexity of LSTMs, we first introduce a method that learns to retain only the important information in the states by pruning redundant information. We then show that our method can prune over 90% of information in the states without incurring any accuracy degradation over a set of temporal tasks. This observation suggests that a large fraction of the recurrent computations are ineffectual and can be avoided to speed up the process during the inference as they involve noncontributory multiplications/accumulations with zero-valued states. Finally, we introduce a custom hardware accelerator that can perform the recurrent computations using both sparse and dense states. Experimental measurements show that performing the computations using the sparse states speeds up the process and improves energy efficiency by up to 5.2Ã\\x97 when compared to implementation results of the accelerator performing the computations using dense states.'}\n","{'text': 'Currently, majority of person re-identification (reID) technologies are network-constrained by Dropout regularization, which relies on the random zeroing out of some features to make these features more independent. However, such random zeroing regularization methods are not very effective for improving network performance, because they neglect the unique contribution of different features to the network performance. To improve the value of indiscriminative features in network training, a DropEasy-based person reID method is proposed in this paper. Features are classified into discriminative and indiscriminative ones, according to the distance between the feature vectors of positive or negative sample pairs wherein the discriminative features are zeroed out, while the indiscriminative features are reserved, and the network only learns through indiscriminative features. Furthermore, because networks are always inclined to make up for incomplete information by drawing on the surrounding features in the feature maps, Dropout loses its effectiveness for the network-constraints. To solve this challenge, the DropEasy2d method that can be effectively applied to convolutional layers is further proposed in this paper. DropEasy2d searches discriminative feature areas in the feature maps by sliding and zeroing windows while reserving the indiscriminative features areas to constrain network learning. The effectiveness of the proposed method is demonstrated using the Market-1501, DuckMTMC-reID, and CUHK03 datasets. For example, in the Market-1501 dataset, DropEasy can improve the mean average precision (mAP) and Rank-1 accuracy of the ID-discriminative embedding (IDE) to 72.7%(+8.8%) and 90.5%(+6.8%), respectively, while DropEasy2d can raise them to 68.5%(+4.6%) and 88.7%(+5.0%), respectively. Based on the results, the proposed method can improve the network performance during the extraction and generalization of the discriminative features.'}\n","{'text': 'Word embedding and document embedding representations have proved good performance in several natural language tasks such as information retrieval, text categorization, etc. Since, these representations capture both the synthetic and semantic information contained in the text. However, the ambiguity of Arabic language is a ubiquitous problem that can be handled by using sense embedding approaches. Learning a distinct representation for each sense of an ambiguous word could lead to train a more powerful and fine-grained models of vector-space representations. In this paper, we propose a method that combined document embedding representation and sense disambiguation to enhance Arabic text representation. Firstly, we benefit from sense embedding. Secondly, we enrich the document embedding model by learning representations for words and their senses and increasing the number of the document to train the model. The proposed method will be explored in the context of Arabic text categorization. Our system is composed of four stages which are: (1) preprocessing, (2) word sense disambiguation, (3) document embedding, (4) document categorization. We have conducted several experiments on OSAC corpus, the obtained results show that our method outperforms the state of art methods.'}\n","{'text': 'Business process and requirement specification are crucial phases in the software development process. Unfortunately, these crucial steps are often performed separately by different teams, resulting in misaligned models. The degree of misalignment grows continuously with their independent evolution. To address this issue, researchers have proposed using integration techniques to bridge the gap between the various heterogeneous models. Our approach is based on this technique and aims to align the business world, represented by BPMN, with the software requirement world, represented by the UML use case. Therefore, this approach is based on this technique to align the business world represented by BPMN and the software requirement world represented by the UML use case. We define an integrated meta-model that incorporates all BPMN and use case elements as well as new others to map traceable elements. Our approach supplements CASE tools with additional information and relationships, effectively maintaining global system consistency. Our approach supplements CASE tools with additional information and relationships to maintain the global system consistency. By integrating business process and requirement specification phases, our technique ensures that software development is efficient and that the full potential of model-driven software development is realized.'}\n","{'text': 'The efficient management of power consumption is crucial for data centers, especially for cloud computing. Accurate estimation of power demand is a key factor in optimizing energy efficiency. In recent years, neural networks have been developed to estimate the power consumption of virtual machines (VMs) in data centers. However, these models often lack generalization to new data sets and may suffer from poor correlation between their predictions and actual measurements. In this paper, we propose a generalized neural model for VMs power consumption estimation in data centers. The model takes into account several factors such as the VMsâ\\x80?memory management and overall workload. To validate the model, we collect data from various data centers and examine the correlation between the predicted and actual values. The results show that our proposed model outperforms existing methods in terms of estimation accuracy and generalization capabilities. Our model promises to provide a better understanding of power consumption patterns in data centers, improve energy efficiency and ultimately reduce operational costs.'}\n","{'text': 'An improved quantum-inspired evolutionary algorithm (iQEA) is presented in this paper to improve the clustering result of a data clustering problem. Comparable to other QEA-based algorithms, iQEA utilizes Q-bits to denote the state of a quantum particle and Q-gate as an evolutionary operator to guide the direction of the search. However, unlike the fixed rotation degree of QEAs, the rotation degree of iQEA is modified at each iteration. Experimental results show that the iQEA is able to find a better result than all the other metaheuristic algorithms compared in this paper in terms of quality.'}\n","{'text': 'In this paper, we present a novel computer audition task: audio-based video game genre classification. The aim of this study is threefold: 1) to check the feasibility of the proposed task; 2) to introduce a new corpus: The Game Genre by Audio + Multimodal Extracts (G2 AME), collected entirely from social multimedia; and 3) to compare the efficacy of various acoustic feature spaces to classify the G2 AME corpus into six game genres using a linear support vector machine classifier. For the classification we extract three different feature representations from the game audio files: 1) Knowledge-based acoustic features; 2) DEEP SPECTRUM features; and 3) quantized DEEP SPECTRUM features using Bag-of-Audio-Words. The DEEP SPECTRUM features are a deep-learning-based representation derived from forwarding the visual representations of the audio instances, in particular spectrograms, mel-spectrograms, chromagrams, and their deltas through deep task-independent pretrained CNNs. Specifically, activations of fully connected layers from three common image classification CNNs, GoogLeNet, AlexNet, and VGG16 are used as feature vectors. Results for the six-genre classification problem indicate the suitability of our deep learning approach for this task. Our best method achieves an accuracy of up to 66.9% unweighted average recall using tenfold cross-validation.'}\n","{'text': 'Previous studies suggest that muscle synergies are the building blocks used by the central nervous system to construct movements. Here, we investigate how to construct reaching movements across different directions and distances by altering the recruitment of a few muscle synergies. To this end, electromyographic (EMG) signals were recorded from nine upper limb muscles during reaching movements across six directions and three distances in the horizontal plane. Non-negative matrix factorization algorithm was employed to extract muscle synergies. For each one of eleven subjects, three muscle synergies could account for a large fraction (88.85Â±1.68%) of variations in EMG signals across all conditions. By characterizing the activation of synergies in each direction and distance, we found that two synergies only activated in specific directions, and positive correlations existed between their activation levels and distance in these directions. However, the remaining synergy was almost activated with the same degree in all directions and distances. Overall, our results demonstrate that the control of a repertoire of reaching movements can be achieved by flexibly modulating the activation of several muscle synergies.'}\n","{'text': 'In this paper we describe an evaluation to test the reliability of a blockchain based Internet of Things application using a continuous-time Markov chain model. The factors affecting the reliability in our system include the number of devices, the reliability of individual devices, and the underlying consensus algorithm etc. The effect of some factors on overall system reliability is tested, and we find that the total number of devices has the most significant factor to affect overall system reliability. So that we can improve system reliability according to the affecting factors.'}\n","{'text': 'This paper proposes a planning strategy for a smart city sensor network utilizing LoRaWAN technology. The successful implementation of smart cities requires a reliable wireless communication system that can accommodate the large number of sensors deployed in densely populated urban areas. Wireless sensor networks offer a feasible solution to this challenge, and LoRaWAN provides an efficient uplink for data transmission. The design of the sensor network architecture utilizes logic gates to optimize the monitoring and control of the smart city infrastructure. This paper highlights the importance of a monitoring system in smart cities and how wireless sensor networks can provide a comprehensive solution for monitoring and control of various components of a city. Overall, this study presents an innovative approach to designing a LoRaWAN-based smart city sensor network that can enhance the quality of life for urban residents and improve the efficiency of city operations.'}\n","{'text': 'This paper proposes a novel direction of arrival (DOA) estimation algorithm that utilizes the received signal strength (RSS) of directional antennas to achieve higher accuracy in location awareness. The proposed algorithm employs software algorithms to estimate the DOA based on the RSS measurements of multiple directional antennas. By using this method, the DOA can be estimated with higher precision, and the position measurement accuracy can also be improved. The use of directional antennas enables the estimation of multiple DOAs simultaneously, while the software algorithms allow for a more efficient and accurate estimation process. The proposed algorithm has the potential to improve the performance of location-based services and position sensing in various applications that require precise positioning, such as navigation systems and indoor positioning. Overall, the proposed DOA estimation algorithm demonstrates a promising direction for improving the accuracy of position sensing using directional antennas.'}\n","{'text': 'For the fault classification of chemical industries, the typical Fisher discriminant analysis (FDA) model requires that all the training samples should be correctly labeled. Actually, training samples tend to be polluted by mislabeled samples for some unavoidable reasons, and thus the performance of the FDA may be severely affected. However, in the chemical process monitoring community, there is little attention to fault classification with label-noise in training samples. To settle this open issue, a manifold-preserving sparse graph (MPSG)-based ensemble FDA model is initially proposed in this paper. First, under the condition of maintaining the underlying manifold structure of training samples, an MPSG is utilized to filter some mislabeled samples. Second, to improve model robustness to the left mislabeled samples, Bagging based on FDA is used to construct several subclassifiers, which are combined to form a robust classifier. Experiments on the benchmark Tennessee Eastman process and a real industrial air separation unit demonstrate the effectiveness and the superiority of the proposed model.'}\n","{'text': \"Traditional endoscopes consist of a flexible body and a steerable tip with therapeutic capability. Although prior endoscopes have relied on operator pushing for actuation, recent robotic concepts have relied on the application of a tip force for guidance. In such case, the body of the endoscope can be passive and compliant; however, the body can have significant effect on mechanics of motion and may require modeling. As the endoscope body's shape is often unknown, we have developed an estimation method to recover the approximate distal shape, local to the endoscope's tip, where the tip position and orientation are the only sensed parameters in the system. We leverage a planar dynamic model and extended Kalman filter to obtain a constant-curvature shape estimate of a magnetically guided endoscope. We validated this estimator in both dynamic simulations and on a physical platform. We then used this estimate in a feed-forward control scheme and demonstrated improved trajectory following. This methodology can enable the use of inverse-dynamic control for the tip-based actuation of an endoscope, without the need for shape sensing.\"}\n","{'text': 'Classification algorithms are widely used in various fields such as monitoring and biomedical acoustics. An important aspect in classification algorithms is feature extraction, which involves selecting the most relevant features from the dataset. Feature weighting is an optimization technique used to improve the performance of classification algorithms by assigning weights to different features. In this paper, we focus on the classification of anuran calls, which is important in biodiversity monitoring. We propose a feature weighting approach to enhance the accuracy of classification using machine learning algorithms. Our experimental results show that the proposed approach outperforms the traditional feature selection methods in terms of accuracy, precision, and recall. Therefore, our approach is a promising solution for accurate and efficient classification in anuran call detection for biodiversity monitoring.'}\n","{'text': 'This work presents the development of a Network-on-Chip environment based on multiagent systems. This simulator aims to provide high level of abstraction to quickly simulate, compare and choose routing algorithms. The simulator calculates routers occupancy rate, number of messages that passed through each router and the number of messages lost. As a case study, the XY and West-First routing algorithms were modeled and analyzed. Simulation results indicated a better use of spare routers by the West-First algorithm when compared to the XY algorithm.'}\n","{'text': 'In this paper, we study communication and state estimation over a state-dependent Gaussian multiple-access channel. We consider the problem of jointly transmitting information and estimating the state of the environment observed by multiple receivers. We introduce a novel framework for state estimation and message decoding that utilizes the properties of the multiple-access channel. We investigate the effects of channel estimation errors and distortion measures on the performance of the proposed system. Our results show that by properly designing the transmitters and receivers, it is possible to achieve efficient communication and accurate state estimation over the multiple-access channel. We also provide theoretical insights on the trade-offs between communication rates, state estimation accuracy, and distortion measures. Overall, our work contributes to the development of effective communication and estimation systems for complex environments where multiple agents observe different aspects of the state information being transmitted.'}\n","{'text': 'We propose and study a new projection formula for training binary weight convolutional neural networks. The projection formula measures the error in approximating a full precision (32 bit) vector by a 1-bit vector in the l_1 norm instead of the standard l_2 norm. The l_1 projector is in closed analytical form and involves a median computation instead of an arithmatic average in the l_2 projector. Experiments on 10 keywords classification show that the l_1 (median) BinaryConnect (BC) method outperforms the regular BC, regardless of cold or warm start. The binary network trained by median BC and a recent blending technique reaches test accuracy 92.4%, which is 1.1% lower than the full-precision network accuracy 93.5%. On Android phone app, the trained binary network doubles the speed of full-precision network in spoken keywords recognition.'}\n","{'text': 'We consider the problem of designing sparse sampling strategies for multidomain signals, which can be represented using tensors that admit a known multilinear decomposition. We leverage the multidomain structure of tensor signals and propose to acquire samples using a Kronecker-structured sensing function, thereby circumventing the curse of dimensionality. For designing such sensing functions, we develop low-complexity greedy algorithms based on submodular optimization methods to compute near-optimal sampling sets. We present several numerical examples, ranging from multiantenna communications to graph signal processing, to validate the developed theory.'}\n","{'text': 'We have developed InP-based 1.55-Î¼m lasers epitaxially grown on (001) Si substrates for photonics integration. To overcome the fundamental material challenges associated with mismatch III-V on Si hetero-epitaxy, a Si V-groove epitaxy platform was established, leading to device quality III-V nanostructures and thin films. Combining metal organic chemical vapor deposition grown 1.55-Î¼m InAs quantum dots (QDs) and the InP/Si thin-film templates, we have achieved electrically driven 1.55-Î¼m QD lasers on Si operating at room temperature. To reduce device footprint and energy consumption, a bufferless integration path by growing InP nano-ridge lasers on prepatterned silicon-on-insulators wafers has been explored. Material and device characterizations and an outlook for device component integration are discussed.'}\n","{'text': \"In this paper, we discuss a time domain finite element method for the approximate solution of Maxwell's equations. A weak formulation is derived for the electric and magnetic fields with appropriate initial and boundary conditions, and the problem is discretized both in space and time. In space, NÃ©delÃ©c curl-conforming and Raviart-Thomas div-conforming finite elements are used to discretize the electric and magnetic fields, respectively. The backward Euler and symplectic schemes are applied to discretize the problem in time. For this system, we prove an error estimate. In addition, computational experiments are presented to validate the method, the electric and magnetic fields are visualized. The method also allows treating complex geometries of various physical systems coupled to electromagnetic fields in 3D.\"}\n","{'text': \"This paper provides a cryptographic extension to related work on the use of Galois Extension Field techniques [1] to combine multiple output streams from independent pseudorandom number generators (PRNGs), modified for use in low-power stream-cipher cryptographic applications. The core extension field techniques are shown to be computationally efficient, scalable, and support a variety of contextual variations that make them suited for improving cryptography on low power Internet of Things (IoT) devices. This paper focuses specifically on the use in scalable, multi-party cryptographic algorithms, with a focus on the invertible transforms that may be applied in the extension field to rapidly encrypt and decrypt data. A key benefit of this technique is the ability to exploit the associative property of the underlying arithmetic to interchange the order of parties encrypting or decrypting the data stream without limitation, making the technique highly versatile, meeting a number of IoT use cases. Testing has shown that this technique passes NIST's test suite for randomness indicating that the produced ciphertext is indistinguishable from a randomly generated sequence. MSP430 implementations in C indicate that this encryption scheme is faster and more energy efficient than AES.\"}\n","{'text': 'The Smart Farming Education Service is dedicated to disseminating crucial farming information. This farming information is supposed from current activities, farming product and from the experience of farmer on the field. If this vital information is unavailable, or not in a form that can be easily accessed by the end producer, the process becomes stagnant. Therefore, the creation of a data store to serve as a repository for such information is key to the automation process. With the implementation of farming data in the farming contents repository, the farming sector stands to benefit immensely as this serves as a knowledge base for the entire automation process.'}\n","{'text': 'Artificial Intelligence (AI) plays an important role in our life and touch base most of our surrounding applications and systems. A huge amounts of data are created every day from many different sources that need to be monitored and analyzed properly and report results and take actions. A more complex software applications have been built, time is becoming a critical factor to release applications that must be fully tested and comply with Business Requirements. AI plays a key role in Software Testing and can get more accurate results and saves time. This paper discuss the Artificial Intelligence key pillars that can be used in Software Testing. It also open a window on how the future will look like in terms of Artificial Intelligence and the Software Testing. The results show that AI can achieve better results in Software Testing and AI-driven testing will lead the new era of the quality assurance (QA) work in the near future. AI Software Testing will reduce time to market and will increase the efficiency of the organization to produce more sophisticated software and will create smarter automated testing.'}\n","{'text': 'We describe a new vision of joint computation and communication resource management that goes beyond the end-to-end and client-server model of the current Internet. Enabled by a growing trend toward embedding processing and networking capabilities into \"smart\" network nodes and devices, for example, smartphones, watches, appliances, and automobiles, Dispersed Computing describes a new resource-centric architecture that leverages the diversity of networked computation points within the network, and the heterogeneity of network links and protocol stacks that connect them. We describe this new, resource-centric architecture as an evolution of both fog/edge networking and active networks. We illustrate the fundamental principles and the advantages over the current Internet architecture, and highlight several commercial use cases enabled by a dispersed computing architecture.'}\n","{'text': 'This study presents an advanced control algorithm for a double-stage grid-connected solar photovoltaic (PV) system in the presence of adverse grid conditions such as DC offset, variable solar insolation, and voltage swell/sag. The main aim of this proposed EGI control algorithm is to extract the fundamental component from the grid voltage, even at adverse grid conditions. A perturb and observe (P&O) based MPPT (Maximum Power Point Tracking) is used for peak power extraction from the PV array. Additionally, Adaptive DC link voltage control is used to minimize the switching losses of Voltage Source Converters (VSC). The proposed system with EGI based control algorithm is simulated in MATLAB. The simulated performance is studied for various odd states like DC offset, voltage swell/sag, insolation change etc. For the validation of the test results, a prototype is built in the laboratory. THD (Total Harmonics Distortion) of the grid current during grid disturbances, is found in limits as recommended by the IEEE-519 standard.'}\n","{'text': \"With the increasing amount of available healthcare data, Big Data analysis has become widely used for the prediction and prevention of many diseases, including Coronary Artery Disease (CAD). Data mining techniques are essential for extracting meaningful information from large datasets and identifying potential risk factors for CAD. In the context of hospitals, Big Data tools and technologies can provide valuable insights for both administrative and clinical decision-making processes. However, it is crucial to ensure the security and privacy of patient data when utilizing Big Data analysis in healthcare. In summary, the application of Big Data analytics in CAD prediction and prevention can greatly enhance the effectiveness and efficiency of healthcare delivery, but it is imperative to maintain data security and privacy to protect patients' rights and interests.\"}\n","{'text': 'Many people ask medical questions online, finding the most suitable answer from candidate answers is an important research area in health care. The IEEE HotICN Knowledge Graph Academic Competition given a question and several candidate answers, then sort the candidate answers to get the best answer. We treated this subtask as a binary classification task, sorted the answers by calculating similarity between the question and each answer. In this work, we proposed a neural selection model trained on the training dataset. Our network architecture is based on the combination of Bi-LSTM and Attention mechanism, extended with biomedical word embeddings. Based on this fact, our model achieve state-of-the-art results on answer selection of medical community.'}\n","{'text': 'Embedding Machine Learning enables integrating intelligence in recent application domains such as Internet of Things, portable healthcare systems, and wearable devices. This paper presents an assessment of approximate computing methods at algorithmic, architecture, and circuit levels and draws perspectives for further developments and applications. The main goal is to investigate how approximate computing may reduce the complexity and enable the feasibility of embedded Machine Learning (ML) systems. Though ML is a powerful paradigm for applications in the perceptual domain (i.e. vision, touch, hearing, etc.), their computational complexity is very high and consequently real time operation and ultra-low power are still very challenging objectives. On the other hand, approximate computing has emerged as an effective solution to reduce hardware complexity, time latency and to increase energy efficiency.'}\n","{'text': 'In this paper, a new exact order reduction approach for Fornasini-Marchesini state-space models will be proposed based on common invariant subspace. It will be shown that this new approach can be applied even to those systems for which the existing approach based on eigenvalues cannot do any further exact order reduction on them. As a consequence, the approach based on eigenvalues can be viewed as a special case of the new proposed approach. Examples will be given to show the effectiveness as well as the details of the proposed approach.'}\n","{'text': 'Hardware/software co-designs are usually defined at high levels of abstractions at the beginning of the design process in order to allow plenty of options how to eventually realize a system. This allows for design exploration which in turn heavily relies on knowing the costs of different design configurations (with respect to hardware usage as well as firmware metrics). To this end, methods for cost estimation are frequently applied in industrial practice. However, currently used methods for cost estimation oversimplify the problem and ignore important features - leading to estimates which are far off from the real values. In this work, we address this problem for memory systems. To this end, we borrow and re-adapt solutions based on Machine Learning (ML) which have been found suitable for problems from the domain of Computer Vision (CV) - in particular age determination of persons depicted in images. We show that, for an ML approach, age determination from the CV domain is actually very similar to cost estimation of a memory system.'}\n","{'text': \"In this paper, we propose a decentralized control strategy for regular polygon formations with fixed size and cyclic sensing constraint in robot sensing systems. The topology of the formation is assumed to be known and the position measurement error is considered. The proposed control law guarantees asymptotic stability and convergence of the formation despite the cyclic sensing constraint. The stability analysis is provided through Lyapunov theory and the convergence is proven by utilizing Barbalat's lemma. Simulation results confirm the effectiveness of the proposed control strategy in achieving the desired regular polygon formations. The presented approach is expected to be applicable to various robotic systems and can lead to new insights in the design of decentralized control algorithms for robotic formations with sensing constraints.\"}\n","{'text': 'In our time of ultra-fast development of Internet technologies an increasing number of people of different ages and interests live in the online reality. Because of this subject-subject communication unfortunately goes to the background. Sociocultural and psychological problems are multiplying as a result. On the other hand the Internet expands the possibilities and boundaries of communication and development. The Internet has entered almost all areas of life: medicine, education, law, culture, etc. One of such areas was art education as evidenced by numerous studies and articles on this topic. Hence the interest in building effective communications with different target audiences appear. As a sociocultural phenomenon the global network has opened up great opportunities for the development of creativity and leisure activities of the population, including teaching painting and drawing. People of different ages and life foundations get a chance to master the technologies of creative development and self-realization. Features of the creative process determine the set of communication tools which are necessary for the effective organization of this activity. Modern scholars argue that it is possible to successfully adapt in the modern world through the development of creativity and communication skills. Hence the subject of this study has become the development of communication models in the field of teaching painting, in other words, communication â\\x80\\x9cnext to the colorsâ\\x80? The basis was the theory of communication which the authors adapted to the field of painting. For the analysis and identification of trends in the development of this phenomenon, the article used methods of statistical analysis and random sampling as well as in-depth interviews with artists which made it possible to analyze communication models in the field of painting teaching using more than forty Internet resources as an example. The study took into account such factors as the level of development of the Internet resource, the specific features of communications related to creative processes in the artistic sphere, the number of subscribers, feedback mechanisms and other.'}\n","{'text': 'People with diabetes may suffer from an eye disease called Diabetic Retinopathy (DR). This is caused by damage to the blood vessels of the light-sensitive tissue at the back of the eye (i.e retina). Fundus images obtained from fundus camera are often imperfect; normally are in low contrast and blurry. Hence, causing difficulty in accurately classifying diabetic retinopathy disease. This study focuses on classification of fundus image that contains with or without signs of DR and utilizes artificial neural network (NN) namely Multi-layered Perceptron (MLP) trained by Levenberg-Marquardt (LM) and Bayesian Regularization (BR) to classify the data. Nineteen features have been extracted from fundus image and used as neural network inputs for the classification. For analysis, evaluation were made using different number of hidden nodes. It is learned that MLP trained with BR provides a better classification performance with 72.11% (training) and 67.47% (testing) as compared to the use of LM. Such a finding indicates the possibility of utilizing BR for other artificial neural network model.'}\n","{'text': 'The depletion of fossil fuel energy resources, increasing concern of air pollution, global warming and energy crisis have encouraged the research to develop innovative alternatives in engineering systems. This work presents a problem of minimizing the life cycle cost (as an economic criterion) of an air conditioning system for vapor compression and maximizing the useful heat (as a thermodynamic criterion). The mathematical model that represents the objective function has four decision variables: evaporation temperature and condensation temperature of the refrigerant, and volumetric flow rate of air in the condenser and the evaporator. The problem is a global optimization and the search method of solution is genetic algorithm. A thermodynamic model included design of exchanger. The methodology used is for R-1234yf, a low GWP refrigerant, which is R-134a refrigerant substitute.'}\n","{'text': 'With the increasing utilization of Internet of Things (IoT) devices, ensuring their security and privacy becomes essential. Address shuffling is a promising approach to address this issue. This method alters the source and destination IP addresses of the packets transmitted between the IoT devices and the servers. By doing so, it makes it harder for attackers to pinpoint the location of the devices and extract sensitive information. In this paper, we propose an easy way to implement address shuffling and improve security in IoT networks. We also analyze the impact of this technique on various protocols commonly used in IoT, including CoAP, MQTT, and HTTP. Additionally, we explore the potential applications of address shuffling in areas such as biomedical imaging, where confidentiality is of utmost importance. Overall, our study provides insights into how address shuffling can enhance the security and privacy of IP networks and IoT deployments, making them safer and more reliable.'}\n","{'text': 'Electrical field (EF) is a popular tool for both basic research and clinical applications, its actions on neuronal activities have been investigated from physiological mechanism and dynamics. However, few studies explore its modulatory influence on neuronal computation from the point of view of dendritic sublinear integration caused by passive dendrites which play an important role in neuronal computation. Here with a reduced biophysical model this problem is explained by observing the impact of EF on neuronal computation and dendritic sublinear operation. It is found that the positive EF results in more linear dendritic sublinear integration because of hyperpolarization in distal dendrites together resulting in higher neuronal excitability in neuronal computation but negative EF inhibits this ability due to more pronounced dendritic sublinear operation resulting from the hyperpolarization in distal dendrites. Further, we explain the modulation of positive EF on dysfunctional neuron combining with Feature Binding Problem. This work builds the gap between neuronal computation and dendritic sublinear operation, which is helpful to understand the modulation of EFs on brain functions.'}\n","{'text': 'Wide Area Monitoring System (WAMS) is an inevitable component in todays power system since a small catastrophe like fluctuations caused by the renewable energy sources, fast changing loads, electric vehicles, etc. will lead to the collapse of the whole system. This paper addresses the optimal planning of WAMS by Nash Differential Evolution (NashDE) Algorithm, in which the variables of the problem are clustered into number of clusters, and will evolve parallelly by Differential Evolution (DE) towards the global objective of the problem. For optimization problems which are based on the connectivity of variables involved as in most of the power system planning processes, the convergence speed will greatly improve if variables in a cluster are physically connected. Further, this will ensure global convergence of the problem. Hence, this paper proposes a NashDE algorithm in which the variables are clustered based on their connectivity. Markov Clustering Algorithm (MCL) is used for clustering the variables based on their connectivity. This is the first paper of such kind which addresses WAMS planning problem by Evolutionary Game Theory. Simulations are carried out for IEEE 14 and 30 bus test system using Python programming and the results are presented graphically.'}\n","{'text': \"Sniffers are among the commonest approaches for capturing network traffic activities and collecting digital evidences in cybercrime investigations. The ubiquity of instant messaging (IM) apps on smartphones has provided criminals with communication channels that are difficult to decode. Moreover, investigators and analysts of cybercrimes are encountering increasingly large datasets. To combat criminal activity, law enforcement agencies (LEAs) often rely on call-record analysis. In this paper, cybercriminals are investigated by network forensics and sniffing techniques. Retrieving valuable information from specific IM apps is difficult because the criminal's IP address records are not easily recognisable on the Internet. Here, a criminal's identity is located more effectively by a packet filter framework that isolates the WhatsApp communication features from huge collections of network packets. A rule extraction method for sniffing packets is proposed that retrieves the relevant attributes from high-dimensional analysis based on geolocation and a pivot table. The utility of this methodology is illustrated on real-time network forensics and a lawful interception system in Taiwan. The methodology also meets the ISO/IEC 27043:2015 standards of fear, uncertainty, and doubt avoidance. Besides supporting LEAs in discovering criminal communication payloads, prosecuting cybercriminals and bringing them to justice, it improves the effectiveness of modern call-record analysis.\"}\n","{'text': 'Compared with the traditional grid, smart grid involves a lot of advanced technologies and applications. However, due to rapid development, it faces a challenge to balance privacy, security, efficiency, and functionality. In this paper, we build a fog computing-based smart grid model and then present an efficient and privacy-preserving scheme which supports aggregation communication and function query based on the proposed model. To the best of our knowledge, this is the first concrete solution focusing on aspects of aggregation communication and data availability (e.g., function query) simultaneously in smart grid. In doing so, we utilize geographically distributed massive fog nodes and a centralized cloud server to achieve low-latency communication and electricity data storage. Encrypted under a double trapdoor cryptosystem, the usage data can be efficiently aggregated by fog nodes. Which supports the service provider to dynamically control and distribute the electricity. With outsourcing the encrypted usage data to the cloud, our scheme allows the service provider to launch various function queries on encrypted usage data, which is necessary for its services (e.g., billing), while letting users to have control of their own data. Therefore, our scheme can be applied to more complex smart grid applications compared with other solutions. Security proofs and analyses show that our scheme guarantees data privacy, confidentiality, authentication, and integrity. Finally, we compare our scheme with related works in terms of functionalities and most importantly, implement the scheme in a simulation environment. Experimental results indicate that our scheme is efficient with low computation and communication overheads.'}\n","{'text': 'With the increasing amount of scientific data generated every day, there is a growing demand for efficient and scalable processing platforms. In this regard, SciAP, a programmable, high-performance platform for large-scale scientific data, has been designed. SciAP provides a distributed architecture that allows efficient processing of scientific data by utilizing Spark-based computation models. The platform also incorporates partitioning algorithms that enable processing of data in parallel, reducing the processing time considerably. Additionally, SciAP offers a variety of data processing techniques, such as data mining and metadata management, which further enhance its usability. Its layout architecture ensures data locality, enabling faster processing times and reducing network overhead. In conclusion, SciAP is a promising platform that can effectively handle the processing of large-scale scientific data by providing a distributed architecture, efficient partitioning algorithms, and versatile data processing techniques.'}\n","{'text': 'Several studies on the improvement of distribution system technologies have surfaced over the past decades. Simple and inexpensive system-based methods to improve voltage profile and minimize losses include balancing, reconfiguration, and equipment penetration. However, improper re-phasing and placement may even worsen system operations. In this paper, optimal phase reconfiguration and capacitor placement is implemented. With the component object model (COM) interface, genetic algorithm (GA) through MATLAB toolbox was used simultaneously with an open-source load flow analyzer, OpenDSS, to gather optimal outcomes. Different treatments were applied to the highly unbalanced IEEE 13-bus test radial distribution system. Results showed that each treatment yielded a significantly lower system loss than the original network. Individually, the load re-phasing approach arrived at a more efficient system than the capacitor placement approach. Still, the combination of both methods yielded the best results out of all the cases. The optimal case was further applied to the IEEE 37-bus network.'}\n","{'text': \"The emerging Fifth Generation (5G) mobile networks have been attracting enormous attention from various stakeholders around the world. In particular, in the research community, prototyping 5G infrastructures and deploying 5G services have gained gears recently towards realising market-oriented 5G trials. However, accessing to and programming on real-world 5G infrastructure is almost prohibitive for most 5G researchers especially in academia. Therefore, it is critical to build realistic yet cost-efficient 5G infrastructure emulators for 5G research labs to enable credible 5G research activities. This paper proposes such a 5G infrastructure emulator that is able to emulate a realistic 5G network in a lab setting based on a small number of commercial-off-the-shelf servers by leveraging virtualization and other technologies. Moreover, this emulator allows a service provider to automatically deploy 5G services from `empty' machines through advanced automation. The emulation platform is described in details with the 5G infrastructure and service deployment procedure highlighted. Empirical results are presented to show the performance of the proposed emulator.\"}\n","{'text': 'This paper presents a systematic literature review of learning analytics dashboards (LADs) research that reports empirical findings to assess the impact on learning and teaching. Several previous literature reviews identified self-regulated learning as a primary focus of LADs. However, there has been much less understanding how learning analytics are grounded in the literature on self-regulated learning and how self-regulated learning is supported. To address this limitation, this review analyzed the existing empirical studies on LADs based on the well-known model of self-regulated learning proposed by Winne and Hadwin. The results show that existing LADs are rarely grounded in learning theory, cannot be suggested to support metacognition, do not offer any information about effective learning tactics and strategies, and have significant limitations in how their evaluation is conducted and reported. Based on the findings of the study and through the synthesis of the literature, the paper proposes that future research and development should not make any a priori design decisions about representation of data and analytic results in learning analytics systems such as LADs. To formalize this proposal, the paper defines the model for user-centered learning analytics systems (MULAS). The MULAS consists of the four dimensions that are cyclically and recursively interconnected including: theory, design, feedback, and evaluation.'}\n","{'text': \"Thermoelectric generators are efficient devices to recover energy from the automotive exhaust gas. In this paper, conversion efficiency of automotive thermoelectric generator (ATEG) and the maximum electrical power generated by the ATEG, defining as the power output of the ATEG excluding the energy loss caused to the engine improved by optimizing the number of thermoelectric modules (TEMs) and its distribution pattern in an ATEG. An advanced numerical model of ATEG considering the effect of the heat transfer among the adjacent TEMs' rows is developed with Simulation-X software. In order to acquire the ATEG's optimal electrical performance, a 3-step optimization is applied. First, 17 independent factors (the number of TEMs in each row from 1 to 18) are assessed and the significant parameters are screened using Plackett-Burman design. Second, an experiment designed with a central composite design is performed to analyze the sensitivity of six selected factors and a surrogate model is built through response surface method. Then, conflicts in two objectives are settled with a multi-objective genetic algorithm. According to the optimization results of a given ATEG, the maximum electrical power generated by the ATEG is 139.47 W and the conversion efficiency is 2.51% under steady engine condition. Finally, the performances of the optimized design under different engine conditions are discussed. The results show that the maximum power generated by the ATEG and efficiency respectively increase by 49.8% and 106.5% after optimization when the exhaust inlet temperature is 805 K and the mass flow rate is 0.5 kg/s.\"}\n","{'text': 'This paper analyzes the convergence properties of signed networks with nonlinear edge functions. We consider diffusively coupled networks comprised of maximal equilibrium-independent passive (MEIP) dynamics on the nodes, and a general class of nonlinear coupling functions on the edges. The first contribution of this paper is to generalize the classical notion of signed networks for graphs with scalar weights to graphs with nonlinear edge functions using notions from the passivity theory. We show that the output of the network can finally form one or several steady-state clusters if all edges are positive and, in particular, all nodes can reach an output agreement if there is a connected subnetwork spanning all nodes and strictly positive edges. When nonpositive edges are present, the paper demonstrates that the networkâ\\x80\\x99s tension converges to the equilibria of the edge functions if the relative outputs of the nodes connected by nonpositive edges converge to their equilibria. Furthermore, we establish the equivalent circuit models for signed nonlinear networks, and define the concept of equivalent edge functions, which is a generalization of the notion of the effective resistance. We finally characterize the relationship between the convergence property and the equivalent edge function, when a nonpositive edge is added to a strictly positive network comprised of nonlinear integrators. The analysis shows that the network always converges if the sum of the equivalent edge function of the previous network and the new edge function is passive.'}\n","{'text': \"In this paper, we propose an optimization technique that uses the Kriging method aided by electromagnetic transient simulation to solve linear programming problems related to automatic voltage control. The technique aims to minimize the reactive power in a power system while maintaining a stable voltage using computational modeling. Our approach involves generating a set of correlated variables for the optimization problem using electromagnetic transient simulations, then developing a Kriging model that incorporates these variables to predict the behavior of the power system. We use the model to optimize the system's objective function by minimizing the reactive power while satisfying voltage constraints using linear programming. Our results show that the proposed technique is effective at reducing reactive power and maintaining voltage stability in a power system, thereby highlighting its potential as a valuable tool for power system operators.\"}\n","{'text': \"This paper focuses on the evaluation of students' dependency on out-of-class learning using a flipped classroom approach in the context of mathematics education in Australia. The study proposes the integration of online services and the Internet to supplement traditional classroom teaching and enhance students' learning experience. The data collected from student surveys and interviews show a positive correlation between flipped classroom approach and students' engagement in out-of-class learning. Additionally, teachers' training and participation in conferences have played a crucial role in the successful implementation of the flipped classroom approach. In conclusion, the flipped classroom approach along with the use of internet-based resources can be an effective approach to promote students' independent learning and achieve better academic outcomes.\"}\n","{'text': 'Software countermeasures to mitigate buffer overflow attacks suffer from excessive memory and/or performance overhead. With such overhead, the defender can use software-only approaches only to the debugging context. In this paper, we present a novel hardware approach to detect stack based buffer overflow attack during runtime. The base and bound information of the static variable in a program are automatically extracted, stored, and compared with the object code in real time without any support from the compiler. Such an approach is transparent to the programmer. Given a traditional five-stage pipeline (fetch, decode, execute, memory, and write back), we introduce an adaptive pipeline architecture to modify the decode and execute stage of Sim-Outorder simulator in the SimpleScalar toolset. Compared to our previous work, which requires compiler support and incurs 7.3% instruction overhead, the proposed technique can demonstrate buffer overflow detection with 0% additional instruction. We validate the technique with NIST benchmark suite (5 C programs) and MIT Static Corpus (270 C programs) and our approach can detect 92.78% of test cases in MIT static Corpus. In addition, the average execution time per test case is five or more orders of magnitude less.'}\n","{'text': 'This paper proposes an event-based near-optimal sampling and tracking control strategy for nonlinear systems. The approach employs artificial neural networks to build a mathematical model of the target system, and optimization techniques to design an optimal control policy. The proposed approach achieves high-performance tracking and reduces sampling to only when necessary. The performance analysis verifies the effectiveness of the strategy in achieving near-optimal performance while reducing the computational burden. Stability analysis demonstrates the robustness of the approach in the presence of external disturbances. The trajectory of the system converges to the desired state with little overshoot, indicating the high accuracy of the proposed approach. Overall, the event-based near-optimal sampling and tracking control strategy presented in this paper provides an efficient and effective means of controlling non-linear systems.'}\n","{'text': 'The article is devoted to the methods of implementation of educational projects aimed at advanced training of participants of various Clusters of St. Petersburg in cooperation with the employment Center. The influence of the educational program \"management of intellectual activity at the enterprise\" on the example Of the Cluster of innovations in energy and industry is shown. The article focuses on the positive and negative aspects of the impact of this program, as well as the possible prospects.'}\n","{'text': 'Real-time monitoring of power quality is essential for ensuring stable and efficient operation of power systems. In this paper, we propose a real-time voltage sag monitoring system based on the embedded S-transform algorithm in Labview. The S-transform is a useful tool for feature extraction in signal processing, as it allows for the simultaneous analysis of both time and frequency domains. By using Labview as the software platform, our system can efficiently and accurately acquire data from power systems. The continuous wavelet transforms are also incorporated into the algorithm to further enhance the detection and analysis of voltage sags. The programming of the system allows for real-time monitoring of voltage sags with high accuracy and sensitivity, providing reliable information for power system operators to make timely decisions. Overall, the proposed system demonstrates its potential to become an effective tool for voltage sag monitoring and diagnosis.'}\n","{'text': 'In this paper, we present a lightweight machine learning-based approach for the supervision of fitness workouts. We propose a performance evaluation framework based on training data obtained from various wearable accelerometers. We apply band-pass filters and principal component analysis to extract relevant features from the data, and then use classification algorithms to identify specific workout activities. Our approach shows promising results in accurately recognizing different exercises and is designed to operate in a resource-constrained environment such as a smartphone. The proposed method can potentially be used as a tool for personal trainers and fitness enthusiasts to monitor their workout activities, track progress, and improve their overall fitness levels.'}\n","{'text': 'Anomaly detection on system logs is to report system failures with utilization of console logs collected from devices, which ensures the reliability of systems. Most previous researches split logs into sequential time windows and regarded each window as an independent instance for classification using popular machine learning methods like support vector machine(SVM), however, neglected the time patterns under logs. Those approaches also suffer from information loss due to the vector representation, and high dimensionality if there is a large number of log events. To make up these deficiencies, unlike most traditional methods that used a vector to represent a period behavior at the macro level, we construct a 2D matrix to reveal more detailed system behaviors in the time period by dividing each window into sequential subwindows. To provide a more efficient representation, we further use the ant colony optimization algorithm to find a highly-coupled event template as the horizontal index of the 2D window matrix to replace the disordered one. To capture time dependencies, a multi-module convolutional auto-encoder is configured as that different paralleled modules scan among different time intervals to extract information respectively. These features are then concatenated in latent space as the final input, which contains diversified time information, for classification by SVM. The experiments on Blue Gene/L log dataset showed that our proposed method outperforms the state-of-art SVM method.'}\n","{'text': 'In this paper, we propose a new fault line detection method based on the combination of the Variational Mode Decomposition (VMD) and Phase Space Reconstruction (PSR) techniques for Resonant Earthed System (RES). The proposed method utilizes time series analysis to extract the relevant features and then calculates the correlation coefficient with the reference signal. By introducing delay time and frequency conversion, the method is capable of accurately detecting the fault line. Transient analysis is performed to investigate the fault characteristics of the RES, and a set of power cables is used as the test bed for the proposed method. Experimental results demonstrate the effectiveness and accuracy of the proposed method for fault detection in RES. The proposed method provides a more efficient way of feature extraction than traditional techniques and can accurately locate the fault lines in a timely manner, thus providing a valuable tool for power system maintenance and fault diagnosis.'}\n","{'text': \"In this paper, we investigate secure communication in a massive multiple-input multiple-output (MIMO) system with multiple users and multiple eavesdroppers (Eve) under both pilot spoofing attack (PSA) and uplink jamming. Specifically, Eve impairs the normal channel estimation by sending identical pilot sequences with the legitimate users. Based on the impaired channel estimation, the base station adopts linear processing schemes for uplink data reception, which is jammed by Eve, and downlink confidential information transmission. We first evaluate the impact of the PSA on the achievable rate with linear processing, and then propose a double channel training based scheme to combat PSA. By using the channel estimation difference in two training phases, the presence of the PSA can be detected and accurate legitimate channel estimation can be obtained by removing the effect of Eve's channel. Furthermore, we analyze the channel estimation errors and derive a closed-form expression of the minimum mean square error precoding scheme to maximize the minimum achievable secrecy rate, which outperforms the conventional linear precoding counterparts.\"}\n","{'text': 'This paper proposes a multiple correlation estimation based digital background calibration scheme for pipelined ADCs. Calibration is necessary to correct the gain and offset errors of ADCs. The proposed scheme utilizes a mathematical model to estimate these errors and then corrects them in digital circuits. A simulation is conducted to validate the effectiveness of the proposed scheme. The results show a significant improvement in the accuracy of the ADC. Furthermore, the multiple correlation estimation technique used in the proposed scheme is a novel approach to ADC calibration. This technique is based on calculating the correlation between the inputs and outputs of the ADC, which can help to improve the accuracy of the estimation. Overall, the proposed scheme offers a promising solution to the problem of ADC calibration, which is critical for applications that require high precision data acquisition.'}\n","{'text': 'This paper aims at presenting the approach for the process of attributes verification in the Attribute-Based Encryption schemes. We considered ABE methods in the Internet of Things environment. The main idea is to allow users or device owners to verify attributes using standardized and well-known authorization protocols like Oauth2. More accurately, Attribute Authority will use Authentication as a Service approach for users and device controllers authentication. We described software service for Attribute-Based Encryption methods in the context of FIWARE platform. Components of this platform use Oauth2 for authentication and authorization mechanisms. More specifically, we developed a web application which allows devices to create orders for ABE secret keys with particular attributes. Further users should approve or deny these orders. We used FIWARE components for users and devices authentication. To the best of our knowledge, it is the first implementation of ABE algorithms in FIWARE ecosystem.'}\n","{'text': 'This paper proposes a method for monaural source separation in real room environments using sequentially trained deep neural networks (DNNs). The method aims to improve the signal to noise ratio by separating the target sound source from background interference. The system is trained using a combination of supervised and unsupervised training methods, with a focus on feature extraction to identify useful information in the input signal. The method is tested on real-world situations with interference from sources such as human speech and music. The authors report significant improvements in separation performance compared to existing methods, particularly in noisy and reverberant environments. The effectiveness of the method is shown to be highly dependent on the quality and quantity of the training data, with a larger and more diverse dataset resulting in improved performance. Overall, the proposed method offers promising results for performing monaural source separation in real-world settings, offering improved signal quality and separation performance.'}\n","{'text': 'Traffic noises, particularly the sound of vehicle horns, have a significant impact on the daily lives of individuals, and researchers have conducted numerous studies on the detection and localization of traffic sounds. This paper proposes a vehicle horn sound location method with an improved SRP-PHAT. Through analyzing the sounds, the frequency domain features for recognizing the vehicle horn sound are selected and the corresponding sound recognition method based on time-frequency transformation (VHSR-TFT) is presented. Complying with the large time cost of SRP-PHAT method for sounds location, the stochastic region contraction method is utilized to improve the real-time performance. The simulation and experimental results showed that the proposed method improved the accuracy and efficiency of sound detection compared to existing methods.'}\n","{'text': 'This note is devoted to the stabilization of a particular class of nonlinear cyclo-passive systems, namely, gradient-like systems. In order to accomplish the control task, we explore alternate representations of those systems with the aim of identifying (new) storage functions. Then, those storage functions are used to design a passivity-based controller that addresses the regulation problem without the necessity of solving partial differential equations.'}\n","{'text': 'This work demonstrates an ultra-low power, software-defined wireless transceiver designed for IoT applications using an open-source 32-bit RISC-V core. The key driver behind this success is an optimized hardware/software partitioning of the receiverâ\\x80\\x99s digital signal processing operators. We benchmarked our architecture on an algorithm for the detection of FSK-modulated frames using a RISC-V compatible core and ARM Cortex-M series processors. We use only standard compilation tools and no assembly-level optimizations. Our results show that Bluetooth LE frames can be detected with an estimated peak core power consumption of 1.6 mW on a 28 nm FDSOI technology, and falling to less than 0.6 mW (on average) during symbol demodulation. This is achieved at nominal voltage. Compared to state of the art, our work offers a power efficient alternative to the design of dedicated baseband processors for ultra-low power software-defined radios with a low software complexity.'}\n","{'text': 'Cloud computing has revolutionized the IT industry by providing an efficient and cost-effective way of delivering services over the internet. However, the increased use of servers in cloud infrastructure has resulted in a significant increase in energy consumption and carbon dioxide emissions. This paper proposes a green cloud framework for reducing carbon dioxide emissions in cloud infrastructure. The framework aims to reduce energy consumption and power demand by optimizing server utilization, improving cooling efficiency, and using renewable energy sources. Moreover, the proposed framework ensures that the quality of service is not compromised while reducing carbon emissions. The framework has the potential to significantly mitigate the environmental impact of cloud computing and provide a sustainable solution for the industry.'}\n","{'text': 'Task-oriented dialogue systems aim to assist users in accomplishing specific tasks with natural language. Recently, with the success of end-to-end chit-chat system, there have been many attempts to build RNN based task-oriented dialogue systems. Hybrid Code Network (HCN) is a practical and efficient end-to-end model using domain-specific software and Recurrent Neural Network (RNN). This paper presents an end-to-end dialogue system for hospital receptionist robot with multi languages using HCN. For this, we synthetically generated dialogue corpus including several tasks. Original HCN was only applied Long Short-Term Memory (LSTM) to train dialogues. We replenish HCN by applying other RNN structures in this architecture such as stacked, reversed input sequence and bidirectional structures. Our proposed RNN model achieved higher performance on the hospital receptionist domain in both English and Korean languages.'}\n","{'text': 'Automatic recommendation has become an important issue for industries, allowing users to discover new items that match their preferences and enabling the system to target items to the right users. In this paper, we present a new framework based on deep learning called deep matrix factorization (DMF) to handle any type of side information efficiently. In DMF, two feature transforming functions are built to directly generate latent factors of users and items from various input information. For implicit feedback input, implicit feedback embedding (IFE) is introduced. IFE converts the high-dimensional and sparse implicit feedback information into a low-dimensional real-valued vector retaining primary features. Using IFE could reduce the scale of model parameters conspicuously and increase model training efficiency. Our experiments on five public databases demonstrate that DMF outperforms other DL-based recommendation algorithms in terms of both accuracy and training efficiency.'}\n","{'text': 'This paper proposes an improved video stabilization technique using the Scale-Invariant Feature Transform (SIFT) and log polar transform for unmanned aerial vehicles (UAVs). The proposed technique involves feature extraction using SIFT and log polar transform to represent the extracted points in scale and rotation invariant coordinates. The stabilized video is generated by estimating the jitter and motion of the camera using Kalman filters. The proposed technique outperforms the conventional SIFT technique by reducing the jitter and camera motion in UAV video footage. The log polar transform used in the technique enables effective representation of the extracted points in a circular coordinate system, which is beneficial for matching feature points across frames. The proposed technique is highly suitable for UAVs, allowing for smoother and more stable video footage even in turbulent conditions.'}\n","{'text': 'This paper presents a dual-band slot dipole with artificial magnetic conductor (AMC) using textiles, which can be used in body area networks. Dipole antennas have been widely used in wireless communication systems due to their simplicity and ease of fabrication. The proposed antenna provides dual-band operation, which enhances the flexibility and versatility of the antenna system. The gain of the antenna is improved by incorporating AMC that acts as a reflector antenna. Additionally, the use of textiles in the design adds flexibility and comfort to the antenna, making it a suitable candidate for wearable devices. The antenna radiation patterns are analyzed, and the results show that the proposed design has a stable gain and radiation pattern at both frequency bands. The simulation results validate the proposed design, which is expected to have potential applications in wireless communication systems.'}\n","{'text': 'With the rise of electronic healthcare and advancements in information and communication technology, national eHealth strategies are being re-visited in the era of the Internet of Things and Big Data. The integration of these technologies has the potential to revolutionize healthcare delivery, but it also presents unique challenges related to data management, privacy, and security. Standards must be established to ensure interoperability and seamless communication between different devices and systems. As national eHealth strategies are re-evaluated, it is important to consider the opportunities presented by the Internet of Things and Big Data, while also addressing the potential risks and challenges. By developing a comprehensive strategy that includes standards for data management, healthcare providers can optimize the potential of these technologies to improve patient care and health outcomes.'}\n","{'text': 'In this paper, an effective improvement of under-modeling frequency-domain Kalman filter is presented, focusing on adaptive filters and frequency-domain analysis. The performance of the filter in steady-state is evaluated, as well as its convergence and computational complexity. The proposed algorithm is particularly relevant in the field of acoustics, where the accuracy of signal processing is essential. Results show that the improved filter outperforms other methods in terms of accuracy and efficiency, making it a promising solution for a wide range of applications.'}\n","{'text': 'Dengue fever is a highly dangerous infectious disease that spreads via the bite of the Aedes mosquito. In severe cases, it can develop into a life-threatening condition known as severe dengue, which includes Dengue Haemorrhagic Fever and shock syndrome. The disease burden of dengue has increased significantly in recent years worldwide, and because a specific antiviral medication for dengue has not been discovered yet, it is crucial to find effective preventive solutions to avoid a widespread outbreak of this disease. Unfortunately, until today, a specific anti-viral medicine for dengue is still undiscovered. The researchers applied monthly dengue cases time series data from the Indonesian region to four hybrid SI algorithms, including Moth Flame Optimization (MFO), Grey Wolf Optimizer (GWO), Firefly Algorithm (FA), and Artificial Bee Colony (ABC) algorithm. These algorithms were hybridized with Least Squares Support Vector Machines, and guided by Mean Square Error (MSE) and Root Mean Square Percentage Error (RMSPE), the study found that these hybrid algorithms could produce competitive results, with a slightly favor for ABCLSSVM. For simulation purposes, a monthly dengue cases time series data in the area of Indonesia were employed, which are fed to four hybrid SI algorithms, namely Moth Flame Optimization (MFO), Grey Wolf Optimizer (GWO), Firefly Algorithm (FA) and Artificial Bee Colony (ABC) algorithm. These algorithms are individually hybrid with Least Squares Support Vector Machines. Guided by Mean Square Error (MSE) and Root Mean Square Percentage Error (RMSPE), findings of the study indicate that the identified hybrid algorithms were able to produce competitive result, with a slightly favor to ABCLSSVM.'}\n","{'text': 'This paper presents an approximation algorithm for solving the 3-dimensional vehicle routing problem (3D-VRP) for a fleet of multi-agents. This problem arises in the context of routing drones for package delivery or other tasks in a 3D space. To address this problem, the algorithm combines the use of genetic algorithms and optimization techniques. The algorithm utilizes biological cells as the basic building blocks of the optimal solution and incorporates sociology and statistics to determine the most efficient routes for the multi-agent fleet. The use of three-dimensional displays allows the user to visualize the optimal solutions and make informed decisions. Overall, the proposed algorithm provides a practical and effective approach for solving complex 3D-VRP problems in a real-world setting.'}\n","{'text': \"The rapid proliferation of Internet of Things (IoT) devices has brought about numerous challenges, particularly in the area of security. With many of these devices being low-power and lacking adequate security measures, there is an urgent need to address this issue. However, security of these devices must be a critical priority, and many current research topics are looking at the composition of low power techniques to increase overall security in these low power commercial devices. Traditional low power TDMA or FDMA protocols are susceptible to reverse engineering, making TRANSEC crucial to safeguard IoT devices. This paper introduces the intentional injection of noise into the phase mapping process of a spread spectrum signal to decrease an eavesdropper's ability to directly observe the true phase and reverse engineer the associated PRNG output or key, even at high SNR. This technique trades a conscious reduction in signal correlation processing for obfuscation. This paper presents a candidate method and quantifies the performance impact in arbitrary-phase PSK-based spread spectrum signals.\"}\n","{'text': 'Association Rule Mining by Aprior method has been one of the popular data mining techniques for decades, where knowledge in the form of item-association rules is harvested from a dataset. The quality of item-association rules nevertheless depends on the concentration of frequent items from the input dataset. When the dataset becomes large, the items are scattered far apart. It is known from previous literature that clustering helps produce some data groups which are concentrated with frequent items. Among all the data clusters generated by a clustering algorithm, there must be one or more clusters which contain suitable and frequent items. In turn, the association rules that are mined from such clusters would be assured of better qualities in terms of high confidence than those mined from the whole dataset. However, it is not known in advance which cluster is the suitable one until all the clusters are tried by association rule mining. It is time consuming if they were to be tested by brute-force. In this paper, a statistical property called prior probability is investigated with respect to selecting the best out of many clusters by a clustering algorithm as a pre-processing step before association rule mining. Experiment results indicate that there is correlation between prior probability of the best cluster and the relatively high quality of association rules generated from that cluster. The results are significant as it is possible to know which cluster should be best used for association rule mining instead of testing them all out exhaustively.'}\n","{'text': 'This paper introduces a new algorithm for satellite image time series change detection. This algorithm is based on image subtraction analysis and does not directly work on raw images, but on their encoded feature representation version. By using image subtraction analysis, this unsupervised algorithm eliminates the need for labeled data in detecting changes. The change detection method is totally unsupervised and does not need any labeled data.'}\n","{'text': 'In recent years, the use of through-silicon vias (TSVs) has become increasingly important in the semiconductor industry due to its high integration capability. However, TSVs are prone to clustering faults, which can significantly affect the performance and reliability of the system. In this paper, we propose a 3-D rotation-based redundancy architecture to address clustering faults in TSVs. Our proposed architecture uses a rotation-based approach to distribute redundancy across multiple TSVs, which effectively mitigates the impact of clustering faults. To evaluate the effectiveness of our proposed architecture, we perform extensive simulations using various benchmarks and real-world applications, such as databases, smart grids, Zigbee, cloud computing, batteries, electric vehicles, and base stations. Our results show that our proposed architecture achieves an average of 25% improvement in reliability compared to existing redundancy architectures for TSVs.'}\n","{'text': 'Low-power wide area networks (LPWANs) have been identified as one of the top emerging wireless technologies due to their autonomy and wide range of applications. Yet, the limited energy resources of battery-powered sensor nodes is a top constraint, especially in single-hop topologies, where nodes located far from the base station must conduct uplink (UL) communications in high power levels. On this point, multi-hop routings in the UL are starting to gain attention due to their capability of reducing energy consumption by enabling transmissions to closer hops. However, identifying energy-efficient multi-hop routings beforehand is not simple due to the unpredictable factors affecting communication links in large LPWAN areas. In this paper, we propose epsilon multi-hop (EMH), a simple reinforcement learning (RL) algorithm based on epsilon-greedy to enable reliable and low consumption LPWAN multi-hop topologies. Results from a real testbed showed that multi-hop topologies utilizing EMH achieve significant energy savings compared to the default single-hop approach, which become more pronounced as network operation progresses.'}\n","{'text': \"This research paper focuses on the analysis of NBA players' performance and shot prediction using two predictive models, namely Random Forest and XGBoost models. The analytical and data models used in this study aim to provide a better understanding of basketball conditions and help trainers make better decisions when training their players to improve their performance. The study highlights the importance of computational modeling in capturing important features of the data, such as shot distance, clock time, and player-related variables. The predictive models developed in this study outperformed other benchmark models, which highlights their utility in shot prediction applications. Overall, this research provides a framework for improving NBA players' performance and enhancing the accuracy of shot prediction, which could lead to better team performance and game outcomes.\"}\n","{'text': 'The increasing demands for the capacity of cellular networks are leading to a significant surge in energy consumption. To tackle this issue, a new approach towards green mobile networks is proposed. This approach involves the concurrent user association and dynamic switching in cells, which seeks to minimize energy consumption while maintaining the quality of service. The use of switches and message passing play a crucial role in achieving the desired objectives. By dynamically switching off base stations during periods of low traffic, energy consumption is reduced with minimal impact on network performance. Meanwhile, the concurrent user association approach optimizes the usage of resources by assigning users to the most suitable cell based on their specific requirements. Therefore, the proposed approach presents a win-win solution that not only reduces energy consumption in cellular networks but also maintains quality of service.'}\n","{'text': 'With the increasing popularity of cloud computing, concerns over security and privacy have become a major issue. One such issue is the possibility of multi-covert channel attacks, affecting not only the protocols employed, but also the servers and software involved. In such attacks, a sender can transmit secret information to receivers over multiple covert channels, which can be difficult to detect and challenge by the system. To mitigate this problem, various techniques have been developed, including adding security policies and monitoring systems. However, the effectiveness of these solutions remains uncertain, and further studies are needed to improve the security of cloud computing. The present paper focuses on the problem of multi-covert channel attacks, analyzes its impact on cloud security, and proposes possible solutions for enhancing the confidentiality and integrity of information over cloud networks.'}\n","{'text': 'Multidisciplinary design optimization techniques become more and more applied in the field of aerodynamics due to the rapid development of computers high-performance, numerical methods and optimization algorithms. These techniques coupled with Computational Fluid Dynamics (CFD), which aims to incorporate mathematical relations and algorithms to analyze and solve fluid flow problems, involve the use of those numerical methods and algorithms to improve the fluid flow solutions. CFD analysis of an airfoil determines its ability by producing results such as lift and drag forces, and the application of an optimization algorithm involves improving the shape of this airfoil in order to manipulate the lift and drag coefficients according to the requirements. In this work, a numerical investigation, using ANSYS/Fluent, of two-dimensional transonic flow over a NACA 0012 airfoil was conducted at various Mach numbers and compared with the provided experimental data. The flow to be considered is compressible and turbulent and the solver used is the density based implicit solver, which gives good results for high speed compressible flows. Then a shape optimization algorithm, based on a Multi-Objective Genetic Algorithm, was used in order to obtain an improved performance control of the aerodynamic coefficients of the optimized airfoil.'}\n","{'text': 'We present NavWalker, a flexible random walk-based approach for learning the representations of vertices in an information network. The proposed method enables us to incorporate different walk strategies into the sampling process of random walks, in order to further boost the network embedding techniques. Specifically, we formulate the proposed method by integrating the adjacency matrix of a network with a pre-defined information augmentation matrix. In contrast to SkipGram-based network embedding methods such as DeepWalk and Node2vec, which use only local network information to learn the representations, our method is flexible to further incorporate global or other auxiliary network information to guide the sampling process. Experiments on six real-world datasets demonstrate the advantages of the flexibility and its superior performance as compared to other state-of-the-art network embedding algorithms for the tasks of classification and recommendation.'}\n","{'text': 'This paper proposes a low overhead distributed approach for IP flow records collection and analysis in IP networks. With the increasing amount of network traffic, scalability has become a critical issue in collecting and analyzing flow records in real-time. This paper presents a new computer architecture, which can efficiently compute flows with a high throughput, that can handle big data in real-time monitoring. Based on this architecture, the proposed approach employs a distributed system model to balance the load among multiple collectors and provides reliable data visualization and information retrieval. The experimental results show that the proposed approach has a significantly lower overhead and achieves better scalability compared to traditional solutions, making it a promising approach for enabling the real-time monitoring of large-scale networks.'}\n","{'text': 'Most of the swarm optimization techniques are inspired by the characteristics as well as behaviour of flock of birds whereas Artificial Bee Colony is based on the foraging characteristics of the bees. However, certain problems which are solved by ABC do not yield desired results in-terms of performance. ABC is a new devised swarm intelligence algorithm and predominately employed for optimization of numerical problems. The main reason for the success of ABC algorithm is that it consists of feature such as fathomable and flexibility when compared to other swarm optimization algorithms and there are many possible applications of ABC. Cloud computing has their limitation in their application and functionality. The cloud computing environment experiences several security issues such as Dos attack, replay attack, flooding attack. In this paper, an effective classifier is proposed based on Artificial Bee Colony for cloud computing. It is evident in the evaluation results that the proposed classifier achieved a higher accuracy rate.'}\n","{'text': 'The routing in Inter-Satellite Telecommunication Networks (ISTN) has a significant impact on their usability. This paper focuses on analyzing the routing mechanisms in ISTN and their effect on network topology and convergence. The study examines the different orbit types used in ISTN and their suitability for routing. The paper concludes that although ISTN involves a small number of satellites, its routing system plays a crucial role in its usability. The network topology and convergence time greatly affect the overall performance of ISTN. Understanding the relationship between routing and orbit types is essential to design a reliable and efficient routing mechanism for ISTN. The analysis of routing usability in ISTN highlights the need for efficient routing algorithms and emphasizes the importance of careful network topology planning.'}\n","{'text': 'Video summarization (VSUMM) has become a popular method in processing massive video data. The key point of VSUMM is to select the key frames to represent the effective contents of a video sequence. The existing methods can only extract the static images of videos as the content summarization, but they ignore the representation of motion information. To cope with these issues, a novel framework for an efficient video content summarization as well as video motion summarization is proposed. Initially, Capsules Net is trained as a spatiotemporal information extractor, and an inter-frames motion curve is generated based on those spatiotemporal features. Subsequently, a transition effects detection method is proposed to automatically segment the video streams into shots. Finally, a self-attention model is introduced to select key-frames sequences inside the shots; thus, key static images are selected as video content summarization, and optical flows can be calculated as video motion summarization. The ultimate experimental results demonstrate that our method is competitive on VSUMM, TvSum, SumMe, and RAI datasets about shot segmentation and video content summarization, and can also represent a good motion summarization result.'}\n","{'text': 'With the continuous development of the Internet of Things (IoT) and communications technology, especially under the epoch of 5G, mobile tasks with big scales of data have a strong demand in deep learning such as virtual speech recognition and video classification. Considering the limited computing resource and battery consumption of mobile devices (MDs), these tasks are often offloaded to the remote infrastructure, like cloud platforms, which leads to the unavoidable offloading transmission delay. Edge computing (EC) is a novel computing paradigm, capable of offloading the computation tasks to the edge of networks, which reduces the transmission delay between the MDs and cloud. Therefore, combining deep learning and EC is expected to be a solution for these tasks. However, how to decide the offloading destination [cloud or deep learning-enabled edge computing nodes (ECNs)] for computation offloading is still a challenge. In this paper, a heuristic offloading method, named HOM, is proposed to minimize the total transmission delay. To be more specific, an offloading framework for deep learning edge services is built upon centralized unit (CU)-distributed unit (DU) architecture. Then, we acquire the appropriate offloading strategy by the origin-destination ECN distance estimation and heuristic searching of the destination virtual machines for accommodating the offloaded computation tasks. Finally, the effectiveness of the scheme is verified by detailed experimental evaluations.'}\n","{'text': 'This paper considers the transceiver design for uplink massive multiple-input multiple-output (MIMO) systems with channel sparsity in the angular domain. Recent progress has shown that sparsity-learning-based blind signal detection is able to retrieve the channel and data by using massage-passing-based sparse matrix factorization methods. Short pilot sequences are inserted into user packets to eliminate the so-called phase and permutation ambiguities inherent in sparse matrix factorization. In this paper, to exploit the knowledge of these short pilot sequences more efficiently, we propose a semi-blind channel-and-signal estimation (SCSE) scheme in which the knowledge of the pilot sequences are integrated into the message passing algorithm for sparse matrix factorization. The SCSE algorithm involves enumeration over all possible user permutations, and so is time-consuming when the number of users is relatively large. To reduce complexity, we further develop the simplified SCSE (S-SCSE) to accommodate systems with a large number of users. The numerical results show that our semi-blind signal detection scheme substantially outperforms the state-of-the-art blind detection and training-based schemes in the short-pilot regime.'}\n","{'text': \"There is an increasing demand for efficient test generation methodologies that can detect Trojan horses in integrated circuits. Side channel analysis is a popular approach that exploits the sensitivity of a circuit to reveal the presence of Trojans. However, the challenge lies in generating test patterns that can trigger the Trojan and distinguish it from normal behavior. This paper proposes a novel method that uses sensitivity-based switching activity optimization (SSAO) and genetic algorithms to generate test patterns efficiently. The SSAO technique exploits the switches' sensitivity to identify critical paths and select the most relevant signals for optimization. The genetic algorithm then searches for the optimal switching behavior that can trigger the Trojan. Experimental results demonstrate that the proposed method outperforms existing techniques in terms of coverage and efficiency. It provides an effective and scalable solution for detecting Trojans in complex switching circuits and can be applied to various systems that rely on logic testing.\"}\n","Processing batch 20/63\n","{'text': 'Impressive growth in the number of wearable health monitoring devices has affected global health industry as they provide rapid and intricate details related to physical examinations, such as discomfort, heart rate, and blood glucose level, which enable doctors to efficiently diagnose sensitive heart troubles. The Internet of Medical Things (IoMT) is a phenomenon wherein computer networks and medical equipment are connected through the Internet to provide real-time interaction between physicians and patients. In this article, we present a comprehensive view of the IoMT and its related Machine Learning (ML)-based developed frameworks designed, or being utilized, in the last decade, i.e., from 2010 to 2019. The presented techniques are designed for monitoring limbs, controlling rural healthcare, identifying e-health applications, monitoring health through mobile apps, classifying heart sounds, detecting stress in drivers, monitoring cardiac diseases, making the decision to predict heart attacks, recognizing human activities, and classifying breast cancer. The aim is to provide a clear picture of the existing IoMT environment so that the analysis may pave the way for the diagnosis of critical disorders such as cancer, heart attack, and blood pressure among others. In the end, we also provide some unresolved challenges that are confronted in the deployment of the secure IoMT-based healthcare systems.'}\n","{'text': 'Breast mass is one of the most distinctive signs for the diagnosis of breast cancer, and the accurate segmentation of masses is critical for improving the accuracy of breast cancer detection and reducing the mortality rate. It is time-consuming for a physician to review the film. Besides, traditional medical segmentation techniques often require prior knowledge or manual extraction of features, which often lead to a subjective diagnosis. Therefore, developing an automatic image segmentation method is important for clinical application. In this paper, a fully automatic method based on deep learning for breast mass segmentation is proposed, which combines densely connected U-Net with attention gates (AGs). It contains an encoder and a decoder. The encoder is a densely connected convolutional network and the decoder is the decoder of U-Net integrated with AGs. The proposed method is tested on the public and authoritative database-Digital Database for Screening Mammography (DDSM) database. F1-score, mean intersection over union, sensitivity, specificity, and overall accuracy are used to evaluate the effectiveness of the proposed method. The experimental results show that dense U-Net integrated AGs achieve better segmentation results than U-Net, attention U-Net, DenseNet, and state-of-the-art methods.'}\n","{'text': \"With the continuous development of the Chinese economy and the gradual acceleration of urbanization, it has caused tremendous damage to the environment. The bad air environment seriously damages the physical and mental health of the people. The change in smog concentration will be affected by many realistic factors and exhibit nonlinear characteristics. The method proposed in this paper is to use the Internet of Things (IoT) technology to monitor the acquired data, process the data, and predict the next data using a neural network. The existing prediction models have limitations. They don't accurately capture the law between the concentration of haze and the factors affecting reality. It is difficult to accurately predict the nonlinear smog data. One algorithm proposed in this paper is a two-layer model prediction algorithm based on Long Short Term Memory Neural Network and Gated Recurrent Unit (LSTM&GRU). We set a double-layer Recurrent Neural Network to predict the PM2.5 value. This model is an improvement and enhancement of the existing prediction method Long Short Term Memory (LSTM). The experiment integrates data monitored by the IoT node and information released by the national environmental protection department. First, the data of 96 consecutive hours in four cities were selected as the experimental samples. The experimental results are close to the true value. Then, we selected daily smog data from 2014/1/1 to 2018/1/1 as a train and test dataset. It contains smog data for 74 city sites. The first 70% of the data was used for training and the rest for testing. The results of this experiment show that our model can play a better prediction.\"}\n","{'text': 'A robust nonlinear output feedback control method is presented, which achieves two degrees of freedom (2-DOF) attitude tracking of a helicopter system test bed. The control law is designed to compensate for uncertainty in the helicopter system dynamic model, including input-multiplicative parametric uncertainty. To reduce the computational requirement in the closed-loop system, constant feedforward estimates of the input-multiplicative uncertainty are utilized in lieu of adaptive parameter estimates. Eschewing the high-gain feedback requirement that is characteristic of standard sliding mode observer methods, the proposed control method utilizes a bank of dynamic filters, which operates as a velocity estimator in the closed-loop system. Computer simulation and experimental results are provided to demonstrate the performance of the attitude tracking control method using the Quanser 2-DOF AERO helicopter.'}\n","{'text': 'This research concerns the detection of unauthorised access within hospital networks through the real-time analysis of audit logs. Privacy is a primary concern amongst patients due to the rising adoption of Electronic Patient Record (EPR) systems. There is growing evidence to suggest that patients may withhold information from healthcare providers due to lack of Trust in the security of EPRs. Yet, patient record data must be available to healthcare providers at the point of care. Ensuring privacy and confidentiality of that data is challenging. Roles within healthcare organisations are dynamic and relying on access control is not sufficient. Through proactive monitoring of audit logs, unauthorised accesses can be detected and presented to an analyst for review. Advanced data analytics and visualisation techniques can be used to aid the analysis of big data within EPR audit logs to identify and highlight pertinent data points. Employing a human-in-the-loop model ensures that suspicious activity is appropriately investigated and the data analytics is continuously improving. This paper presents a system that employs a Human-in-the-Loop Machine Learning (HILML) algorithm, in addition to a density-based local outlier detection model. The system is able to detect 145 anomalous behaviours in an unlabelled dataset of 1,007,727 audit logs. This equates to 0.014% of the EPR accesses being labelled as anomalous in a specialist Liverpool (UK) hospital.'}\n","{'text': 'This paper proposes a robust adaptive cancellation strategy to handle unknown sinusoidal disturbances in control systems. The method utilizes frequency estimation to map the disturbance signal to an unknown function, which is then compensated through an adaptive control scheme. The proposed method guarantees the asymptotic stability of the closed-loop system and allows for convergence to the manifolds associated with the unknown disturbance. A PI control law is also proposed to maintain steady-state performance. Experimental results demonstrate the effectiveness of the proposed approach in canceling unknown sinusoidal disturbances. This method has important implications for adaptive systems, particularly those with uncertain or time-varying disturbances.'}\n","{'text': 'The problem of link prediction has captured considerable attention from various disciplines due to its wide range of applications. A multitude of link prediction methods have been proposed with various techniques. The local NaÃ¯ve Bayes (LNB) model is an effective one, which discriminates the contribution of different common neighbors by a role function. This paper proposes a new link prediction method, which further enhances the accuracy of the LNB model by considering the local community links and the degree of seed nodes. The experimental results on 12 real-world networks demonstrate that the proposed method outperforms the compared methods in the top-L link prediction task.'}\n","{'text': 'We provide new sequential predictors for a large class of linear time-varying systems that contain constant delays in the vector fields and also constant delays in the inputs. We allow the input delays to be arbitrarily large. Through our sequential predictors-based feedback control, we demonstrate the global exponential stability of the origin in an augmented system that encompasses the original system in closed loop. We illustrate our new theorem in an example from identification theory.'}\n","{'text': \"Ground Penetrating Radar (GPR) is widely used for subsurface imaging in various applications, including geophysical exploration, geological mapping, and archaeological studies. However, the accuracy of GPR data can be affected by the characteristics of radar antennas, which can result in errors in the interpretation of the subsurface information. In this paper, we propose a method for filtering out antenna effects from GPR data by utilizing a Radial Basis Function (RBF) Neural Network. The algorithm works by training the RBF network with the help of Green's function methods, which are used to model the behavior of antenna radiation. The training data includes both aperture antennas and cylindrical antennas, which are commonly used in GPR. The proposed method can effectively remove antenna effects, leading to more accurate and reliable GPR data. Compared to traditional methods that rely on calibration procedures, the proposed method is more efficient and cost-effective. Our experimental results demonstrate the superiority of the proposed method in eliminating antenna effects, which can greatly improve the performance of GPR systems in practice.\"}\n","{'text': 'This paper introduces a new approach for face inpainting, utilizing a dilated skip architecture and multi-scale adversarial networks. The combination of these two techniques improves image reconstruction and increases training efficiency. The proposed method is specifically designed for faces, and can effectively fill in missing or damaged regions of facial images. The dilated skip architecture expands the receptive field of the network and provides a more efficient and accurate feature extraction process. The multi-scale adversarial networks enable the model to capture higher-level textures and details in face images. Overall, this method improves the maintenance engineering of facial images by delivering higher image resolution and accuracy. The proposed technique can be integrated with existing computer architecture to enhance facial imaging capabilities for various applications.'}\n","{'text': 'This paper presents a novel approach for Electrocardiography (ECG) Authentication using a Neural Network Hardware Design with Collective Optimization of Low Precision and Structured Compression. The proposed method involves training the neural network using a combination of low-precision and structured compression techniques to improve the hardware performance. In addition, specific Neurons are selected for feature extraction, and a cost function is used to guide the optimization process. The results of the experiments show that the proposed method is effective in reducing hardware complexity while maintaining a high level of accuracy for ECG authentication. This research contributes to the development of more efficient and reliable hardware designs for ECG authentication systems.'}\n","{'text': 'In case of cardiac arrest, prompt intervention of bystanders can be vital in saving lives. Basic Life Support and Defibrillation (BLSD) is a procedure designed to deliver a proficient emergency first response. Developing skills in BLSD in a large part of the population is a primary educational goal of resuscitation medicine. In this context, novel computer science technologies like Augmented Reality (AR) and Virtual Reality (VR) can alleviate some of the drawbacks of traditional instructor-led courses, especially concerning time and cost constraints. This paper presents Holo-BLSD, an AR system that allows users to learn and train the different operations involved in BLSD and receive an automatic assessment. The system uses a standard manikin which is â\\x80\\x9caugmentedâ\\x80?by an interactive virtual environment that reproduces realistic emergency scenarios. The proposed approach has been validated through a user study. Subjective results confirmed the usability of the devised tool and its capability to stimulate learnersâ\\x80?attention. Objective results indicated no statistical significance in the differences between the examinersâ\\x80?evaluation of users who underwent traditional and AR training; they also showed a close agreement between expert and automatic assessments, suggesting that Holo-BLSD can be regarded as an effective self-learning method and a reliable self-evaluation tool.'}\n","{'text': 'In this paper, we present a novel deep model named coarse-fine convolutional neural network (CFCNN) for person re-identification in camera sensor networks, which jointly learns global and multi-scale local features simultaneously. To this end, we design the CFCNN as a multi-branch network, which is composed of one coarse and two fine branches. Specifically, the global feature is learned from the coarse branch, and the two fine branches are developed to extract two kinds of local features with different scales. Afterward, each branch is followed by a classification loss to make the identity prediction. Finally, we obtain completed pedestrian representations via concatenating the learned global and all local features. We conduct a number of experiments to evaluate the effectiveness of the CFCNN on three datasets. The CFCNN achieves high rank-1 and mAP accuracy with 94.0%/81.2%, 64.6%/58.4%, and 85.7%/72.4% on Market-1501, CUHK03, and DukeMTMC-reID, respectively. These results significantly outperform the prior state-of-the-art methods.'}\n","{'text': 'Personal clouds are becoming popular due to the raising privacy concerns regarding the available public cloud services. This is mainly because user data is being used for data mining purposes by recommendations and e-commerce tasks. However, there are limitations in personal cloud devices which makes the user experience poor. Although it is challenging to embrace hybrid cloud solutions for personal use, people tend to use Network-Attached Storage (NAS) and hybrid cloud solutions which are available for enterprise usage. This paper presents a novel concept which enables personal cloud devices to perform synchronization over nomadic access devices and provide remote access similar to that of existing cloud storage services. The presented personal cloud solution implements the most widely used features, while successfully obtaining a competitive user experience and performance in comparison with existing cloud services. Furthermore, this solution provides the users with expected privacy for content as in the case of a generic NAS device. The highlighted features include remote file browsing, shareable link generation, robust synchronization among personal cloud devices, simple user management similar to cloud services and remote file uploading/downloading facilities. The developed features intend to bridge the gap between existing cloud storage solutions and NAS devices by introducing cloud services to the NAS devices. The presented solution provides the features at a minimum bandwidth utilization while providing a greater user experience along with the privacy of data.'}\n","{'text': 'The Digital Ant Mechanism is a novel approach to solving complex optimization problems in communication networks by mimicking the behavior of ant colonies. This paper explores the applications of the Digital Ant Mechanism in network security, focusing on the use of sensors to collect data, task analysis to identify and prioritize security threats, and decision making to implement effective security measures. The Particle Swarm Optimization algorithm is used as a tool to optimize the performance of the Digital Ant Mechanism, enabling it to adapt to changing network conditions and maximize network security. This paper concludes by highlighting the potential of the Digital Ant Mechanism to enhance network security and mitigate the risks associated with cyber threats.'}\n","{'text': 'This paper presents a novel evaluation method for web server security based on multi-source data. By integrating data from various sources such as IP networks and XML, this method allows for a more comprehensive and accurate assessment of server security. The use of information processing techniques and data models facilitates the analysis and interpretation of the collected data. Additionally, safety considerations are taken into account to ensure that the evaluation is conducted in a secure and reliable manner. Overall, this method provides a robust and effective solution for assessing web server security and is applicable in a variety of contexts.'}\n","{'text': 'In this paper, we propose an IoT assisted Kernel Linear Discriminant Analysis based Gait Phase Detection Algorithm for walking with cognitive tasks. The focus is on legged locomotion where cognitive tasks are present. The proposed algorithm involves three stages: task analysis, feature extraction, and phase detection. The algorithm incorporates electromyography sensors and other IoT sensors to extract features and identify gait phases accurately. The proposed method includes a kernel-based feature transformation to capture the non-linear patterns of the gait cycle. The combination of IoT, kernel-based algorithms, and linear discriminant analysis provides a robust and efficient method to detect gait phases during walking with cognitive tasks. The proposed method achieves high accuracy in detecting gait phases under different cognitive loads. The results indicate the potential of the IoT-based approach in detecting human activity phases during walking with cognitive tasks.'}\n","{'text': 'This paper proposes a novel approach to enhance the performance of Cube-to-ERP conversion for 360 video content using geometry features. Specifically, we focus on utilizing the geometry and face properties of 360 video structure to enhance the accuracy of data interpolation and compression, thereby improving the overall performance of Cube-to-ERP conversion. We utilize information science and convolutional neural network techniques to extract and analyze the geometry features of the 360 video content. Our preliminary results demonstrate that incorporating geometry features can significantly improve the quality of Cube-to-ERP conversion output while minimizing the computational overhead. Overall, this paper highlights the potential of using geometry features to enhance the performance of Cube-to-ERP conversion for 360 video content, and offers insights into the possibilities of further research in this area.'}\n","{'text': 'Revised: \\nSecure group communication within the Internet of Things (IoT) necessitates the establishment and management of one or more group keys for confidential group messaging, among other group security services. One of the main challenges in ensuring secure group communication in IoT is designing a group key establishment scheme that is feasible for nodes with limited computational capabilities. To address this issue, we propose a lightweight group key establishment scheme based on fast symmetric-key encryption in this paper. We show a mechanism for designing a lightweight and secure IoT group key establishment and management scheme whose security is underpinned by the perfect secrecy provided by the One Time Pad. We then argue that the scheme is convenient for IoT group applications where nodes are resource-constrained. We prove that our scheme is secure under a threat model where the attacker has sufficiently large computational power. We also prove that the scheme provides desired group security properties such as confidentiality, key secrecy and independent group session keys generation.'}\n","{'text': 'In this paper, differential evolution (DE) is used to find optimal weights for echo state neural network model and also to optimize the number of rules of the modeled fuzzy system that presents the input to the echo state neural network (ESNN) model. ESNN designed in this work possess a recurrent neuronal infra-structure called as reservoir. This work aims to develop a good reservoir for the ESNN model employing the coherent features and the ability of the differential evolution algorithm and fuzzy rule base system. DE aims to pre-train the fixed weight values of the network with its effective exploration and exploitation capability and fuzzy rule base system (FRBS) formulates a set of rules, which provides inferences for the inputs presented to the echo state network model. The performance of the developed optimized network is evaluated based on the error metrics and the computational time incurred for the training of the model. The test results of ESNN model using DE and FRBS are compared with that of ESNN without optimization and fuzzy rule to prove its validity and also with the related existing techniques. The perceived DE based fuzzy ESNN model is verified for its effectiveness with a set of time series forecasting benchmark problems. The empirical results prove the superiority and the effectiveness of the DE based fuzzy ESNN learning outcomes.'}\n","{'text': 'A novel and widespread business model in cloud computing is to provide on-demand software as a service (SaaS) over the Internet. The software runs on a server and the user access it through an Internet connection. A single application instance can be shared by multiple users which provide a cost-effective solution to SaaS providers. Varying requirements from multiple users increase complexity in SaaS application design. The success of SaaS depends on its design. SaaS is different than traditional web-based application, so traditional application design model cannot full fill many SaaS specific design requirements. This paper provides a better understanding of key design factors in SaaS development process which results in a successful SaaS product following an improved design process. This study identifies key design factors through literature review and provides guidelines for key design factors on the SaaS application development. Ultimately, it will be beneficial for SaaS developers to improve the SaaS application development process and have a positive impact on the final product.'}\n","{'text': 'We investigate the challenge of distributed state estimation of a linear dynamical process in an environment that is vulnerable to attacks. A network of sensors, some of which can be compromised by adversaries, aim to estimate the state of the process. We examine the impact of having a small subset of \"trusted\" nodes that are immune to attacks. By identifying necessary and sufficient conditions for resilient distributed state estimation given a set of trusted nodes, we demonstrate how even a small trusted set can achieve the desired level of robustness. We use such conditions to illustrate how even a small trusted set can achieve a desired degree of robustness (where the robustness metric is specific to the problem under consideration) that could otherwise only be achieved via additional measurement and communication-link augmentation. We then establish that, unfortunately, the problem of selecting trusted nodes is NP-hard. Finally, we develop an attack-resilient, provably-correct distributed state estimation algorithm that appropriately leverages the presence of the trusted nodes.'}\n","{'text': 'In recent times, machine learning algorithms have proven to be quite useful in industrial processes. However, the analysis of static and dynamic representations together has not been comprehensively addressed. In this paper, an enhanced random forest algorithm with a concurrent analysis of static and dynamic nodes is proposed to address this issue for fault classification. Firstly, a new slowness index that is more suited for the problem of supervised fault classification is designed by modifying the standard slow feature analysis. Second, a feature ranking process is conducted to determine the significant features. These features, which substitute the raw variables in the nodes, are used to build the enhanced random forest. Using this method, the significant static and dynamic nodes are selected to increase the discriminative ability and interpretation. With the selected uncorrelated slow features, which are more ideal for training the forest than the initial correlated variables, the dynamic characteristics of industrial processes are comprehensively addressed. The application of the proposed method to fault classification is evaluated by both the Tennessee Eastman benchmark and a real-world three-phase flow process. The experimental results show that the proposed method significantly outperforms traditional learning algorithms, with both accuracy and F1 scores exceeding 70% for the 16-class Tennessee Eastman process and exceeding 99% for the 4-class three-phase flow process. The selected significant features reveal that both the static and dynamic information play important roles in fault classification.'}\n","{'text': 'The smart wheelchair is designed to aid people with infirmity, comprehensive impairment have a better quality, and a more self-supporting lifestyle. The aim of this paper is to increase a typical wheelchair attached with sensors to an audio combination that interpret commands, and a mobility-control software as an outcome of the wheelchair\\'s movement. Automated chair studies the arrangement of surrounding area (school, infirmary, healing center, houses, shopping mall etc.,) through a recited, directed journey that a person enters. Eventually, the chair will move to any formerly-updated position underneath the voice instruction (e.g., \"Take ME to the cafeteria\"). This automation is acceptable to those that have quality due to brain injury or the loss of limbs. The technology may enhance safety for users who use standard joystick-controlled high-powered wheelchairs, by preventing collisions with walls, mounted objects, article of furniture and people. We envision that a voice-commendable wheelchair could improve the quality of life and safety of tens of thousands of users. Moreover, considerable health improvements.'}\n","{'text': 'Animation studios render 3D scenes using a technique called path tracing which enables them to create high quality photorealistic frames. Path tracing involves shooting 1000â\\x80\\x99s of rays into a pixel randomly (Monte Carlo) which will then hit the objects in the scene and, based on the reflective property of the object, these rays reflect or refract or get absorbed. The colors returned by these rays are averaged to determine the color of the pixel. This process is repeated for all the pixels. Due to the computational complexity it might take 8â\\x80?6 hours to render a single frame. We implemented a neural network-based solution to reduce the time it takes to render a frame to less than a second using a generative adversarial network (GAN), once the network is trained. The main idea behind this proposed method is to render the image using a much smaller number of samples per pixel than is normal for path tracing (e.g., 1, 4, or 8 samples instead of, say, 32,000 samples) and then pass the noisy, incompletely rendered image to our network, which is capable of generating a high-quality photorealistic image.'}\n","{'text': 'In recent years, energy harvesting (EH) has become a promising technology for powering wireless sensor networks (WSNs). This has led to the development of mobile simultaneous wireless information and power transfer (SWIPT) networks, which have the potential to harvest energy from radio frequency (RF) signals and use that energy to transfer information. The nonlinearity of the EH model, however, poses a significant challenge in the design and analysis of these networks. To address this issue, integrated circuit modeling and numerical models are being used to study the information-energy region of mobile SWIPT networks. Additionally, the development of new receivers and wireless communication protocols is being pursued to enhance the efficiency and reliability of these networks. Despite these efforts, there is still much to be done to fully understand and realize the potential of mobile SWIPT networks.'}\n","{'text': 'The projective synchronization of three memristor chaotic systems with unknown parameters via adaptive control has been extensively studied in the field of chaotic communication. This approach has shown to be highly effective for achieving synchronization between multiple chaotic systems. The memristors have become a popular choice for chaotic communication due to their nonlinear dynamic characteristics. The system relies on the adaptive control to adaptively adjust the control parameters along with the system dynamics to achieve synchronization. The parameter estimation plays a key role in attaining synchronization by ensuring that the control parameters are accurately estimated. The approach has been validated through numerical simulations, where it was observed that the three memristor chaotic systems achieved synchronization in a short period. The results highlight the effectiveness of this approach in achieving synchronization of chaotic systems, which has enormous potential in the field of secure communications.'}\n","{'text': 'This paper introduces an innovative approach for computing rational models that can be used in electromagnetic transients simulations. Our methodology combines the Loewner Matrix (LM) and Matrix Pencil Method (MPM) techniques to identify the model order, along with the highly accurate vector fitting (VF) technique. Our results demonstrate that our proposed technique surpasses the individual application of MPM, LM, and VF methods. A unique advantage of the proposed algorithm is that the model order can be determined automatically.'}\n","{'text': 'An optimization based on genetic algorithm (GA) for determining the cutting parameters in machining operations is proposed. In turning metal cutting processes, cutting conditions are influencing the tool wear and material removal rate. The GA is utilized as an optimal solution tool to find optimal cutting parameters during the turning process by considering minimum tool wear and maximum material removal rate. The EN24T steel is chosen as the material for machining as it is widely used for different applications such as rollers, bolts, screws, and connecting rods. The turning operation is carried out on a CNC lathe with SINUMERIK 802D using coated carbide inserts cutting tool. Additionally, the analysis of variance (ANOVA) is applied to identify the significant input parameters that affect the output responses. The proposed methodology offers the advantage of performing multi-object optimization by using GA which can obtain a near-optimal solution. This approach is suitable for machining parameter selection of machined parts that require many machining constraints. The main advantage of the proposed methodology is the capability to perform multi-object optimization. The optimal value of cutting speed is determined to be 296.100 m/min, depth of cut is 1.33 mm, and feed is 0.4 mm/rev. Finally, it can be concluded from the results of this work that the optimal value of cutting speed is (296.100 m/min), depth of cut is (1.33 mm) and feed is (0.4 mm/rev).'}\n","{'text': \"In the traditional Multiple Model Adaptive Estimation (MMAE) algorithm, the extended Kalman filter has theoretical limitations, and the establishment of accurate aircraft mathematical model is almost impossible. In this paper, the Kernel Adaptive Filter (KAF) is introduced to replace the Kalman filter, a new multi-model adaptive estimation fault diagnosis method is proposed. Based on the kernel methods, the complex nonlinear system is mapped to the high-dimensional feature space, then the adaptive filter is designed in the high-dimensional feature space without the need to know the system model in advance. After KAF training using the offline input control signal and output flight state measurement with noise, real flight state values and actuator fault detection and isolation can be achieved online. Simulation results demonstrate the new fault diagnosis method's excellent performance in actuator fault diagnosis.\"}\n","{'text': 'People experience mental stress on a daily basis from a variety of different reasons, including environmental reasons (traffic, noise, or bad weather), social reasons (family issues, friends, and financial problems), or from events such as wedding planning or giving a presentation in front of large audience. A manageable amount of stress is healthy and can motivate a person; however, a large amount of continuous stress or a strong response to stress can be harmful. Therefore, the identification and prediction of mental stress has become a crucial area of research, and there are numerous approaches in the literature for stress detection using machine learning. In this paper, we review and summarize various approaches found in the literature for stress detection using machine learning and suggest directions for future research and interventions.'}\n","{'text': 'Small cells (SCs) mounted on top of the unmanned aerial vehicles (UAVs) are a promising solution to boost the capacity in hotspot areas. However, the adoption of UAV-SCs involves the planning of their missions over time, which includes the scheduling of recharging actions of each UAV-SC at ground sites. Typically, the energy needed to recharge UAV-SCs is derived from the grid, which can be coupled with microgeneration exploiting renewable energy sources (e.g., solar panels). In this architecture, the energy that is locally produced can be either sold to the grid or used to recharge the UAV-SCs. On the other hand, when the energy from microgeneration is insufficient for recharging the UAV-SCs, additional energy can be bought from the grid. In this paper, we investigate the trade-off between maximizing the throughput provided by the UAV-SCs over a set of areas, maximizing energy sold to the grid, and maximizing energy bought from the grid. The proposed model, MaxUAVProfit, is designed to (i) plan the UAV-SCs missions as a sequence of positions and actions in 3D space vs. time, (ii) manage the grid-connected microgeneration, and (iii) control the amount of throughput received by each hotspot. We then evaluate the MaxUAVProfit in a realistic scenario, which is based on the measurement of real cellular metrics and a realistic UAV-SC energy consumption model. Our findings demonstrate the superiority of the MaxUAVProfit with respect to other competing solutions, which include either optimization of microgeneration or maximization of the area throughput.'}\n","{'text': 'In this paper, we describe accuracy verification of simultaneous localization and mapping (SLAM) in a crowded area where measured data often becomes insufficient. To realize autonomous locomotion of robots in an unknown environment, they need to create an environment map while estimating self-pose with measured data. When the robot works in an area where many people exist, however, the measured data is frequently occluded by them and become insufficient to achieve the SLAM. Applying moving horizon estimation to SLAM, when the measured data is insufficient, the evaluation of the motion model becomes more dominant than that of the matching error of the measured data. To verify the effectiveness of SLAM based on MHE, we conduct experiments in the crowded area to compare the result with that of SLAM based on extended Kalman filter. Also, we applied sequential quadratic programming to the optimization to reduce the computational complexity of the proposed method. It was confirmed that the computational complexity was reduced by about 88 % compared to the trust region method.'}\n","{'text': \"Indoor/outdoor localization topic has gained a significant research interest due to the wide range of potential applications. Commonly, the Fingerprinting methods for spatial characterization of the environments monitored are employed in deterministic/statistical estimation. However, there are Fingerprint parameters that are generally neglected and can seriously affect the performance yielding to low accurate location. Nowadays, machine and deep learning (DL) methods are employed in this topic due to its ability to approximate complex non-linear models being capable of mitigating the undesirable effects of wireless propagation. In this paper, a complete overview of most influential aspects in Fingerprinting and indoor tracking methods is presented. Furthermore, a novel multi-modal complete tracking system, called SWiBluX, based on statistic and DL techniques is presented. The system relies on relevant feature extraction from available data sources to estimate user's/target indoor position using a multi-phase statistical Fingerprint and DL disruptive approach. In addition, a Gaussian outlier filter is applied to the position estimation model output to further reduce the error in the estimation. The set of experiments performed shows that Fingerprint positioning accuracy estimation can be improved up to 45% resulting in a final estimation error that outperforms related literature.\"}\n","{'text': \"This paper presents the SDQ-PPPI, a Software Defined Quadcopter-Power Prediction Platform IoT for Efficient Wind Turbine Power Generation. The system uses wind speed measurements to predict the power generation of wind turbines and adjusts the quadcopter's position to optimize the efficiency of power generation. The system employs biological neural networks, inspired by neurons in the brain, to train control systems with big data. The proposed system has the potential to improve the efficiency and cost-effectiveness of wind power generation. The findings suggest that the SDQ-PPPI is a promising solution to address the challenges of renewable energy systems.\"}\n","{'text': \"The article describes a method to generate training data for the neural network used in aircrafts' classification, localization and parameters' estimation problem. The standard description of the approach used, top-level algorithms and their configuration details provided. The simplified problem described, modeled and solved; results also included.\"}\n","{'text': 'As an important precondition for underwater acoustic signal analysis and underwater target detection & identification, classification of underwater acoustic sensor signal (especially in low signal-to-noise ratio) has become a research focus on underwater acoustic sensor signal processing in terms of complicated acoustic environment and increasingly slighter target noise. Mel-Frequency Cepstrum Coefficients (MFCC) of underwater acoustic signal are extracted in the Paper to classify and identify characteristics spectrogram of MFCC of underwater acoustic signal in combination with recurrent neural network and convolutional neural network and a Deep Neural Network (DNN) model is established for classification of underwater acoustic signal to propose a method of underwater acoustic signal classification based on DNN, support efficient classification of underwater acoustic signal, and provide high-quality data input for underwater acoustic signal analysis and underwater target identification.'}\n","{'text': 'Procedural content generation is helping game developers to create significant quantity of high quality dynamic content for video games at a fraction of cost of the traditional methods. Procedural texture synthesis is a sub category of procedural content generation which helps video games to have significant variations in textures of the environments and the objects across the progress of the game and to avoid repetition. Procedural texture synthesis is a subcategory of procedural content generation that enables video games to have varied textures of environments and objects, eliminating repetition. Generative Adversarial Networks (GANs) are deep learning algorithms that can learn and create new patterns. In this paper, GANs were used for procedural content generation to synthesize original textures for video game development. This process saves significant time and cost in video game development. The particular attention in this paper is on procedural synthesis of ground surface textures. The generated texture samples were visually acceptable, with a mean score of 2.45 and a standard deviation of 0.1 after 2K iterations. Also the discriminator loss of generated samples reached 0.74 at the final stage of training. This proposed framework can be an effective procedural texture synthesis method for video game design and development.'}\n","{'text': 'This paper develops a novel hyperspectral image (HSI) classification framework by exploiting the spectral-spatial features of multiscale superpixels via recurrent neural networks with stacked autoencoders. The superpixels can be used to segment an HSI into shape-adaptive regions, and multiscale superpixels can capture the object information more accurately. Therefore, the superpixel-based classification methods have been studied by many researchers. In this paper, we propose a multiscale superpixel-based classification method. In contrast to current research, the proposed method not only captures the features of each scale but also considers the correlation among different scales via recurrent neural networks. In this way, the spectral-spatial information within a superpixel is more efficiently exploited. In this paper, we first segment the HSI from coarse to fine scales using the superpixels. Then, the spatial features within each superpixel and among superpixels are sufficiently exploited by the local and nonlocal similarity measure. Finally, recurrent neural networks with stacked autoencoders are proposed to learn the high-level multiscale spectral-spatial features. Experiments are conducted on real HSI datasets. The results demonstrate the superiority of the proposed method over several well-known methods in both visual appearance and classification accuracy.'}\n","{'text': 'Conversion of existing image and video content to High Dynamic Range (HDR) using inverse Tone Mapping Operators (iTMOs) is expected to enable the HDR market and open new market opportunities for studios and content owners. In this paper, we propose a high contrast video iTMO that addresses shortcomings of existing approaches, yielding HDR video quality worth the expectations of the emerging HDR technology. Our approach is content adaptive and is able to convert SDR videos to HDR videos of any target dynamic range. Our approach follows the Human Visual System (HVS) characteristic of being more sensitive to luminance changes in dark areas than bright and normal ones, mapping each of these areas accordingly. Our subjective evaluations demonstrate that our proposed method on average outperforms existing iTMOs in terms of overall HDR visual quality.'}\n","{'text': 'Proactive caching is a promising means to handle increasing wireless traffic. However, how heterogeneous user preferences impact the caching gain is still an open problem. In this paper, a two-phase cache-aided multicasting network is investigated, in which users with heterogeneous preferences are served by a base station through a shared link. It is shown that the achievable domain of effective throughput of the users is a convex set and can be characterized by its boundary in the positive orthant. A special type of caching schemes, named uncoded placement absolutely fair (UPAF) caching, is studied. For the two user case, the achievable domain of UPAF policies has a piecewise linear boundary. For the multiuser case, a feasible UPAF policy is proposed to obtain caching and multicasting gains. Simulation results demonstrate that users with more concentrated preferences can attain higher effective throughput.'}\n","{'text': 'Analyzing the sources of performance anomalies in cloud-based applications accurately is a challenging task due to both the multi-tenant nature of cloud deployment and changing application workloads. To that end many different resource instrumentation and application performance modeling frameworks have been developed in recent years to help in the effective deployment and resource management decisions. However, the significant differences among these frameworks in terms of their APIs, ability to instrument resources, and interpretation of the collected information make it difficult to use these frameworks effectively. Not addressing these complexities can result in operators providing incompatible and incorrect configurations leading to inaccurate diagnosis of performance issues and hence incorrect resource management. In order to tackle these challenges, UPSARA is introduced as a model-driven generative framework that provides a lightweight, scalable, and extensible performance monitoring, analysis, and testing framework for cloud-hosted applications. UPSARA helps alleviate the accidental complexities in configuring the right resource monitoring and performance testing strategies for the underlying instrumentation frameworks used. We evaluate the effectiveness of UPSARA in the context of representative use cases highlighting its features and benefits.'}\n","{'text': \"Visual data such as images and videos contain a rich source of structured semantic labels as well as a wide range of interacting components. Visual content could be assigned with fine-grained labels describing major components, coarse-grained labels depicting high level abstractions, or a set of labels revealing attributes. Such categorization over different, interacting layers of labels evinces the potential for a graph-based encoding of label information. In this paper, we exploit this rich structure for performing graph-based inference in label space for a number of tasks: multi-label image and video classification and action detection in untrimmed videos. We consider the use of the Bidirectional Inference Neural Network (BINN) and Structured Inference Neural Network (SINN) for performing graph-based inference in label space and propose a Long Short-Term Memory (LSTM) based extension for exploiting activity progression on untrimmed videos. The methods were evaluated on (i) the Animal with Attributes (AwA), Scene Understanding (SUN) and NUS-WIDE datasets for multi-label image classification, (ii) the first two releases of the YouTube-8M large scale dataset for multi-label video classification, and (iii) the THUMOS'14 and MultiTHUMOS video datasets for action detection. Our results demonstrate the effectiveness of structured label inference in these challenging tasks, achieving significant improvements against baselines.\"}\n","{'text': 'This paper proposes an unsupervised neural network approach for modulation format discrimination and identification, utilizing a combination of convolution and feature extraction techniques. The neural network is trained using a set of training data, where the kernel is adjusted to achieve the best possible performance. The proposed approach is able to accurately identify and discriminate between different modulation formats, without requiring labeled data or manual feature engineering. The use of neural networks and convolutional layers allows for efficient and automatic processing of signals, enabling the approach to perform well even in noisy environments. Overall, this approach offers a promising solution for improving the efficiency and accuracy of modulation format discrimination and identification.'}\n","{'text': 'In video encoder, hard-decision quantization (HDQ) is well-suited for parallel processing, but suffers from non-negligible coding performance degradation compared with soft-decision quantization (SDQ). In this paper, by fully simulating the behavior of SDQ, a coefficient-adaptive offset model constructed by the deep learning approach is proposed to adjust the output of HDQ. Experiment results show that the proposed algorithm achieves promising RD performance and well-suited for hardware encoder implementation design.'}\n","{'text': 'Intelligent Fault Diagnosis is an essential part of machinery maintenance to ensure safety and reliability. In this study, we propose the use of Transferable Convolutional Neural Network (TCNN) for fault diagnosis of rotary machinery. The TCNN approach uses task analysis to identify the fault diagnosis problem, followed by feature extraction using kernel methods. The extracted features are fed into a deep learning model for training. The training data is generated from labeled samples of healthy and faulty machinery. By using TCNN, we can transfer knowledge from pre-trained models and improve the performance of the fault diagnosis task. The proposed approach has been tested on real-world datasets with promising results. The findings of this study suggest that TCNN is a powerful tool for intelligent fault diagnosis, providing a more accurate and efficient alternative to current methods.'}\n","{'text': 'This brief investigates resilient consensus problems of hybrid multi-agent systems containing both continuous-time dynamical agents and discrete-time dynamical agents. A hybrid censoring strategy is developed to reach resilient consensus for cooperative agents in the directed networks in which some Byzantine agents are present. The number, location, and dynamics of Byzantine agents are assumed to be unavailable to the cooperative agents. Sufficient conditions based on network robustness are established when the number of Byzantine agents is locally bounded. They are further extended to cope with resilient scaled hybrid consensus where dictated ratios instead of a common value can be reached. Numerical examples are presented to illustrate the theoretical results.'}\n","{'text': 'Mining the rich structure and semantic information hidden in heterogeneous information networks is one of the important tasks of network representation learning. At present, there are relatively few studies on network representation for heterogeneous information network which contains different types of nodes and link relationships. Most studies on network science are based on the homogeneous networks where nodes are objects of the same entity type and the links between nodes are also of the same type. In this paper, we propose a new network representation learning method for heterogeneous network. The core of this method contains tow parts: First, according to semantic of different meta-paths, we get weights between nodes of the same type in heterogeneous information network based on attention mechanism. And then, through biased random walk on nodes of the same type, we get node sequences which can be processed by the skip-gram model to generate representation vectors of nodes. To verify our method, we do experiments on DBLP and Aminer dataset. The experimental results demonstrate that the embeddings learned from the proposed model achieve better performance than state-of-the-art methods in tasks including node classification and similarity research.'}\n","{'text': 'This paper presents the second part of a modified Radau collocation method for solving optimal control problems with nonsmooth solutions. The focus of this paper is on costate estimation and the transformed adjoint system. The modified Radau collocation method is an effective numerical tool used for solving optimal control problems, and it is widely accepted as a standard in the field. The method is based on the use of differential equations and programming, and it has been shown to be convergent for a wide range of problems. The transformed adjoint system is used to improve the convergence and reduce the coercive force of the method. The proposed method is then applied to an aerospace engineering problem, and the results demonstrate its effectiveness in solving complex problems with nonsmooth solutions. The paper provides a valuable contribution to the field of optimal control and presents a useful tool for solving a range of practical problems.'}\n","{'text': 'This paper presents a simulation that investigates the impact of approximation errors on multiple signal classification for direction of arrival estimation. The focus lies on computer approximations of sine and cosine. Two potential error sources are identified, and their effects are estimated by constraining the approximation precision. The simulation results are then evaluated with an emphasis on optimized calculation times while maintaining good angle estimation results.'}\n","{'text': 'In this paper, we propose a parallel K nearest neighbor matching algorithm for 3D reconstruction. The algorithm utilizes the power of graphics processing units (GPUs) to accelerate the feature extraction and matching process, significantly reducing the computational time. We demonstrate the effectiveness of our proposed algorithm with experiments on both synthetic and real-world datasets, showing improved accuracy and speed compared to existing methods. Furthermore, our algorithm has potential applications in various fields such as solid modeling, computational modeling, and three-dimensional displays. The use of cameras in these fields can be optimized with the accelerated feature extraction and matching, allowing for faster and more accurate reconstructions. Overall, our proposed parallel K nearest neighbor matching algorithm provides a valuable contribution to the field of 3D reconstruction.'}\n","{'text': \"The devices that interconnected to the Internet of Things (IoT) will continue to grow exponentially, and in addition, the amount of data that they report. Sensor nodes (SNs) that arranged in WSNs will create some of IoT data and transmit their readings to Gateway (GW), which driving the sensor nodes to quick expenditure their energy and storage. The low costs of SNs impose a restriction on their energy and storage. To handle these problems it's prefer to carry out reduction on data at the source nodes to reduce both of utilized storage and consumed energy. A large portion of proposed solutions implement data reduction just at one level of the IoT design (e.g. at gateways). A Two-Tier Data Reduction (TTDR) technique is proposed to work at two tier of the network that are: sensor nodes and the gateway. At the sensor node tier we use a simple and suitable data compression methods for constrained IoT sensor nodes. The techniques exploit the temporal correlation in sensor data and use Delta Encoding followed by Run-Length Encoding (RLE). At the gateway tier we apply the hierarchical clustering for grouping data sets received from sensor nodes dependent on the Minimum Description Length (MDL) principle. If any pairs of received data sets can be compressed by the MDL principle, they will be combined into one cluster. Consequently, the amount of data sets is decreased gradually, and the merging of sets in clusters is stopped if the discovery of any match of sets to compress is impossible. Finally, the TTDR performance is evaluated based on real sensory data and using OMNeT++ simulator. The acquired outcomes illustrate the proficiency of the proposed system in regarding data transmission and energy.\"}\n","{'text': 'This paper proposes a novel approach to adaptive game-theoretic decision making for autonomous vehicle control at roundabouts. The key focus of this study is decision making, which is a fundamental component of autonomous vehicle technology. The aim of this research is to develop a computational modeling platform that can effectively adapt to different road conditions and predict future events using adaptation models and predictive models. The proposed framework integrates game theoretic principles, allowing each vehicle to make strategic decisions that maximize its benefits while considering the actions of other vehicles on the road. This approach is suitable for complex traffic scenarios, such as roundabouts, where multiple vehicles are interacting simultaneously. The results of this study show that the proposed adaptive game-theoretic decision making approach improves the safety and efficiency of autonomous vehicles at roundabouts, providing a promising direction towards achieving intelligent and autonomous transportation systems.'}\n","{'text': 'Agile software development methodologies have become very popular today in a world that demands quicker and more efficient ways to develop software. Many software development companies have adopted this methodology to deliver high quality software rapidly. Today global software development is the norm of developing software. When Agile methods are used in global software development, several challenges are introduced due to geographical distance, time zone differences, cultural differences and technology barriers. The focus of this research was to identify the impact of challenges on project success. A hypothetical model of challenges was developed based on the literature. A survey was conducted to collect data and the model was analysed using quantitative methods. According to study results, to ensure success of their projects, managers are urged to focus on choosing a technically competent team, ensure effective communication and continuous customer engagement throughout the project, encourage autonomy and manage a low staff turnover in teams.'}\n","{'text': 'Electronic transactions with cryptocurrency systems based on blockchain in our days have become very popular due to the good reputation of this technology. However, that good reputation cannot deny the serious anomalies and the risks that can cause these cryptocurrencies. In this work, we propose a new model for anomaly detection over bitcoin electronic transactions. We used in our proposal two machine learning algorithms, namely the One Class Support Vector Machines (OCSVM) algorithm to detect outliers and the K-Means algorithm in order to group the similar outliers with the same type of anomalies. We evaluated our work by generating detection results and we obtained high performance results on accuracy.'}\n","{'text': 'This paper proposes BRIEF, a backward reduction algorithm that explores compact CNN-model designs from the information flow perspective. This algorithm can remove substantial non-zero weighting parameters (redundant neural channels) of a network by considering its dynamic behavior, which traditional model-compaction techniques cannot achieve. With the aid of our proposed algorithm, we achieve significant model reduction on ResNet-34 in the ImageNet scale (32.3% reduction), which is 3X better than the previous result (10.8%). Even for highly optimized models such as SqueezeNet and MobileNet, we can achieve additional 10.81% and 37.56% reduction, respectively, with negligible performance degradation.'}\n","{'text': 'The proposed paper presents a functional programming model for embedded dataflow applications, which utilizes cluster computing architecture to optimize computational modeling for embedded systems. The model employs functional programming concepts to define data models and utilize machine learning algorithms to efficiently process the dataflow. This approach to embedded system design differs from traditional imperative programming techniques, as the functional paradigm emphasizes immutability and data transformations rather than explicit control flow. The benefits of using this approach are highlighted in the paper, as it enables more efficient and scalable processing of large datasets that are often encountered in data-driven applications. The authors also discuss the challenges and future directions for developing functional programming models in embedded systems, including the need for specialized compilers and tools to facilitate implementation.'}\n","{'text': 'In recent years, there has been a growing interest in developing soft robotic systems for use in wearable assistive devices. In this study, we present a novel robotic forearm orthosis which utilizes soft fabric-based helical actuators to generate torque for different tasks. We conducted a task analysis to identify the specific requirements for the device, and designed the soft robotic system to meet these needs. We found that pneumatic systems using flexible fabrics as actuators were an effective solution for generating the necessary torque while maintaining flexibility and comfort for the wearer. Our results demonstrate the potential for fabric-based soft robotics in the development of assistive devices for individuals with upper extremity impairments. Further research in this field could lead to more advanced and effective soft robotic devices for use in a variety of applications.'}\n","{'text': 'DPRNet, a deep 3D point-based residual network, is developed for semantic segmentation and classification of 3D point clouds. The system is designed to accurately interpret and analyze the three-dimensional displays of shapes to identify and classify them based on their semantics. DPRNet uses advanced computer architecture to perform efficient feature extraction and segmentation, which is essential for its high accuracy and efficiency. The system can be used for numerous applications such as developing autonomous vehicles, robotic navigation, and virtual reality systems. By incorporating two-dimensional displays with the power of deep learning algorithms, DPRNet provides a valuable tool in the field of image segmentation, which has vast applications in various fields such as medicine, engineering, and entertainment. Overall, DPRNet is a significant contribution in the field of semantic segmentation and classification of 3D point clouds, and its advanced design and feature extraction capabilities make it suitable for a wide range of applications.'}\n","{'text': 'Three novel structures using simultaneous wireless information and power transfer in energy-harvesting (EH) amplify-and-forward relaying are investigated in this paper. Different combinations of time-switching and power-splitting (PS) EH protocols are studied. Three dynamic schemes are proposed as channel estimation PS (CEPS), data transmission PS (DTPS), and combination PS (CPS). From source to relay in these schemes, the data packet includes three parts: channel estimation, data transmission, and EH. From relay to destination in these schemes, the data packet includes two parts: data transmission and channel estimation. Closed-form expressions for the cumulative distribution function of the end-to-end signal-to-noise ratio for the three structures are derived. Using these expressions, achievable rate and bit-error-rate are derived. Different parameters are examined. Numerical results show the optimal splitting ratio for the channel estimation, EH, and data transmission, when the packet size is fixed.'}\n","{'text': 'The increasing penetration of power-electronic-interfaced devices is expected to have a significant effect on the overall system inertia and a crucial impact on the system dynamics. In future, the reduction of inertia will have drastic consequences on protection and real-time control and will play a crucial role in the system operation. Therefore, in a highly deregulated and uncertain environment, it is necessary for transmission system operators to be able to monitor the system inertia in real time. We address this problem by developing and validating an online inertia estimation algorithm. The estimator is derived using the recently proposed dynamic regressor and mixing procedure. The performance of the estimator is demonstrated via several test cases using the 1013-machine ENTSO-E dynamic model.'}\n","{'text': 'Blocks oriented models are the most structure used to describe nonlinear systems. These models are composed with two blocks: the first is a nonlinear part and the second is a linear part. Hammerstein model is one of block oriented models. Recently, the design of sliding mode control (SMC) in discrete-time for nonlinear systems is done using this structure. However, SMC suffer from a major problem: the chattering phenomenon. So, this work proposes to synthesize an integral sliding function to control nonlinear systems using Input/Output (I/O) Hammerstein structure in order to remove the chattering phenoenon. The effenciency of the proposed DISMC in terms of chattering phenomenon minimisation was verified by a simulation example and results are given at the end of this paper.'}\n","{'text': 'Software Defined Network (SDN) is a new network construction. But due to its construction, SDN is vulnerable to be attacked by Distributed Denial of Service (DDoS) attack. So it is important to detect DDoS attack in SDN network. This paper presents a DDoS detection scheme based on k-means algorithm in SDN environment. The establishment of this scheme is based on the two hypotheses that the daily network works normally most of the time, and there is a significant difference between the data characteristics of normal situation and abnormal situation. At the same time, these two hypotheses are also true to the daily network condition. After demonstrating the validity of k-means clustering algorithm, the paper proposes 5 flow table features that can be used to detect DDoS attacks. Finally, the DDoS detection scheme was tested by simulation experiment. The test results showed that the method proposed by the author could effectively detect DDoS, with an average success rate of 97.78%.'}\n","{'text': 'This paper explores the use of a soft ground-truth mask (â\\x80\\x9csoft maskâ\\x80? to train a Fully Convolutional Neural Network (FCNN) for segmentation of Multiple Sclerosis (MS) lesions. Detection and segmentation of MS lesions is a complex task largely due to the extreme unbalanced data, with very small number of lesion pixels that can be used for training. Utilizing the anatomical knowledge that the lesion surrounding pixels may also include some lesion level information, we suggest to increase the data set of the lesion class with neighboring pixel data -with a reduced confidence weight. A soft mask is constructed by morphological dilation of the binary segmentation mask provided by a given expert, where expert-marked voxels receive label 1 and voxels of the dilated region are assigned a soft label. In the methodology proposed, the FCNN is trained using the soft mask. On the ISBI 2015 challenge dataset, this is shown to provide a better precision-recall tradeoff and to achieve a higher average Dice similarity coefficient. We also show that by using this soft mask scheme we can improve the network segmentation performance when compared to a second independent expert.'}\n","{'text': 'In todayâ\\x80\\x99s era of industrial automation, mobile robots play a crucial role. And continuous improvement of mobile robot performance can be an important research topic. To simulate the results, we used Matlab 2018 Simulink. In the paper genetic algorithm based parameters tuning for the hybrid intelligent controller design for the manipulation of the mobile robot is proposed. This controller combines a traditional PID controller with a fuzzy logic controller to form an intelligent or fuzzy PID controller. Furthermore, we use a genetic algorithm to tune the parameters of the membership function of the fuzzy logic controller to achieve the desired performance index of the robot. From simulation results it can be found that the response speed is raised and the settling time is decreased. Finally, we implement the proposed intelligent controller on a mobile robot and confirm its superior performance.'}\n","{'text': 'This study proposes a robust machine learning approach for predicting traffic noise levels based on Wilcoxon norm. The neural network models are utilized to develop mathematical models for traffic noise prediction. The predictive models are trained using data models generated from road traffic noise and pollution data. The proposed approach is shown to outperform existing methods in terms of accuracy and robustness. The findings suggest that the Wilcoxon norm based approach can provide better noise prediction for urban planners and policymakers, leading to more effective management of traffic noise and its impacts on public health.'}\n","{'text': 'Creativity is the generation of an idea or artifact judged to be novel and high-quality by a knowledgeable social group, and is often said to be the pinnacle of intelligence. Several computational creativity systems of various designs are now being demonstrated and deployed. These myriad design possibilities raise the natural question: Are there fundamental limits to creativity? Here, we define a mathematical abstraction to capture key aspects of combinatorial creativity and study fundamental tradeoffs between novelty and quality. The functional form of this fundamental limit resembles the capacity-cost relationship in information theory, especially when measuring novelty using Bayesian surpriseâ\\x80\\x94the relative entropy between the empirical distribution of an inspiration set and that set updated with the new idea or artifact. As such, we show how information geometry techniques provide insight into the limits of creativity and find that the maturity of the creative domain directly parameterizes the fundamental limit. This result is extended to the case when there is a diverse audience for creativity and when the quality function is not known but must be estimated from samples.'}\n","{'text': 'A mobile-based virtual try-on system is proposed to deal with the problems of high cost and conflicts between computational complexity and simulation effects. In this paper, several modules are included, such as automatic 3D face reconstruction based on a single image, auto-skinning and realtime local simulation of cloth. According to the experiments, the virtual try-on system introduced in this paper is able to achieve better fitting effects with lower constructing and computing costs, in which case good experience of mobile-based virtual try-on system is provided.'}\n","{'text': 'This paper proposes a real-time impedance estimation method for grid-connected photovoltaic systems using the discrete Fourier transform. The method accurately estimates the impedance of the PV system without the need for additional sensors or hardware. The discrete Fourier transforms are used to analyze the voltage and current signals, and the resistance of the system is then calculated based on the phase angle difference between them. The proposed method also provides a detailed control system for voltage control, which improves the power quality of the grid-connected PV system. With its real-time and accurate estimation capabilities, the method can be utilized in the design and optimization of grid-connected PV systems to improve their overall efficiency and performance.'}\n","{'text': \"In today's digital age, having digital skills is becoming increasingly important for graduates as they enter various industries. Therefore, it is crucial to determine the digital skills preparedness of graduates for employment, training, banking, and economics. This paper proposes a framework that can be used to assess the digital skills of graduates in these areas. By analyzing various factors such as the use of digital tools and platforms, familiarity with digital resources, and the ability to solve digital problems, the framework is able to provide a comprehensive evaluation of a graduate's digital skills preparedness. The findings of this study can be used by educators and employers to better understand the digital skills that are needed in today's workplace and to provide targeted training to develop these skills in graduates. Overall, this framework can be a valuable tool in ensuring that graduates are well equipped with the digital skills necessary to succeed in their chosen careers.\"}\n","{'text': 'Nowadays, non-linier loads show declining effect for power quality in electric power system that be concerned by engineering and scientist community. In order to prohibit harmonic from deflate the power quality in power system caused by non linear loads, detecting harmonic for harmonic mitigations becomes critical issue. This paper presents an effective procedure based on levenberg marquardt backpropagation neural network is offered to find harmonic of the measured signal that is an input harmonics content sampling signal. The result from neural network harmonic detection method are compare to Fast Fourier Transform algorithm. To validate the proposed algorithm compared under varying neurons in hidden layer. The result show that the proposed algorithm has good accuracy for harmonic detection on the first harmonic signal with 5 neurons has average 0,00083 percent and 10 neurons has average 0,00033 percent and in the second harmonic signal with 5 neurons has average 0,00005 percent and 10 neurons has average 0 percent.'}\n","{'text': 'Estimating the location of radio emitters in multipath environments is known to be challenging, particularly when no Line of Sight (LOS) path is present. We propose novel non-cooperate Maximum Likelihood (ML) location estimator for use in dense urban environments which uniquely exploits the scattering environment geometry in order to mitigate the need for LOS paths. A simple scattering model is used to assess the performance of the algorithm. Simulation results are included demonstrating a mean location error of 89 m.'}\n","{'text': 'This paper proposes a Simulated Kalman Filter Optimization Algorithm to maximize the coverage of Wireless Sensor Networks. Wireless Sensor Networks are comprised of numerous sensors that can measure various environmental conditions, such as temperature, humidity, and light. The optimization process is achieved through the utilization of Kalman filters and genetic algorithms. The Kalman filter is used for estimation of current measurement values, while the genetic algorithm optimizes the values for coverage maximization. The proposed algorithm has been compared to several other algorithms, and the results show that it can achieve higher coverage rates. In summary, this paper provides a novel approach to optimizing Wireless Sensor Networks coverage, which may enable better monitoring of environmental changes and improved decision making.'}\n","{'text': \"This paper presents a Nonlinear Model Predictive Control (NMPC) approach using the Iterative Steepest Descent (ISD) algorithm to control an inverted pendulum. Optimal control is achieved by minimizing a cost function using predictive control. Nonlinear systems pose significant challenges in control theory due to their unsteady and often unpredictable behavior. However, the NMPC approach allows for the use of prediction algorithms, which can help to make effective control decisions. The ISD algorithm is a powerful optimization technique that enables the control of nonlinear systems by iteratively adjusting the control input. By using this technique in the control of an inverted pendulum, it is possible to achieve both stability and accurate tracking of the pendulum's motion. Overall, this study demonstrates the effectiveness of the NMPC and ISD algorithm in controlling nonlinear systems with predictive control.\"}\n","{'text': 'Paraphrase Identification is a critical problem for many NLP tasks such as question answering, information extraction, machine translation, and others. Recently, neural network models have achieved state-of-the-art results on several textual similarity measurement datasets. While training neural network models requires a large amount of labeled data which is costly and time consuming, unlabeled data is relatively easy to collect from a social media such as Twitter. Co-training is a semi-supervised learning method to exploit the unlabeled data by partitioning a feature set into two conditionally independent views. In this paper, we assume that a combination of word-level representation and character-level representation is effective in identifying paraphrases by capturing lexical and superficial features respectively, and investigate the application of co-training on neural network paraphrase identification models by using both word-level and character-level information. We evaluate the co-training method on Twitter URL Paraphrase Corpus. As a result, the experiments demonstrated that our approach achieved a robust performance in comparison to simple self-training algorithm.'}\n","{'text': 'The demand for wireless sensor networks in space vehicles has increased drastically in recent years, leading to the need for energy-harvesting technology. Rectifiers play a key role in converting radio frequency (RF) energy to usable DC power. The C-Band HySIC Rectifier, featuring gallium nitride (GaN) technology, has emerged as a promising solution for RF energy harvesting in spacecraft due to its superior performance and efficiency when compared to conventional silicon-based rectifiers. The HySIC Rectifier has shown exceptional power conversion efficiency at the C-bandfrequencies typically used in satellite communications, which make it a suitable candidate for use in space-based applications. This paper presents an overview of the HySIC Rectifier and examines its potential for use in wireless sensor networks in space vehicles.'}\n","{'text': 'Inspired by the characteristics of the human visual system, a novel method is proposed for detecting the visually salient regions on 3D point clouds. First, the local distinctness of each point is evaluated based on the difference with its local surroundings. Then, the point cloud is decomposed into small clusters, and the initial global rarity value of each cluster is calculated; a random walk ranking method is then used to introduce cluster-level global rarity refinement to each point in all the clusters. Finally, an optimization framework is proposed to integrate both the local distinctness and the global rarity values to obtain the final saliency detection result of the point cloud. We compare the proposed method with several relevant algorithms and apply it to some computer graphics applications, such as interest point detection, viewpoint selection, and mesh simplification. The experimental results demonstrate the superior performance of the proposed method.'}\n","{'text': \"This paper proposes a novel image feature set based on a principled information theoretic analysis of the convolutional neural network (CNN). The output of convolutional filters is modeled as a random variable conditioned on the object class and network filter bank. The conditional entropy (CENT) of filter outputs is shown in theory and experiments to be a highly compact and class-informative feature that can be computed from the CNN feature maps and used to obtain higher classification accuracy than the original CNN itself. Experiments involve three binary classification tasks using the 3D brain MRI data: Alzheimer's disease (AD) versus healthy controls (HC), young versus old age, and male versus female, where the area under the curve (AUC) values for the CENT feature classification (93.9%, 96.7%, and 71.9%) are significantly higher than the softmax output of the original CNN classifier trained for the task (81.6%, 79.4%, and 63.1%). A statistical analysis based on the Wilcoxon test identifies CENT features with significant links to brain labels, which could potentially serve as diagnostic biomarkers.\"}\n","{'text': 'Compared to visible spectrum image the infrared image is much clearer in poor lighting conditions. Infrared imaging devices are capable to operate even without the availability of visible light, acquires clear images of objects which are helpful in efficient classification and detection. For image object classification and detection, CNN which belongs to the class of feed-forward ANN, has been successfully used. Fast RCNN combines advantages of modern CNN detectors i.e. RCNN and SPPnet to classify object proposals more efficiently, resulting in better and faster detection. To further improve the detection rate and speed of Fast RCNN, two modifications are proposed in this paper. One for accuracy in which an extra convolutional layer is added to the network and named it as Fast RCNN type 2, the other for speed in which the input channel is reduced from three channel input to one and named as Fast RCNN type 3.Fast RCNN type 1 has better detection rate than RCNN and compare to Fast RCNN, Fast RCNN type 2 has better detection rate while Fast RCNN type 3 is faster.'}\n","{'text': 'Following the recent advances in computing, the multimodal interface concept has attracted a good deal of attention as a means of enabling users to interact naturally with a computer. This paper examines a case study to evaluate how access can be obtained to local and cloud servers through a multimodal interface, which is quite usual when handling applications in a Digital TV. The study focuses on the multimodal app and its validation using Quality of Service (QoS) metrics. In addition, this IS followed by a discussion on the use of local and cloud servers with a focus on costs and computational resources. The results are shown with regard to both the technical and financial feasibility of the proposed architectures.'}\n","{'text': 'Robot recognition, particularly in service robots, is crucial to help robots accurately identify, track, and interact with objects and humans. Traditional recognition techniques rely on feature extraction to recognize the target, but these methods are limited in their ability to classify complex or dynamic images. This paper proposes a new method using attention mechanism and convolutional neural network (CNN) for robot recognition. The attention mechanism is able to selectively focus on relevant parts of the image, while the CNN extracts high-level features from the image. To test the effectiveness of the proposed method, the research used an image color analysis tool to generate a large dataset of robot images for training. The results showed that the proposed method achieved high accuracy in target recognition, outperforming traditional recognition methods. Overall, the attention mechanism and CNN-based approach provides a promising technique for improving robot recognition in a variety of applications.'}\n","{'text': 'This paper studies the use of drone-base stations to enhance the performance of heterogeneous cellular networks. In particular, we analyze the impact of deploying drone-base stations on the bit rate, signal to noise ratio, and overall performance of these cellular networks. Through simulations and experiments, we demonstrate that the use of drone-base stations can significantly improve the quality of service provided by these networks, especially in areas with poor or nonexistent coverage. We also investigate the potential benefits of satellite broadcasting in conjunction with drone-base stations. Our findings suggest that the use of drone-base stations can be a promising solution for improving the coverage and performance of cellular networks, and we discuss the implications of our results for future research and development in this area. This work was presented at several conferences and is an important contribution to the ongoing efforts to improve wireless communication systems and services.'}\n","{'text': 'This article presents a two-layer hybrid neural network framework, termed enhanced ELITE (E-ELITE), for short-term load forecasting (STLF) with high-performance forecasting capability and accuracy. The design of the E-ELITE is based on a novel three-stage methodology that is composed of Stage I: optimal structure, Stage II: highly accurate and diverse members of neural network, and Stage III: a neural network-based ensemble. We explore the capability of our proposed consensus-based mixed-integer particle swarm optimization-assisted TRUST-TECH (CMPSOATT) method in each of the three-stage methodology to achieve the following advantages: first high-quality local optimal solutions or even the global optimal solution and second computational speed; consequently, the forecasting accuracy and generalization ability of the E-ELITE is enhanced by CMPSOATT via a training procedure to design a diverse set of optimal ANN forecasting engines in the bottom layer and another training procedure to achieve higher performance results than any engines in the top layer. The resulting E-ELITE is shown to obtain a more accurate, scalable, and better generalization STLF forecasting performance with less computational effort than other powerful forecasting methods through a utility-scale dataset.'}\n","{'text': 'Customer service majorly involves a one-way kind of communication where the organization usually controls the point of interaction through either a call center, helpdesk email address, or even a postal address. The challenges faced by this model are 1) response time (time it takes a customer to get a response about an inquiry they have made) and 2) response rate (rate at which customer inquiries are retrieved and attended to).This paper looks at the use of machine learning algorithms and classifiers, utilizing extractive text summarization techniques for semantic and key phrase extraction of customer queries to facilitate customer response retrieval from a Frequently Asked Questions database. A comparative study of two text summarization approaches (supervised and unsupervised) is carried out by implementing a prototype of an automated agent to respond to customer queries in an electronic media domain.The study illustrates the use of machine learning; text summarization techniques to develop tools that can assist organizations manage their customer interactions effectively and implement robust, efficient, and effective electronic media enabled customer support mechanisms.'}\n","{'text': 'Software maintainability is a crucial aspect of software development which requires much attention. Predictive models have been developed to address the issue of software maintainability prediction. This study aims to conduct a qualitative evaluation on these predictive models to determine their effectiveness. The study focuses on analytical models, computational modeling, mathematical modeling, and data models. The qualitative evaluation is based on the reliability of the models. The results of the study will contribute towards the improvement of software maintenance practices.'}\n","{'text': \"Stress testing is an important task in software testing, which examines the behavior of a program under a heavy load. Symbolic execution is a useful tool to find out the worst-case input values for the stress testing. However, symbolic execution does not scale to a large program, since the number of paths to search grows exponentially with an input size. So far, such a scalability issue has been mostly managed by pruning out unpromising paths in the middle of searching based on heuristics, but this kind of work easily eliminates the true worst case as well, providing sub-optimal one only. Another way to achieve scalability is to learn a branching policy of worst-case complexity from small scale tests and apply it to a large scale. However, use cases of such a method are restricted to programs whose worst-case branching policy has a simple pattern. To address such limitations, we propose PySE that uses symbolic execution to collect the behaviors of a given branching policy, and updates the policy using a reinforcement learning approach through multiple executions. PySE's branching policy keeps evolving in a way that the length of an execution path increases in the long term, and ultimately reaches the worst-case complexity. PySE can also learn the worst-case branching policy of a complex or irregular pattern, using an artificial neural network in a fully automatic way. Experiment results demonstrate that PySE can effectively find a path of worst-case complexity for various Python benchmark programs and scales.\"}\n","{'text': \"In this paper, data-aided sensing as a cross-layer approach in Internet-of-Things (IoT) applications is studied, where multiple IoT nodes collect measurements and transmit them to an access point (AP). It is assumed that measurements have a sparse representation (due to spatial correlation) and the notion of compressive sensing (CS) can be exploited for efficient data collection. For data-aided sensing, a node selection criterion is proposed to efficiently reconstruct a target signal through iterations with a small number of measurements from selected nodes. Together with compressive random access (CRA) to collect measurements from nodes, compressive transmission request is proposed to efficiently send a request signal to a group of selected nodes. Error analysis on compressive transmission request is carried out and the impact of errors on the performance of data-aided sensing is studied. Simulation results show that data-aided sensing allows to reconstruct the target information with a small number of active nodes and is robust to nodes' decision errors on compressive transmission request.\"}\n","{'text': 'Object recognition is a fundamental task in computer vision, which aims to identify different objects in images or videos. Convolutional neural networks (CNNs) have been widely used for object recognition due to their powerful feature extraction capability. However, training very deep CNNs is challenging due to the vanishing gradient problem. To address this issue, this paper proposes an improved very deep recurrent convolutional neural network (IVD-RCNN) for object recognition. The proposed approach incorporates convolutional codes with long short-term memory (LSTM) units to learn diverse representations in a robust and efficient manner. Furthermore, a novel training pipeline is introduced, which includes task analysis and feature extraction modules. Experimental results on benchmark datasets demonstrate that the IVD-RCNN outperforms state-of-the-art methods in terms of recognition accuracy and efficiency.'}\n","{'text': \"This paper develops an event-triggered decentralized tracking control (DTC) approach for modular reconfigurable robots (MRRs) by using adaptive dynamic programming. By establishing a decentralized neural network (NN) observer, which uses local input-output data and desired states of coupling subsystems, the local dynamics of MRR subsystem can be obtained. In order to obtain the DTC, the tracking error subsystem is augmented by the exosystem with the desired trajectory. Based on the event-triggered mechanism and a modified local cost function, the DTC is derived by solving the local Hamilton-Jacobi-Bellman equation via a local critic NN with asymptotically stable structure. The stability of the entire closed-loop MRR system is analyzed by Lyapunov's direct method. The simulation of a two-degree of freedom MRR system ensures that the developed event-triggered DTC scheme is effective.\"}\n","{'text': 'A multistatic system is a system that uses a transmitter to illuminate an object and collects the reflected signal by multiple receivers to determine its location. In some scenarios such as passive coherent localization or for gaining flexibility, the position of the transmitter is not known. This paper explores the potential of joint estimation of the object and transmitter positions from both indirect and direct measurements, which can result in a more accurate object location estimate by removing the dependency on transmitter position. We show that joint estimation of the object and transmitter positions from both the indirect and direct measurements can yield a better object location estimate than using the indirect measurements only by eliminating the dependency of the transmitter position. To gain further insight, the optimal receiver placement in the absence of transmitter position is derived by minimizing the estimation confidence region or the mean-square estimation error for the object location. To complete the study and gain insight, the optimal receiver placement in the absence of transmitter position is derived by minimizing the estimation confidence region or the mean-square estimation error for the object location. The theoretical developments are confirmed through simulations, and the results show that joint estimation of object and transmitter positions can significantly improve the object location estimate in multistatic systems. Simulations confirm well with the theoretical developments.'}\n","{'text': 'Considering the importance of software systems in human life, their quality assurance is very important. Fault localization is one of the software testing steps, it tries to find the exact location of fault in code. Most of automatic fault localization techniques use coverage information and results of test cases to calculate the program entities suspiciousness by similarity coefficients. The similarity coefficients designed based on the insight and understanding of developers from software system and they do not have the same performance in different scenarios. To overcome with this problem, we use the Back Propagation neural network and investigate the effect of weighted the neural network to accuracy of locating faults in software programs, because the Back propagation neural network is sensitive to weight and by the initial proper weights to the input layer neurons connections, the search space to achieve optimal weight is decreasing and network accuracy improves. We analyze the effectiveness of the proposed method with randomly weighting the input layer neurons and some basic and efficient similarity coefficients on Siemens suite benchmark. The results show that proposed method has a satisfactory performance for the software fault localization process.'}\n","{'text': 'This paper presents a study focused on the inversion of the slip distribution of an earthquake using InSAR phase gradients. The Izmit case study is analyzed to demonstrate different examples of this method. The strain and geometry of the fault systems are taken into consideration, as well as the estimation of the slip distribution. Synthetic aperture radar (SAR) measurements are used to obtain the InSAR phase gradients, which are inversely modeled to retrieve the slip distribution. The results show that this methodology is a powerful tool for studying earthquakes and can provide valuable insights into the mechanics and behavior of fault systems. Overall, this study highlights the importance of utilizing advanced technologies and methods for accurate earthquake analysis and prediction.'}\n","{'text': 'Scheduling of smart appliances is one of the ways which can be used to reduce the demand peak. Sometimes this results in under utilization of the available power thus creating a gap between the desired demand target power and the actual used power. This is mainly caused by appliances that consume constant power during the course of their operation. In this paper we have studied the distributed scheduling algorithm proposed by [Chen et al, 2014] and we propose a new way in which this gap can be filled so as to fully utilize the available power during peak hours and eventually result in some appliances finishing to run earlier.'}\n","{'text': 'The current IoT landscape is dominated by cloud-based platforms offering non-standardized interfaces to access virtualized IoT resources and adopting proprietary information models. The implementation of cross-platform and cross-domain IoT applications becomes cumbersome and usually leads to custom solutions, tailored to the involved platforms, due to the semantic and syntactic incompatibilities. The symbIoTe approach offers mediation services for search and controlled access to IoT resources (sensors, actuators, and related services) across platforms in a uniform way. It provides an IoT Portal with registration and search capabilities using semantic web technologies for semantic interoperability, and an abstraction layer for unified and secure access to those resources across distributed IoT platform instances for syntactic interoperability. In this paper, we present the general concepts and design decisions built into the symbIoTe open source middleware and showcase the evolving symbIoTe ecosystem which facilitates the rapid development of innovative cross-platform IoT applications. The open IoT Portal currently integrates 15 IoT platforms and data sources for Smart City and Smart Residence domains, and hosts metadata registering more than 4,000 various IoT resources.'}\n","{'text': \"Degradation modeling plays a key role in accelerated degradation test data analysis and condition-based maintenance. The degradation rate of a degradation process usually depends on both unit's age and its state. Several agestate-dependent degradation models have been proposed in the literature. A main drawback of these models is their intractability. In this paper, we propose an analytically tractable age-state-dependent degradation model. The proposed model is defined in terms of degradation rate, whose mean function is represented by a bivariate power-law model. The degradation increment is modeled by a non-homogeneous gamma process, whose mean function depends on both age and degradation level and has a closed-form expression. The model includes age-and state-dependent models as its special cases. An approach is proposed to make selection among the general case and special cases based on the Akaike information criterion. A real-world example is used to illustrate the flexibility and usefulness of the proposed model and approach.\"}\n","{'text': 'Deep neural networks usually require large labeled datasets to construct accurate models; however, in many real-world scenarios, such as medical image segmentation, labeling data are a time-consuming and costly human (expert) intelligent task. Semi-supervised methods leverage this issue by making use of a small labeled dataset and a larger set of unlabeled data. In this paper, we present a flexible framework for semi-supervised learning that combines the power of supervised methods that learn feature representations using state-of-the-art deep convolutional neural networks with the deeply embedded clustering algorithm that assigns data points to clusters based on their probability distributions and feature representations learned by the networks. Our proposed semi-supervised learning algorithm based on deeply embedded clustering (SSLDEC) learns feature representations via iterations by alternatively using labeled and unlabeled data points and computing target distributions from predictions. During this iterative procedure, the algorithm uses labeled samples to keep the model consistent and tuned with labeling, as it simultaneously learns to improve feature representation and predictions. The SSLDEC requires a few hyper-parameters and thus does not need large labeled validation sets, which addresses one of the main limitations of many semi-supervised learning algorithms. It is also flexible and can be used with many state-of-the-art deep neural network configurations for image classification and segmentation tasks. To this end, we implemented and tested our approach on benchmark image classification tasks as well as in a challenging medical image segmentation scenario. In benchmark classification tasks, the SSLDEC outperformed several state-of-the-art semi-supervised learning methods, achieving 0.46% error on MNIST with 1000 labeled points and 4.43% error on SVHN with 500 labeled points. In the iso-intense infant brain MRI tissue segmentation task, we implemented SSLDEC on a 3D densely connected fully convolutional neural network where we achieved significant improvement over supervised-only training as well as a semi-supervised method based on pseudo-labeling. Our results show that the SSLDEC can be effectively used to reduce the need for costly expert annotations, enhancing applications, such as automatic medical image segmentation.'}\n","{'text': 'This paper presents an integrated mathematical model for estimating travel time variability and route choice. The model incorporates time measurement and data models to account for uncertainty and measurement errors. Gaussian distribution is used to represent the variability of travel time. By utilizing this framework, accurate predictions can be made about travel time and route choice for a given trip. The results of this study will be valuable to transportation planners and engineers in optimizing traffic flow and improving the overall efficiency of transportation systems.'}\n","{'text': 'WLAN-based indoor positioning algorithm has the characteristics of simple layout and low price, and it has gradually become a hotspot in both academia and industry. However, due to the poor stability of Wi-Fi signals, received signal strength (RSS) fingerprints of some adjacent reference positions are difficult to evaluate similarity when utilizing traditional distance-based calculation methods. By clustering these RSS fingerprints into one region, the commonly utilized KNN algorithm in the past cannot achieve accurate positioning in the region. For this, we introduce a concept of the insensitive region of the RSS fingerprint and a new algorithm named DBSCAN-KRF. This algorithm can delete noise sample and detect insensitive region, then, different methods are selected to achieve indoor positioning by judging the region of the estimated fingerprint sample, the KNN algorithm is selected when the region is sensitive, and random forest algorithm is selected when the region is insensitive. The experimental results show that the DBSCAN-KRF algorithm is superior while compared with other alternative indoor positioning algorithms.'}\n","{'text': \"The Internet of Everything is an intelligent connection between people, process, data and things. It is an extension of Internet of Things. IoE is emerging technology of current years. In the four core elements the `things' are connecting the devices in to internet. Those are called Sensors. In this emerging world the micro and nano sensors are used for healthcare, smart home, smart city, and etc. sensors are plays vital role in IoT, IoE, WoT, and other sub domains of mentioned fields. It easily connects the wired/ wireless connections. In this paper explains the IOE and its overview, sensors used in IOE and advantages over using sensors in IoE.\"}\n","{'text': \"Thermoelectric generators are efficient devices to recover energy from the automotive exhaust gas. In this paper, conversion efficiency of automotive thermoelectric generator (ATEG) and the maximum electrical power generated by the ATEG, defining as the power output of the ATEG excluding the energy loss caused to the engine improved by optimizing the number of thermoelectric modules (TEMs) and its distribution pattern in an ATEG. An advanced numerical model of ATEG considering the effect of the heat transfer among the adjacent TEMs' rows is developed with Simulation-X software. In order to acquire the ATEG's optimal electrical performance, a 3-step optimization is applied. First, 17 independent factors (the number of TEMs in each row from 1 to 18) are assessed and the significant parameters are screened using Plackett-Burman design. Second, an experiment designed with a central composite design is performed to analyze the sensitivity of six selected factors and a surrogate model is built through response surface method. Then, conflicts in two objectives are settled with a multi-objective genetic algorithm. According to the optimization results of a given ATEG, the maximum electrical power generated by the ATEG is 139.47 W and the conversion efficiency is 2.51% under steady engine condition. Finally, the performances of the optimized design under different engine conditions are discussed. The results show that the maximum power generated by the ATEG and efficiency respectively increase by 49.8% and 106.5% after optimization when the exhaust inlet temperature is 805 K and the mass flow rate is 0.5 kg/s.\"}\n","{'text': 'In recent times, the accurate detection and location of circuit faults in underground power cables have become essential for ensuring reliable electricity supply. The use of sensors and prediction algorithms has been explored by researchers in this field with varying degrees of success. However, the adoption of machine learning algorithms such as the Random Forest algorithm has shown promising results in accurately locating faulty segments of power cables. The Random Forest algorithm is a popular ensemble method which combines multiple decision trees to improve accuracy and robustness. This paper presents an overview of underground cable faults and explores the application of the Random Forest algorithm in fault location. The results demonstrate that the proposed algorithm is efficient, reliable and can accurately predict faulty cable segments with a high level of accuracy. Therefore, it can be concluded that the use of machine learning algorithms such as the Random Forest algorithm represents an effective strategy for locating underground cable faults.'}\n","{'text': 'Accurate detection of network-based attacks is crucial to prevent security breaches of information systems. The recent application of deep learning approaches for network intrusion detection has shown promising. However, the challenges remain on how to deal with imbalance data and small samples as well as reducing false alarm rate (FAR). To address these issues, this work has proposed a multiple-layer representation learning model for accurate end-to-end network intrusion detection by combining deep convolutional neural networks (CNN) with gcForest. The contributions of this work lie in 1) a new data encoding scheme based on P-Zigzag to encode network traffic data into two-dimensional gray-scale images for representation learning without loss of original information; 2) The combination of gcForest and CNN allows accurate detection on imbalanced data and small scale data with fewer hyperparamters comparing to most existing deep learning models, which increase computational efficiency. The proposed approach is based on a multiple-layer approach consisting of a coarse layer and a fine layer, in which the coarse layer with the improved CNN model (GoogLeNetNP) focuses on identification of N abnormal classes and a normal class. While in the fine layer, an improved model based on gcForest (caXGBoost) further classifies the abnormal classes into N-1 subclasses. This ensures fine-grained detection of various attacks. The proposed framework has been compared with the existing deep learning models using three real datasets (a new dataset NBC, a combination of UNSW-NB15 and CICIDS2017 consisting of 101 classes). The experimental results show that our proposed method outperforms other single deep learning methods (i.e., AlexNet, VGG19, GoogleNet, InceptionV3, ResNet18) in terms of accuracy, detection rate, and FAR, which demonstrates its effectiveness in detecting fine-grained attacks and handling imbalanced datasets with high-precision and low FAR.'}\n","{'text': 'Wireless sensor networks have become a popular system for monitoring different environments due to their low cost and ease of deployment. However, distance measurement is an important factor for accurately locating sensor nodes, which can be achieved by distance-based localization algorithms such as DV-Hop. In this paper, we propose an Improved DV-Hop algorithm based on minimum hops correction and reevaluate hop distance. The proposed algorithm corrects the minimum hops error and reevaluate hop distance caused by the irregularity of the networks to improve the localization accuracy. In addition, we apply the least mean squares method to establish the mathematical model, which makes the calculation more efficient. Simulation results show that the proposed algorithm outperforms the traditional DV-Hop algorithm in terms of accuracy and stability, making it suitable for monitoring in wireless communication systems where accurate node locations are required. This algorithm can also be used in classification algorithms such as clustering, which require accurate distance measurements for high-quality data analysis.'}\n","{'text': 'This paper proposes an adaptive energy optimization algorithm that is specifically designed for Internet of Medical Things (IoMT) applications. IoMT is a network of medical devices and equipment that communicate wirelessly for improved medical services. One of the major challenges of IoMT is energy efficiency, as the devices often rely on wireless sensor networks for communication. The proposed algorithm is aimed at minimizing energy consumption while ensuring reliable and efficient wireless communication within the IoMT network. The algorithm utilizes an adaptive system that dynamically adjusts the transmission power of the devices to optimize energy usage. The algorithm also takes into consideration the optimization of the routing paths of the data packets in order to reduce energy consumption. The proposed algorithm demonstrates significant improvements in energy efficiency compared to existing optimization algorithms. The research findings are expected to contribute to the overall development of IoMT technology, leading to improved medical services that are cost-effective, reliable and energy-efficient.'}\n","{'text': 'This brief briefly addresses the problem of power flow solution for direct-current (dc) networks with radial configuration and constant power loads (CPLs). It proposes a novel iterative method based on the upper triangular relationship between nodal and branch currents, it also uses a primitive impedance matrix. The main advantage of this method lies in the possibility of avoiding inversions of non-diagonal matrices, which allows its convergence to be improved in terms of the number of iterations and processing times required in comparison to classical admittance-based methods. Three different radial dc resistive networks composed by 21, 33, and 69 nodes are employed to validate the effectiveness of the proposed power flow solution method. For comparison purposes, the Newton-Raphson method, and also successive approximations and Taylor-based approaches are implemented. All simulations have performed in MATLAB software.'}\n","{'text': 'Covert or low probability of detection communication is crucial to protect user privacy and provide a strong security. We analyze the joint impact of imperfect knowledge of the channel gain (channel uncertainty) and noise power (noise uncertainty) on the average probability of detection error at the eavesdropper and the covert throughput in Rayleigh fading channel. We characterize the covert throughput gain provided by the channel uncertainty as well as the covert throughput loss caused by the channel fading as a function of the noise uncertainty. Our result shows that the channel fading is essential to hiding the signal transmission, particularly when the noise uncertainty is below a threshold and/or the receive SNR is above a threshold. Overall, our study provides insights into the effectiveness of covert communication in the presence of channel and noise uncertainties.'}\n","{'text': \"This paper proposes an event-triggered consensus tracking control strategy for stochastic nonlinear multi-agent systems. The study focuses specifically on the use of protocols to enhance the system's ability to achieve consensus over time. The nonlinear nature of the system is taken into account through the use of trajectory analysis, which allows for the determination of the system's stability within certain topological constraints. Furthermore, the paper examines the use of eigenvalues and eigenfunctions to model the system's behavior, which in turn provides insights into the calculations and techniques used to develop the control strategy. The proposed method is demonstrated on a simulation of multi-agent systems, which provides evidence of the efficacy and performance of the approach. Overall, the research highlights the importance of considering nonlinear dynamics and proposes a robust and effective approach to address the problems of consensus tracking in stochastic nonlinear multi-agent systems.\"}\n","{'text': \"In the Internet era of knowledge fragmentation and network dissemination, teachers need to interact more with the Internet, improve their ability to acquire knowledge, build their own knowledge systems and professional knowledge, and enhance their personal value and competitiveness, which is teachers' personal knowledge management. This article aims at solving the four problems and dilemmas in the teacher's personal knowledge management. Based on the four knowledge transformation modes of the SECI model and the four processes of the teachers' personal knowledge management, teachers' personal knowledge management tools and application strategies are correspondingly proposed.\"}\n","{'text': 'The work is devoted to the problems of knowledge formation and competence according to the goal-setting of employers and taking into account general trends in the development of the economy. The article notes the problems and considers an approach for modeling and evaluating of the effectiveness of targeted training.'}\n","{'text': 'This paper explores the use of deep learning algorithms to predict obstructive sleep apnea through the analysis of facial depth maps. Sleep apnea is a serious sleep disorder that results in breathing interruptions during sleep and affects a significant portion of the population. By analyzing facial characteristics using three-dimensional displays, researchers in Australia have developed a deep learning model that can accurately predict the presence of obstructive sleep apnea. The model was trained using a large dataset of facial depth maps and achieved high accuracy in its predictions. This research has the potential to greatly improve the diagnosis and treatment of sleep apnea and provide a more effective and efficient way to identify at-risk individuals.'}\n","{'text': 'In this paper, we propose and thoroughly compare strategies for training convolutional neural networks (CNNs) for cell localization and segmentation in microscopy images with both little training data and in presence of significant label noise. Insufficient availability of ground truth (GT) is a common issue in the field of microscopy image analysis, hence the usefulness of such approaches. Performance evaluation is done using phase contrast microscopy human fibrosarcoma (HT1080) cells and comparing the resulting F-scores.'}\n","{'text': 'The delay-and-sum beamforming technique uses multiple microphones to localize sound sources. One disadvantage of this technique is that adjustments of the position or of the number of microphones change the quality nonlinearly. Additionally, due to the number of combinations possible, it is computationally hard to find the best configuration. This paper uses genetic algorithms to solve this problem. The algorithm searches for the microphone array configuration that provides the highest directivity for each steered orientation. The experiments showed that the genetic algorithm could find the best solution of a constrained search space comprising 33 554 431 solutions in a matter of seconds instead of days. Furthermore, this paper presents the used techniques to reduce the time of evolution, provides a web application and the source code of the implementation.'}\n","{'text': 'Effort has been made to find biomarkers for vascular dementia (VaD). Nevertheless, the current findings are typically obtained through statistical tests of group level differences. In clinical practice, however, it is more common to perform individual level inferences, e.g., to determine if a subject is suffering from VaD, which cannot be resolved with statistical analysis. The goal of this study is to develop a method to effectively discriminate early VaD patients from normal controls by combining EEG features with machine learning methods. The EEG signals were recorded from a total of 15 VaD patients and 21 controls during a visual oddball task. Interregional directed connectivity was derived from directed transfer function (DTF) analysis and used as features in classification. Three machine learning methods, including linear discriminant analysis (LDA), error back-propagation (BP) neural network, and support vector machine (SVM) were used as classifiers, and their classification performance was compared. It was found that VaD patients can be effectively identified using the BP and SVM classifiers with high accuracy. In particular, when the SVM classifier was combined with feature selection by Fisher score, it reached an accuracy 86.11%, sensitivity 86.67%, and specificity 85.71%. The area under the curve (AUC, 0.854) indicates a good identification of VaD patients from the normal controls. Since the EEG is noninvasive, inexpensive, and widely available to use, the current study presents a novel clinical application of machine learning methods and could facilitate automatic screening and diagnosis of the VaD at an early stage in future.'}\n","{'text': 'This paper presents a crowd panic detection method based on an autoencoder that uses motion features extracted from non-uniform spatio-temporal region. The autoencoder is fed with recent motion based feature called Histogram of Optical Flow Orientation and Magnitude (HOFM). This feature is extracted from a non-uniform spatio-temporal region that considers the surveillance camera position with respect to the scene. The autoencoder is trained with such features from scenes that involve normal crowd behaviour. The detection of a crowd panic situation is based on the fact that the trained autoencoder will struggle to reconstruct the features extracted from a crowd panic scene. The proposed crowd panic detection methodology is tested on three crowd panic sequences that are part of the LV dataset.'}\n","{'text': \"In this paper, based on a fuzzy entropy feature selection framework, different methods have been implemented and compared to improve the key components of the framework. Different methods, including three ideal vector calculations, three maximal similarity classifiers and three fuzzy entropy functions, were combined and compared to optimize the key components of the framework. Furthermore, various feature removal orders based on the fuzzy entropy values were examined. The proposed method was evaluated on three publicly available biomedical datasets, including Wisconsin Breast Cancer(WBC), Wisconsin Diagnostic Breast Cancer(WDBC) and Parkinsons. Our experiments indicated that the optimized combination of the ideal vector, similarity classifier and fuzzy entropy function yielded the best performance for feature selection. Additionally, we compared our proposed method with six classical filter-based feature selection methods, and found that the proposed method outperformed most of them. The proposed method was ranked as one of the top performers together with the Correlation and ReliefF methods. Our proposed method achieved classification accuracies of 96.97%, 94.85% and 78.23% for the WBC, WDBC and Parkinson's datasets, respectively. It is worth noting that our method exhibited the most stable performance for all three datasets when features were gradually removed. This indicates a better feature ranking performance than the other compared methods.\"}\n","{'text': \"With the development of smart education, how to promote students' deep learning in smart classrooms has become a hot topic of information classroom teaching reform. The development of higher-order thinking skills, especially critical thinking is an important dimension of students' deep learning. In this study, a debate teaching model was designed based on the APT (Assessment, Pedagogy, Technology, model in the smart classroom. The Chinese curriculum in the primary school was used as an example to carry out the debate teaching activities for reading. The survey questionnaire and qualitative analysis methods were used to analyze the influence of debate teaching in the smart classroom based on the APT model on students' critical thinking. The study found that the debate teaching based on the APT model can improve the students' critical thinking and higher-level knowledge building to a certain extent. The task of debate and problem solving are helpful for the development of students' knowledge building.\"}\n","{'text': 'In fifth-generation wireless communications, data transmission is challenging due to the occurrence of burst errors and packet losses that are caused by multipath fading in multipath transmissions. To acquire more efficient and reliable data transmissions and to mitigate the transmission medium degradation in the 5G networks, it is important to study the error patterns or burst the error sequences that can provide insights into the behavior of 5G wireless data transmissions. In this paper, a two-state Markov-based 5G error model is investigated and developed to model the statistical characteristics of the underlying error process in the 5G network. The underlying 5G error process was obtained from our 5G wireless simulation, which was implemented based on three different kinds of modulation methods, including QPSK, 16QAM, and 64QAM, and was employed using the LDPC and TURBO coding methods. By comparing the burst or gap error statistics of the reference error sequences from the 5G wireless simulations and those of the generated error sequences from the two-state Markov error model, we show that the error behaviors of the coded OFDM 5G simulations can be adequately modeled by using the two-state Markov error model. Our proposed two-state Markov-based wireless error model can help to provide a more thorough understanding of the error process in 5G wireless communications and to evaluate the error control strategies with less computational complexity and shorter simulation times.'}\n","{'text': 'This paper proposes a novel neural network model based on memristor cells and fractional order template for image edge detection. The use of memristors, a new class of electronic devices with the ability to store and process information, provides a promising approach to information processing. The proposed model is inspired by both biological neural networks and cellular neural networks, which have shown great potential in data mining and image processing. In addition, fractional order calculus is employed to improve the accuracy and convergence of the proposed model. The results demonstrate that the proposed model outperforms traditional edge detection methods in terms of accuracy and efficiency. This study opens the door for more exploration and experimentation of memristor technology in the field of neural networks and image processing.'}\n","{'text': 'This paper proposes an efficient equivalent model of patch antenna for the fast prediction of its installed radiation pattern. More CPU time and memory cost are required for accurate prediction of installed radiation pattern of patch antenna on different platforms. However, a fast and efficient prediction can save CPU time and memory cost when constructing an equivalent model of patch antenna that can reproduce a similar radiation pattern to that of the patch antenna. A code is developed to determine the electric field of a magnetic dipole based on Green function derivation. The result of the radiation pattern for the far-field and near-field are computed and validated with the result using commercial software tool (FEKO). The magnetic dipole is used to construct the equivalent model of patch antenna based on the radiation mechanism to predict its installed radiation pattern. The numbers of design parameters needed to be optimized are reduced to only two parameters which are the spacing distance between the dipoles in the x- and y-directions. The height of the dipole is kept at a fixed value above the same ground plane as that of the patch antenna. This makes it more computational efficient by reducing the CPU time and memory cost. After the equivalent model is optimized with FEKO optimization tool, it is further installed on a platform to compute the installed radiation pattern. The simulation results show that the proposed equivalent model based on a magnetic dipole with only two design parameters can obtain a fast prediction of installed radiation pattern of patch antenna when mounted on a platform. The equivalent model does not require detailed geometry and material information of the patch antenna.'}\n","{'text': 'Compressed Sensing (CS) based channel estimation techniques have recently emerged as an effective way to acquire the channel of millimeter-wave (mmWave) systems with a small number of measurements. These techniques, however, are based on prior knowledge of transmit and receive array manifolds, and assume perfect antenna arrays at both the transmitter and the receiver. In the presence of antenna imperfections, the geometry and response of the arrays are modified. This distorts the CS measurement matrix and results in channel estimation errors. This paper studies the effects of both transmit and receive antenna imperfections on the mmWave channel estimate. A relay-aided solution which corrects for errors caused by faulty transmit arrays is then proposed. Simulation results demonstrate the effectiveness of the proposed solution and show that comparable channel estimates can be obtained when compared to systems with perfect antennas without the need for additional training overhead.'}\n","{'text': \"This paper covers an overview of Information Communication Technology (ICT) training drives currently being undertaken in the Eastern Cape province of South Africa. ICT is both a driver and enabler of changing people's lives. For example, it changes the way people communicate, study and do business. Mobile phones and internet are becoming more available even in the most under developed regions and the hardest to reach communities. While the use of these ICTs is creating a wealth of new opportunities, it may include risks created by other users who use ICTs in an unethical manner. Therefore there is a need to make people aware of the opportunities and dangers or risks that comes with the use of ICTs. This paper seeks to unveil the path that the Eastern Cape e-Skills CoLab (EC e-Skills CoLab) has taken to provide training, aligned towards the fourth industrial revolution (4IR), around the province. The CoLab has embarked on a number of training and awareness campaigns ranging from basic Computer Literacy, Cyber Security, Internet of Things (IoT) and Robotics. Training is provided for basic computer users (e.g. learners, teachers), sector users, ICT practitioners, and e-Leaders. Each of these user groups has its own training model that has targeted a specific focus. For example, learners are given training and workshops on both Cyber Awareness and Robotics, whereas ICT practitioners are provided with training ranging from Cyber Security to IoT. The aim of the paper is to present and share the overview of e-skills experiences on number of ICT training that the EC e-Skills CoLab has rolled out.\"}\n","{'text': 'Stereo matching aims to perceive the 3D geometric configuration of scenes and facilitates a variety of computer vision in advanced driver assistance systems (ADAS) applications. Recently, deep convolutional neural networks (CNNs) have shown dramatic performance improvements for computing the matching cost in the stereo matching. However, the performance of CNN-based approaches relies heavily on datasets, requiring a large number of ground truth data which needs tremendous works. To overcome this limitation, we present a novel framework to learn CNNs for matching cost computation in an unsupervised manner. Our method leverages an image domain learning combined with stereo epipolar constraints. By exploiting the correspondence consistency between stereo images, our method selects putative positive samples in each training iteration and utilizes them to train the networks. We further propose a positive sample propagation scheme to leverage additional training samples. Our unsupervised learning method is evaluated with two kinds of network architectures, simple and precise CNNs, and shows comparable performance to that of the state-of-the-art methods including both supervised and unsupervised learning approaches on KITTI, Middlebury, HCI, and Yonsei datasets. This extensive evaluation demonstrates that the proposed learning framework can be applied to deal with various real driving conditions.'}\n","{'text': 'Continuous glucose monitoring systems (CGMSs) generate a vast amount of data by measuring the blood glucose concentration of a diabetic patient at a high sampling rate. These data can be effectively utilized by machine learning techniques to predict future glucose values, thereby enabling early prevention of dangerous hyperglycemic or hypoglycemic states and better optimization of the treatment. However, most methods in the literature rely on learning a prediction model from past samples of the same patient, rendering the system less usable. To overcome this challenge, we propose a method that trains prediction models on glucose signals obtained from a diverse cohort of patients and applies them to infer future glucose-level values in a completely new patient. To achieve this purpose, we designed and compared two different types of solutions that were proved successful in many time-series prediction problems based respectively, on non-linear autoregressive (NAR) neural network and on long short-term memory (LSTM) networks. We compared these solutions with three other literature-based approaches, namely feed-forward neural networks (FNNs), autoregressive (AR) models, and recurrent neural networks (RNN). While the NAR method showed good prediction performance only for short-term predictions (within 30 minutes), the LSTM method exhibited excellent performance for both short- and long-term glucose level prediction (60 minutes and more), surpassing all other methods in terms of correlation between measured and predicted glucose signals, and clinical outcome.'}\n","{'text': \"Cloud storage auditing helps users to check the integrity of their data stored on the cloud. However, if the client's auditing secret key is exposed to the malicious cloud, the client's data may be deleted by the malicious cloud without being detected. In this paper, we propose a public auditing protocol with intrusion-resilience to relieve damage caused by the key-exposure problem. The proposed protocol divides the lifetime of files stored on the cloud into several time periods, and each time period is further divided into several refreshing periods. The auditing secret key is updated in each time period, and secret values used to update the auditing secret key change in every refreshing period. These two update operations are completed by the client and the third party auditor (TPA). This protocol is secure against the adversary as long as the client and TPA are not compromised in the same refreshing period. Security proof under random oracle model proves the protocol is secure, and the experimental results indicate that the performance of the protocol is acceptable.\"}\n","{'text': \"Optical Character Recognition (OCR) of Arabic text from manuscripts images is virtually impossible, this is due to the semi-cursive nature of Arabic script which is very difficult to explore by algorithms and image processing methods.In this paper, we present a method of exploration and research in content of Arabic manuscript images. It's about characterizing segmented handwritten words with a set points of interest by providing a means of identification and research in these manuscripts. Each word segmented and described by key features will be compared to query words.The results of this method are encouraging in comparison with other methods, especially when it comes to the same of handwritten style used in the text.\"}\n","{'text': \"Text-based retrieval systems have been popular, but content-based retrieval systems have gained widespread acceptance in recent years to directly retrieve diverse media based on their visual content, such as color, texture, and shape. Among many content-based retrieval systems, sketch-based media retrieval systems have attracted attention recently with the proliferation of tablet PCs and smart mobile devices. Sketch-based retrieval requires the user to draw a freehand sketch query, but freehand drawing can be challenging for those with limited drawing skills. This degrades retrieval performance, since successful retrieval depends on the quality of the sketch query image drawn by the user. To address this issue, we propose a real-time stroke guidance for freehand sketch retrieval that continuously displays next-stroke shadow sketches on the canvas based on the user's step-by-step partial strokes. We train a stroke guidance network that learns the mapping between the step-wise stroke relations to predict the user's next stroke. The proposed stroke guidance for freehand sketch retrieval system runs on a five step next-stroke prediction model that identifies candidate next-stroke sketches from a database of millions of sketches. The system retrieves variable number of sketch object classes at different drawing stages. During the initial sketching stage, diverse drawing possibilities are covered by retrieving multiple sketch classes; as the sketching progresses, the intended sketch class is narrowed down to one. Deep binary hashing is employed for efficient similarity matching of relevant next-stroke sketches. We extend the Google QuickDraw dataset to create a five step sketch stroke database. Qualitative and quantitative experiments are conducted to verify the effectiveness of the proposed system, which can be utilized for drawing guidance, tracing, and sketch retrieval. Tracing refers to the act of copying the shadowed line of a guiding image by drawing over its lines.\"}\n","{'text': 'Channel estimation and equalization is one of the challenges of the filter bank multicarrier (FBMC) systems because of the existence of intrinsic imaginary interference. In this paper, we try to solve this challenge from a learning-based perspective. Based on the study of the intrinsic relationship between bidirectional long short-term memory (BLSTM) recurrent neural networks (RNN) and the FBMC radio signals, we propose a novel deep BLSTM network based channel estimation and equalization scheme, abbreviated as BLSTM-CE scheme. In the BLSTM-CE scheme, the input and output of some traditional independent modules are seen as an unknown nonlinear mapping and use a deep BLSTM network to approximate it. Numerical simulation shows that our proposed BLSTM-CE scheme can obtain perfect channel estimation performance in the FBMC systems.'}\n","{'text': 'This paper presents the concept of a radio frequency (RF) compressed sensing radar for indoor localization. A digital beamforming architecture for RF physical layer compressed sensing is discussed. Compressed sensing can reconstruct an under-sampled signal provided it is sparse in nature. A pseudo random multi-beam radiation pattern will be used to scan the target frame. The spatial sparsity in the target frame helps in recovering the entire frame using less number of scans compared to the conventional indoor localization system.'}\n","{'text': 'This paper proposes an Automated E-R Diagram Generation (AGER) System that can generate E-R Diagram from a given text in Natural Language given as input. Natural language texts are used to perform the information extraction by parsing the syntax of the sentences and semantically analyzing their content. The AGER System parses an input text in natural language, semantically analyzes it and internally uses some domain specific database and POS tagging to detect Entity and Relations from the given passage and builds a graph that represents the E-R Diagram. The E-R Diagram can be traversed to generate Data Definition Language to create the actual relations in any RDBMS system. The abstract nature of entity relationship diagram makes it difficult for database designers to directly create E-R Diagram from the natural language text input statement which is used to create the physical model of the database. In the requirement analysis phase of any software design, often Databases designers need to have elaborate discussions with the client on the use cases of the databases and at the end of the work they come up with a neat E-R Diagram which shall be used in subsequent phases to physically realize the relations and implement them. The AGER system proposed here is aimed to assist database designers to create E-R Diagram directly from Clientâ\\x80\\x99s requirements in natural language.'}\n","{'text': 'This paper describes the development of a web application for learning and training of mouse handling as an interaction device in digital environments. The application, called \"Mice,\" is designed to provide users with a comprehensive understanding of the use of mice and their associated software programs. This training platform is accessible through the Internet which allows anyone with an active online connection to access the application from anywhere around the world. Mice training emphasizes the importance of computer input devices, especially keyboards and mouse for motor coordination. The application can be used as an effective tool for individuals seeking to improve their knowledge and skills in the use of mice as information systems input devices. This research underscores the potential of web-based educational applications in providing practical and affordable ways to learn new skills and improve existing ones.'}\n","{'text': \"As the Internet continues to get stronger, so does the potential risk of malicious users trying to harm others. An intrusion detection system (IDS) can be used to alert the appropriate entities when potentially dangerous operations are happening within a host of set of hosts. Nowadays, we need a system that can accurately process large amount of network data quickly. Most of the state-of-the art IDSs apply the traditional machine learning algorithms to classify whether a packet is a part of an attack. However, these algorithms typically aren't implemented with a big data platform. In this research, we will use Apache Spark, a big data processing tool known for handling tasks at fast speeds, to process network packet data. This paper utilizes the Spark libraries to implement Random Forest, Support Vector Machines (SVMs), Logistic Regression, NaÃ¯ve Bayes, and Gradient Boosted Trees. We also implement a Deep Multilayer Perceptron, which is a Spark implementation of a deep learning algorithm. We compare the results of the traditional machine learning algorithms to the deep learning method. Our results show that the deep learning algorithm produces favorable accuracy, precision, and recall, but takes longer to analyze the data than classical machine learning algorithms.\"}\n","{'text': \"Visible Light Communication (VLC) based on LEDs has been a hot topic investigated for over a decade. However, most of the research efforts assume the intensity of LED light is constant. This hypothesis is not true when Smart Lighting is introduced to VLC, which requires LEDs to adapt their brightness based on the intensity of natural ambient light. Smart lighting saves power consumption and improves user comfort. However, intensity adaptation severely affects the throughput performance of data communication. In this paper, we propose SmartVLC, a system that can maximize the throughput (benefit communication) while still maintaining the LEDs' illumination function (benefit smart lighting). A novel Adaptive Multiple Pulse Position Modulation (AMPPM) scheme is proposed to support fine-grained dimming levels to avoid flickering while maximizing the throughput under each dimming level. SmartVLC is implemented on off-the-shelf commodity hardware. Several real-life challenges in both hardware and software are addressed to make it a robust real-time system. Comprehensive experiments are carried out to evaluate the system performance under multifaceted scenarios. Experimental results demonstrate that SmartVLC supports a communication distance up to 3.6m, and improves the throughput achieved with two state-of-the-art approaches by 40 and 12 percent on average, respectively, without bringing any flickering to users.\"}\n","{'text': 'Global utilities deploy smart meters as foundation for smart grids and smart cities, thereby providing more energy options and choices for customers to save energy. Advanced Metering Infrastructure (AMI) deployment involves business process review, technology evaluation, system and network design, customer engagement, workforce management and technology applications. CLP Power Hong Kong Limited (CLP) will upgrade all conventional meters of residential, and small and medium business customers to smart meters starting from end 2018. This paper aims to describe the deployment and technical challenges when developing a full roll-out AMI deployment programme.'}\n","{'text': 'In this paper, the output synchronization problem for complex dynamical networks (CDNs) with multiple output or output derivative couplings is discussed in detail. Under the help of Lyapunov functional and inequality techniques, an output synchronization criterion is presented for CDNs with multiple output couplings (CDNMOCs). To ensure the output synchronization of CDNMOCs, an adaptive control scheme is also devised. Similarly, we also take into account the adaptive output synchronization and output synchronization of CDNs with multiple output derivative couplings. At last, several numerical examples are designed to testify the effectiveness of the proposed results.'}\n","{'text': 'The incorporation of phasor measurement units (PMUs) into power systems has been a significant development in recent years. These devices can provide highly accurate measurements of current, voltage, and power, allowing for more precise system monitoring and control. The integration of PMUs into state estimators has been shown to improve the accuracy and efficiency of estimation. This paper proposes the inclusion of PMUs into a Least Measurement Rejected State Estimator (LMRSE) in order to further enhance estimation performance. The LMRSE method is based on rejecting measurements that contribute the least to the overall accuracy of the estimate. The proposed approach involves using information from PMUs in addition to the standard meters used for measurement. Simulation results demonstrate the improved estimation performance when PMUs are included in the LMRSE. This research sheds light on the potential benefits of utilizing PMUs in state estimation for power systems.'}\n","{'text': 'The high-impedance faults (HIF) occurring on distribution lines go undetected by the conventional relays due to their low current magnitude. HIFs are identified with their unique characteristics such as nonlinearity, randomness, and harmonic load switching. With the integration of Distributed Generators (DG), the current contribution through the substation alters, impacting the HIF detection. This paper presents an intelligent HIF detection technique for distribution lines incorporating the DGs. Variational Mode Decomposition (VMD) is the signal processing technique used to extract input patterns. The commonly used empirical mode decomposition has limitation of modal aliasing that is overcome by VMD. VMD decomposes the signal into different modes that are further converted to singular values so as to obtain the analytic signal. These are finally used as an input to an efficient classifier known as the support vector machine, to create an intelligent classifier. The effectiveness of this methodology is assessed on a modified IEEE 13-bus feeder for various situations by incorporating changes in DG parameters and considering the noise levels.'}\n","{'text': 'In this paper, we propose a scheme to classify different Wireless Capsule Endoscopy (WCE) lesion images for diagnosis. The main contribution is to quantify multi-scale pooled channel-wise information and merge multi-level features together by explicitly modeling interdependencies between all feature maps of different convolution layers. Firstly, feature maps are resized into multi-scale size with bicubic interpolation, and then down-sampling convolution method is adopted to obtain pooled feature maps of the same resolution, and finally one by one convolution kernels are utilized to fuse feature maps after quantization operation based on channel-wise attention mechanism in order to enhance feature extraction of the proposed architecture. Preliminary experimental result shows that our proposed scheme with less model parameters achieves competitive results compared to the state-of-the-art methods in WCE image classification task.'}\n","{'text': 'Recent work has demonstrated the efficacy of Procedural Techniques for simulation of realistic textures emulating rippled-sand and random roughness seafloors, as well as bioturbation by fish feeding pits. Separately, recent work has presented a sonar time series model, which has been shown to agree with theory for the mean, mean square, and spatial coherence of the roughness-scattered acoustic field. In this work, we apply these state of the art environmental generation techniques, inspired by the computer graphics industry, for generation of realistic seafloor textures, combined with the massive parallelization afforded by modern graphics processing units to compute acoustic models, for generation of simulated sonar time series. The resulting time series are then demonstrated to be suitable for coherent synthetic aperture signal processing resulting in a high-fidelity simulated SAS image.'}\n","{'text': 'This paper proposes a DCNN (Deep Convolutional Neural Network) based real-time adaptive ship license plate recognition system, named as DRASLPR, that is designed specifically for marine vehicles. The system employs advanced techniques in license plate recognition, text recognition, detectors and character recognition to enable the automated and accurate recognition of ship license plates in real-time. The use of deep learning models in the system helps improve the performance of the license plate recognition system. The proposed DRASLPR system is suitable for use in real-time systems, and can provide a better and more efficient method for recognizing ship license plates for marine vessels. This research highlights the importance of using advanced technologies such as deep learning and character recognition in developing efficient license plate recognition systems for marine vehicles. Future research can explore the integration of additional features, such as image processing algorithms and optical character recognition to further enhance the performance of the system.'}\n","{'text': \"Automatic mouth detection can assist in controlling a robotic system with self-feeding of individuals with disability. To address this need we developed and evaluated algorithms that: 1) detect and track the mouth of an individual in real-time, and 2) classify if the mouth is open or closed. A k-nearest neighbors (KNN) clustering algorithm was used to classify and recognize the mouth's posture. The KNN algorithm classified image frames using features extracted by four methods including a histogram of oriented gradients, Harris-Stephens algorithm, maximally stable extremal regions, and local binary patterns. The results of this study indicated a high classification accuracy (~87%) using 10-fold cross validation for three participants without disability. The study has shown that the algorithms can detect the mouth postures of a person in near real-time (<;1s) while they have a robot-assisted meal in a social setting.\"}\n","{'text': 'A language model (LM) is an important part of a speech recognition system. Language model adaptation techniques use a large amount of source domain data and limited target domain data to improve the performance of language models in target domain. Even though text datasets are easy to obtain, there is no public Chinese text dataset for language model adaptation tasks. This paper presents a language model adaptation dataset which consists of four different domains of news data, i.e., sport, stock, fashion, finance. The discrepancy between the domains of data is evaluated. Model combination based adaptation of n-gram is evaluated on the dataset. Three different fine-tuning adaptation methods of recurrent neural network language models (RNNLMs) are evaluated. WER results on AIShell speech data with the language models trained on this dataset are also provided. The absolute WER reduction of lattice rescoring with adapted RNNLM is 4.74%.'}\n","{'text': 'This paper presents a novel approach to prognostics utilizing multiple sensors and prediction interval optimization. The method incorporates \"reservoirs\" to capture and analyze dynamic data from the sensors. Additionally, uncertainty is accounted for through the use of Gaussian processes, allowing for more accurate predictive models. Bayesian methods are employed in the training process to further improve performance. The proposed approach demonstrates promising results in predicting the remaining useful life of equipment and could have significant implications for maintenance and decision-making in industries such as manufacturing and transportation.'}\n","{'text': 'This paper present a fuzzy supervisor for neural emulator of nonlinear MIMO processes to guarantee good performances of the neural emulator by its convergence rapidity and its accurent representation. In this proposed case, without initializing the parameter and online adaptation, both are needed. Numerical simulations are realized to clarify the performances improvement relatively to the classical case where the starting term is necessary.'}\n","{'text': 'This paper presents a novel deep arrhythmia-diagnosis network that can be used for atrial fibrillation classification using electrocardiogram (ECG) signals. The proposed network utilizes deep learning techniques to extract features from the ECG signals and classify them into different types of arrhythmias. Specifically, the network is designed to focus on the diagnosis of atrial fibrillation, a common and serious heart condition that affects millions of people worldwide. To train and evaluate the network, the authors use a large ECG database, which contains a wide range of heartbeats and arrhythmias. The results demonstrate that the proposed deep learning network outperforms traditional machine learning techniques and can accurately classify ECG signals into different arrhythmia types, including atrial fibrillation. This research contributes to the development of more accurate and reliable diagnostic tools for clinicians to diagnose and treat patients with heart conditions.'}\n","{'text': 'This article evaluates the current situation regarding the development of Intelligent Agents. First, it introduces and explains in detail all of the defining characteristics of an agent, and how each trait separates an AI from a normal software code. Then, this article examines what Intelligent agents must possess in order to be successful, and outline the main problems that it faces. Finally, a few real-life examples are given in order to demonstrate the goals and purposes of a few different types of agents.'}\n","{'text': 'Mobile operators around the world have been caught off guard by the popularity of mobile data services and with the massive deployment of macro base stations, and mobile data traffic continues to increase at an exponential speed. This increases overall energy consumption, which translates into a much higher rejection of carbon dioxide into the atmosphere. By the integration of small cells, i.e., femtocells, in the new generation networks, important questions are raised about the energy consumption in heterogeneous networks. In this paper, a new proposed Dynamic transmit power (DTP) based scheme is proposed to decrease the network power consumption. A stochastic geometry model is used to describe the different femtocells position in the network with realistic constraints and to evaluate the performance of our solution. Performance has been studied in terms of energy consumption and energy gains. Simulation results are used to confirm the analytical results and show that the DTP based scheme can reach an energy gain up to 35% compared to the constant transmit power (CTP) based scheme.'}\n","{'text': 'This paper presents a survey of data-driven methods for predictive maintenance of industrial equipment. Predictive maintenance refers to the use of data models and prognostics and health management techniques to predict equipment failures and schedule maintenance activities accordingly. Predictive models are typically designed using machine learning algorithms that enable them to learn from historical data and predict future failures. Fault diagnosis is another important aspect of predictive maintenance and involves the use of data-driven techniques to identify and isolate the root cause of equipment problems. The paper provides an overview of the current state of the art in data-driven predictive maintenance and highlights some of the key research challenges that need to be addressed in order to realize its full potential. Overall, the survey demonstrates the significant potential of data-driven methods for improving the efficiency and reliability of industrial equipment maintenance.'}\n","{'text': \"Wildfires are an increasing threat to global societies, with significant impacts on emergency communication systems. In this paper, we present a framework for the analysis of wildfire effects on these systems. Our framework consists of several tools, including plasmas, communication networks, radio propagation, real-time systems, and base stations. We demonstrate the effectiveness of our framework by applying it to real-world scenarios and show how it can assist emergency responders in mitigating the effects of wildfires on communication systems. Our results highlight the importance of considering the complex interplay between various factors in emergency communication during wildfires, and emphasize the need for proactive planning and effective strategies to ensure uninterrupted communication during disasters. Overall, our framework provides a valuable resource for researchers and emergency responders alike in improving emergency communication systems' resilience to wildfires.\"}\n","{'text': 'Phonetic recognition is one of the most challenging problems in the field of speech analysis. These applications can be mentioned such as dialect identification [1], mispronunciation detection [2], spoken document retrieval [3], and so on. There are different approaches to solve these problems such as improving the feature selection on input speech [4], applying deep learning technique [5] [6] [7] or combining both of them [8]. With the sequence data as the phonetics, the architecture which is based on recurrent neural network (RNN) is an appropriate approach [9]. It is even more powerful when combined with the improvement of features selection on input data. In our approach, we combine the Mel Frequency Cepstral Coefficients (MFCC) method with sequence-length to present the acoustic features of speech and use some RNN models to phonetic classification. Our experiments are implemented on the Texas Instruments Massachusetts Institute of Technology (TIMIT) [10] phone recognition dataset. Especially, our data processing and features selection method give consistently better results than other researches using the same neural network model. Currently, we have achieved the lowest error test rate (13.05%) by using Bidirectional LSTM, which is the best result in TIMIT dataset with the reduction of about 3.5% over the last best result [5] [6].'}\n","{'text': 'This paper presents a fast and distributed method for solving coupled Lagrangian problems using a control approach. The proposed method is proven to have convergence properties and can be implemented using both heuristic algorithms and optimization techniques. This method is suitable for solving problems in various fields such as radio frequency engineering and matrix decomposition. The use of convex functions and transfer functions is explored in the optimization process. Overall, the proposed method provides an efficient and practical solution for solving coupled Lagrangian problems.'}\n","{'text': 'In this paper, we propose an optimal robust state estimator using maximum likelihood optimization with the t-distribution noise model. In robust statistics literature, the t-distribution is used to model Gaussian and non-Gaussian statistics. The influence function, an analytical tool in robust statistics, is employed to obtain the solution to the resulting maximum likelihood estimation optimization problem, so that the proposed estimator can be implemented within the framework of traditional robust estimators. Numerical results obtained from simulations of the IEEE 14-bus system, IEEE 118-bus system, and experiment on a microgrid demonstrated the effectiveness and robustness of the proposed estimator. The proposed estimator could suppress the influence of outliers with smaller average mean-squared errors (AMSE) than the traditional robust estimators, such as quadratic-linear, squareroot, Schweppe-Huber generalized-M, multiple-segment, and least absolute value estimators. A new approximate AMSE formula is also derived for the proposed estimator to predict and evaluate its precision.'}\n","{'text': 'This paper discusses the acceleration of backward convolution in convolutional neural networks (CNNs) using the BWDSP platform. Backward convolution, also known as backpropagation, is a crucial aspect in training CNNs for deep learning tasks. The authors propose using the BWDSP platform to optimize signal processing algorithms and computer architecture for embedded systems. By utilizing parallel computing and hardware acceleration, the BWDSP platform is able to significantly speed up the backward convolution process. This paper presents experimental results demonstrating the effectiveness of the proposed method in reducing training time for CNNs. Overall, this work provides valuable insight into improving the efficiency of CNN training by leveraging specialized hardware and software platforms.'}\n","{'text': 'In this paper, we develop a closed-form lower bound for the achievable uplink rate of users in a single-cell massive multiple-input multiple-output (MIMO) system using zero-forcing (ZF) receiver. The base station (BS) is equipped with a large number of uniformly and linearly spaced antennas and serves single-antenna users. It estimates channel state information (CSI) using uplink pilot symbols. The channel model is also supposed to have a finite dimension. We then define the spectral efficiency as the sum of derived uplink rates. Through power allocation between data and pilot symbols, we further optimize this approximate expression of spectral efficiency. Simulation results are presented to evaluate the approximation of spectral efficiency and to show the advantage of our power allocation scheme in comparison to equal power allocation. The results also demonstrate that in low signal-to-noise ratios, more power should be allocated to the pilot symbols.'}\n","{'text': 'Vehicle type recognition in surveillance images plays an important role in traffic management and public security. This paper proposed a cost-effective approach to vehicle type recognition, which utilizes deep active learning and web data. Specifically, the proposed approach leverages the entropy-based sample selection strategy to reduce the uncertainty during the training and fine-tuning stages. Moreover, feature extraction based on deep learning is applied in the vehicle type recognition task, which enables high accuracy performance. Experiments demonstrated that the proposed approach significantly increases the efficiency and accuracy of vehicle type recognition in surveillance images, outperforming several state-of-the-art methods. Overall, the proposed approach provides a promising solution for cost-effective vehicle type recognition in the context of surveillance and image recognition.'}\n","{'text': 'The increasing availability of big data has sparked an interest in utilizing machine learning and predictive analytics to extract insights and make better decisions. Machine learning is a key component of this process, enabling the development of predictive models that can identify patterns and trends in large datasets. This involves performing task analysis and data analysis, identifying patterns and trends, and ultimately building analytical models that can be used to make predictions and guide decision-making processes. With the right tools and expertise, big data can be harnessed to drive innovation and improve outcomes in a variety of industries. This paper explores the ways in which machine learning, big data, and predictive analytics are being used to transform businesses and organizations, and highlights some of the key challenges and opportunities associated with this approach.'}\n","{'text': 'Small cells (SCs) mounted on top of the unmanned aerial vehicles (UAVs) are a promising solution to boost the capacity in hotspot areas. However, the adoption of UAV-SCs involves the planning of their missions over time, which includes the scheduling of recharging actions of each UAV-SC at ground sites. Typically, the energy needed to recharge UAV-SCs is derived from the grid, which can be coupled with microgeneration exploiting renewable energy sources (e.g., solar panels). In this architecture, the energy that is locally produced can be either sold to the grid or used to recharge the UAV-SCs. On the other hand, when the energy from microgeneration is insufficient for recharging the UAV-SCs, additional energy can be bought from the grid. In this paper, we investigate the trade-off between maximizing the throughput provided by the UAV-SCs over a set of areas, maximizing energy sold to the grid, and maximizing energy bought from the grid. The proposed model, MaxUAVProfit, is designed to (i) plan the UAV-SCs missions as a sequence of positions and actions in 3D space vs. time, (ii) manage the grid-connected microgeneration, and (iii) control the amount of throughput received by each hotspot. We then evaluate the MaxUAVProfit in a realistic scenario, which is based on the measurement of real cellular metrics and a realistic UAV-SC energy consumption model. Our findings demonstrate the superiority of the MaxUAVProfit with respect to other competing solutions, which include either optimization of microgeneration or maximization of the area throughput.'}\n","{'text': 'This paper presents a framework for predicting failures in ground tests on aircrafts. The framework incorporates data mining techniques, predictive models, atmospheric modeling, and data models to provide accurate predictions of potential failures in testing. The use of such a framework can greatly benefit aircraft companies by reducing the amount of failed tests and minimizing costs associated with repairs and delays. Through the integration of various data sources and models, this framework offers a comprehensive approach to predicting failures in ground testing that has the potential to improve the safety and efficacy of aircrafts.'}\n","{'text': 'Cyber-Physical Systems (CPSs) and Internet of Things (IoT) have seen burgeoning growth in every sphere of life. With this growth, researchers now face new challenges in sensor network security. Most of the research in this area only deals with vulnerabilities, attacks and countermeasures. However, considering security of WSN as a comprehensive unit in the practical deployment of CPS is still missing. System engineers need to assess the performance of a WSN against attacks and failures so that they may design reliable and stable networks. In this paper, we propose a novel multi-level Network Security Evaluation Scheme (NSES) to represent different security levels. The main objective of this evaluation scheme is to help system engineers and security experts to be able to assess the security needs of their networks and maintain the required protection level of the network at early design phases. Through several case studies, we have demonstrated the application of this scheme to evaluate and assess the security in different scenarios. These case studies also help in endorsing the usability of the proposed scheme across different application domains.'}\n","{'text': 'Solving mathematical word problems (MWPs) automatically is challenging, primarily due to the semantic gap between human-readable words and machine-understandable logics. Despite the long history dated back to the 1960s, MWPs have regained intensive attention in the past few years with the advancement of Artificial Intelligence (AI). Solving MWPs successfully is considered as a milestone towards general AI. Many systems have claimed promising results in self-crafted and small-scale datasets. However, when applied on large and diverse datasets, none of the proposed methods in the literature achieves high precision, revealing that current MWP solvers still have much room for improvement. This motivated us to present a comprehensive survey to deliver a clear and complete picture of automatic math problem solvers. In this survey, we emphasize on algebraic word problems, summarize their extracted features and proposed techniques to bridge the semantic gap, and compare their performance in the publicly accessible datasets. We also cover automatic solvers for other types of math problems such as geometric problems that require the understanding of diagrams. Finally, we identify several emerging research directions for the readers with interests in MWPs.'}\n","{'text': 'A 60GHz Yagi-Uda circular array antenna with omni-directional pattern for millimeter-wave WBAN applications is proposed. Center fed octagonal plates is used for feeding 8 Yagi-U da antennas located at the vertices of top and bottom octagonal plates. In order to improve the gain, each arm of dipole element is bent. The simulated 10-dB return loss bandwidth is 4085 MHz (57.17 GHz - 62.02 GHz) which covers a potential frequency band of 5G communication. The simulated results show that the proposed antenna has an omni-directional radiation pattern toward the body surface with the maximum gain of 2.86 dBi at 60 GHz.'}\n","Processing batch 30/63\n","{'text': 'Ever since the introduction of the domain name system (DNS), attacks on the DNS ecosystem have been a steady companion. Over time, targets and techniques have shifted, and in the recent past a new type of attack on the DNS has emerged. In this paper we report on the DNS random subdomain attack, querying floods of non-existent subdomains, intended to cause a denial-of-service on DNS servers. Based on five major attacks in 2018 obtained through backscatter measurements in a large network telescope, we show the techniques pursued by adversaries, and develop a taxonomy of strategies of this attack.'}\n","{'text': \"Continuous authentication (CA) is the process which continuously verifying a user based on their on-going interaction with a computer system. In this paper, we propose an adaptive continuous authentication method based on the changes of context, in which providing protection for the user's on-going interaction with computer in different contexts. In order to prevent a situation where an attacker tries to avoid detection by limiting to one input device, we considered both keystroke and mouse usage behavior patterns. In this research, collecting 30 users' data in an uncontrolled environment, extracting the user behavior feature from data by a new feature extraction method, using fusion technology to identify users, and then, according to the recognition result we can judge whether the current user is a real user or not. The experiment result shows that our scheme has a false acceptance rate (FAR) of 0%, a false rejection rate (FRR) of 2.04%, and the authentication time that between 10 seconds and 60 seconds for authentication.\"}\n","{'text': 'As key electrical equipment in the power system, the normal operation of a high-voltage circuit breaker is related to the reliability and economy of the power supply. In this paper, a mechanical fault diagnostic method for a high-voltage circuit breaker via the hybrid feature extraction and the integrated extreme learning machine (IELM) is investigated. First, the complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN) is used to decompose the vibration signal to obtain intrinsic mode functions (IMF). Then, the sub-band reconstruction of each order IMF component is performed by combining the Hilbert transform and the band-pass filter in order to obtain the time-frequency matrix. Moreover, mechanical fault feature vectors can be formed by the time-frequency entropy and the singular entropy, which are extracted by transforming the time-frequency matrix into the energy matrix and normalizing the frequency bands via the normal cumulative distribution function (NCDF). Moreover, an IELM model is developed for fault classification. The proposed CEEMDAN scheme, coupled with band-pass filtering, eliminates modal aliasing and reduces auxiliary noise addition while increasing decomposition efficiency. Besides, the performance of the singular entropy normalized by the NCDF is more stable, and the IELM composed of multiple weak classifiers can solve the shortcomings of the traditional extreme learning machine. Experimental results using measured data show that the proposed method can diagnose mechanical failures in high-voltage circuit breakers effectively, even with small sample sizes.'}\n","{'text': \"Acute lymphoblastic leukemia can be diagnosed through a series of tests which include the minimally invasive microscopic examination of a stained peripheral blood smear. Manual microscopy is a slow process with variable accuracy depending on the laboratorian's skill level. Thus automating microscopy is a goal in cell biology. Current methods involve hand-selecting features from cell images as inputs to a variety of standard machine learning classifiers. Underrepresented in this filed, yet successful in practice, is the convolutional neural network that learns features from fine-grained images. This paper compares the performance of a convolutional neural network model with other models to determine the validity of using whole cell images rather than hand-selected features for acute lymphoblastic leukemia classification.\"}\n","{'text': 'Natural scenic images usually contains textual data which may provide valuable information about the scene. To make this textual data useful, processing of scenic images involves various phases such as detection, localization, segmentation and recognition of text. First phase i.e. extraction of textual data plays an important role in further processing. Text extraction becomes difficult owing to variation in text font, size, skewness and noise in the captured image and is a challenge for the researchers. Over the years a lot of research has been dedicated to overcome these challenges and, this work presents extraction methods used for text in different Indian and non-Indian scripts. This article will provide academicians and practitioners with state of the art and future directions in this phase.'}\n","{'text': 'This article proposes a system for real-time visual feedback to aid in strength self-training, particularly for beginners who can benefit from observing the comparison between their own movements and those of experts. Using a camera-based motion capture and a normal LCD, the system does not require any additional devices to wear. The simplicity of installation ensures that the system can be utilized within a gym or at home. The performance and usefulness of the system are evaluated by a user test.'}\n","{'text': 'Artificial intelligence (AI) has in recent times assumed a relevant role in the most diverse sectors of our society. However, the idea of machines making decisions and â\\x80\\x9cthinkingâ\\x80?raises significant ethical concerns that must be addressed. The idea of â\\x80\\x9cthinkingâ\\x80?machines existence, making decisions by Humans raises several ethical questions. It is fundamental to study and investigate the best approaches to their integration. This article identifies the guiding principles of ethics in the context of using intelligent and autonomous systems. Here we present a bibliometric study, reporting the main ACM and IEEE studies on Ethics and AI. Thus, it is necessary to continue exploring and researching ethical principles in the context of AI integration to ensure its utilization benefits society as a whole.'}\n","{'text': 'Edge computing is an emerging computing paradigm that aims to solve the cloud limitations by bringing its applications closer to the Internet of Things (IoT) devices. Thanks to its horizontal scalability, this paradigm leverages from the rapid growth of connected devices and makes it in its favor. As a result, it improves the scalability and reduces the latency. However, the adoption of this paradigm alone does not guarantee to meet the quality of service (QoS). Due to the heterogeneity of those devices and their requirements, the QoS is more influenced by the nature of the devices that are responsible for offloading the task, and by their location, which complicates the offloading process. To address this issue, in this paper, we present a tasks orchestration platform for IoT. It focuses on the role of edge computing in order to guarantee a high scalability and enable the self-capabilities of IoT. We also present a tasks orchestration algorithm that is based on Fuzzy Decision Tree. It leverages from reinforcement learning which enables it to adapt to the unpredictable environmental changes. As opposed to the existing solutions, the proposed architecture has provided more scalability and low delays regardless of the number of devices. On the other hand, the proposed algorithm has reduced the tasks completion delay by nearly 32%, the energy consumption by 52%, and the failure rate by 44%, as compared to the state of the art algorithm.'}\n","{'text': 'This paper proposes an idea of employing sparse reconstruction-based technique for thermal imaging defect detection. The implementation of the reconstruction technique is tested on a carbon fiber reinforced polymer test piece with artificially drilled defects and the test results are compared with the established cross correlation method. The two processes are compared in terms of defect detectability, their SNR variation with defect depth and their computation complexity. When compared with cross correlation algorithm, the technique is expected to solve memory space problems by compressing all information from large cross-correlated pulse video into a single reconstructed image as an output. Furthermore, in existing cross correlation methods, the pulse peak time shifts with defect depth. Hence, defect quantification algorithms, such as SNR calculation, require multiple frame analysis. Such algorithms are comparatively simplified in sparse reconstruction technique. This paper explores sparse reconstruction algorithm for resolving close-spaced defects. This paper further describes cross-validation method for optimization of a user parameter in sparse reconstruction method.'}\n","{'text': 'Wireless sensor networks (WSN) constitute the communication backbone for many modern cyber-physical systems (CPS). Fault-tolerance is a mandatory requirement under several CPS domains. This paper addresses an important aspect to increase the dependability of WSN, describing and evaluating a protocol that uses multiple redundant gateways and fully reactive geographic routing, able to deliver messages to all gateways and handling voids natively. Through simulations, it is shown that the delivery rates of the WSN will remain high even in the presence of voids that compromise the delivering of messages when using a single gateway. In conjunction with other fault tolerance methods, like agreement or voting protocols and hardware/software diversity, the proposed protocol provides mechanisms to build more reliable WSN.'}\n","{'text': 'We present novel low-level audio features that are based on correlations between sub-band audio signals decomposed by undecimated wavelet transform. Under the assumption that SVM is used for classifier learning, the experimental results on GTZAN dataset showed that the proposed method demonstrated the best accuracy of 81.5%, outperforming the conventional methods.'}\n","{'text': 'In this contribution, an original approach for invivo estimation of electrical properties of biological tissues is presented. Such an estimation represents an essential step in hyperthermia treatment planning, wherein typically magnetic resonance or computerized tomography images are exploited and turned into electric parameters, based on available ex-vivo measured properties, to predict the effects of the treatment. As parameters change from patient to patient and can be quite different from the ex-vivo ones, the proposed approach is based on the solution of an inverse scattering problem, processing backscattered data measured from the patient and conveniently exploiting the morphological information on tissues available from medical images, to overcome the well-known issues arising in the solution of inverse problems.'}\n","{'text': 'This paper proposes a hierarchical segmentation approach with convolution-recursive deep learning for 3D multi-object recognition under partial occlusion conditions. The method focuses on object recognition in three-dimensional displays using computer vision and robot sensing systems. The proposed method involves training a deep learning network to perform image segmentation at multiple scales, allowing for more accurate recognition of objects even when partially occluded. The approach aims to improve the accuracy of multi-object recognition while also reducing the complexity associated with such tasks. The results of this study demonstrate the effectiveness of the proposed approach in improving recognition accuracy for objects under partial occlusion conditions, making it a promising advancement in the field of robot sensing systems and surface treatment.'}\n","{'text': \"Parkinson's disease (PD) is a degenerative disease that affects the motor system, which may cause slowness of the speech and the movements, and the anomaly of writing abilities due to tremor. PD diagnosis by Deep Learning approach has become an important worldwide medical issue through the last years. It is obvious that these patients due to their physical conditions are not suitable for every kind of PD diagnosis test. One of the non-invasive PD identification methods is the handwriting test, which is utilized in hospitals since many years ago. In this work we propose Convolutional Neural Network (CNN) based Deep Learning system to learn features from Handwriting drawing spirals which are drawn by People with Parkinson; also, we evaluated the performance of our deep learning model by K-Fold cross validation and Leave-one-out cross validation (LOOCV) techniques. Moreover, we introduce a dataset with a novel test which is called Dynamic Spiral Test (DST) along with traditional Static Spiral Test (SST) for PD recognition. We used both dynamic features and visual attributes of spirals. The proposed approach was reached to 88% accuracy value. The analysis of handwritten drawing tests proves that it is useful to combine SST and DST tests for automatic PD identification.\"}\n","{'text': 'Agile release planning is a crucial part of software engineering that involves determining the requirements and features of a software release. However, this process can be time-consuming and complex. Natural language processing algorithms can aid in automating and simplifying the planning process. This paper explores the use of natural language processing algorithms in Agile release planning. In particular, we examine how these algorithms can facilitate the extraction of requirements from natural language text, and how they can be used to prioritize these requirements. We also discuss the use of software algorithms, such as those implemented in Java, to implement these natural language processing techniques effectively. Overall, this paper highlights the potential benefits of utilizing natural language processing algorithms in Agile release planning, including increased efficiency, accuracy, and precision in the planning process.'}\n","{'text': 'This article explores the pivotal role of virtualization in cloud computing, and provides a comprehensive analysis of its various components. The authors highlight the significance of virtual machine monitors as the backbone of cloud infrastructure, enabling multiple virtual machines to run on a single physical server, thereby optimizing hardware capacity and utilization. They also discuss the importance of security and how virtualization addresses many of the challenges faced by traditional data centers. The article further delves into the concept of virtual machining, which allows remote hardware to be accessed as a service, reducing capital expenditure and maintenance costs for organizations. Overall, the study emphasizes the importance of virtualization in driving the scalability and flexibility of cloud computing, and asserts that it will continue to be a crucial element of cloud infrastructure in the future.'}\n","{'text': \"Different physiological theories and experiments have studied the link between emotions and humans' information provided by biofeedback sensors. However, only few works have been proposed regarding the acquisition of physiological data in order to investigate the emotions of video game players. In this paper, we propose an overview of different features which can be extracted from a set of physiological data acquired from players during video game sessions. Moreover, we provide a method to select only the most important features to use in a generic supervised learning algorithm. With these features, researchers can develop a model able to predict, in real-time, the players' emotions. Thus, we have conducted a set of experiments, in which we have acquired a set of physiological information, and the self-assessed participants' emotional state. On these data, we have applied a feature selection algorithm providing an overview of the most interesting physiological signals and features that should be considered during the studies on emotions in video game research field.\"}\n","{'text': 'IoT devices can be used to fulfil many of our daily tasks. IoT could be wearable devices, home appliances, or even light bulbs. With the introduction of this new technology, however, vulnerabilities are being introduced and can be leveraged or exploited by malicious users. One common vehicle of exploitation is malicious software, or malware. Malware can be extremely harmful and compromise the confidentiality, integrity and availability (CIA triad) of information systems. This paper analyzes the types of malware attacks, introduce some mitigation approaches and discusses future challenges.'}\n","{'text': 'Effort has been made to find biomarkers for vascular dementia (VaD). Nevertheless, the current findings are typically obtained through statistical tests of group level differences. In clinical practice, however, it is more common to perform individual level inferences, e.g., to determine if a subject is suffering from VaD, which cannot be resolved with statistical analysis. The goal of this study is to develop a method to effectively discriminate early VaD patients from normal controls by combining EEG features with machine learning methods. The EEG signals were recorded from a total of 15 VaD patients and 21 controls during a visual oddball task. Interregional directed connectivity was derived from directed transfer function (DTF) analysis and used as features in classification. Three machine learning methods, including linear discriminant analysis (LDA), error back-propagation (BP) neural network, and support vector machine (SVM) were used as classifiers, and their classification performance was compared. It was found that VaD patients can be effectively identified using the BP and SVM classifiers with high accuracy. In particular, when the SVM classifier was combined with feature selection by Fisher score, it reached an accuracy 86.11%, sensitivity 86.67%, and specificity 85.71%. The area under the curve (AUC, 0.854) indicates a good identification of VaD patients from the normal controls. Since the EEG is noninvasive, inexpensive, and widely available to use, the current study presents a novel clinical application of machine learning methods and could facilitate automatic screening and diagnosis of the VaD at an early stage in future.'}\n","{'text': 'This paper presents a word-level sentiment visualizer for financial documents, which provides a comprehensive and intuitive understanding of sentiment analysis results. The training process utilized recurrent neural networks to capture the complex relationship between language and sentiment. The visualization component is designed to assist users in task analysis by displaying the sentiment distribution of different vocabulary words. The vocabulary was carefully selected to reflect the unique characteristics of stock markets. The visualizer enables users to quickly identify the sentiment polarity of each word and gain insights into market trends. The effectiveness of the proposed tool is demonstrated through a case study, which shows that the visualizer can effectively reveal the temporal patterns of stock prices and sentiment in financial reports. The results suggest that the proposed visualizer can be a valuable tool for sentiment analysis in financial domains.'}\n","{'text': 'A novel robust Rauch-Tung-Striebel smoothing framework is proposed based on a generalized Gaussian scale mixture (GGScM) distribution for a linear state-space model with heavy-tailed and/or skew noises. The state trajectory, mixing parameters, and unknown distribution parameters are jointly inferred using the variational Bayesian approach. As such, a major contribution of this paper is unifying results within the GGScM distribution framework. Simulation and experimental results demonstrate that the proposed smoother has better accuracy than existing smoothers.'}\n","{'text': 'This paper presents an inertial sensor aided technique for beam alignment and tracking in massive multiple-input multiple-output (MIMO) vehicle-to-vehicle (V2V) communications based on millimeter waves (mmWave). Since directional communications in vehicular scenarios are severely hindered by beam pointing issues, a beam alignment procedure has to be periodically carried out to guarantee the communication reliability. When dealing with massive MIMO links, the beam sweeping approach is known to be time consuming and often unfeasible due to latency constraints. To speed up the process, we propose a method that exploits a-priori information on array dynamics provided by an inertial sensor on transceivers to assist the beam alignment procedure. The proposed inertial sensor aided technique allows a continuous tracking of the beam while transmitting, avoiding frequent realignment phases. Numerical results based on real measurements of on-transceiver accelerometers demonstrate a significant gain in terms of V2V communication throughput with respect to conventional beam alignment protocols.'}\n","{'text': 'Children with intellectual disabilities (ID), especially those who fail to communicate with normal speech, suffer from various limitations in their social functioning. They often rely on alternate methods to supplement or replace verbal communication. There is a rapidly growing number of augmentative and alternative communication (AAC) mobile applications available over recent years. However, the operation of these applications remains a challenge for users with ID since they may not have the sufficient cognitive proficiency to cope with the application interface. In this paper, we present the design, implementation, and evaluation of a Bluetooth low energy (BLE) based context-aware AAC system. Our system facilitates daily communication for nonverbal school children with moderate ID in order to address their learning and communication needs. We have piloted and evaluated our system at a special education school in Hong Kong. Our technical contribution is twofold. First, we introduce BLE technology to the AAC field and show its effectiveness on users with ID. Second, by converting conventionally standalone AAC software into a service system and empowering it with Internet of Things functionality, we open up many new opportunities brought by the system-of-systems (SoS) paradigm for the intellectually disabled population.'}\n","{'text': \"Recent advancements in brain-computer interface (BCI) technology hold immense potential for improving the quality of life for individuals with motor disabilities. However, designing a robust BCI system that accurately interprets the user's motor imagery signals requires a significant amount of training data, which may not always be feasible to obtain. In this paper, we propose a method for transferring common spatial filters between subjects without the need for additional training data. We utilize semi-supervised learning techniques to derive effective feature extraction and estimation models from a limited amount of labeled data. Additionally, we employ support vector machines for calibration to further enhance the performance of the system. Our experimental results demonstrate that our proposed method can achieve comparable accuracy to traditional methods that rely on a large amount of training data, showing promising potential for practical applications in real-world settings where obtaining training data is a challenging issue.\"}\n","{'text': 'In vehicle-to-everything (V2X) communications, collecting sensing data from nearby entities is common and essential. However, this approach also raises grave concerns about the truthfulness of data reported by the senders, particularly the unreliable stakeholders. For example, a compromised vehicle may deliberately disseminate its false location to the surrounding receivers. Trusting the data, a receiver can be trapped to change a wrong lane or accelerate unexpectedly. Such problems can potentially lead to a crash. This letter introduces a novel method by exploiting valuable information from the received physical signals of the multi-array beamforming antennas equipped in V2X-supported vehicles to verify the truthfulness of the claimed GPS location in V2X messages without requiring the availability of many dedicated anchors as in conventional approaches. Simulation results demonstrate that our method is effective and significantly helps to prevent the location forgery attacks in V2X.'}\n","{'text': 'This paper presents a study on the productivity of brands on social media, specifically focusing on their responsiveness on Twitter. The study utilizes feature extraction techniques to analyze the behavior of companies on social media and measure their productivity. The Internet has revolutionized the way businesses interact with their customers, and social media platforms like Twitter have become essential tools for marketing and brand management. The field of computer science has played a critical role in enabling businesses to measure and quantify their social media presence, and this study is an important contribution to the ongoing efforts to understand the impact and effectiveness of social media marketing strategies. Overall, the findings of this research provide valuable insights for companies seeking to improve their social media productivity and engage more effectively with their customers on Twitter.'}\n","{'text': 'By the advent of FaaS Cloud services and the micro-services programming architecture, designing task allocation algorithms with higher performance has become a crucial task. Motivated by this high-interested challenge, we propose a new allocation algorithm called PESS-MinA based on our novel modular model for FaaS Edge-Cloud environments. In contradiction to widely-used Max-Min and Min-Min algorithms which are both reactive and deterministic, this algorithm is based on stochastic score, and thus provides proactivity considerations. Experiments with Google Cloud Trace dataset show that our algorithm exhibits better performance in both resource load balancing and QoS assurance of FaaS. According to simulations, PESS-MinA decreased the dropped tasks percentage from 2.9% to 0.01%, alongside with a triple balancing score.'}\n","{'text': 'DITUS is a web-based intelligent tutoring system developed and used at our institution as an additional learning platform. To make the system even more adaptive we expanded its architecture with several modules that perform educational data mining tasks such as clustering, to discover groups of students that use the system in a similar manner, and high-utility sequential pattern mining to discover efficient learning paths through the knowledge domain. The results of these modules enable the system to offer hints to students on which knowledge units to learn before or after the currently selected unit. One of the main pre-conditions of the quality of hints is the clustering phase in which we discover groups of students that are using the system in a similar manner in terms of learning activity and efficiency. In this paper, we analyze the results of several well-known clustering algorithms on our datasets, to determine which one is best suited for the needs of our system.'}\n","{'text': 'The cloud, and the flexibility it provides is fast becoming a popular platform for SaaS, a popular software delivery model. Cloud has many advantages, such as increased flexibility, no maintenance, easy access and easy to share information. However, there are many concerns around issues like system security, communication security, data security, latency and availability. And these security issues need to be addressed during the design and development of cloud SaaS application in order to provide security compliance and trusted environment for user using cloud SaaS. In this paper, we explore the security pattern for Cloud SaaS. We work on the patterns covering different security aspects from system and data security to privacy.'}\n","{'text': 'this paper, we describe experimental, simulation, and analytical approaches to study bend losses in single and fewmode optical fibers bent into a circle (in-plane bend) and helix. For the in-plane bend case, we compute loss through simulations and experiments, over the bend diameter range of 9.5-19.5 mm at 1550 nm wavelength. For in-plane bend simulations, we obtain the refractive index profile of an equivalent straight fiber by applying the geometrically exact beam theory (GEBT) and conformal mapping, against the conventional approach to use an elasto-optic factor to account for stresses experienced by the fiber. We apply GEBT to compute the strain tensor of a bent fiber. The strain tensor,in turn, is used in the stress-optic law to obtain the refractive index due to bending stress. To account for the geometric effect, we apply the conformal mapping technique. The refractive index profile obtained by applying GEBT followed by conformal mapping is used in full-vectorial FEM simulations carried out in COMSOL to compute bend loss at different diameters. The simulation and experimental results are in close agreement. We extend our approach to few-mode fibers by calculating the planar bend losses for higher order modes. The close agreement of the simulation results, generated without making any ad hoc assumptions about the elasto-optic factor to account for the stress effects, with literature validates our approach. Next, we describe the results of experiments to measure the bending losses of fibers wound helically around the mandrel for bend diameter range 9.5-19.5 mm and different helix pitch values. We derive an analytical formula to compute helical bend losses based on the method outlined by Marcuse. Although the results from the formula are in close agreement with the experimental results and predict the exponential decrease of loss with increasing pitch, the formula does not account for the non-monotonous dependence of bend loss on helix pitch, observed experimentally. We present a simple empirical formula to account for the nonmonotonic dependence. Finally, we study the influence of microbend loss, due to the surface roughness of the mandrels used in the experiments on the bending losses. While the effect of surface roughness can be neglected for the mandrels used in our experiments, its effect may become important in mandrels with higher surface roughness, especially at larger bend diameters.'}\n","{'text': 'This paper proposes an approach for the inspection, identification, and monitoring of cracked concrete structures using image processing techniques. The method involves feature extraction and image edge detection to accurately detect surface cracks in concrete. The use of gray-scale images improves the accuracy of the process. Additionally, surface treatment is applied to concrete structures to better capture images, which aids in the detection and monitoring of cracks. The implementation of this approach has great potential for the maintenance and repair of concrete structures, as it allows for the early detection of cracks and the monitoring of their progression. The proposed method is a promising tool for the identification and repair monitoring of concrete structures, and it may ultimately help extend the lifespan of these important structures.'}\n","{'text': 'The Name Weighted Round Robin (NWRR) algorithm has been proposed as a scheduling mechanism for Named Data Networking (NDN) that aims to manage network resources and ensure quality of service (QoS) for users. This algorithm is designed to support DiffServ networks and takes into account the varying importance and popularity of different data objects through a weighting system. NWRR allocates bandwidth to each named data object that is enqueued in a priority queue, according to its weight and position in the queue. This mechanism ensures fairness and balance in resource allocation, while also providing differentiated treatment for high-priority objects. The algorithm utilizes a round-robin scheduling approach, where each named data object is processed for a certain length of time before moving onto the next one. This ensures that all the data objects are processed in a timely and efficient manner. NWRR has been evaluated through simulations and compared with other scheduling algorithms in both NDN and IP networks. The results demonstrate the effectiveness of NWRR in improving QoS metrics such as delay and jitter, while maintaining stable performance under varying traffic conditions.'}\n","{'text': 'Hybrid storage devices have been widely deployed in cloud platforms to provide cost-efficient storage services. So the performance isolation on hybrid storage devices is important and necessary to ensure the quality-of-service (QoS) of cloud tenants. However, existing performance isolation techniques (e.g., the widely used cgroup) cannot provide accurate performance isolation on hybrid devices, usually leading to an unexpected throughput shrink than the user-specified value. In this paper, we propose a new Self-Adaptive Accurate Throttling (SAAT) method to achieve accurate performance isolation on hybrid storage devices. SAAT can give an accurate estimation of the throughput shift of existing solutions periodically according to the latest status of hybrid storage devices, and then adjust the assigned throughput of cgroup to achieve the accurate performance isolation. The experimental results exhibit that SAAT outperform the original cgroup method for 3.42 times on the difference of average throughput (DAT) between the target and the measured one, i.e., reducing DAT from 6.56% to 1.94%; in the meanwhile, SAAT reduces the Average Jitter of practical throughput from 6.62% to 5.25%.'}\n","{'text': 'With the advancement of digital technology, use of various multimedia devices such as portable camera and mobile camera has grown at rapid pace. Now days, these portable devices are used to capture various scene images which usually contain text. The text part in the scene images sometimes contain useful information which needs to be recognized for various applications. But, text detection in natural scene images is very challenging process due to factors such as uneven illumination, arbitrary layouts, perspective distortion and warped text. In order to overcome these challenges, study is being done by various researchers to detect text from the natural scene images. In this paper, author explains the various text detection techniques which have already been previously used for text detection in natural images. Apart from that, author has also described the new era of technology i.e. Deep Learning based techniques for text detection in natural scene images.'}\n","{'text': 'In order to reduce the high-frequency switching harmonics of cascaded H-bridge (CHB) converters, phase-shifting pulsewidth modulation (PWM) using a centralized controller has been extensively studied. In this letter, an improved decentralized PWM strategy is proposed as an alternative approach for decentralized modulation. First, the output current of CHB converter is measured by each power cell as an effective synchronization indicator to identify the digital carrier angle of each power cell at the exact time of output current fundamental component zero crossing. Then, a PI controller dynamically adjusts the carrier relative angles of all power cells until they are properly interleaved. Together with the an inverse power factor droop for power sharing control, a CHB converter system can operate at autonomous islanded mode in a fully decentralized manner. Experiments from a single phase islanded CHB converter have been conducted to validate the correctness of the proposed approach.'}\n","{'text': 'Stochastic control is a widely used approach to modeling and controlling uncertain systems. However, the accuracy of the mathematical model used to describe the system is critical to the performance of the control algorithm. This paper investigates the problem of robustness to incorrect system models in stochastic control. The concept of convergence is introduced to measure the degree of convergence between the true system model and the approximation used in the control algorithm. The paper focuses on the use of kernel-based learning methods to adapt to the unknown system model, which can improve the robustness of the control system. Real-world applications of data-driven learning in stochastic control are also discussed, emphasizing the importance of accurate data models to ensure the effective use of this approach. The paper concludes by highlighting the need for further research in robust stochastic control to address the challenges posed by inaccurate system models and measurement.'}\n","{'text': \"Surrogate modeling is an effective method for solving computationally expensive problems by constructing a simplified surrogate model to replace the original model. However, constructing a surrogate model with a small scattered dataset and satisfying a priori knowledge, such as monotonicity experience, remains a challenging task. In this paper, we proposed an evolutionary neural network-based method for constructing a surrogate model that addresses this problem. Specifically, the proposed method combines neural networks and evolutionary computation to train the neural network model with a small scattered dataset and obtain an accurate surrogate model with good interpolation and extrapolation ability. To demonstrate the effectiveness of the proposed method, we applied it to a mechanical engineering case study of shape optimization, where we constructed a surrogate model for the aerodynamic performance of a car's rear wing. The results show that the proposed method can significantly improve the accuracy of the surrogate model and may have great potential in various computational modeling applications.\"}\n","{'text': 'Recent work has shown significant progress in the direction of synthetic data generation using Generative Adversarial Networks (GANs). GANs have been applied in many fields of computer vision including text-to-image conversion, domain transfer, super-resolution, and image-to-video applications. In computer vision, traditional GANs are based on deep convolutional neural networks. However, deep convolutional neural networks can require extensive computational resources because they are based on multiple operations performed by convolutional layers, which can consist of millions of trainable parameters. Training a GAN model can be difficult and it takes a significant amount of time to reach an equilibrium point In this paper, we investigate the use of depthwise separable convolutions to reduce training time while maintaining data generation performance. Our results show that a DepthwiseGAN architecture can generate realistic images in shorter training periods when compared to a StarGan architecture, but that model capacity still plays a significant role in generative modelling. In addition, we show that depthwise separable convolutions perform best when only applied to the generator. For quality evaluation of generated images, we use the FrÃ©chet Inception Distance (FID), which compares the similarity between the generated image distribution and that of the training dataset.'}\n","{'text': 'Frequency channel allocation is a key technique for improving the performance of cellular networks. In this paper, we address the channel allocation problem for a 5G multi-cell system. We consider a heterogeneous network in which cellular users, micro-cell users, and device-to-device (D2D) communications coexist within the radio footprint of the macro cell. We maximize the aggregate transmission rate, exploiting channel diversity and managing both the inter-cell interference, typical of cellular networks and the intra-cell interference generated by the nonorthogonal transmissions of the small-cell and D2D users. By modeling the allocation problem as a potential game, whose Nash equilibria correspond to the local optima of the objective function, we propose a new decentralized solution. The convergence of our scheme is enforced by using a better response dynamic based on a message passing approach. The simulation results assess the validity of the proposed scheme in terms of convergence time and achievable rate under different settings.'}\n","{'text': 'Conventionally the semi-supervised learning methods require assumptions about the pattern of data when utilizing unlabeled data. Inappropriate assumptions can result in causing error messages to propagate, which can degrade the performance of the classification. This paper first introduces the feature dimension-increasing model, then proposes a hidden feature transformation model for extracting the projection matrix from the dimension-enhancing space. Furthermore, a new semi-supervised classification model based on hidden feature dimension enhancement is proposed. The proposed method only uses the information of the labeled data in the original space and the hidden space to train the model, and does not need to utilize the information of the unlabeled data. The proposed method shows better classification performance in our experiments.'}\n","{'text': 'Network localization and synchronization (NLS) is a paradigm that considers joint inference of positions and clock parameters in a network consisting of completely asynchronous nodes. NLS has the potential to achieve significant performance gains in terms of localization and synchronization accuracy. In this paper, we derive fundamental performance limits of NLS by considering a problem formulation in the non-Bayesian inference framework, in which the waveforms received by different nodes in the network are considered as measurements. We perform equivalent Fisher information analysis to obtain bounds on the accuracy of NLS, and our results reveal how physical parameters and signal departure times affect the inference performance. The analytical results are verified by simulations based on a realistic channel model that takes spatial consistency into consideration.'}\n","{'text': 'Cloud computing is a new paradigm in which computing is offered as services rather than physical products. Computing services are provided by third-party service providers which offer consumers affordable and flexible computing services via shared resources. Cloud providers offer different layers/levels of services to consumers over many types of application domains. Server consolidation is a technique for reducing operating costs of computer resources in virtualization. These expenses can lead to increasement of financial costs of servers, power consumption of servers, data-center cooling systems and labour costs. It is inefficient if there are under-utilized servers that have more space and consume more resources. The proposed method meets the requirements for effective resource allocation for cloud computing. The effectiveness of the proposed method is evaluated and reveals higher performance in cloud computing.'}\n","{'text': 'InNet is a novel approach to detecting shadows in images using injection networks. The method involves feature extraction, image edge detection, and analysis of image color. The approach takes into account task analysis to ensure that the system learns to detect shadows accurately. The use of neural networks in the estimation process offers a more efficient means of detecting shadows than traditional methods. Training the system using the proposed method results in a highly accurate model capable of detecting shadows in both outdoor and indoor environments. Overall, InNet offers a promising approach to detecting shadows, with potential applications in various fields such as autonomous vehicles, surveillance systems, and image analysis.'}\n","{'text': 'The identification of nodal road network features in remote sensing imagery is an important object detection task due to its versatility of application. A successful capability enables urban sprawl tracking, automatic or semi-automated map accuracy validation and updating, and macro-scale infrastructure damage evaluation and tracking just to name a few. We have curated a custom, novel dataset that includes nodal road network features such as bridges, cul-de-sacs, freeway exchanges and exits, freeway overpasses, intersections, and traffic circles. From this curated data we have evaluated the use of deep machine learning for object recognition across two variations in this image dataset. These variations are expanded versus semantically coalesced classes. We have evaluated the performance of two deep convolutional neural networks, ResNet50 and Xception, to detect these features across these variations of the image datasets. We have also explored the use of class-specific data augmentation to improve the performance of the models trained for nodal road network feature detection. Cross-validation performance of the models evaluated on four variations of this nodal road network feature dataset range from 0.81 to 0.96 (F1 scores). Coalescing highly specific, semantically challenging classes into more semantically generalized classes has a significant impact on the accuracy of the models. Our analysis provides insight into if and how these techniques can improve the performance of machine learning models, facilitating application to broad area imagery analysis in numerous application domains.'}\n","{'text': 'The performance of most of the classical sound source localization algorithms degrades seriously in the presence of background noise or reverberation. Recently, deep neural networks (DNNs) have successfully been applied to sound source localization, which mainly aim to classify the direction-of-arrival (DoA) into one of the candidate sectors. In this paper, we propose a DNN-based phase difference enhancement for DoA estimation, which turned out to be better than the direct estimation of the DoAs from the input interchannel phase differences (IPDs). The sinusoidal functions of the phase differences for â\\x80\\x9cclean and dryâ\\x80?source signals are estimated from the sinusoidal functions of the IPDs for the input signals, which may include directional signals, diffuse noise, and reverberation. The resulted DoA is further refined to compensate for the estimation bias near the end-fire directions. From the enhanced IPDs, we can determine the DoA for each frequency bin and the DoAs for the current frame from the distributions of the DoAs for frequencies. Experimental results with various types and levels of background noise, reverberation times, numbers of sources, room impulse responses, and DoAs showed that the proposed method outperformed conventional approaches.'}\n","{'text': 'In this paper, the problem of coarse timing synchronization of low signal-to-noise radio (SNR) wireless orthogonal frequency-division-multiplexing systems (OFDM) for Internet of Things (IoT) is investigated. When OFDM is applied in IoT scenarios, the system needs to work at quite low SNR to achieve extended coverage. The proposed coarse synchronization method can response efficiently to the aforementioned challenge with a noise-eliminated timing metric. The simulation results of detection failure probability at different SNRs and number of processed frames indicate that significant performance improvement is obtained with the proposed scheme.'}\n","{'text': 'There are numerous algorithms for designing lead compensators, some of which are graphical whereas others are analytical. When designing a lead compensator, the parameters of the compensator are considered as an optimization problem which aims at getting the required time and frequency specifications. This paper presents a comparison between lead compensators designed by nature-inspired algorithms against those designed by conventional algorithms for various types of systems. The nature-inspired algorithms considered in this paper are the genetic algorithm (GA), which is built on the concept of natural selection process which imitates biological evolution, and the particle swarm optimization (PSO), which is stimulated by social behavior of fish schooling or bird flocking. In this paper, two different examples are considered to demonstrate the comparison between the design methods. The simulation results of these examples show that the nature-inspired algorithms provided better transient response due to reduced settling and rise times and provided better relative stability due to zero overshoot and higher phase margin.'}\n","{'text': \"This paper proposes an 8 channel patient specific neuromorphic processor for the early screening of autistic children through emotion detection. The proposed approach utilizes electroencephalography (EEG) and support vector machines (SVMs) to classify the emotions of the patients. The hardware implementation is specifically designed for pediatrics, ensuring that the system is safe and easy to use for children. The system leverages table lookup and feature extraction techniques to enhance its performance. The system's primary objective is to provide an early screening tool for autistic children, which can enable early detection and intervention. The proposed system has the potential to enhance the early diagnosis of autism and support early intervention, which can significantly improve the outcomes for autistic children.\"}\n","{'text': 'This paper proposes the use of a synchronous LoRa mesh network for monitoring processes in underground infrastructure. The network utilizes logic gates to ensure reliable data communication among wireless sensor nodes. The monitoring system adheres to established standards to ensure compatibility with existing infrastructure. The ability for wireless communication in an underground environment provides a cost-effective solution for monitoring and maintenance. The reliability of the network ensures that data is accurately transmitted and received, providing accurate and timely information for decision making. Overall, the use of a synchronous LoRa mesh network provides a powerful tool for monitoring processes in underground infrastructure.'}\n","{'text': 'In order to realize automatic recognition and extraction of entities in unstructured medical texts, a model combining language model conditional random field algorithm (CRF) and Bi-directional Long Short-term Memory networks (BiLSTM) is proposed. We crawled 804 drug specifications for treating asthma from the Internet, and then quantized the normalized field of drug specification word by a vector as the input of the neural network. Compared with the traditional machine learning algorithm CRF model, the system accuracy, recall and F1 value are improved by 6.18%, 5.2% and 4.87%. This model is applicable to extract named entity information from drug specification.'}\n","{'text': 'Visual ergonomics through ocular biomechanical analysis is an inviting, non-invasive method to add insights into the effect of immersion on our ocular system. It can also add insights into the mental and cognitive state, due to the tight coupling of eye movement and mental state. Eye movement tracking has been used in studying eye movement in normal activities and with the use of embedded eye trackers into virtual reality headsets, this can be easily extended into virtual environments. In this paper, we present a biomechanical analysis of eye movements recorded from subjects during immersion. Our objective is to validate the ocular biomechanical model used, through comparing recorded and muscle-driven eye movement. The regression analysis between the recorded eye movement and the muscle-driven eye movement shows a strong significant positive correlation. In addition, the computed extra-ocular muscle controls show agonist-antagonist relationships which is in accordance with the normal realistic eye movement. Insights into the different eye-head coordination styles performed by subjects are highlighted, too.'}\n","{'text': 'Crowdsourcing is a distributed business service model brought by Internet. However, users always pursue the maximum benefits with the least effort, which may lead to the low quality of solutions submitted by receivers. In addition, each user is most concerned about their own benefits, and sometimes they do not objectively evaluate the solutions. Based on blockchain technology, this paper implements crowdsourcing process through smart contract, and proposes credit and arbitration mechanisms suitable for general online industrial services. To be specific, the credit mechanism defines the historical reputation of each user through credit score, which is beneficial for the sender to find a satisfactory receiver, and provides criteria for the selection of members of the arbitration institution. We also combine punishment and incentive measures to ensure the earnest implementation of the crowdsourcing business by users. Arbitration mechanism refers to the arbitration of task solutions submitted by receivers through the decentralized and credible arbitration institution rather than senders or the crowdsourcing platform, which ensures the fairness and impartiality of the solution evaluation. The experimental results demonstrate the effectiveness of the proposed credit mechanism and arbitration mechanism.'}\n","{'text': 'This paper examines the impact of various deterministic noise sources on jitter in a CMOS inverter. The study focuses on the effects of power supplies, transfer functions, and substrates on jitter. Analytical models were developed for the estimation of jitter induced by power supply and substrate noise. The results show that power supply noise can have a significant impact on jitter, especially at higher frequencies. The study also found that the substrate can act as a noise source and can negatively affect the performance of the CMOS inverter. In addition, the transfer function of the inverter can also impact the jitter performance. Overall, this research provides valuable insights into the factors that affect jitter in CMOS inverters and offers a framework for the development of effective jitter reduction strategies.'}\n","{'text': \"Due to assorted reasons, when a sender sends an email to a receiver, the email does not get delivered. The non-delivery of an email is said to be a bounce and a bounce memo typically known as a failed Delivery Status Notification (DSN) is directed to the sender's server. Bounces can ensue because of temporary failures or permanent issues. Permanent bounces should be evaded at any cost and temporary/transient bounces should be abated. When bounces are numerous, the existing Email Service Providers (ESPs) may denounce the sender as a likely spammer. The failure messages sent by the different ESPs are unlike both in the format and in the message content, in-addition to sending ambiguous bounce messages for the same scenario. Also, when quite a few ambiguities are involved, the relay servers obscure the identification of the original reason of bounce. Prediction of bounce reason is therefore vital to proactively avoid being listed as a spammer in any public Remote Black Holes(blacklists). This paper proposes to use the One-vs-All Multiclass classifier with the best fit, the Two-Class Locally Deep Support Vector Machine to predict the bounce category by comparing the performance of the various binary classifiers in the One-vs-Multiclass classifier setup.\"}\n","{'text': 'The effective management of work items is crucial for enhancing the productivity and efficiency of the overall business operations. In this regard, the adoption of look-ahead strategies for work item selection has gained significant attention in the research community. Task analysis and computational modeling have enabled businesses to identify the critical tasks that demand immediate attention and prioritize them accordingly. Key performance indicators have emerged as an effective metric to measure the performance of work items and track their progress. Process modeling has facilitated the identification of bottlenecks and inefficiencies in the work item selection process. Resource management has emerged as a critical aspect that enables businesses to allocate resources effectively, optimize their utilization and minimize delays. In conclusion, the adoption of look-ahead strategies for work item selection has the potential to enhance overall business productivity, efficiency, and profitability.'}\n","{'text': 'This paper presents a novel method to detect unusual crowd behavior in a video sequence using probability models of speeds and directions. Thus, optical flow is used to extract velocities at each image frame, which are then reduced to speed and motion orientations. Using expectation maximization algorithm, we construct a mixture model of von Mises distribution describing the set of directions, and a mixture model of normal distribution related to the speed set. Each frame is compared with a collection of reference frames using distance of probability densities. This distance is then used to indicate changes in the crowd motion. Unlike the speed based detection, using the direction model is not yet adapted to the case of unstructured crowds. The proposed method was tested on various publicly available crowd datasets.'}\n","{'text': \"This paper discusses a novel approach to medical augmented reality through the use of fluorescence and color feature-based image registration. The method involves capturing multiple imaging modalities, such as reflectivity and fluorescence, and performing image color analysis for feature extraction. Signal processing algorithms are then used to register these images based on their color features, allowing for accurate overlaying of different modalities in the context of an augmented reality system. This approach has the potential to greatly improve medical visualization and diagnosis by providing a more comprehensive view of the patient's condition.\"}\n","{'text': 'Hospitality and tourism industry websites attract a lot of customers that book hotels on a regular basis. The modern trend to book hotels is through online websites due to the convenience and discounts offered. When a customer visits a hotel they usually post a positive or negative review about their experience on the respective booking website. Identifying maintenance related issues from these reviews is a major problem that even most large hotel chains face. There are many applications for customers related to that area (such as hotel aggregators) but there are only a very few applications for the hotel management to improve their workflow and provide a better service to the customers. This research is to explore a method to analyze hotel reviews and extract maintenance related problems and present them in a user-friendly manner for the hotel management to take the necessary action. It explores the use of machine learning techniques such as binary classifiers, multiclass classifiers along with natural language processing techniques such as sentiment analysis to extract maintenance related issues from text and categorize the issues. A publicly available data source of reviews was used to test and the results show that the SVM classifier performs best for both cases.'}\n","{'text': 'The behavior of APT attack has been the hot topic in recent network security study. It is critical to understand the implementation principle of APT attack. In this paper, we analyze the behavior of APT attack in the Ngay campaign from two aspects: network traffic and code implementation. We first set up the attack chain by using network traffic analysis. Then, the vulnerability exploitation process is detailed through reverse code analysis. After that, we illustrate the process of building back door. Lastly, we introduce the obfuscation technology applied in the APT malware samples.'}\n","{'text': 'This paper focuses on the decentralized control problem of multi-agent systems with multiple control objectives, including target tracking, velocity synchronization, collision avoidance, and obstacle avoidance. To enable the real-time application and optimization, a control scheme is constructed based on the idea of adaptive dynamic programming (ADP). The cost function is defined according to the control objectives and approximated by a critic neural network. An action neural network is applied to approximate the optimal controller, which is achieved by minimizing the cost function. Based on the deduced weight updating laws, the proposed control scheme can learn online with good adaptability to unknown environment. Finally, a simulation of seven agents moving in two-obstacle environment is conducted to show the validity of the intelligent controller.'}\n","{'text': 'In this paper, we present a student project dedicated to the Internet of Things (IoT). The objective is to design and deploy a network of connected devices using LoRa technology to monitor the 20.000 m2 of our engineering school, ENSEIRB-MATMECA. Supervising the school using connected device came to the requirements to control our energy consumption. We choose a deployment in LoRa technology (open model compared to Sigfox) in order to master the deployment of the network from the beginning to the end. Modtronix LoRa modules inAIR9 and inAIR4 operating respectively in the 868MHz and 433MHz frequency bands were used as key components. There are 3 main blocks: sensor, gateway and server. All three are fully designed in the scope of this project by a team composed of 18 students.'}\n","{'text': 'This paper discusses kernel LMS-based estimation techniques for radar systems, focusing specifically on the use of OFDM modulation and the estimation of radar cross-sections, delays, and Doppler radar. The kernel method is shown to be effective in addressing the issues of sparsity and nonlinearity that can arise in radar signal processing, and it can produce accurate estimates even for signals with low SNR. The authors demonstrate the effectiveness of the approach using simulations and experiments, with results showing that the kernel LMS-based estimator outperformed other methods in terms of accuracy, speed, and robustness. The paper concludes that kernel-based techniques have great potential for further advancing radar systems and could provide significant benefits in a range of applications.'}\n","{'text': 'Deep learning-based methods, especially deep convolutional neural networks (CNNs), have shown their effectiveness for hyperspectral image (HSI) classification. In previous deep CNN-based HSI classification methods, a cuboid is empirically determined as the input. The dimensionalities of the cuboid, including height and weight, are crucial to the final classification results. Unfortunately, these superparameters (i.e., the dimensionalities of input cube) are hand-crafted, which means the inputs of a classifier are not optimized according to the specific hyperspectral dataset. In this letter, spatial transformation network (STN) is explored to obtain the optimal input for CNN-based HSI classification for the first time. STN is used to translate, rotate, and scale the original input to obtain optimized input for the following CNN. Moreover, in order to mitigate the overfitting problem in CNN-based HSI classification, DropBlock is introduced as a regularization technique for HSI accurate classification. Compared with dropout, which is a popular regularization technique, DropBlock obtains better classification accuracy. The proposed methods are tested on two widely used hyperspectral data sets (i.e., Salinas and Kennedy Space Center). The obtained experimental results show that the proposed methods provide competitive results compared with state-of-the-art methods including deep CNN-based methods.'}\n","{'text': 'Human behavior recognition is a popular research area in the field of computer vision and has been studied due to its important applications such as visual surveillance and video retrieval. In this paper, we propose a new approach for recognizing human-object interaction actions based on multitask 2D convolutional neural network, which combines human body motion, human hand motion and object recognition network. By using RGBD camera and digital gloves, refined recognition of human body and hand movements are collected and learned. In addition, a new object recognition network based on YOLOv3 is introduced which increases the accuracy of predicting human-object interaction labels. We designed eight representative actions and built our own data set containing body and accurate hand motions. In our experiment, the accuracy of recognizing interactive actions reached 93%, which shows the correctness and effectiveness of the multitasking framework we propose.'}\n","{'text': 'When taking pictures in a low-light scene with artificial lighting, we often encounter the following problem: we can use short exposure setting which yields a dim, noise image but with a sharp outline, or we can use a longer exposure setting which yields a bright, saturated image but with blurred areas. In many cases, none of those images is good enough. Good brightness and color information are retained in longer-exposure images, whereas sharp outlines are retained in shorter ones. In this paper, we present a patch-based method to combine such image pair into a better one. In our method, we firstly perform a coarse-to-fine strategy to detect inconsistent pixels caused by moving objects, then we draw information from the two exposures based on a novel patch-based technique. Experimental results show that the proposed method effectively preserves sharp edges of the short-exposure image, and maintains the color, brightness, and details of the long-exposure image.'}\n","{'text': 'Facial expression recognition plays a vital role in several domains, such as human-computer interaction, psychology, and physiology. However, accurately recognizing facial expressions poses challenges due to the complex geometric and appearance variations of the human face. This paper proposes a discriminative attention-based convolutional neural network for 3D facial expression recognition. The network employs a dense block with a squeeze-and-excitation attention mechanism for feature extraction, followed by global average pooling and fully connected layers for classification. Furthermore, a 3D face modeling technique using the 3D face shape and texture information is utilized as input. Experimental results demonstrate that the proposed method achieves state-of-the-art performance in 3D facial expression recognition on the CK+ and Oulu-CASIA datasets. These results suggest that the proposed method can be applied in various domains such as three-dimensional displays, solid modeling, and face recognition.'}\n","{'text': 'Due to their high spatial resolution, thin-section magnetic resonance (MR) images serve as ideal medical images for brain structure investigation and brain surgery navigation. However, compared with the clinically widely used thick-section MR images, thin-section MR images are less available due to the imaging cost. Thin-section MR images of infants are even scarcer but are quite valuable for the study of human brain development. Therefore, we propose a method for the reconstruction of thin-section MR images from thick-section images. A two-stage reconstruction framework based on generative adversarial networks (GANs) and a convolutional neural network (CNN) is proposed to reconstruct thin-section MR images from thick-section images in the axial and sagittal planes. A 3D-Y-Net-GAN is first proposed to fuse MR images from the axial and sagittal planes and to achieve the first-stage thin-section reconstruction. A 3D-DenseU-Net followed by a stack of enhanced residual blocks is then proposed to provide further detail recalibrations and structural corrections in the sagittal plane. In this method, a comprehensive loss function is also proposed to help the networks capture more structural details. The reconstruction performance of the proposed method is compared with bicubic interpolation, sparse representation, and 3D-SRU-Net. Cross-validation based on 35 cases and independent testing based on two datasets with totally 114 cases reveal that, compared with the other three methods, the proposed method provides an average 23.5% improvement in peak signal-to-noise ratio (PSNR), 90.5% improvement in structural similarity (SSIM), and 21.5% improvement in normalized mutual information (NMI). The quantitative evaluation and visual inspection demonstrate that our proposed method outperforms those methods by reconstructing more realistic results with better structural details.'}\n","{'text': 'This paper presents a new neural network methodology to identify low frequency oscillation modes in power systems. We use fast Fourier transform for order selection and design a neural network that adheres to the exponentially damped sinusoidal model of low frequency oscillation signals. We thus turn the parameter estimation into an optimization problem. Simulations show that the proposed approach is superior to the state-of-art neural network schemes in anti-noise ability, parameter accuracy and computation speed.'}\n","{'text': 'The motion compensation (MOCO) for the airborne SAR with ultrahigh resolution and wide swath is required to consider the range-dependent (RD) phase error. The RD phase error may cause an RD residual-range cell migration (RCM) after the correction of RCM, which can degrade the performance of phase gradient autofocus (PGA) when estimating the phase error. In addition, because the PGA estimation is based on the strong scattering point, it may wrongly estimate the phase error for some observation scenes without strong scattering point. Alternatively, to take into account the above two problems, we study a MOCO algorithm based on two-step accuracy improvement. In the algorithm, the first step is to estimate and correct the RD residual-RCM and thus improves the accuracy of PGA. The second step is to develop a prior-information-based-weighted least square (PI-WLS) to further improve the accuracy of RD phase error estimation. Processing of airborne real data validates the effectiveness of the proposed algorithm.'}\n","{'text': 'To estimate the level of 10kV distribution network line losses more integrally and precisely, an evaluation method based on BP neural network (BPNN) improved by particle swarm optimization (PSO) has been proposed. Making full use of existing data resources in the State Grid Corporation of China, the relevant information in the process of10 kV distribution network line and line loss has been collected and integrated, to formulate the power grid equipment data and operation data in the process of power distribution and utilization. Firstly, the electrical characteristic indices have been selected and established to reflect the structure and operation state of 10kV distribution network. Secondly, the inertia weight and the acceleration coefficient of PSO have been dynamically adjusted so that the weights and biases of BPNN are searched more effectively. Then nonlinear relation between electrical characteristic indexes and line losses is fitted through the learning of training sample sets so as to predict the line losses of test sample sets. Finally, the PSO-BPNN is proved to be effective and proper through an actual 10kV distribution network sample data.'}\n","{'text': 'The widespread use of computer technology and large-scale integrated circuits has increased the performance of the system while also significantly increasing the complexity of the system. These systems with increasingly complex structures and levels may have many different working states, and the fault features are also characterized by high dimensionality, confounding, sparseness and the like. The change of working conditions will bring about the coupling relationship between faults and faults, faults and working conditions, which will inevitably lead to problems such as long test time, difficult diagnosis and high maintenance cost. Therefore, in view of the various effects that multi-case systems may bring to diagnostic tests, research was done based on multi-case identification and random forest fault diagnosis methods. By coding the working condition information, establishing an extended decision tree, and finally establishing a random forest model, the fault diagnosis of the multi-case system is carried out. Finally, the PSpice simulation software is used to switch the case conditions and fault injection, collect and organize related the data, in turn, apply the case study to the above multi-case related research methods, and compare and analyze several methods. The results verify the effectiveness of the proposed method.'}\n","{'text': 'This paper presents an analysis of electrical power quality in the context of under voltage load shedding (UVLS) with the support of a battery energy storage system (BESS) in Brazil. Load modeling and power quality analysis were performed through computational and integrated circuit modeling, obtaining a set of indexes related to reactive power and voltages. The use of BESS showed improvements in power system stability and increased supply capacity during load shedding events. The analysis also demonstrated the benefits of using batteries to smooth out fluctuations in power supply, decreasing the impact of voltage sags and enhancing power factor correction. The findings of this study contribute to the development of more efficient and reliable power systems, particularly in regions with high demand and variable energy sources.'}\n","{'text': 'The joint coherent demodulation of low earth orbit satellite communication ASIC plays a crucial role in achieving high-quality communication performance. One of the key challenges in this field is frequency estimation and synchronization, which are essential for demodulation and error correction. This paper proposes a computing resource multiplexed carrier synchronization joint coherent demodulation approach that uses advanced estimation algorithms to compensate for the Doppler effect and other signal distortions caused by the motion of satellites. With this method, the ASIC can accurately estimate and synchronize the signal frequency, phase, and timing parameters, which improves the overall demodulation performance. Experimental results demonstrate that the proposed approach achieves better performance than existing methods for signal estimation and demodulation. The research presented in this paper is significant for the development of low earth orbit satellite communication and provides new insights into the design and optimization of satellite communication ASICs.'}\n","{'text': 'Streaming services have become increasingly popular in recent years, causing an upsurge in video traffic. The continuing upsurge will put enormous stress on existing network infrastructures. This has motivated researchers to find innovative solutions to address this challenge. Proactive content caching at the network edge is considered one such innovative solution, which can reduce backhaul congestion during evening peak hours. Consequently, researchers have introduced numerous approaches to cache content at the network edge. While the focus so far is on reducing the congestion, security issues in relation to content breach at caching nodes have not been adequately addressed so far. Content storage units at the network edge are more vulnerable to malicious attacks, and the loss incurred in this process can be significant. In this paper, we introduce a security aware caching technique to reduce the amount of potential loss caused by security attacks. We investigate the trade-off between the savings achieved from the implementation of proactive caching at caching nodes and the probable loss caused by security attacks. We model the research question as an optimization problem, and provide an optimal solution, which selects the suitable content to be cached at the most suitable nodes so that the loss caused by content breach becomes marginal. Simulation results show that our proposed technique significantly minimizes the loss caused by security attacks.'}\n","{'text': 'The detection of non-technical losses (NTL) is a very important economic issue for power utilities. Diverse machine learning strategies have been proposed to support electric power companies tackling this problem. Methods performance is often measured using standard cost-insensitive metrics, such as the accuracy, true positive ratio, AUC, or F1. In contrast, we propose to design a NTL detection solution that maximizes the effective economic return. To that end, both the income recovered and the inspection cost are considered. Furthermore, the proposed framework can be used to design the infrastructure of the division in charge of performing customers inspections. Then, assisting not only short term decisions, e.g., which customer should be inspected first, but also the elaboration of long term strategies, e.g., planning of NTL company budget. The problem is formulated in a Bayesian risk framework. Experimental validation is presented using a large dataset of real users from the Uruguayan utility. The results obtained show that the proposed method can boost companies profit and provide a highly efficient and realistic countermeasure to NTL. Moreover, the proposed pipeline is general and can be easily adapted to other practical problems.'}\n","{'text': 'This work consists of evaluating the main technologies of wireless communications of new generation oriented to their use and implementation in rural areas in order to obtain data on what technologies are the most appropriate based on a specific scenario characterized by a network of sensors. A previous classification of the technologies in two categories is made based on the scope in terms of distance they can provide. From this, scores are defined for each parameter compared based on factors and priorities obtained from qualitative indicators, and taking into consideration its use and functionality with satellite backhaul.'}\n","{'text': \"This paper presents an automated process for end-to-end embedded system design following OMG's model driven architecture (MDA) vision. It tackles a major challenge in automation: bridging the large semantic gap between the specification and the target code. The shown MDA adaption proposes an uniform and systematic way by splitting the translation process into multiple layers and introducing design platform independent and implementation independent views.In our adaption of MDA, we start with a formalized specification and we end with code (view) generation. The code is then compiled (software) or synthesized (hardware) and finally assembled to the embedded system design. We split the translation process in Model-of-Thing (MoT), Model-of-Design (MoD) and Model-of-View (MoV) layers. MoTs represent the formalized specification, MoDs contain the implementation architecture in a view independent way, and MoVs are implementation dependent and view dependent, i.e., specific details in target language.MoT is translated to MoD, MoD is translated to MoV and MoV is finally used to generate views. The translation between the Models is based on templates, that reflect design and coding blueprints. The final step of the view generation is itself part of generation. The Model MoV and the unparse method are generated from a view language description.The approach has been successfully adapted for generating digital hardware (RTL), properties for verification (SVA), and snippets of firmware that have been successfully synthesized to an FPGA.\"}\n","{'text': 'Low-voltage, high-frequency gyrotrons with hundreds watts of power are useful in magnetic resonance spectroscopy and plasma diagnostic applications. In this paper, a 10 kV, 478 W, 250 GHz gyrotron with efficiency near 40% and pitch ratio of 1.5 was designed through linear and nonlinear numerical analysis and Vsim particle-in-cell (PIC) simulation. Vsim is a highly efficient parallel PIC code, but it has seldom been used to carry out electron beam wave interaction simulations of gyro-devices. The setting up of the parameters required for the Vsim simulations of the gyrotron is presented. The results of Vsim simulations agree well with that of nonlinear numerical calculation.'}\n","{'text': 'Vision-based navigation can be classified primarily into relative and absolute navigation. Absolute navigation can estimate stable position solution of the vehicle. However, the performance of the feature detection algorithm greatly varies depending on the environment, and the matching accuracy may not be guaranteed. This represents navigation accuracy and can lead to serious navigation errors if an appropriate feature detector is not used. Therefore, in this study, we propose an algorithm that uses optimized feature information detector through frequency analysis of input image. To verify the performance of the proposed algorithm, we used the data obtained from flight experiments. The proposed algorithm prevents the occurrence of mismatching in flight experiments.'}\n","{'text': 'Orthogonal frequency-division multiplexing (OFDM) is a promising technology for communication systems. This paper investigates the impacts of unknown noise variance on the popular spectrum sensing scheme, i.e., energy detection, for OFDM cognitive radios over multipath fading channels. To study the effects of unknown parameters on the energy detector, a new maximum-likelihood estimation of noise and signal powers employing the cyclic prefix of OFDM is presented in this paper. The mean values and Cramer-Rao lower bounds of the estimation are obtained. Furthermore, the performances of the energy detector for both hypotheses, i.e., false-alarm rate and detection probability, under the influence of unknown noise variance are validated by both simulation and analytical results. The assessment on the required number of samples for the proposed energy detector is conducted, which indicates that an amount of 40-50% samples can be saved compared to the conventional energy detector.'}\n","{'text': 'Industrial gas leaks cause accidents and pose threats to the environment and human life. Thus, it is essential to detect gas leaks in time. Usually, the abnormal concentration signals are defined by a fixed concentration value, such as 25% of the lower explosive limit. However, it is difficult to accumulate to the fixed point quickly when the leak is small. In addition, the actual leak signals are seldom available, making many data classifications inoperable. To solve these problems, this paper proposes a detection approach using the auto-correlation function (ACF) of the normal concentration segment. The feature of each normal segment is obtained by calculating the correlation coefficients between ACFs. According to the features of statistical analysis, a nonconcentration threshold is determined to detect the real-time signals. In addition, the weighted fusion algorithm based on the distance between the sensors and virtual leak source is used to fuse multisensory data. The proposed method has been implemented in a field by building a wireless sensor network. It is confirmed that the system detection rate reaches as high as 96.7% and the average detection time delay is less than 30 s on the premise of low false alarm rate.'}\n","{'text': 'In long-term evolution (LTE) systems, there is an option to extend the size of the cyclic-prefix (CP) when the propagation environment is characterized by severe time dispersion. Such a peculiar feature makes the system more resilient against multipath distortions, but inevitably complicates the downlink synchronization task, which cannot be accomplished through conventional techniques devised for a specified CP size. In this paper, we study the problem of CP length detection in the LTE downlink in the presence of a timing uncertainty and frequency offset. In contrast to previous investigations based on heuristic arguments, our approach relies on the maximum likelihood (ML) estimation criterion. Furthermore, it accounts for the irregular LTE symbol (characterized by a different CP size), which is present in the normal CP operation mode. The resulting scheme operates in the time-domain and computes a different metric for each possible position of the irregular symbol within the observation window. Due to its flexibility, the proposed ML approach can be applied to any future multicarrier standard for the design of a CP length detection algorithm, either in the presence or in the absence of irregular symbols.'}\n","{'text': 'The reliability of a wireless sensor network (WSN) is often assessed on node-to-node communication performance through link characterization. Long-term routing stability is an aspect of a WSN that is often overlooked in routing protocol implementations. In this paper, we investigate the routing stability of ZigBee PRO implemented WSN nodes that are deployed in a real-world environment. Frequent changes in next hops along routing paths between source and destination nodes can result in an increase in undesired energy consumption of the WSN. Hence, the relative routing path usage count, usage rate of unique next hop and switching frequency count are proposed as routing stability indicators. Our findings show that routing stability is subjected to not only the quality of a link but also to the implemented routing protocols, deployed environment and routing options available. More importantly, next hops with low usage rates are shown to experience a higher probability of disconnection from the Neighbor Table of respective source nodes, causing them to be short-lived. The need to avoid these links shows the importance of evaluating routing stability and identifying network bottlenecks.'}\n","{'text': 'The internet of Things (IoT) architecture was originally envisaged as a two-layer technical platform, with sensors collecting data at the edge with minimal compute requirements, solely to prepare and transporting the data to a centralized or cloud based infrastructure for processing. This model is suitable in some scenarios, for example where data is being stored for historical, regulatory or trending usage however in other use cases such as health monitoring for acute illness or autonomous vehicle computer vision the latency in transporting this data to a remote location for processing may cause latencies that would seriously affect performance of the application. There are many different and sometimes overlapping definitions of IoT topologies being discussed within industry. This paper reviews this original topology of an IoT solution, and different techniques and layers available to alleviate the issues inherent of the original paradigm, and how a new method of defining at these topologies is gaining speed.'}\n","{'text': 'Network coding is a promising technique in the field of Information Theory used to improve performance of communication networks. Several benefits related to energy savings or increase throughput have been reported in different areas when network coding is used. This paper presents a dynamic network coding approach for a collaborative multisource system. Peer-to-peer paradigm is used to build our collaborative network between nodes in a dynamic way. Peers are synchronized by a coordinator server, which is responsible for assigning dynamic roles to the nodes that are inside the system during the network coding process. Furthermore, multiple sources are created to synchronize nodes regarding the contents they share. Likewise, multiple sources are created to synchronize the nodes in terms of the contents shared by them.'}\n","{'text': 'Testing plays a crucial role in software development for ensuring quality. Mutation testing in general and higher order mutation in particular are the good techniques to evaluate the quality of test data, i.e. determining if test data can uncover errors. However, higher order mutation is often very costly because of huge number of generated mutants. In this work, we focus on reducing the cost of higher order mutation testing. We propose different strategies to combine first order mutants to generate less number of higher order mutants for a program under test, but keep the quality of generated mutants. The proposed strategies are experimented on a set of different programs and the results show the effectiveness in terms of number of generated mutants and mutation score.'}\n","{'text': 'Deep-learning technology proliferates in a wide spectrum of applications. Modern communications applications require innovative solutions that can deliver near optimum performance in diverse and evolving environments. This paper proposes several substantial simplifications to deep-learning networks applied to the decoding of linear block codes. All proposed techniques reduce computational and interconnection complexity required for the inference in a deep-learning network over prior art. The proposed techniques build on inducing or exploiting sparsity in the trained network. Complexity savings of 60% to more than 80% are achieved without any practical degradation on decoding performance, quantified as coding gain.'}\n","{'text': 'In recent years, the demand for high-resolution Earth observation data has increased, leading to an oversubscription of targets for multiple agile Earth observation satellites. In order to efficiently schedule observation tasks for these satellites, we propose the use of Complex Networks Theory to model the satellite system and develop approximation algorithms to optimize the scheduling of orbits. Our approach considers various factors such as satellite priorities, target visibility, and maneuverability, and aims to minimize the time required to complete all observation tasks while ensuring that each target is observed at least once within a predefined time frame. The proposed method has been tested on a real-world dataset and the results show that it can effectively schedule multiple agile Earth observation satellites for oversubscribed targets. This approach can assist in the efficient management of Earth Observing System data and contribute to the better understanding of our planet through the acquisition of high-quality Earth observation data.'}\n","{'text': 'Each company defines performance in a different way based on specific indicators in line with its strategic perspectives and tactical structure. In order to enhance the Performance Indicators, companies tend towards the use of multiple Information Systems such as ERP, WMS, APS, TMS or other similar existing systems to keep their exploitation under control. Supply chain Management is the heart of the modern corporation. The Internet of Things (IoT) is a revolution in the field of Information and Communication Technologies (ICT), with the aim of extracting, transferring, storing, processing and sharing the necessary information at every logistics activity. In addition, it is important to automatically communicate and share each operation related to the logistics flows to the actors involved for a better collaboration and interoperability improvement in the Supply Chain. In this paper, we give an approach of the IoT use in the Supply Chain Management to ensure the convenience of its activities and that it is thus collaborative and communicative'}\n","{'text': \"In recent years, the application of Massive Multiple-Input Multiple-Output (MIMO) communication systems has gained significant attention in the field of wireless communication. Training and channel estimation are critical aspects to ensure the proper functioning of such systems. However, the accuracy of the estimated channel deteriorates over time due to channel aging. This paper focuses on the uplink training process and channel estimation in Massive MIMO systems under channel aging. Specifically, the authors investigate the impact of channel aging on the performance of base stations and receivers in uplink training scenarios. The results reveal that channel aging may lead to a significant degradation in channel estimation accuracy, which can harm the data transmission rate and the overall system performance. Therefore, the authors propose an effective algorithm to mitigate the effects of channel aging in uplink training scenarios. The proposed algorithm helps to maintain the accuracy of the channel estimation, enhance the overall system performance, and overcome the challenges associated with Massive MIMO systems' aging channels.\"}\n","{'text': 'The problem on loss free burst transmission has been well studied in Burst Switching Networks (BSN). There are number of approaches discussed for the performance development, but suffers to achieve higher performance. To overcome the issue, an burst rate based dynamic IO Queue management scheme has been presented. The method monitors the incoming burst traffic from more number of nodes and according to the rate of burst coming, the input output queue systems has been modified for their size. The burst in the queue system has been routed through available routes whenever identified. The method is capable of triggering the IO queue systems up and down according to the burst traffic. The proposed method improves the performance of burst switching networks.'}\n","{'text': 'This article delves into the development and usage of a speech emotion recognition system. The system is trained in Czech emotionally coloured speech. The output of the system is the evaluation one of the four emotional states. To achieve this, a multi-classifier with three sub-classifiers is employed, whose results are fused together using the Bayes Believe rule. The proposed system was deployed in the Secure Mobile Communication Infrastructure developed for the Czech Republic Security Components.'}\n","{'text': 'This chapter discusses techniques to estimate parameters and their accuracies. It studies two types of parameter estimation: maximum likelihood (ML) and linear regression (LR). Their accuracy and how they relate to graphical analysis are included. The relation of parameter estimation to graphical analysis is elaborated for the Weibull distribution, the exponential distribution, and the normal distribution. The chapter discusses the general aspects of parameter estimation and some characteristics of estimators in greater depth, with additional focus on the asymptotic behaviour of estimated parameters and their moments. The ML estimator is explained for both the uncensored case and the censored case. The LR estimator works with ranked plotting positions quite similar to graphical analysis with parametric plots. The chapter discusses the adjusted ranking method and the adjusted plotting position method for manipulating the ranked plotting positions.'}\n","{'text': 'This paper presents low-power and low-energy 8T dual-port SRAM with a novel MSB-based (most-significant-bit-based) inversion logic for an image processor such a deep-learning processor. Our proposed SRAM is suitable for real-time and low-power image processing, in which data have statistical correlation and data bit reordering are exploited. The proposed MSB-based inversion logic eliminates an additional flag bit in a majority logic; the MSB digit in an input datum judges whether or not to invert the datum. Thus, the area overhead of 12.5% for the 8-bit conventional majority logic is dramatically saved. The area overhead of the proposed SRAM is merely 0.6% for the MSB-based inversion logic. We verified that, with the proposed technique, 14.76% of total energy can be saved in a 28-nm 64-kb FD-SOI SRAM when a set of images are read out. Furthermore, the saving factor is extended to 17.31% when image processing in the VGG-F convolutional neural network (CNN) is considered, where 304.81 fJ/cycle in the read operation is achieved.'}\n","{'text': 'Mitotic detection and counting are the primary diagnostic factors used for cancer detection and grading. In this paper, we introduce a method of automatically obtaining masks for the cells and using the generated masks for mitotic detection. In the first stage of processing, we use the Mask R-CNN network to obtain the masks for the cells and also classify the cells with a high recall and low precision. These cells detected in the first stage are further processed in a second stage to eliminate false positives. In the second stage the cell candidates are classified as mitotic or non-mitotic using a combination of hand-crafted features and features obtained from a deep convolutional neural network pre-trained on ImageNet. We have evaluated our method on the public ICPR 2012 and ICPR 2014 mitosis datasets and obtained improved performance over fully-supervised segmentation methods and also those using a combination of hand-crafted and learned deep features. We also show that masks learned from the small ICPR 2012 dataset can be effectively transferred to the ICPR 2014 dataset, which does not provide cell mask annotations.'}\n","{'text': 'This paper addresses the problem of predicting the success of motion pictures using various machine learning algorithms and comparing their performance. The study focuses on the correlation between the success of movies and factors such as social networking, computational modeling, and prediction algorithms. The machine learning algorithms used in the study are trained and tested on a dataset of previously released movies. Results from the experiment show that machine learning algorithms are effective in predicting the success of movies. Furthermore, the performance of different machine learning algorithms is compared in terms of their accuracy, precision, and recall. Overall, the study provides insight into the potential of machine learning algorithms for predicting the success of motion pictures and highlights the importance of choosing the most suitable algorithm for a given problem.'}\n","{'text': 'Process capability indices (PCIs) are employed to select an appropriate supplier for customers. However, data fraud events may lead to incorrect decisions on quality management, it is more reliable to assess the manufacturing process capability based on supplied products. According to the quality requirement of the specification limits, the quality data of supplied products are doubly truncated. Thus, process capability analysis from supplied products is adopted to evaluate the manufacturing process capability, supervise and check the quality data provided by suppliers. For this purpose, under normal assumption, EM algorithm is firstly adopted to estimate the unknown parameters of the quality distribution of supplied products. Then, a quantile-filling algorithm is proposed to convert the truncated data into the pseudo-complete data. Next, based on the pseudo-complete data, the interval estimation of PCIs is carried out by the generalized confidence interval method. Finally, a practical example is given to show the implement of the proposed method.'}\n","{'text': 'Facial expression recognition (FER) is central to the field of computational modeling of human behavior. The classic approach in FER is to focus on detecting specific features on the face, with the mouth being a particularly important one. However, recent research has shown that deep convolutional neural networks (CNNs) can surpass the performance of traditional feature-based methods. In this paper, we propose a new method for FER called Hybrid Inherited Feature Learning Network (HiNet), which combines information filters and CNNs. HiNet is able to achieve state-of-the-art performance on the challenging gold standard face dataset, demonstrating the effectiveness of our approach to facial expression recognition.'}\n","{'text': 'Codebook-based beamforming is used in millimeter wave communications to alleviate the difficulty of obtaining accurate channel state information (CSI) for large antenna arrays. However, the required codebook size is usually large thus codebook search becomes computationally prohibitive due to its exponential growth. To address this, we propose a direct search technique with the concept of tracking the strong beam stream based on the recently proposed global direct search (GDS) optimization method. Simulation results show that our beam training technique achieves a near-optimal performance (about 97% as that of the exhaustive search) at much lower complexity levels.'}\n","{'text': 'Wireless Sensor Network is one of the major areas in wireless communications which extend its application in military, security, internet and scientific purposes. For a network which has dynamically varying channel gain and random topology, selection of operating parameters which improves network performance is always a challenging task. Single channel MAC is generally used in statistical analysis, but providing multi channel MAC will improve the performance of the channel. Multichannel is available in 802.11b/g which operates at 3 different non overlapping channels. In this paper we implemented 802.11g multichannel MAC using NS-2.34 and compared the performance of the network with single channel MAC in terms of throughput, packet delivery ratio and throughput. The multichannel uses back off algorithm and switches between the 3 non overlapping channels whenever the contention window of distributed coordination function reaches the maximum threshold value and thus gives better performance.'}\n","{'text': 'Due to the vast demand for monitoring a structure or area in linear topology, linear sensor networks (LSNs) have recently attracted plenty of attention. Since sensor nodes are usually battery-powered, duty-cycling techniques have been widely studied to improve energy efficiency, which, however, introduces a significant issue known as sleep latency. Thereafter pipelined forwarding has been proposed in the literature as a promising way to alleviate this issue. This paper focuses on interference analysis for data collection services in a multihop LSN running a duty-cycling and pipelined-forwarding protocol, where multiple concurrent transmissions along a data collection path can severely interfere with each other. We first obtain the nodal distance distributions associated with all concurrent transmissions. Based on the obtained distance distributions and the path-loss model in an interference-limited environment, we analyze the distributions of signal-to-interference-plus-noise ratio (SINR) and link capacity. The obtained SINR distribution indicates the link outage probability at a given SINR threshold. By investigating the transmission which receives the strongest cumulative interference, our model can provide useful guidelines for duty cycle setting to achieve a desired network performance.'}\n","{'text': 'Performance-aware energy management is very important for scientific computing. Inspired by the roofline model, we studied the time performance model and energy consumption model of scientific computing applications. The influence of the number of active cores and CPU frequency to the performance and energy consumption is analyzed. Based on the characteristic of computing platform and scientific computing application, the policy of determining the optimal number of active cores and frequency is proposed. Using the DVFS and power states management API, the number of active cores and their frequencies are adjusted to acquire the optimal balance between performance and energy. The proposed method has been implemented and tested with the NAS Parallel Benchmark, UGKS, and Fluent. Experimental results show that the proposed method can accurately estimate the number of optimal active cores and frequency for scientific applications and the average error of CPU power model is about 7%. Compared with the optimal performance resource allocation, the energy and performance balanced method can save 24.5% energy and just 9.8% performance degradation.'}\n","{'text': 'This paper proposes a single method for diagnosing multiple faults in regenerative PMSM (permanent magnet synchronous motor) drives, including IGBT (insulated gate bipolar transistors), current and speed sensors. The method utilizes observers for fault detection and diagnosis, and incorporates computational modeling and adaptation models for achieving robustness and adaptability. The proposed method is able to diagnose faults in both the IGBT switches and the rotor circuit, and can handle multiple faults occurring simultaneously. The effectiveness of the method is verified through simulations, and it demonstrates that the proposed method can accurately diagnose faults in PMSM drives, providing a valuable tool for improving the reliability and safety of electric motor systems.'}\n","{'text': 'This paper proposes an architecture for real-time LED flicker detection and mitigation implemented on a Field Programmable Gate Array (FPGA). LED technology has rapidly advanced over the years, making it a popular choice for lighting in various applications. However, LED lighting can produce flicker that is not visible to the naked eye but can cause serious negative health effects. The proposed architecture utilizes hardware for motion estimation and random access memory for data storage. Additionally, the system is designed to detect and mitigate flicker in real-time, making it suitable for use in various real-time systems. The FPGA implementation allows for flexibility and customization to meet specific needs. This paper presents a comprehensive solution for real-time LED flicker detection and mitigation that effectively addresses the challenges of flicker in LED lighting, and provides insights into the potential of FPGA-based integrated optics systems for this application.'}\n","{'text': \"Demand response (DR) is essential to managing the increasing charging load caused by the growing deployment of electric vehicles (EVs). However, traditional DR studies that use model predictive control face difficulties in coping with the uncertainty of EV scenarios, such as unpredictable customer behavior. Model-free approaches, based on reinforcement learning (RL), are an attractive alternative. We propose a new Markov decision process (MDP) formulation in the RL framework, to jointly coordinate a set of charging stations. Unlike current state-of-the-art algorithms that focus on controlling either a single EV or an aggregate of EVs separately, our RL approach offers a unique solution that controls the entire set of EVs at once. We present a new MDP formulation that offers a scalable state representation that's independent of the number of charging stations. We contribute a new MDP formulation with a scalable state representation independent of the number of charging stations. With real-world data, we conduct simulations that 1) explore different training settings, 2) compare the approach's performance to an all-knowing benchmark, which sets the upper performance bound, 3) analyze the fluctuations in its performance throughout a full year, and 4) demonstrate its generalization capabilities to larger sets of charging stations. Our approach offers a more holistic and scalable approach to EV charging optimization, making it a promising solution for managing the ever-increasing EV charging load.\"}\n","{'text': 'Music emotion recognition, which enables effective and efficient music organization and retrieval, is a challenging subject in the field of music information retrieval. In this paper, we propose a new bidirectional convolutional recurrent sparse network (BCRSN) for music emotion recognition based on convolutional neural networks and recurrent neural networks. Our model adaptively learns the sequential-information-included affect-salient features (SII-ASF) from the 2-D timeâ\\x80\\x93frequency representation (i.e., spectrogram) of music audio signals. By combining feature extraction, ASF selection, and emotion prediction, the BCRSN can achieve continuous emotion prediction of audio files. To reduce the high computational complexity caused by the numerical-type ground truth, we propose a weighted hybrid binary representation (WHBR) method that converts the regression prediction process into a weighted combination of multiple binary classification problems. We test our method on two benchmark databases, that is, the Database for Emotional Analysis in Music and MoodSwings Turk. The results show that the WHBR method can greatly reduce the training time and improve the prediction accuracy. The extracted SII-ASF is robust to genre, timbre, and noise variation and is sensitive to emotion. It achieves significant improvement compared to the best performing feature sets in MediaEval 2015. Meanwhile, extensive experiments demonstrate that the proposed method outperforms the state-of-the-art methods.'}\n","{'text': \"The exponential growth of multimodal content in today's competitive business environment leads to a huge volume of unstructured data. Unstructured big data has no particular format or structure and can be in any form, such as text, audio, images, and video. In this paper, we address the challenges of emotion and sentiment modeling due to unstructured big data with different modalities. We first include an up-to-date review on emotion and sentiment modeling including the state-of-the-art techniques. We then propose a new architecture of multimodal emotion and sentiment modeling for big data. The proposed architecture consists of five essential modules: data collection module, multimodal data aggregation module, multimodal data feature extraction module, fusion and decision module, and application module. Novel feature extraction techniques called the divide-and-conquer principal component analysis (Div-ConPCA) and the divide-and-conquer linear discriminant analysis (Div-ConLDA) are proposed for the multimodal data feature extraction module in the architecture. The experiments on a multicore machine architecture are performed to validate the performance of the proposed techniques.\"}\n","{'text': 'Inter-subject variability in brain signals can significantly impact the accuracy of brain-computer interface (BCI) systems. Every subject has different brain signals; also, the performance of a subject varies widely between sessions, within a session, between on-line and off-line settings, and even from epoch to epoch. Such variabilities arise in measurements obtained during different BCI sessions require subject and session specific decoder models. This work proposes three different deep learning models for subject-independent decoding of event-related potentials in electroencephalographic signals: (1) shallow convolutional neural network, (2) gated recurrent neural network, and (3) CNN-RNN-Net: a hybrid one-dimensional convolution and a gated recurrent unit model. Experimental results show that the proposed models outperform conventional baseline models in decoding subject-independent data. Moreover, among the three models, the CNN-RNN-Net has shown improved classification results.'}\n","{'text': 'This elaboration presents the method of obtaining experimental data for the neural network training process. A family of data and the initial conditions were obtained by the stabilization experiment of the levitating sphere and by a short-term control. On the basis of these data, a structure of the feedback network was developed. The nonlinear autoregresive neural network realizes the task of the velocity estimation of the levitating sphere. The structure of the neural network was assessed and then applied in real time to the stabilization task. The results of experiments were compared with two different methods of a velocity estimation.'}\n","{'text': 'This paper presents a framework for incorporating four-valued logic into UML/OCL models, providing a \"playground\" for the MVL community. The proposed approach is based on the use of sets of truth values and introduces a new type of inference rule that allows the reasoning about incomplete or uncertain knowledge in the context of UML/OCL modeling. The framework is evaluated through several case studies, including a task analysis model and a parallel processing application. The use of virtualization and computational modeling techniques is also explored, emphasizing the importance of resource management in such systems. Overall, this paper provides important insights into the practical applications of four-valued logic and its potential impact on software engineering and related fields.'}\n","{'text': 'In order to carry out high-precision and low-cost infection screening, our group is working on the development of a contactless infection screening system using multiple vital signs detected from a microwave sensor. This study focuses on the extraction of respiration and heart beat signals with high accuracy through sensor signal processing, as well as the construction of a machine learning model suitable for screening infectious diseases using Neural Network and SoftMax functions. To reduce the effect of respiration on heart rate measurements, we corrected the phase shift of the respiration signal and subtracted the respiratory component measured from the microwave sensor. The machine learning model of Neural Network was Logistic Regression using SoftMax function as an activation function. The proposed system was tested on a total of 158 subjects (79 normal subjects, 79 infected subjects), and we were able to determine not only whether the disease was infectious but also to express the probability of infection through the SoftMax function. Since the SoftMax function can provide a stochastic expression as output, it is now possible to not only determine whether the disease is an infectious one but also to express the probability of infection. We obtained a highly generalized training model by evaluating the generalization of the training model with the cross-entropy loss function and achieved a classification accuracy of 98%.'}\n","{'text': 'This paper presents a parallel crowd simulation based on power law, which is a computational modeling approach commonly used in complex systems. The simulation is driven by force and is based on solid modeling. By utilizing graphics processing units (GPUs) and optimizing the instruction sets, the simulation algorithm achieved significant speedup compared to the traditional CPU-based algorithm. Moreover, the simulation is implemented on a kernel architecture, which further improves the performance. The proposed parallel crowd simulation is validated through extensive experimentation and compared with existing methods. The results demonstrate the effectiveness and efficiency of the proposed approach in terms of both runtime and memory usage. Furthermore, the paper explores the potential application of this approach in microscopy and other related fields.'}\n","{'text': 'This article provides an introduction to the Special Issue on the 2018 IEEE Symposium on VLSI Circuitsâ\\x80\\x94Part II. The issue explores various topics related to very large scale integration (VLSI), including special issues and sections, meetings, and advancements in CMOS technology. One of the key areas of focus in this edition is the application of deep learning algorithms in VLSI design. Additionally, the issue features several papers on the development of photomultipliers, a key component in VLSI circuit design. Overall, the Special Issue on the 2018 IEEE Symposium on VLSI Circuitsâ\\x80\\x94Part II serves as a comprehensive resource for engineers and researchers interested in stayed up-to-date with the latest advancements in VLSI circuit design.'}\n","{'text': 'This paper proposes a business model for place time capacity based resource allocation in an aerial radio architecture. The focus is on wireless communication and the creation of ecosystems that enable the efficient allocation of resources based on pragmatic considerations. The goal is to leverage business intelligence to make informed decisions about resource allocation in an ad hoc network of aerial nodes. The proposed architecture uses millimeter wave communication to achieve high throughput and low latency. This approach presents a significant opportunity for companies to leverage aerial radio architecture for applications such as smart cities, transportation, and industrial communications. The business model provides a framework for companies to create sustainable revenue streams by leveraging the capacity of aerial nodes and intelligently allocating resources based on pragmatic considerations. The proposed model represents a significant advance in the development of wireless communication systems and provides a roadmap for companies seeking to create value in this rapidly evolving landscape.'}\n","{'text': 'A tracking controller design problem for the discrete-time uncertain systems is investigated in this paper. A discrete-time terminal sliding-mode tracking controller is designed to achieve high-performance tracking with alleviated chattering phenomenon. A novel reaching-law is proposed which reduces the bandwidth of the quasi-sliding-mode domain and suppresses the chattering. Furthermore, the reaching process and the bound of the tracking error are analyzed in detail. Finally, comparative experimental results are presented to illustrate the effectiveness and advantages of the proposed strategy.'}\n","{'text': 'The paper analyzes the state program of competitiveness improvement of Russian universities in the international arena. The objective of the program is to ensure that the top five Russian universities make it to the top 100 educational institutions in the world by 2020. The analysis of achievements of the Russian universities in the international ratings Quacquarelli Symonds, Times Higher Education and Academic Ranking of World Universities is carried out. Additionally, the study sheds light on the financial aspects of the program, specifically examining the financial indicators of each university from an investment perspective as well as its ranking position. Based on the findings of the research, the effectiveness of the state program is assessed, and the potential for achieving the set goals is evaluated.'}\n","{'text': 'Recently several deep learning approaches have been attempted to detect malware binaries using convolutional neural networks and stacked deep autoencoders. Although they have shown respectable performance on a large corpus of dataset, practical defense systems require precise detection during the malware outbreaks where only a handful of samples are available. This paper demonstrates the effectiveness of the latent representations obtained through the adversarial autoencoder for malware outbreak detection. Using instruction sequence distribution mapped to a semantic latent vector, the model provides a highly effective neural signature that helps detecting variants of a previously identified malware within a campaign mutated with minor functional upgrade, function shuffling, or slightly modified obfuscations. The method demonstrates how adversarial autoencoder can turn a multiclass classification task into a clustering problem when the sample set size is limited and the distribution is biased. The model performance is evaluated on OS X malware dataset against traditional machine learning models.'}\n","{'text': 'Internet of things (IoT) comprises is the system of physical devices, machines and different devices inserted with electronics, programming, sensors, Actuators, and interconnectivity that have unique identities and are connected to the internet. Traditionally the productivity of CNC was confined to the counts of the products produced. In Industrial Internet of Things the productivity can be measured with the help of predictive and prescriptive maintenance. This paper is focused on study of productivity using IoT platforms. A feasibility analysis was carried out with and without using a software platform designed to make manufacturing efficient and cost effective. Various factors affecting the productivity of CNC were explored. The predictive breakdowns during the manufacturing were calculated. Analysis was carried out to check for differences in Overall Equipment Efficiency (OEE) in traditional CNC and IoT enabled CNC. Finally it is observed that the OEE was increased for the CNC from 59.9% to 78.59%.'}\n","{'text': 'using the cloud technology with Smart Protect Network (SPN) to do file virus scanning. The overwhelming increase of population will lead to an increase network traffic usage. In most products, local cache mechanism is implemented for the purpose of reducing the network traffics. However, the database designed to store cache is limited, lot of times, cache will get purged when there are lots of queries sent and replaced by other newest queries. It is not an efficient by using traditional methodology to build or forming cache. In order to reduce the network traffic usage, the paper propose a solution, which utilize data mining technique with clustering concept, by gathering the current feedback data we have from our SPN, we are able to form these data in groups with similarity, and by deploying these data to client side, to achieve the reduction of traffic usage. In prototyping, this design for military communications can really reduce network traffic more than 20%. And the speed of file scanning time can faster more than 12%.'}\n","{'text': 'In this paper, an array of multiband Wi-Fi antenna using genetic algorithm (GA)is proposed and optimized. The two-element antenna array is designed and simulated using CST Microwave Studio. Details of the design, simulation results on return loss and gain of the antenna array is also presented. The proposed array increased the gain in both 5.2 GHz band and 5.8 GHz bands used for Wi-Fi communications.'}\n","{'text': 'This paper evaluates the classification of objects given their signal data via a simple convolutional neural network (CNN). Many of the signal processing neural networks involve sound frequency data or Doppler signatures that contain the characteristic features of each object. In this study, we use frequency-intensity data within range-time domain from a Frequency-Modulated Continuous-Wave (FMCW) radar to classify detected objects. The application of various data augmentation methods mitigated the scarcity of labeled data from our field experiments. Time stretching, frequency shifting and noise addition preserved the semantic information of each rangetime data, further improving the models ability to generalize. Modifications applied to our data, which is then converted into a low-level log-scaled mel-spectrogram representation, are learned by CNN models with a set of convolutional and max-pooling layers along with fully-connected layers and selective residual module. Based on our experiments, we conclude that raw radar data can be used for training CNNs for classification and thus can be used to classify a car, a human, and an UAV.'}\n","{'text': 'This paper describes a stress simulation analysis of electronic devices utilizing a cloud platform. The focus of the analysis is on vibrations and the use of analytical models for load and solid modeling. Additionally, three-dimensional displays are utilized for visualizing the results of the simulation. The finite element analysis and computational modeling techniques are used to further enhance the accuracy of the simulation. The results of the analysis provide valuable insight into the performance of electronic devices under varying levels of stress and can be used to improve their design and reliability. The use of a cloud platform allows for efficient and effective collaboration among multiple stakeholders involved in the design and testing process.'}\n","{'text': 'Use of mobile health (mHealth) systems has increased with the advancement and proliferation of mobile computing and related technologies. It has improved efficiency and effectiveness of healthcare services. Non-invasive pain level detection from facial images is one of the promising mHealth applications. Effective pain treatment requires regular and continuous pain assessment. Most of the pain research tools are study or disease specific while some are pain (lumbar pain, cancer pain, etc.) and patient group specific (neonatal, adult, woman, etc.). This results in recurrent but potentially avoidable costs such as time, money, and workforce to develop similar services or software research tools for each research study. In this study, we have proposed, designed, and implemented a customizable personalized pain study platform that offers real-time data collection, research participant management, role-based access control, research data anonymization etc. It is also used to investigate pain level detection accuracy using evidence-based continuous learning from the facial expression data, collected from Bangladesh, Nepal and USA, which yielded about 71% classification accuracy.'}\n","{'text': 'In this article, we delve into the crucial elements of building a national innovation system, centred on the generation and transfer of new technologies to industry. Universities possess significant scientific knowledge that can foster innovation, thus enterprises can partner with them to access novel technologies. After examining various forms of university-enterprise collaboration, we identified the most effective and promising options for their partnership. Particular attention was paid to cooperation in the development and promotion of innovation, because the technological development of the industry based on the development and implementation of new technologies. Based on the analysis, it was possible to make recommendations on creating an integrated system of interaction between basic science and industrial production, as a result, the demand for innovation will be satisfied.'}\n","{'text': 'Automated fabric defect detection is a critical task in the textile industry. Fabrics are inspected for defects during the weaving process to ensure high quality and prevent product defects. Due to the limitations of human inspectors, automation is necessary for efficiency and accuracy. Lighting plays a crucial role in fabric defect detection, as proper illumination is necessary to capture and classify defects. Feature extraction is another important aspect of automated defect detection, as it allows for the identification and comparison of different types of defects. Visualization techniques are also commonly used to aid in the identification and classification of defects. Overall, automated fabric defect detection has the potential to greatly improve efficiency and quality in the textile industry.'}\n","{'text': 'The Internet of Things (IoT) has revolutionized the way we interact with and utilize data. With the vast number of sensors and connected devices, it is essential to ensure that databases are performing optimally for IoT systems. This paper evaluates databases performance for IoT systems using the Scrovegni Chapel as a use case. The study focuses on analyzing the hardware requirements for databases, evaluating the performance of wireless sensor networks, and ensuring that Structured Query Language queries are executed efficiently. By analyzing these key factors, this study provides insights into the best practices for designing and implementing databases for IoT systems. It highlights the importance of ensuring that the hardware is capable of supporting the database workload and that the wireless sensor networks are designed to handle the data throughput effectively. Ultimately, this paper demonstrates the importance of rigorous performance evaluation when designing databases for IoT systems.'}\n","{'text': 'The recent evolution of mobile communication systems toward a 5G network is associated with the search for new types of non-orthogonal modulations such as sparse code multiple access (SCMA). Such modulations are proposed in response to demands for increasing the number of connected users. SCMA is a non-orthogonal multiple access technique that offers improved bit error rate performance and higher spectral efficiency than other comparable techniques, but these improvements come at the cost of complex decoders. There are many challenges in designing near-optimum high throughput SCMA decoders. This paper explores means to enhance the performance of SCMA decoders. To achieve this goal, various improvements to the MPA algorithms are proposed. They notably aim at adapting SCMA decoding to the single instruction multiple data paradigm. Approximate modeling of noise is performed to reduce the complexity of floating-point calculations. The effects of forwarding error corrections such as polar, turbo, and LDPC codes, as well as different ways of accessing memory and improving power efficiency of modified MPAs are investigated. The results show that the throughput of an SCMA decoder can be increased by 3.1 to 21 times when compared to the original MPA on different computing platforms using the suggested improvements.'}\n","{'text': 'In recent years, Distributed Ledger Technology (DLT) has been playing a more and more important role in building trust and security for Internet of Things (IoT). However, the unacceptable performance of the current mainstream DLT systems such as Bitcoin can hardly meet the efficiency and scalability requirements of IoT. In this paper, we propose a scalable transactive smart homes infrastructure by leveraging a Directed Acyclic Graph (DAG) based DLT and following the separation of concerns (SOC) design principle. Based on the proposed solution, an experiment with 40 Home Nodes is conducted to prove the concepts. From the results, we find that our solution provides a high transaction speed and scalability, as well as good performance on security and micropayment which are important in IoT settings. Then, we conduct an analysis and discuss how the new system breaks out the well-known Trilemma, which claims that it is hard for a DLT platform to simultaneously reach decentralization, scalability and security. Finally, we conclude that the proposed DAG-based distributed ledger is an effective solution for building an IoT infrastructure for smart communities.'}\n","{'text': 'Developing multi-biometric systems using multi-modal signals is the recent trend in biometric identification problem. Integrating heart and brain electrical signals (ECG and EEG) is very important because of their liveliness property and robustness against falsification. In this study, we have investigated the fusion of ECG and EEG signals from low-cost devices with multiple classifiers (KNN, LDA, and ESAVM) using wavelet domain statistical feature. After preprocessing, multiscale wavelet packet decomposition is applied to the signal (ECG/EEG) segment. Feature vectors are computed from the transformed signal using statistical descriptors, called wavelet packet statistics (WPS). ECG and EEG traits are fused at feature level, while two classifiers are fused at the decision level. An experiment with ten human subjects showed promising results of human identification using fused trait (ECG-EEG) with fused classifiers. The fused trait i.e., the fused WPS vectors from ECG and EEG signals with the fused classifier produces the highest average Fscore (90.5%), when compared with the single trait (ECG or EEG) with single classifier (54.7% with ECG; 74.9% with EEG) or single trait with fused classifier (66.0% with ECG; 87.3% with EEG). A brief ROC analysis also confirmed the above findings.'}\n","{'text': 'This paper presents a systematic literature review of Error Correction Codes (ECC) in Wireless Sensor Networks (WSN). WSN is a new paradigm in the field of wireless communication that consists of small, low-power, and autonomous devices that can sense, process, and communicate data wirelessly. However, due to the nature of wireless communication, data transmission is vulnerable to errors, which can occur during the transmission process. ECC is used to detect and correct these errors in WSN. Two types of ECC are used in WSN, namely parity check codes and convolutional codes. Parity check codes are commonly used in WSN for single-bit error correction, while convolutional codes are used for correcting burst errors. This paper also discusses the advantages and disadvantages of Forward Error Correction (FEC), which is a class of ECC that can correct errors without requiring feedback from the receiver. Overall, this literature review provides a comprehensive understanding of ECC in WSN, their applications, and their current research trends.'}\n","{'text': 'This paper proposes a layout-based dual-cell-aware test approach for detecting circuit faults, which takes into account both the layout and runtime effects of integrated circuits. The traditional method of solely relying on libraries and SPICE models for circuit testing is no longer effective. This new approach involves using computational modeling to simulate the behavior of the circuit under varying conditions, leading to more accurate and efficient testing. The study focuses on circuit faults that occur due to the presence of multiple cells in the layout, which can often go undetected. The results demonstrate the effectiveness of the proposed approach in detecting such faults. This study is crucial for improving the reliability and quality of integrated circuits and will have important implications for the design and optimization of future electronic systems.'}\n","{'text': 'Crowd management aims to develop support infrastructures that can effectively manage crowds at any time. In emergency and disruptive scenarios this concept can minimize the risk to human life and to the infrastructure. We propose the Communication Architecture for Crowd Management (CACROM), which can support crowd management under emergency and disruptive scenarios. We identify, describe, and discuss the various components of the proposed architecture, and we briefly discuss open challenges in the design of crowd management systems for emergency and disruptive scenarios.'}\n","{'text': 'DAO attack showed that formal verification of smart contracts is an important issue that should be addressed to prevent irreversible consequences due to design faults activation in Blockchain applications. This paper proposes a modeling method of an Ethereum application based on smart contracts, with the aim of applying a formal method, namely Model-Checking, to verify that the application implementation complies with its specification, formalized by a set of temporal logic propositions. NuSMV tool has been chosen to support this first approach. The proposed model template is shaped by three layers capturing respectively the behavior of Ethereum blockchain, the smart contracts themselves and the execution framework. The approach is illustrated by a case study coming from energy market field.'}\n","{'text': 'In order to ascertain the mechanical stability of composite materials that have production defects, it is important to classify these faults based on their size, depth, and shape. Radar-based systems can be used for non-contact and nondestructive measurements of composite materials and provide 3D tomographic images of the components. By using GaAs-based technologies the available bandwidth of 24 GHz in the millimeter-wave regime combined with a low-noise figure enable the detection of low-contrast flaws in glass-fiber reinforced plastics. It is shown that the location of wedges, made of epoxy, inside a glass fiber-reinforced plastic sample can be detected as well as orientation, shape, size, and impact to the adjacent fiber scrims can be determined by evaluating the phase information of the reflected signals.'}\n","{'text': 'The solution of large linear systems with multiple right-hand sides given simultaneously is required in many large-scale scientific and engineering applications modelled by either partial differential or boundary integral equations. In this paper we introduce variants of the block GMRES method that combine initial deflation and eigenvalue recycling strategies to remedy some typical convergence problems of block Krylov solvers.'}\n","{'text': 'As cloud computing continues to gain popularity, it has become increasingly important to evaluate the quality of Platform as a Service (PaaS) cloud applications. This paper proposes a new tool, called PaaSArch, for conducting quality evaluations using generated prototypes. The tool utilizes Unified Modeling Language (UML) to create prototypes that mimic the behavior of PaaS cloud applications. These prototypes can then be used to conduct benchmark testing and assess the performance and functionality of the software. By using PaaSArch, developers can quickly and easily evaluate the quality of their PaaS cloud applications, identify areas for improvement, and make necessary adjustments to ensure optimal performance. Overall, this tool represents a significant step forward in the field of cloud computing, and has the potential to greatly improve the quality and reliability of PaaS cloud applications going forward.'}\n","{'text': 'This paper presents a live demonstration of an autoencoder-based predictive maintenance system for Internet of Things (IoT) devices. The system is specifically designed for detecting anomalies in the vibrations of DC motors, which are frequently used in industrial processes. The system employs sensors to capture the vibrational data and applies feature extraction techniques to make the data suitable for analysis. The Field Programmable Gate Arrays (FPGAs) are then used to perform the anomaly detection task. The system utilizes the autoencoder algorithm for predictive maintenance, which is first trained on normal vibration data and then subsequently used to identify anomalies in the streaming data. Our live demonstration illustrates the effectiveness and reliability of the proposed system for predictive maintenance of industrial IoT devices.'}\n","{'text': 'Handwritten document recognition is an important task in optical character recognition software, which has been the subject of much research in recent years. In this paper, we propose a novel approach for Kannada handwritten document recognition using convolutional neural network. The proposed method involves feature extraction, character recognition using hidden Markov models, and a deep learning technique based on convolutional neural networks. Our results indicate that our method outperforms existing methods for Kannada handwritten document recognition, achieving a recognition rate of 97.4%. The proposed method has been presented at several conferences and has received positive feedback from the research community. In conclusion, this approach serves as a promising technique for Kannada handwritten document recognition, and has the potential to be applied in other domains as well.'}\n","{'text': \"Human activity recognition is a critical task in many applications such as healthcare, security, and robotics. Training deep learning models for activity recognition requires a large amount of labeled data, which can be a challenge to obtain. In this paper, we propose a semisupervised recurrent convolutional attention model for human activity recognition that can effectively leverage unlabeled data for training. Our model integrates semisupervised learning into the training process, allowing us to use both labeled and unlabeled data to improve the model's performance. The proposed model also combines recurrent and convolutional neural networks with an attention mechanism to capture the temporal and spatial aspects of activity data. We evaluate the proposed model on two public datasets, demonstrating its effectiveness in activity recognition. Our approach can potentially reduce the need for manual labeling, making it a promising method for training data models for activity recognition tasks.\"}\n","{'text': 'In mm-wave multiple antenna systems, accurate channel estimation is crucial for achieving high data rates. This paper proposes a low-rank channel estimation method using joint spatio-temporal covariance matrices. The method relies on estimating the covariance matrices of the received signals using antenna arrays and minimizing the rank of the estimated matrices. The proposed method also improves the accuracy of direction-of-arrival estimation, leading to better estimation of the signal to noise ratio. Simulation results show that the proposed method outperforms existing methods in terms of estimation accuracy and computational complexity. Overall, this paper presents a promising approach to channel estimation in mm-wave multiple antenna systems.'}\n","{'text': 'This paper presents a set-membership approach for the coordinated control of a fleet of UAVs aiming to search and track an a priori unknown number of targets spread over some delimited geographical area. The originality of the approach lies in the description of the perturbations and measurement uncertainties via bounded sets. A set-membership approach is used to address the localization and tracking problem. At each time step, sets guaranteed to contain the actual state of already localized targets are provided. A set containing the states of targets still to be discovered is also evaluated. These sets are then used to evaluate the control input to apply to the UAVs so as to minimize the estimation uncertainty at the next time step. Simulations considering several UAVs show that the proposed set-membership estimator and the associated control input optimization are able to provide good localization and tracking performance for multiple targets.'}\n","{'text': 'Finding the intersection of two subspaces is of great interest in many fields of signal processing. Over several decades, there have been numerous formulas discovered to solve this problem, among which the alternate projection method (APM) is the most popular one. However, APM suffers from high computational complexity, especially for real-time applications. Moreover, APM only gives the projection instead of the orthogonal basis of two given subspaces. This paper presents two alternate algorithms which have a closed form and reduced complexity as compared to the APM technique. Numerical simulations are conducted to verify the correctness and the effectiveness of the proposed methods.'}\n","{'text': 'Multi-source remote sensing imagery has become widely accessible owing to the development of data acquisition systems. In this paper, we address the challenging task of the semantic segmentation of buildings via multi-source remote sensing imagery with different spatial resolutions. Unlike previous works that mainly focused on optimizing the segmentation model, which did not enable the severe problems caused by the unaligned resolution between the training and testing data to be fundamentally solved, we propose to integrate SR techniques with the existing framework to enhance the segmentation performance. The feasibility of the proposed method was evaluated by utilizing representative multi-source study materials: high-resolution (HR) aerial and low-resolution (LR) panchromatic satellite imagery as the training and testing data, respectively. Instead of directly conducting building segmentation from the LR imagery by using the model trained using the HR imagery, the deep learning-based super-resolution (SR) model was first adopted to super-resolved LR imagery into SR space, which could mitigate the influence of the difference in resolution between the training and testing data. The experimental results obtained from the test area in Tokyo, Japan, demonstrate that the proposed SR-integrated method significantly outperforms that without SR, improving the Jaccard index and kappa by approximately 19.01% and 19.10%, respectively. The results confirmed that the proposed method is a viable tool for building semantic segmentation, especially when the resolution is unaligned.'}\n","{'text': 'Elastography produces images of mechanical properties of tissue such as elasticity, which is a clinically significant biomarker of different pathologies such as liver fibrosis and cancer. However, elastography reconstruction is a highly ill-conditioned problem that requires the use of spatial filtering and regularizers. These leads to results that depend on the filter parameters and on optimization problems that are not provably convergent to an optimal solution. We have formulated the 2D elasticity reconstruction as a bi-convex optimization problem with bi-affine equality constraints. We also proposed a solver using the alternating direction method of multipliers (ADMM) and total variation (TV) regularization. ADMM provides simple closed-form updates of the elasticity with one forward solution and one direct inversion and converges faster compared to other gradient-based methods. The proposed method does not require separate data filtering and provides better convergence and superior performance to other algorithms for both numerical and experimental data.'}\n","{'text': 'The memory physics induced unknown offset of the channel is a critical and difficult issue to be tackled for many non-volatile memories (NVMs). In this paper, we first propose novel neural network (NN) detectors by using the multilayer perceptron (MLP) network and the recurrent neural network (RNN), which can effectively tackle the unknown offset of the channel. However, compared with the conventional threshold detector, the NN detectors will incur a significant delay of the read latency and more power consumption. Therefore, we further propose a novel dynamic threshold detector (DTD), whose detection threshold can be derived based on the outputs of the proposed NN detectors. In this way, the NN-based detection only needs to be invoked when the error correction code (ECC) decoder fails, or periodically when the system is in the idle state. Thereafter, the threshold detector will still be adopted by using the adjusted detection threshold derived base on the outputs of the NN detector, until a further adjustment of the detection threshold is needed. Simulation results demonstrate that the proposed DTD based on the RNN detection can achieve the error performance of the optimum detector, without the prior knowledge of the channel.'}\n","{'text': 'This paper proposes a novel method for estimating chromatic dispersion (CD) in fiber optic communication systems using the auto-correlation of the signal power waveform. The proposed method takes into account optical polarization and optical crosstalk, and incorporates signal processing algorithms to accurately estimate CD in frequency modulated fibers (FMFs). The use of multiplexing techniques is explored to improve the accuracy of CD estimation, and the paper presents simulation results to demonstrate the effectiveness of the proposed method. The results show that the proposed method can estimate CD with high accuracy even in the presence of crosstalk and polarization-dependent effects. The proposed method is expected to contribute to the development of more efficient and reliable fiber optic communication systems.'}\n","{'text': \"This paper proposes a 5G framework for user distribution aided beamforming and iterative traffic sensing. The proposed framework utilizes array signal processing techniques to improve the performance of beamforming systems by employing multiple antennas to transmit and receive signals. Moreover, it incorporates servers to store and process data, which aids in training the system for optimal performance. The architecture of the proposed framework is based on phased array techniques, which enable the use of multiple beams to achieve greater throughput. Additionally, the framework employs iterative traffic sensing techniques to improve the accuracy of the system's predictions. The proposed 5G architecture has the potential to revolutionize wireless communication systems by providing high-speed data transmission and efficient use of bandwidth.\"}\n","{'text': 'This paper addresses the angle tracking and vibration suppression for a flexible manipulator with uncertain parameters. Based on the partial differential equation (PDE) model, a unified framework of weighted multiple neural network boundary control (WMNNBC) is proposed to deal with the jumping parameters, in which neural networks are designed as the local boundary controllers to suppress vibrations. A novel proportion-derivative-like machine learning algorithm is developed to guarantee the learning convergence. Besides, the weighting algorithm is used to fuse multiple local neural network controllers to generate the appropriate global control signals with the variations of plant parameters. The stability of the overall closed-loop system is proved by the virtual equivalent system (VES) theory. The simulations are implemented to illustrate the feasibility and control performance of the proposed WMNNBC strategy.'}\n","{'text': 'With the rapid development of information technology, video surveillance system has become a key part in the security and protection system of modern cities. Especially in prisons, surveillance cameras could be found almost everywhere. However, with the continuous expansion of the surveillance network, surveillance cameras not only bring convenience, but also produce a massive amount of monitoring data, which poses huge challenges to storage, analytics and retrieval. The smart monitoring system equipped with intelligent video analytics technology can monitor as well as pre-alarm abnormal events or behaviours, which is a hot research direction in the field of surveillance. This paper combines deep learning methods, using the state-of-the-art framework for instance segmentation, called Mask R-CNN, to train the fine-tuning network on our datasets, which can efficiently detect objects in a video image while simultaneously generating a high-quality segmentation mask for each instance. The experiment show that our network is simple to train and easy to generalize to other datasets, and the mask average precision is nearly up to 98.5% on our own datasets.'}\n","{'text': 'In this paper, we study blind signal detection by exploiting the hidden sparsity of angular-domain propagation channels in massive MIMO systems. The state-of-the-art approach utilizes the channel sparsity by representing the angular-domain channel with a uniform angle-sampling grid. However, this approach is only applicable to uniform linear arrays and may cause a substantial performance loss due to the energy leakage problem. In contrast to this approach, we deploy a sparse channel representation with a fixed general sampling grid. Based on that, we formulate the blind signal detection problem as an affine matrix factorization task and develop a novel message passing algorithm to estimate the channel and the user signals simultaneously. Unlike the existing approach, the proposed algorithm is applicable to general antenna arrays. Numerical results show that our proposed method significantly reduces the estimation error compared to the state-of-the-art approach by avoiding the leakage of energy.'}\n","{'text': 'In this paper, an extension of Precision Time Protocol (PTP) to enable energy-efficient clock synchronization between the nodes within Wireless Sensor Network (WSN) is proposed. PTP is nanosecond accuracy clock synchronization protocol in which nodes are organized in master-slave hierarchy on the basis of clock accuracy by means of Best Master Clock (BMC) algorithm. The algorithm considers clock accuracy to select best clock in the system. A novel modification of IEEE 1588 BMC algorithm for energy-constraint multi-hop WSN has been proposed to reduce clock convergence time and energy needed by considering out-degree of clocks without sacrificing synchronization accuracy. The new algorithm results in energy efficient clock synchronization that makes it most appropriate for low-power multi-hop wireless sensor networks. We present NS-3 simulation data that confirms the effectiveness of work.'}\n","{'text': 'Energy efficiency is the important factor being noticed caused by reduced battery capacity of the sensor in sensor networks. In existing system there are various issues such as hotspot problem, overheads that cause battery to drain easily. In this paper ring routing with multiple mobile sinks is proposed to reduce the overheads to make it more efficient, and the method is that it forms ring structure with ring nodes by using clustering algorithm. Ring structure is constructed according to the determined radius, nodes near to the ring form the ring structure and the sink position is updated and the location of the sink node is shared between all the ring candidates then the data dissemination takes place. The proposed system makes improvement in network lifetime and reduces delay and focuses mainly on the energy efficiency.'}\n","{'text': 'In this paper, a real-time object recognition system based on deep learning is proposed to identify whether the operator has worn the specific safety equipment. Normally this is done by labor force to examine the real-time video feedback from camera, however it is extremely inefficiency and costly. Traditional object recognition methods are heavily relying on human designed features. As a result, their performance will downgrade dramatically under complex environment and cannot be used in real-time application due to low processing speed. In this paper, the original VGG16 neural network of Single Shot Multi-Box Detector (SSD) has been modified by introducing Inception module to improve its sensitivity to small objects, Combined with multi-object tracking technology to bind face recognition results with pedestrian identity, the experiments have proved that proposed system can recognize specific safety equipment of specific operator accurately and in real time at operation site.'}\n","{'text': 'This paper presents an iterative approach to jointly estimate the states in combined heat and power systems (CHPS). The node method is used to address the temperature quasi-dynamics in the district heating system (DHS), resulting in a dynamic state estimation (DSE) model. An alternating estimation strategy is employed to effectively handle the complicated time-delay constraints of temperature in the computation of DSE. Case studies are conducted on two CHPS test systems to verify the effectiveness of the DSE and the alternating approach. Simulation results show that the DSE in CHPS outperforms the static state estimation and the separate state estimation in individual energy systems in terms of accuracy.'}\n","{'text': 'This paper focuses on the development of a new scalable smart telemetry system for industrial systems using IoT solutions. The system is designed to utilize temperature sensors to measure temperature in real-time, which is then transmitted through Ethernet and analyzed using various protocols. With the increasing demand for IoT solutions in industrial systems, the new smart telemetry system is scalable and can be easily integrated with existing systems. The system is capable of transmitting temperature measurements with high accuracy and efficiency, allowing for real-time monitoring and control of industrial processes. With the ability to analyze and process large amounts of data through the Internet of Things, the system provides a reliable and efficient solution for temperature measurement in real-time systems.'}\n","{'text': 'An adaptive control scheme is proposed to compensate the effects caused by cable-harness disturbance in spatial turntable. The proposed control tactics applied feedforward compensation method which is based on a PD structure and estimated value of the disturbance. Firstly, the estimation is given by a radial basis function(RBF) neural network with adaptive algorithm. Then, a control scheme is designed and the stability of system has been proved by Lyapunov theory. Finally, the simulation results demonstrate that the proposed control scheme effectively eliminated cable-harness disturbance.'}\n","{'text': 'This paper proposed a sensorless position control method for a compact dual solenoid actuator using a disturbance observer. The aim of the study was to develop a reliable and robust position control method that does not require additional sensors. The paper presented a mathematical model of the actuator that takes into account the magnetic forces, inductance, and other important parameters. The proposed method uses an observer to estimate the disturbance caused by the force generated by the actuator. The disturbance estimation is then used to compensate for the force and improve the accuracy of the position control. Simulation results showed that the proposed method achieved accurate position control while maintaining the compactness of the actuator. The proposed method has potential applications in various fields such as robotics, automation, and mechatronics.'}\n","{'text': 'To evaluate the reliability of power electronic systems, it is necessary to estimate the junction temperatures of power devices under periodic power loss profiles due to the fundamental-frequency current. However, a large number of periodic power loss profiles under long-term reliability evaluation (e.g., 1 year) are challenging to compute quickly. On the other hand, in order to improve computational efficiency, unvalidated simplified thermal analysis methods may impair the confidence of the reliability outcome. Therefore, this paper proposes an analytical model for power semiconductors with a compromise of the thermal estimation accuracy and computational efficiency. With the proposed model, it is indicated that minimum computation efforts can be obtained for thermal estimation under a maximum allowable error. The proposed method, thus, enables computation-efficient thermal stress analysis for power semiconductor devices with a preset modeling error. The effectiveness of the proposed method has been verified by simulations and experiments on a power electronic system with 1200-V/50-A insulated gate bipolar transistor (IGBT) modules.'}\n","{'text': 'Activity recognition is a critical task in computer vision, which has been widely applied in various fields such as surveillance and human-computer interaction. Nowadays, deep learning has shown great potential in activity recognition because of its excellent performance in handling large-scale and unstructured data. However, deep architectures require a large amount of labeled data, which is costly and time-consuming to collect. To improve the efficiency of activity recognition, transfer learning has been introduced to deep architectures. This technique enables the sharing of knowledge between related tasks and reduces the need for labeled data. In this study, we investigate the effectiveness of transfer learning in improving the performance of deep architectures for group activity recognition. We analyze the data models and task analysis, as well as the training process, and evaluate the performance of the proposed model using a publicly available dataset. Our experiments show that transfer learning significantly enhances the recognition accuracy of group activities, and it outperforms the baseline method without transfer learning. This study provides insights into the application of transfer learning in deep architectures for activity recognition and contributes to the advancement of this area. The results could be useful for researchers in fields such as surveillance, robotics, and human-computer interaction. This study was presented at a recent conference on computer vision and machine learning.'}\n","{'text': \"The development of cloud computing technology has brought great convenience to people's lives. However, cloud computing also faces a series of security problems, which makes the intrusion detection system become very important. In this paper, we propose an effective swarm optimization based intrusion detection classifier system for cloud computing. By leveraging artificial intelligence techniques such as particle swarm optimization and artificial bee colony algorithm, our proposed system aims to optimize the intrusion detection process and increase the classification accuracy. Moreover, task analysis is conducted to identify the potential intrusion scenarios, which enhances the system's ability to detect and prevent various types of attacks. Various classification algorithms are tested, and our results show that the proposed system is effective in detecting intrusion with high accuracy. The proposed system is a promising solution for intrusion detection in cloud computing environments, and it provides a useful reference for designing communication systems with improved security.\"}\n","Processing batch 40/63\n","{'text': 'The paper addresses the discrete-time distributed Kalman filtering over a sensor network to generate system fault residuals. The problem of interest are distributed sensor data consensus filtering for systems whose dynamics, as well as the control objectives, are not decoupled. Limited to linear systems and fixed network connectivity, the state observability and fault detectability is analyzed to guarantee stability of the distributed filters and responsibility of fault residuals. The performance of fault residuals generated within distributed Kalman filtering algorithms are demonstrated in the numerical example.'}\n","{'text': 'This paper presents a cooperative radar system capable of accurately measuring both the velocity and position of a target using a 77-GHz frequency. The velocity measurement is achieved through the Doppler effect while the position estimation is based on the phase difference between the transmitted and received signals. The system uses multiple antennas to improve the accuracy of radar measurements and minimize the impact of interference. A calibration procedure is also implemented to ensure accurate results. The proposed system opens up new possibilities for the development of sensor systems that require precise velocity and position measurements.'}\n","{'text': \"The research developed during my PhD [1] was driven by the need to understand how people interact with the web. This information gives ISPs and network managers better visibility and understanding of how users and web services change over time. Thanks to traces and logs of users' traffic, my work focuses on two complementary aspects: (i) data analytics, and (ii) user modelling.In this work, I show how to reconstruct users' online activity from passive measurements and to model their behaviour. I introduce machine learning approaches to identify the intentionally visited web-pages and web-sites. I highlight device usage evolution, the structure of the navigation and the interactions with social networks and search engines. I build users' profiles and then I show how to re-identify users in a future time thanks to their behavioural fingerprints. This is also instrumental for security applications. I next study the interaction with online ads, capturing the impact of the temporal dynamics of shown advertisement and improving revenues.I make available all the anonymized datasets and code for the community, to guarantee results reproducibility and foster further analyses.\"}\n","{'text': 'This paper proposes a novel image enhancement technique using maximum entropy bi-histogram equalization. The method employs histogram analysis to adjust the brightness levels of an image in order to increase its overall clarity and perceptibility. By using entropy as a measure of image quality, the proposed algorithm determines the optimal distribution of pixel intensities for the image in question. The results of our experiments demonstrate that the use of our technique produces images with higher contrast, better detail, and greater uniformity in their distribution of pixel intensities. Our approach has the potential to be applied to a wide range of image enhancement applications, from medical imaging to industrial visualization. This research contributes significantly to the field of image processing and could serve as a basis for future studies in this area, particularly in the application of density functional theory. This paper was presented at various conferences and has received positive feedback from the community.'}\n","{'text': 'Partially observable Markov decision processes (POMDPs) are models for sequential decision-making under state transition uncertainty, and sensing uncertainty of the underlying state. Model uncertainty is an important concern when the models, for which an action policy was optimized, change in time, e.g., degrading sensors that result in a drift in the observation function. Replanning a policy whenever a model drifts (if feasible) is both a time consuming and computationally expensive process. At the other extreme, ignoring the drift and following the original policy can lead to high-risk actions with high costs. We present an efficient approach that post-processes a policy computed using initial models to select actions robust to changes in the observation function. The key idea is to maintain a belief region rather than a belief point about the state of the system, and perform online robust action selection w.r.t. the current belief region. Specifically, we formulate a convex optimization problem to select the action that maximizes the worst case reward function for a convexified belief region. Simulation results demonstrate the ability of our approach to avoid high-risk actions when the system is in uncertain states.'}\n","{'text': 'One of the main causes of increased mortality among women is breast cancer. The ultrasound scan is the most widely used method for diagnosing geological disease i.e. breast cancer. The first step for identifying the abnormality of the breast cancer (malignant from benign), is the extraction of the region of interest (ROI). In order to achieve this, a new approach to breast ROI extraction is proposed for the purpose of reducing false positive cases (FP). The proposed model was built based on the local pixel information and neural network. It includes two stages namely, training and testing. In the training stage, a trained model was built by extracting the number of batches from both ROI and background. The testing stage involved scanning the image with a fixed size window to detect the ROI from the background. Afterwards, a distance transform was used to identify the ROI and remove non-ROI. Experiments were conducted on the on-data set with 250 ultrasound images (150 benign and 100 malignant) the preliminary results show that the proposed method achieves a success rate of about 95.4% for breast contour extraction. The performance of the proposed solution also has been compared with the existing solutions that have been used to segment different types of images.'}\n","{'text': 'In this article the author analyzes the structure of engineering activity, and reveals problems of its formation in higher education institutions. The author considers the organization of educational departments based on the leading higher education institutions of St. Petersburg as an important factor of graduates training for independent work. The article studies issue of the professional orientation of schoolchildren to choosing engineering professions through organization of extracurricular activities in the general secondary school.'}\n","{'text': 'Ultra-dense Internet of Things (IoT) network has greatly facilitated the development of smart environments and the realization of diverse sophisticated applications. Power constrained and resource limited IoT devices often need to perform computation-intensive and delay-sensitive tasks in such a network. Mobile edge computing and non-orthogonal multiple access are two promising techniques to address the corresponding challenges. In this paper, in order to improve the fairness and resource efficiency among IoT users, resource allocation problems are formulated in ultra-dense MEC-enabled IoT networks with NOMA considered. An iterative algorithm based on successive convex approximation technique is proposed to solve those challenging non-convex problems. Simulation results show that our proposed allocation method outperforms the benchmark schemes and verifies the efficiency of the proposed algorithm.'}\n","{'text': 'Measurement corresponds to a large part of software engineering, since it allows get important informations for the development of software projects. There are many tools to support measurement activities. Therefore, choosing the best tool can be difficult. Faced with such problem, this study aims at creating an analysis regarding measurement tools presented in literature. The methodology chosen for the task was the systematic literature review. The results present the metric tools chosen in literature, their functionalities, and the main metric used by these tools. Based on the results, a measurement tool was developed. The tool seeks to use the strengths of the tools analyzed and at the same time cover the gaps that the tools of the study presented.'}\n","{'text': \"Traditional Wireless Sensor Networks (WSN) use stationary sensor nodes to sense relevant events in their vicinity and relay this information for further analysis. These nodes may fail to cover the entire search space either due to inaccurate placement, an insufficient number of nodes or failure of some nodes, resulting in `coverage holes.' Mobile nodes can be deployed, in such cases, to visit the coverage holes and collect the necessary data. It is critical to plan the path taken by these mobile nodes to maximize area coverage and minimize trip time. In this paper, we propose a novel Mixed Integer Linear Programming (MILP) formulation, to determine the path taken by the mobile node. The goal is to find a route that achieves the specified level of coverage in the least amount of time. We have run simulations with different WSN sizes and sensing capabilities of the sensor nodes to evaluate the proposed MILP.\"}\n","{'text': 'In this paper, the Adaptive Equivalent Consumption Minimization Strategy (AECMS) of PHEV is designed based on the Equivalent Consumption Minimization Strategy (ECMS), which the equivalent of the oil and electricity equivalence factor changes with the initial SOC of the battery and mileage, is created based on genetic algorithm. The system simulation model was established by Simulink and Cruise, and the results were compared and analyzed. The simulation results show that PHEV Adaptive Equivalent Consumption Minimization Strategy can adapt to driving cycle characteristics, and the SOC of the battery can be reasonably planned, then the economic performance of PHEV is improved.'}\n","{'text': 'Given emotion is important in maintaining mental and physical well-being. To regulate emotions in human-robot interactions, a multi-objective weighted reinforcement learning (MOW-RL) decision method has been proposed. The aim of this method is to minimize the cost of the service while eliminating negative emotions or maintaining positive emotions of the user. To address the coordination issue of these two objectives, fuzzy analytic hierarchy process (FAHP) has been used to determine the weight of each target reward and punishment function under different conditions. In addition, the influence factors of different personality on the difficulty level of emotion transfer are calculated by FAHP. In a laboratory scenario, 20 experimenters were involved in the experiments, and the results suggest that the satisfaction level of the experimenters was close to 2.3.'}\n","{'text': 'In recent years, the classification of synchronized brainwave recordings has been a hot topic in the field of neuroscience. Electroencephalography (EEG) is a widely used technique for monitoring synchronized brain activity in humans. However, making sense of large amounts of EEG data is a challenge, requiring advanced techniques for feature extraction and categorization. Machine learning and deep learning approaches are increasingly being used for this purpose. Deep learning technologies such as artificial neural networks can be trained to model complex relationships between EEG recordings and identify patterns of synchronization. Logistic regression is another popular statistical method used to model relationships between EEG data and predict classification outcomes. The use of these advanced techniques for EEG signal analysis is expected to be a critical tool for the development of better diagnostic tools and treatments for a range of neurological disorders. As such, the present paper provides an overview of the potential of machine learning and deep learning approaches for the classification of synchronized brainwave recordings and provides a brief summary of the applications of brain modeling in neuroscience research.'}\n","{'text': 'Future wireless communications aim to encompass all aspects of seamless and comprehensive dissemination of network resources. Previous research has explored various ways to achieve this, including terrestrial and aerial methods. However, the success of a Network Service Provider (NSP) is not in bedaubing an Area of Interest (AoI) with appropriate resources, but also in the businesses that use these services. In this paper, we propose a network-centric architecture known as the Internet of Ergonomics (IoE) and examine the business modelling of such an architecture.'}\n","{'text': \"Brain-inspired computing is a novel computing technology based on neural morphological engineering, which draws lessons from methods of human brain information processing and storage. Combining with the high-performance computing (HPC) platform, they constitute the foundation of general artificial intelligence. However, current brain HPC platforms generally suffer from slow speed, poor scalability, and high energy consumption, which severely restrain its potential and circumscribe the development of general artificial intelligence. The dataflow model was first proposed in the 1970s, providing a novel idea for the development of HPC. In addition, the dataflow model shares similar information processing mechanisms with human's neural system, which makes dataflow models naturally suit the emulation of brain-inspired computing. Based on the contemporary progress of the dataflow model, the Codelet model was proposed. Through a fine-grained asynchronous program execution and resource allocation, the Codelet model successfully realized the distributed computing on the heterogeneous system, effectively improved the computing power and speed, and open up a new path to overcome the shortcomings of the existing high-performance computing technology. We propose a dataflow-based emulation platform, aiming at providing high-performance computing technology support for general brain-inspired intelligent system, as well as using characteristics of dataflow models to fully explore the potential of brain-inspired intelligence. As an example, we will select a convolutional neural network (LeNet5) that already has a spectacular user base to initially verify the superiority and feasibility of our proposal.\"}\n","{'text': 'In recent years, researchers have shown increasing interest in applying adaptive control techniques to address the challenges posed by nonlinear systems. One approach is to use fuzzy control, which is particularly suited to handling uncertain systems. Another popular technique is the use of Lyapunov methods, which provide a way to verify system stability. In this paper, the authors propose using Adaptive Fuzzy Control with High-Order Barrier Lyapunov Functions to address the challenges posed by High-Order Uncertain Nonlinear Systems with Full-State Constraints. Specifically, the authors introduce a new design method for Barrier Lyapunov Functions, which serve as a key component of the proposed algorithm. The authors demonstrate the effectiveness of their approach on a simulated example, showing that it outperforms existing methods such as Backstepping.'}\n","{'text': 'Due to the variety of background model in the real world, detecting changes in a video cannot be addressed exhaustively by a simple background subtraction method, especially with several motion detection challenges, such as dynamic background, camera jitter, intermittent object motion, and so on. In this paper, we propose an efficient background subtraction method, namely locally statistical dual-mode (LSD), for detecting moving objects in video-based surveillance systems. The method includes a local intensity pattern comparison algorithm for foreground segmentation by analyzing the homogeneity of intensity patterns of the input frame and the background model, in which the homogeneity is calculated by the mean and standard deviation of pixel intensity. Besides that, a dual-mode scheme is developed to temporally update the background model for the short- and long-term scenarios corresponding to sudden and gradual changes in the background. The advantage of this scheme is the allowance of updating the model in both pixel- and frame-wise manners simultaneously. The parameters used in both the local intensity pattern comparison algorithm and the dual-mode background model updating scheme are estimated for every input frame consecutively based on local and global statistical information of segmentation result. In experiments, the proposed LSD method is extensively evaluated on the Wallflower and CDnet2014 datasets; and remarkable performance demonstrates its preeminence to the many state-of-the-art background subtraction approaches in terms of segmentation accuracy and computational complexity.'}\n","{'text': 'We propose the fast optical flow extractor, a filtering scheme that recovers artifact-free optical flow fields from HEVC-compressed video. To extract accurate optical flow fields, we form a regularized optimization problem that considers the smoothness of the solution and the pixelwise confidence weights of the artifact-ridden HEVC motion field. Solving such an optimization problem is slow, so we first convert the problem into a confidence-weighted filtering task. We then use the extracted optical flow fields for fast synthetic refocus of video using camera motion. By leveraging the already-available HEVC motion information, we achieve a 10-fold speed-up in the running times compared to similar methods. Our fast optical flow extractor is useful since video signals encountered in real life are typically available already in coded formats. Our fast optical flow extractor is general, and works on motion fields of any video coder.'}\n","{'text': 'Traffic signs are an important aspect of road safety and can greatly benefit from innovative technologies such as augmented reality (AR). In this paper, we propose a multithreaded approach to detect and recognize traffic signs in real-time. The system is trained on a large set of annotated data to achieve high accuracy and robustness. Furthermore, the visualization of detected signs is facilitated by the integration of AR technology. Rendering of computer graphics and feature extraction are employed to enhance the quality and precision of the visual effects. To further streamline the system, we implement a streaming media technology that allows for fast and efficient data transmission. The performance of our proposed method is evaluated using eigenvalues and eigenfunctions analysis of the output, demonstrating promising results under various scenarios. The proposed system has the potential to contribute to the development of safer and more efficient driving practices through the application of AR technology in traffic sign detection and visualization.'}\n","{'text': 'Foresight is a manifestation of human-level intelligence. In model-based reinforcement learning, obtaining a perfect environment model is essential and significant. Although recent research has achieved impressive advances in improving prediction accuracy, existing environment models are unable to generalize well across environments, mainly because appearance-independent dynamics learning completely relies on appearance-specific representation learning. In this paper, we propose a novel predictive model named transferable environment model (TEM) which disentangles state representation and dynamics. The disentanglement allows the model to deal with different observation distributions and meanwhile share a cross-environment latent dynamics. In a 3D visual platform, we show that our model has good generalization performance in target environments with very few data. Furthermore, the TEM is able to continually adapt to a sequence of target environments without forgetting the knowledge for previous environments. To the best of our knowledge, this paper is the first to endow a predictive model with the ability to work across multiple environments.'}\n","{'text': 'In order to extract keywords from cross-language documents as accurately as possible, especially for the language whose keyword extraction technology is not mature, a text keyword extraction method based on information entropy and TextRank is proposed to extract the accurate keywords from the translated Chinese documents. This method determines the basic importance of words according to the information entropy of words, and then uses the information entropy of words to vote iteratively through the TextRank algorithm. This method solves the problem that TextRank algorithm easily extracts frequent non key words as keywords. The experimental results show that the proposed method can extract keywords more accurately than TextRank in the processing of cross-lingual bilingual translated documents.'}\n","{'text': \"In proposed system an automated attendance marking and management system is proposed by using face detection and recognition algorithms. Identification of human faces by the unique characteristics or features of their face is known as Face recognition. Currently, Face recognition technology is the fastest growing technology. Instead of using the traditional methods, this proposed system aims to develop an automated system that records the student's attendance by using facial recognition technology for those who are present during lecture hours. The main objective of this work is to make the attendance marking and management system fully automatic, simple and easy. In this work the facial recognition of face is done by image processing techniques. The processed image is used to match with the existing stored record and then attendance is marked in the database correspondingly. Compared to existing system traditional attendance marking system, this system reduces the workload of people and also saves times. This proposed system is been implemented with 4 modules such as Image Capturing, Segmentation of group photo and Face Detection, Face comparison and Recognition, Updating of Attendance in database.\"}\n","{'text': 'Detection and diagnosis of material degradation are of a complex and challenging task since it is presently hand-operated by a human. Therefore, it leads to misinterpretation and avoids correct classification and diagnosis. In this paper, we develop a computer-assisted detection method of material failure by utilizing a deep learning approach. A deep convolutional neural network (CNN) model, combined with an image processing technique, e.g., adaptive histogram equalization, is trained to classify a real-world turbine tube degradation image data set, which is retrieved from a power generation company. The experimental result demonstrates the effectiveness of the proposed approach with predictive classification accuracy is up to 99.99% in comparison with a shallow machine learning algorithm, e.g., linear SVM. Furthermore, performance evaluation of a deep CNN with and without an above-mentioned image processing technique is exhibited and benchmarked. We successfully demonstrate a novel application in constructing a deep-structure neural network model for material degradation diagnosis, which is not available in the current literature.'}\n","{'text': 'This paper presents Chip-to-Cloud, an autonomous and energy-efficient platform for smart vision applications that integrates directive antennas, computer architecture, wireless communication, servers, acceleration, and wireless sensor networks. The platform aims to address the growing demand for smart vision applications in a range of industries, including healthcare, agriculture, and security. The platform incorporates directive antennas, which can enhance the performance of wireless communication in terms of range and reliability. Furthermore, computer architecture, servers, and acceleration are used to process and analyze the vast amounts of data generated by these applications in a time-efficient manner. Finally, wireless sensor networks provide the necessary energy efficiency required for the platform to operate autonomously. Overall, the Chip-to-Cloud platform offers a promising solution for advancing the efficient and autonomous deployment of smart vision applications in various industries.'}\n","{'text': 'Mobile visual food recognition is emerging as an important application in food logging and dietary monitoring in recent years. Existing food recognition methods use conventional many-shot learning to train a large backbone network, which refers to the use of sufficient number of training data to train the network. However, these methods firstly do not consider the cases where certain food categories have limited training data. Therefore, they cannot use the conventional training using many-shot learning. Further, existing solutions focus on improving the food recognition performance by implementing state-of-the-art large full networks, and do not pay much attention to reduce the size and computational cost of the network. As a result, they are not amenable for deployment on mobile devices. In this paper, we address these issues by proposing a new few-shot and many-shot fusion learning for mobile visual food recognition, it has a compact framework and is able to learn from existing dataset categories, and also new food categories given only a few sample images. We construct a new Indian food dataset called NTU-IndianFood107 in order to evaluate the performance of the proposed method. The dataset has two parts: (i) a Base Dataset of 83 classes of Indian food images with over 600 images per class to perform many-shot learning, and (ii) a Food Diary of 24 classes captured in restaurants with limited number to simulate the few-shot learning on new food categories. The proposed fusion method achieves a Top-1 classification accuracy of 72.0% on the new dataset.'}\n","{'text': 'In this paper, we propose a NOMA-aided massive MIMO downlink system with distributed antenna arrays. With the increasing demand for efficient spectrum utilization in next-generation wireless communication systems, MIMO communication has received widespread attention due to their superiority in achieving high spectral efficiency. However, the traditional MIMO system still suffers from poor performance caused by multiple access interference. To overcome this problem, NOMA is introduced to ensure simultaneous transmission of multiple users in the same time and frequency resources. Moreover, in this proposal, we focus on employing distributed antenna arrays for channel estimation to improve the system performance. Finally, we investigate the performance of the proposed system under various scenarios in the uplink transmission using silicon carbide. The simulation results demonstrate significant performance improvement of the proposed NOMA-aided massive MIMO system with distributed antenna arrays compared to the traditional MIMO system.'}\n","{'text': 'Wireless communications can leverage UAVs to provide ubiquitous connectivity to different device types. Recently, there has been growing interest in integrating UAVs into macro cell networks to supplement terrestrial cellular networks. UAVs have several advantages compared to communications with fixed infrastructure, including easy deployment, higher capacity due to LoS communication links, and greater design flexibility with controlled mobility. Despite offering these benefits, UAV communication faces security challenges due to the broadcasting nature of wireless communication. Therefore, information security is a fundamental requirement, which we address in this article. In this article, we first consider two application cases of UAVs (i.e., a UAV as a flying base station and a UAV as an aerial node) in conjunction with safeguarding the exchange of confidential messages. Then, we demonstrate physical layer security mechanisms via two case studies to ensure security, and numerically show superior performance gains. Finally, we highlight new opportunities in the emerging network architecture that can guide future research directions.'}\n","{'text': 'Biometric-based human identification has been investigated and applied in daily life applications, but some of them meet fundamental limitations, e.g., highly sensitive to the ambient light of the image-based recognition and unable to detect wrinkle finger with the fingerprint identification, and therefore, decrease the user experience. Recently, electrocardiogram (ECG) has demonstrated to be a very attractive identification technique against attacks. However, the ECG-based human identification is still not a convenient solution since direct skin-contact and chest/body hair shaving are required for ECG acquisition even with the novel single-lead ECG. We propose and experimentally demonstrate an unobtrusive and continuous ballistocardiogram (BCG)-based human identification system using a microbend fiber sensor, which provides a more convenient way to identify the human who is seating on the chair with leaning back against the specially-designed cushion. To the best of our knowledge, this is the first study that a microbend fiber sensor is exploited for human identification. The results show that the proposed 1D-convolutional neural network (CNN) delivers outstanding performance with an average of 100% and 90% identification rate under 15 subjects and 30 subjects, respectively. We recommend that the BCG-based biometric identification technique has great potential to be an innovative solution in smart, private, and security applications with a small group.'}\n","{'text': 'The iterative reconstruction algorithms can get better reconstruction result by adding constraints in the case of incomplete or uneven projection. In the iterative reconstruction algorithm, how to obtain the relationship between the reconstructed image and the projected data, namely, projection matrix, is the key to the image reconstruction. In this paper, the neural network algorithm is used to calculate the projection matrix, which gives a solution to a class of problems. In simulation, we use the projection matrix trained by the neural network to achieve the reconstruction, and the results show that the original image can be well reconstructed.'}\n","{'text': 'This paper discusses the use of directive and reconfigurable antennas in wireless sensor networks (WSNs) to improve the quality of the links between the nodes. The authors explore the use of PIN photodiodes, antenna arrays, and directive antennas to achieve this goal. The paper provides an overview of the various types of antenna radiation patterns and describes how they can be used to enhance the link quality between nodes. The authors also discuss the importance of considering the azimuth and elevation angles when designing WSNs for different application scenarios. Overall, the study highlights the potential benefits of using directive and reconfigurable antennas in WSNs and provides insights on how to optimize the design of the antenna systems for desired performance metrics.'}\n","{'text': \"This paper focuses on the use of the three-point IpDFT algorithm to track the variation of the power system frequency and use this estimate as a sampling clock frequency of the Analog to Digital converter of the PMU (phasor measurement unit). This new approach improves the accuracy of the synchrophasor that is based on the joint application of the Modulated Sliding DFT and the Taylor's series expansion. The accuracy requirements of the IEEE Std C37.118.1â\\x84?2011 and its latest amendment IEEE Std C37.118.1aâ\\x84?2014 under steady-state and dynamic environments are analyzed and discussed.\"}\n","{'text': 'Java-Bali grid is the largest electricity grid in Indonesia. The most recent recorded peak load of 26.834 MW occurred on October 2, 2018. Several loss of generation events have been recorded by Phasor Measurement Unit (PMU) which placed in several locations in Java-Bali system. The recently installed Wide Area Monitoring System (WAMS) can collect PMU data within the Java-Bali grid so the data can be compared with high accuracy. This paper shows monitoring of frequency response in Java-Bali system during loss of generation event in 2018. The analysis includes rate of change of frequency, grid frequency control evaluation, and simplified estimation of system inertia constant.'}\n","{'text': 'As of late, the significance of moderate access to dependable equipment, programming assets and minimizing the support expenses and security concerns have energized vast foundation supervisors and organizations to relocate to distributed computing i.e. to cloud computing. The cloud services are running the world at a good pace. The paper presents the two services of cloud that is salesforce.com and Force.com and also the functionality of these services by introducing a ticket booking desktop application for metro rail users using Salesforce.com and Force.com. Salesforce.com is a suite of CRM (Customer Relationship Management) tools which are designed to help big and small businesses dramatically improving their customer service, retention rates, purchase analysis and much, much more. Salesforce provides both SaaS and PaaS cloud services. Force.com is the platform provided by salesforce, is used for application development.'}\n","{'text': 'In spectrum-sliced elastic optical path networks (SLICE), the lightpath bandwidth is variable, and the virtual topology overlay on a physical topology shall be designed to optimize the spectrum utilization. Under static traffic, SLICE networks are typically designed through a mixed integer linear programming (MILP) with the aim of minimizing the spectrum utilization. In this paper, a new MILP formulation for protection in SLICE networks is proposed, which uses the concept of bandwidth squeezing and grooming to guarantee a minimum agreed bandwidth for each source-destination pair in the surviving bandwidth. The route for each demand on the physical topology is determined by balance equations together with physical layer constraints in the formulation, so that no pre-calculated routes are required and the modulation format of each established lightpath may be chosen with enough quality of transmission and to save network spectrum. Therefore, the proposed formulation jointly solves the virtual topology design and physical topology design problems. The first results evaluate the effectiveness of the MILP formulation for two small networks when connections are under different service-level agreement (SLA) requirements and are provisioned by an appropriate protection scheme and different modulation formats. Due to the NP-hard nature of the proposed MILP formulation, a heuristic algorithm for moderately large networks is also proposed. Case studies are carried out to analyze the basic properties of the formulation and the performance of the proposed heuristic. With the proposed formulation, it is possible to identify the configurations that ensure minimum spectrum occupation with different kinds of protection for each lightpath. Different kinds of modulation formats are considered and contrasted to the benchmark case of a single modulation format and using the same kind of protection for all lightpaths.'}\n","{'text': 'Optimum design of the weighting factors for a multi-objective cost function is one of the major challenges of Finite-Set Model Predictive Control (FS-MPC) operated power electronic converters. Especially for multi-level topologies, where multi-objectives must be included in the cost function to ensure a safe operation of the converter, the complexity of the optimization problem is rapidly growing with each new objective included in the cost function. In this paper a new approach for design of the weighting factors for a three level neutral point clamped (NPC) converter using artificial neural network (ANN) is proposed. The ANN is used as a surrogate model of the detailed converter model. In the first step a detailed converter model is simulated for different weighting factor combinations. From the simulations obtained performance metrics (e.g. total harmonic distortion (THD), average switching frequency, DC-link voltage balance) are used to train the ANN. Once the network is trained, it can be used to estimate the performance metrics for any combination of weighting factors. By defining a fitness function using the metrics, weighting factor combinations that optimize the function are found to be very fast. The design is also validated on an experimental set-up, where the measured performance metrics are compared to the ones predicted by the ANN. It is concluded that the results match very well with a difference being below 10%.'}\n","{'text': 'LabSMILING is a Software as a Service (SaaS) framework that is designed to provide a comprehensive set of tools and testbeds for the analysis, design, and management of low data-rate wireless personal area networks (WPANs) based on the IEEE 802.15.4 standard. The framework is composed of a number of remotely accessible testbeds and related software tools that are designed to facilitate the development and deployment of WPANs. The LabSMILING framework allows users to experiment with hardware and software configurations, test network topologies, and simulate real-time systems. The framework is designed to work with a range of devices, including switches, wireless sensor networks, and Universal Serial Bus (USB) devices. The LabSMILING framework is a powerful tool for researchers and developers who are working on low data-rate WPANs and require a comprehensive set of tools and testbeds for their work.'}\n","{'text': 'We present a stochastic, limited-memory Broyden Fletcher Goldfarb Shanno (LBFGS) algorithm that is suitable for handling very large amounts of data. A direct application of this algorithm is radio interferometric calibration of raw data at fine time and frequency resolution. Almost all existing radio interferometric calibration algorithms assume that it is possible to fit the dataset being calibrated into memory. Therefore, the raw data is averaged in time and frequency to reduce its size by many orders of magnitude before calibration is performed. However, this averaging is detrimental for the detection of some signals of interest that have narrow bandwidth and time duration such as fast radio bursts (FRBs). Using the proposed algorithm, it is possible to calibrate data at such a fine resolution that they cannot be entirely loaded into memory, thus preserving such signals. As an additional demonstration, we use the proposed algorithm for training deep neural networks and compare the performance against the mainstream first order optimization algorithms that are used in deep learning.'}\n","{'text': 'Computationally efficient matrix multiplication is a fundamental requirement in various fields, including and particularly in data analytics. To do so, the computation task of a large-scale matrix multiplication is typically outsourced to multiple servers. However, due to data misusage at the servers, security is typically of concern. In this paper, we study the two-sided secure matrix multiplication problem, where a user is interested in the matrix product AB of two finite field private matrices A and B. In this problem, the user exploits the computational resources of N servers to compute the matrix product, but simultaneously tries to conceal the private matrices from the servers. Our goal is to maximize the communication rate while preserving security, where we allow for up to â\\x84?â\\x89?N servers to collude. To this end, we propose a general aligned secret sharing and matrix partition scheme for which we optimize the partition of matrices A and B as a function of N and â\\x84?in order to maximize the achievable rate. A proposed inductive approach gives us an analytical close-to-optimal solution which significantly outperforms the existing scheme of Chang and Tandon in terms of (i) communication rate, (ii) maximum tolerable number of colluding servers and (iii) computational complexity.'}\n","{'text': 'In this paper, we propose an integrated two-pose calibration method for estimating the head-eye parameters of a Robotic Bionic Eye. The calibration method involves leveraging mathematical models, kinematic equations, and parameter estimation techniques to obtain accurate estimates of the head-eye parameters. We use multiple cameras to capture images from different angles and analyze the neck movement of the robotic device to improve the calibration accuracy. Our proposed method allows for accurate and efficient calibration of the Robotic Bionic Eye, facilitating its ability to perform various visual tasks such as recognizing objects, tracking movements, and scanning environments. The results of our experiments demonstrate the effectiveness of the proposed calibration method, which can be further extended to other robotic or autonomous systems that require accurate head-eye calibration.'}\n","{'text': 'This paper discusses the process discovery approaches and their role in decision making, particularly in sales activities. The use of Hidden Markov Models, a mathematical model used in probability theory, is explored for the purpose of tracking observations that cannot be directly observed. The role of decision making in this process is emphasized, as it allows for the selection of optimal actions based on the analysis of collected data. Estimation of underlying processes plays a key role in decision making, as it allows for the generation of accurate predictions and informed decisions. In addition, data mining techniques such as Bayes methods are explored, which involve modeling and estimation of the probability distribution of model parameters. Finally, the importance of training data in the process discovery approach is discussed, as this data is crucial in building effective models that can contribute to the improvement of sales activities. Overall, this paper provides an overview of various process discovery approaches and their implications for decision making in sales activities.'}\n","{'text': 'A novel resource allocation scheme for cache-aided mobile-edge computing (MEC) is proposed, to efficiently offer communication, storage and computing service for intensive computation and sensitive latency computational tasks. In this paper, the considered resource allocation problem is formulated as a mixed integer non-linear program (MINLP) that involves a joint optimization of tasks offloading decision, cache allocation, computation allocation, and dynamic power distribution. To tackle this non-trivial problem, Markov decision process (MDP) is invoked for mobile users and the access point (AP) to learn the optimal offloading and resource allocation policy from historical experience and automatically improve allocation efficiency. In particular, to break the curse of high dimensionality in the state space of MDP, a deep reinforcement learning (DRL) algorithm is proposed to solve this optimization problem with low complexity. Moreover, extensive simulations demonstrate that the proposed algorithm is capable of achieving a quasi-optimal performance under various system setups, and significantly outperform the other representative benchmark methods considered. The effectiveness of the proposed algorithm is confirmed from the comparison with the results of the optimal solution.'}\n","{'text': 'This paper proposes a CNN-RNN neural network approach to crowd counting and density estimation. The task analysis involves understanding the complex dynamics of crowd behavior and predicting crowd density in an accurate and efficient manner. The proposed method involves training a network using a combination of convolutional neural networks (CNN) and recurrent neural networks (RNN) with the long short-term memory (LSTM) module for feature extraction and estimation. The obtained results show that the proposed method outperforms existing methods in terms of accuracy and execution speed. The paper also discusses the application of this method to various scenarios using different types of cameras. This research provides important contributions to the field of crowd analysis and can be a valuable resource for future conferences and research in this area.'}\n","{'text': 'This paper addresses the issue of anti-jamming communication in dynamic and unknown environment for ultradense network (UDN). A deep reinforcement learning based antijamming algorithm is proposed by exploiting the frequency-hopping technology to cope with the jamming attack without estimating the mode and parameters of the jamming. In contrast to existing learning based schemes, in which the anti-jamming action, e.g., frequency hopping and transmit power adjustment, is taken from a pre-defined discrete anti-jamming strategy space, the proposed anti-jamming algorithm takes anti-jamming action from the continuous action space based on deterministic policy gradient. We represent this anti-jamming algorithm in an actor-critic framework, for which a convolution neural network (CNN) is adopted as the actor for anti-jamming action selection, and a deep neural network (DNN) is used as the critic for value estimation. We have implemented the proposed algorithm based on Google TensorFlow. Simulation results show that the system performance can be significantly improved by the proposed algorithm.'}\n","{'text': 'This paper proposes an approximate regularized maximum likelihood estimation (ML) approach to censor outliers in Gaussian radar data. The approach takes into consideration the data models and covariance matrices of the radar, and uses training data to estimate the parameters of the data model. The method is designed to handle clutter and other forms of noise that can cause outliers in the data. The paper shows the effectiveness of the approach in removing outliers and improving the accuracy of radar data.'}\n","{'text': 'In the present study, a new approach has been proposed for optimizing reactive power modes based on neural network technologies. Reactive power is an important factor in ensuring the stability and efficiency of power systems. One of the key advantages of using biological neural networks for reactive power optimization is their ability to learn and adapt to changes in the system. The proposed method utilizes forecasting techniques to predict the reactive power demand and optimize the output of the power system accordingly. The neurons in the neural network model are trained using data obtained from the power system, and the optimization process is performed through a series of iterations. The results show that the proposed method is more accurate and efficient compared to traditional optimization methods. This research has important implications for the development of more intelligent and sustainable power systems.'}\n","{'text': 'This paper presents an automatic content-based image retrieval (CBIR) system for brain tumors on T1-weighted contrast-enhanced magnetic resonance images (CE-MRI). The key challenge in CBIR systems for MR images is the semantic gap between the low-level visual information captured by the MRI machine and the high-level information perceived by the human evaluator. The traditional feature extraction methods focus only on low-level or high-level features and use some handcrafted features to reduce this gap. It is necessary to design a feature extraction framework to reduce this gap without using handcrafted features by encoding/combining low-level and high-level features. Deep learning is very powerful for feature representation that can depict low-level and high-level information completely and embed the phase of feature extraction in self-learning. Therefore, we propose a deep convolutional neural network VGG19-based novel feature extraction framework and apply closed-form metric learning to measure the similarity between the query image and database images. Furthermore, we adopt transfer learning and propose a block-wise fine-tuning strategy to enhance the retrieval performance. The extensive experiments are performed on a publicly available CE-MRI dataset that consists of three types of brain tumors (i.e., glioma, meningioma, and pituitary tumor) collected from 233 patients with a total of 3064 images across the axial, coronal, and sagittal views. Our method is more generic, as we do not use any handcrafted features; it requires minimal preprocessing, tested as robust on fivefold cross-validation, can achieve a fivefold mean average precision of 96.13%, and outperforms the state-of-the-art CBIR systems on the CE-MRI dataset.'}\n","{'text': 'In recent years, the identification of disease-associated circular RNAs (circRNAs) has become increasingly important in the field of human informatics. In this study, we propose a novel computational prediction algorithm for disease-associated circRNAs based on a manifold regularization learning framework. Specifically, we introduce a kernel method to construct heterogeneous networks of circRNA-gene-disease associations, and then use manifold regularization to achieve simultaneous feature selection and parameter estimation. By applying our algorithm to several disease datasets, we show that it outperforms existing methods in terms of both prediction accuracy and robustness. Our results suggest that manifold regularization offers a powerful tool for the computational prediction of disease-associated circRNAs, and highlight the promise of circRNA-based biomarker discovery in the medical field.'}\n","{'text': 'Reinforcement learning is an effective approach for designing intelligent autonomous systems that can learn from their environment to improve their performance. However, the process of learning can be time-consuming and computationally complex. To address this issue, this paper proposes a novel technique for accelerating Q-learning based on state-space partitioning. The proposed method applies task analysis to divide the state space into subspaces that can be learned independently. This approach allows the agent to focus on specific regions of the state space and speeds up the learning process. The proposed method is evaluated on a variety of games and real-time systems, demonstrating significant improvements in learning efficiency and performance. Additionally, the paper presents adaptation models that enable the approach to adapt to changes in the environment and achieve robust learning over time. Overall, this research provides an effective and efficient solution for accelerating Q-learning, which has potential applications in various domains, such as autonomous systems and game AI.'}\n","{'text': 'Nutrient elements of NPK are macro nutrients that play an important role in the growth and development of plants, therefore it is necessary to measure NPK nutrient content to measure how well soil fertility condition before the land planting period, but NPK measurement through laboratory tests takes a relatively long time. This research develops a prototype of NPK nutrient measurement system based on a mobile application by using soil image for determining the textural characteristic, the textural characteristics are processed with local binary pattern and back-propagation neural network to accelerate the measurement process.Sample data in this research was taken on rice field land in the province of Yogyakarta Special Region by varying the distance at 30 cm to 110 cm with interval 20 cm and angle image capture at -30Â° to 30Â° with interval 10Â°. Datasets were being pre-processed to improve image quality and adjust image format. Preprocessed results are extracted using local binary pattern uniform to obtain texture features. The texture features were being inputted of the neural network model, that being trained with a back-propagation algorithm by varying parameters of the neural network model.The model tested to determine the effect of distance and angle of image capture, system processing speed, and effect of artificial neural network parameters. The best model is implemented on a smartphone application. The results obtained an average of computation time 0.65s, and the optimal result is obtained at distance capture of 50 cm and angle capture of 0Â° with the measurement accuracy at each soil nutrient level of nitrogen 91.80%, while phosphorus 83.49%, and potassium 82.54%, therefore the average is 84.16%.'}\n","{'text': \"Alzheimer's disease (AD) is an irreversible progressive neurodegenerative disorder. Mild cognitive impairment (MCI) is the prodromal state of AD, which is further classified into a progressive state (i.e., pMCI) and a stable state (i.e., sMCI). With the development of deep learning, the convolutional neural networks (CNNs) have made great progress in image recognition using magnetic resonance imaging (MRI) and positron emission tomography (PET) for AD diagnosis. However, due to the limited availability of these imaging data, it is still challenging to effectively use CNNs for AD diagnosis. Toward this end, we design a novel deep learning framework. Specifically, the virtues of 3D-CNN and fully stacked bidirectional long short-term memory (FSBi-LSTM) are exploited in our framework. First, we design a 3D-CNN architecture to derive deep feature representation from both MRI and PET. Then, we apply FSBi-LSTM on the hidden spatial information from deep feature maps to further improve its performance. Finally, we validate our method on the AD neuroimaging initiative (ADNI) dataset. Our method achieves average accuracies of 94.82%, 86.36%, and 65.35% for differentiating AD from normal control (NC), pMCI from NC, and sMCI from NC, respectively, and outperforms the related algorithms in the literature.\"}\n","{'text': 'This letter leverages a framework based on averaged operators to tackle the problem of tracking fixed points associated with maps that evolve over time. In particular, this letter considers the Krasnoselâ\\x80\\x99skiÄ\\xadâ\\x80\\x93Mann (KM) method in a settings where: 1) the underlying map may change at each step of the algorithm, thus leading to a â\\x80\\x9crunningâ\\x80?implementation of the KM method, and 2) an imperfect information of the map may be available. An imperfect knowledge of the maps can capture cases where processors feature a finite precision or quantization errors, or the case where (part of) the map is obtained from measurements. The analytical results are applicable to inexact running algorithms for solving optimization problems, whenever the algorithmic steps can be written in the form of (a composition of) averaged operators; examples are provided for inexact running gradient methods and the forwardâ\\x80\\x93backward splitting method. Convergence of the average fixed-point residual is investigated for the non-expansive case; linear convergence to a unique fixed-point trajectory is showen in the case of inexact running algorithms emerging from contractive operators.'}\n","{'text': \"High-dimensional and sparse (HiDS) matrices from recommender systems contain various useful patterns. A latent factor (LF) analysis is highly efficient in grasping these patterns. Stochastic gradient descent (SGD) is a widely adopted algorithm to train an LF model. Can its extensions be capable of further improving an LF models' convergence rate and prediction accuracy for missing data? To answer this question, this work selects two of representative extended SGD algorithms to propose two novel LF models. Experimental results from two HiDS matrices generated by real recommender systems show that compared standard SGD, extended SGD algorithms enable an LF model to achieve a higher prediction accuracy for missing data of an HiDS matrix, a faster convergence rate, and a larger model diversity.\"}\n","{'text': 'Current indoor semantic recognition systems rely on smartphones to sense patterns. In this paper, we propose WiFiMap+, which is a first-ever automatical inference system using WiFi signals to recognize highlevel indoor semantics from human activities and environments, where the high-level indoor semantics consist of indoor facilities and environments. To characterize the static indoor environments and dynamical human activities separately with channel state information (CSI), we propose a novel two-stream architecture to generate the spatial streams and the movement streams independently. Compared to the recent research on activity recognition, this two-stream architecture can make the content area of CSI samples extend from human activities to indoor environments. The CSI-environment model reduces the effect of human activities on environment detection. The environment-based testing sample representation method utilizes environment knowledge to overcome CSI diversity caused by environment changes. Finally, we implement WiFiMap+ using commercial WiFi devices and evaluate its performance for seven common semantic detection cases in sixroom scenarios. The experimental results show that our proposed WiFiMap+ is robust to the multi-room scenario and can achieve the average accuracy of 92.8% and the lowest accuracy of about 82%.'}\n","{'text': 'To measure the ability of a machine to understand professional-level scientific articles, we construct a scientific question answering task called PaperQA. The PaperQA task is based on more than 80 000 â\\x80\\x9cfill-in-the-blankâ\\x80?type questions on articles from reputed scientific journals such as Nature and Science. We perform fine-grained linguistic analysis and evaluation to compare PaperQA and other conventional question and answering (QA) tasks on general literature (e.g., books, news articles, and Wikipedia texts). The results indicate that the PaperQA task is the most difficult QA task for both humans (lay people) and machines (deep-learning models). Moreover, humans generally outperform machines in conventional QA tasks, but we found that advanced deep-learning models outperform humans by 3%-13% on average in the PaperQA task. The PaperQA dataset used in this paper is publicly available at http://dmis.korea.ac.kr/downloads?id=PaperQA.'}\n","{'text': 'JavaScript plays an important role in web applications and services, which is used by millions of web pages in optimizing interface design, embedding dynamic texts, reading and writing HTML elements, validating form data, responding to browser events, controlling cookies and much more. However, since JavaScript is cross-platform and can be executed dynamically, it has been a major vehicle for web-based attacks. Existing solutions work by performing static analysis or monitoring program execution dynamically. However, since the heavy use of obfuscation techniques, many methods no longer apply to malicious JavaScript code detection, and it has been a huge challenge to de-obfuscate obfuscated malicious JavaScript code accurately. In this paper, we propose a hybrid analysis method combining static and dynamic analysis for detecting malicious JavaScript code that works by first conducting syntax analysis and dynamic instrumentation to extract internal features that are related to malicious code and then performing classification-based detection to distinguish attacks. In addition, based on code instrumentation, we propose a new method which can deobfuscate part of obfuscated malicious JavaScript code accurately. Ultimately, we implement a browser plug-in called MJDetector and perform evaluation on 450 real web pages. Evaluation results show that our method can detect malicious JavaScript code and de-obfuscate obfucation effectively and efficiently. Specifically, MJDetector can detect JavaScipt attacks in current web pages with high accuracy 94.76% and de-obfuscate obfuscate code of specific types with accuracy 100% whereas the base line method can only detect with accuracy 81.16% and has no capacity of de-obfuscation.'}\n","{'text': 'This paper presents a tool for detecting fake news, which utilizes various machine learning algorithms for feature extraction and computational modeling. The tool combines probabilistic logic and data mining techniques to provide a comprehensive analysis of news articles and determine their authenticity. Additionally, the tool can assist in identifying false information in social media posts by analyzing the content and the source. The effectiveness of the tool is demonstrated through experiments, where it achieved promising results in detecting fake news with high precision and recall. As fake news has become a widespread issue, this tool provides a valuable contribution in combating the spread of misinformation. Overall, this research highlights the importance of using machine learning and computational modeling for fake news detection, and the potential impact of such tools on society.'}\n","{'text': \"This paper proposes a bio-inspired data collection framework called bioSmartSense for energy-efficient and quality-of-information (QoI)-aware smart city applications. The framework utilizes the concept of energy states and topology to construct an optimal sensor network for data collection. The proposed framework reduces the energy consumption of sensors and extends the network lifetime, which is a significant challenge in wireless sensor networks. Furthermore, it considers the QoI requirement of smart city applications by adapting the data collection process according to the user's preferences. The performance of the proposed framework is evaluated through simulation experiments where it outperforms existing schemes in terms of energy consumption, network lifetime, and QoI. The bioSmartSense framework leverages the scalability and adaptability of the biological systems to create an efficient and reliable data collection mechanism for smart cities.\"}\n","{'text': 'Smart grid is a large complex network with a myriad of vulnerabilities, usually operated in adversarial settings and regulated based on estimated system states. In this study, we propose a novel highly secure distributed dynamic state estimation mechanism for wide-area (multi-area) smart grids, composed of geographically separated subregions, each supervised by a local control center. We first propose a distributed state estimator assuming regular system operation that achieves near-optimal performance based on the local Kalman filters and with the exchange of necessary information between local centers. To enhance the security, we further propose to 1) protect the network database and the network communication channels against attacks and data manipulations via a blockchain (BC)-based system design, where the BC operates on the peer-to-peer network of local centers, 2) locally detect the measurement anomalies in real-time to eliminate their effects on the state estimation process, and 3) detect misbehaving (hacked/faulty) local centers in real-time via a distributed trust management scheme over the network. We provide theoretical guarantees regarding the false alarm rates of the proposed detection schemes, where the false alarms can be easily controlled. Numerical studies illustrate that the proposed mechanism offers reliable state estimation under regular system operation, timely and accurate detection of anomalies, and good state recovery performance in case of anomalies.'}\n","{'text': \"Building an image processing model for prediction or classification application has to overcome quite a lot of challenges. Convolutional neural network (CNN) is the pillar of image processing in deep learning perspective. In order to bring down the disadvantages and for improving the performance compared to the CNN, a new architecture of CNN had been devised which is known as Capsule neural network (Capsule-Net). By this paper we analyze Capsule-Net for solid waste management which is separation of plastic and non-plastic. This task is viewed as of at most significance in today's world due to volumes of waste generated and nonavailability of human labor for this work. The capsule-Net is evaluated using 2 different datasets. Dataset 1 represents materials collected from public places and Dataset 2 represents materials collected from private environment. The proposed architecture with capsule-Net gives an accuracy of 96.3% for Dataset 1 and 95.7% for Dataset 2. The necessary hardware setup has been developed and tested. This will be a grace to the society which faces unexplainable difficulty in disposing wastes. It is inexpensive labor free and harmless to health.\"}\n","{'text': 'This paper presents a fast and efficient visualization method for the radiation field based on the geometric features of the target. The method utilizes finite element analysis and interpolation to construct a computational model of the radiation field, which is then rendered using solid modeling techniques and surface textures. The proposed method is capable of generating real-time visualizations of the radiation field, making it a valuable tool in various applications where quick and accurate visualization is crucial. The effectiveness of the proposed method is demonstrated through experimental results, which show that the method can produce high-quality visualizations of the radiation field with minimal computational cost. In summary, the method presented in this paper provides a viable option for efficiently visualizing radiation fields in real-time applications.'}\n","{'text': 'The aim of this research is to develop an innovative low cost and affordable platform for smart home control and energy monitoring interfaced with augmented reality. The goal is to educate people about energy usage, particularly as fuel costs continue to rise, and provide new methods of interaction for those with disabilities. In order to increase the awareness of energy consumption, we have developed an interactive system using Augmented Reality to show live energy usage of electrical components. This system allows the user to view his real time energy consumption and at the same time offers the possibility to interact with the device in Augmented Reality. The energy usage was captured and stored in a database which can be accessed for energy monitoring. We believe that the combinations of both, complex smart home applications and transparent interactive user interface will increase the awareness of energy consumption.'}\n","{'text': 'This paper explores the use of Generative Adversarial Networks (GANs) to enhance retinal images obtained from a Line-Scanning Ophthalmoscope (LSO). The retina is an important part of the eye that helps us to see, and imaging it is crucial for diagnosing eye diseases. However, the spatial resolution of retinal images obtained from LSOs can often be poor due to several factors, such as eye movement and imaging artifacts. To address this issue, the authors propose a method that uses GANs to reconstruct high-resolution retinal images from low-resolution image sequences obtained from an LSO. The results of their experiments show that their method is able to increase the spatial resolution of the retinal images, improving the overall image quality and aiding in the diagnosis of eye diseases. This study provides an innovative approach to retinal imaging that may have significant implications for improving the quality of healthcare for those suffering from eye diseases.'}\n","{'text': 'This paper introduces a novel singular value relaxation technique for learning sparsifying transforms. The proposed technique is aimed at optimizing the sparsity of transforms by incorporating both analytical and computational modeling approaches. The method utilizes dictionaries and matching pursuit algorithms to effectively encode data and generate efficient transforms with minimal redundancies. The optimization problem is formulated as a singular value minimization problem, and can be efficiently solved using standard convex optimization techniques. By applying this technique, we demonstrate significant improvement in the sparsity and quality of the learned transforms, thus enabling more efficient and effective data encoding and processing.'}\n","{'text': 'This paper proposes a model and algorithms for the planning of fog computing networks, which are becoming increasingly important in the age of the Internet of Things. The traditional cloud computing paradigm may not be sufficient to handle the massive amounts of data generated from IoT devices, leading to latency issues and delays. Hence, fog computing, which allows for processing closer to the edge of the network, has gained popularity. This paper focuses on the planning phase of fog computing networks, using computational modeling and evolutionary computation to optimize the network structure and minimize delays. The proposed algorithms take into account various factors such as the location of IoT devices, available network infrastructure, and data requirements. The results show that the proposed model and algorithms provide an efficient solution for the planning of fog computing networks, which can significantly improve the performance of IoT applications.'}\n","{'text': 'This paper proposes an Internet of Things (IoT) based smart window that uses the DHT11 temperature sensor for temperature measurement. The smart window is operated by Microsoft Windows and utilizes DC motors to open and close the window. The DHT11 temperature sensor is responsible for measuring the indoor and outdoor temperature, which triggers the smart window to open or close accordingly. The proposed smart window is a cost-effective solution that provides an automated way to control the temperature inside the room. This project is innovative as it combines the fields of computer science and temperature measurement to design a solution that is not only sustainable but also enhances the overall comfort of the room. By using the proposed IoT based smart window, one can ensure a comfortable indoor environment while reducing their energy consumption.'}\n","{'text': 'Virtual reality technologies have been a subject of academic research in supporting teaching and learning for several decades. However, in the recent five years, significant advancements have been made in virtual reality technology, and it is becoming more feasible to implement it into education. This paper highlights the applications of virtual reality in education, specifically using the Oculus Rift platform. The purpose of this study is to explore the current use of virtual reality to support teaching and learning. The findings of the research shed light on the distribution of curriculum content in virtual reality applications, as well as identification of the highest-rated educational virtual reality applications.'}\n","{'text': 'This paper proposes a method for discovering and obtaining company hot events from internet news. The method involves the use of clustering algorithms, partitioning algorithms and heuristic algorithms to extract and analyze data models from news articles found on the internet. With this method, companies can easily discover and obtain information regarding important events and trends in their respective industries. The use of data mining techniques makes it possible to extract valuable insights from vast amounts of unstructured data available on the internet, thereby enabling companies to make informed decisions. This method is an effective way to harness the power of the internet to obtain valuable insights, and could prove to be a valuable tool for companies seeking to stay ahead of the curve.'}\n","{'text': 'Detecting static obstacles along roads is important for improving the safety of autonomous vehicles as well as enhancing the efficiency of human-driven vehicles. In order to accomplish this task, a combined method using histograms, image segmentation, artificial neural networks, and image edge detection is proposed. Histograms are utilized to extract the prominent features of the road, while image segmentation is used to segment the road and the obstacles. Artificial neural networks are employed to detect the presence of obstacles based on the segmented images. Finally, image edge detection is used to obtain the exact boundary of the obstacles. This combined method has been tested on images captured by smart phones, and the results show that it is effective in detecting obstacles along the road. This method can be further developed and applied to different types of vehicles and environments, contributing to the development of advanced driver assistance systems and autonomous driving technologies.'}\n","{'text': 'Realistic knowledge of transport properties of the environment is necessary while modeling gas-dynamic processes that occur in the units of energy power systems based on the macro levels of heat and mass transfer. In this article we offer an approach based on the kinetic molecular theory of gases to determine a transport coefficient in the multicomponent gaseous environments. The authors offer a mathematical model of description of molecular interaction in the K-component gaseous environments in which their microstructure, in particular, elastic and geometric characteristics of interacting molecules are taken into consideration. This approach allows to determine transport properties of a multicomponent environment in the macrosystems at a qualitatively new level taking into account its microscopic properties.'}\n","{'text': 'The amount of data extracted from learning experiences has grown at an astonishing pace both in depth due to the increasing variety of data sources, and in breath with courses now being offered to massive student cohorts. However, in this emerging scenario instructors are now facing the challenge of connecting the knowledge emerging from data analysis with the provision of meaningful support actions to students within the context of an instructional design. The objective of this workshop is to give attendees a set of hypothetical scenarios in which the knowledge extracted from a learning experience needs to be used to provide frequent personalized feedback to students.'}\n","{'text': 'With the development of artificial intelligence and self-driving, vehicular ad-hoc network (VANET) has become an irreplaceable part of the Intelligent Transportation Systems (ITSs). However, the traditional network of the ground cannot meet the requirements of transmission, processing, and storage among vehicles. Under this circumstance, integrating space and air nodes into the whole network can provide comprehensive traffic information and reduce the transmission delay. The high mobility and low latency in the Space-Air-Ground Integrated Network (SAGIN) put forward higher requirements for security issues such as identity authentication, privacy protection and data security. This paper simplifies the Blockchain and proposes an identity authentication and privacy protection scheme based on the Hashchain in the SAGIN. The scheme focuses on the characteristics of the wireless signal to identify and authenticate the nodes. The verification and backup of the records on the block are implemented with the distributed streaming platform, Kafka algorithm, instead of the consensus. Furthermore, this paper analyzes the security of this scheme. Afterward, the experimental results reveal the delay brought by the scheme using the simulation of SUMO, OMNeT++, and Veins.'}\n","{'text': 'The technical challenge of creating a self-driving vehicle remains an open problem despite significant advancements from universities, car manufacturers, and technology companies. Full autonomy, known as level 5 (see \"Society of Automotive Engineers Levels of Driving Automation\"), is defined as full-time performance by an automated driving system of all aspects of the dynamic driving task under all roadway and environmental conditions that can be managed by a human driver. It is estimated that level 5 autonomous vehicles on public roads will help eliminate more than 90% [1] of the 35,000 annual traffic fatalities caused by human error in the United States [2]; reduce commute time, road congestion, and pollution; and increase driving resource utilization [3].'}\n","{'text': 'In this paper, we propose an analog implementation of optimization algorithms from a distributed optimization view. The proposed method utilizes capacitors and inductors to represent the cost function and the electric potential, respectively. The optimization process is carried out by applying optimization algorithms to the pins of the circuit. The convergence of the algorithm is analyzed and discussed. The proposed analog optimization method has significant advantages in terms of speed, power consumption and scalability compared to traditional digital optimization methods. Therefore, it has great potential for applications in fields such as machine learning, signal processing and optimization.'}\n","{'text': 'This paper establishes the applicability of observable block companion form linear Kalman innovation models, for secret key generation between communicating parties (Alice and Bob) in a multipath wireless channel. First, Kalman models are identified to describe the dynamics of the channel between both users, based on real measurements of the Received Signal Strength Indicator (RSSI) corresponding to various blocks of information. Afterwards, it was verified that the innovation errors exhibited a significant randomness content, and that there was high correlation between the parameters of Alice and Bob for the same block. In addition, improved values of maximum channel capacity for secret key generation were obtained. Additional features that make innovation Kalman models an excellent alternative for secret key generation include: simplicity of implementation, high computational efficiency, excellent performance in modeling time-varying systems, and they do not require to estimate the properties of the noise.'}\n","{'text': \"Video anomaly detection and localization is a fundamental task analysis problem in deep learning. This paper proposes an adaptive intra-frame classification network for anomaly detection by leveraging feature extraction and training. The proposed approach offers an adaptation model that incorporates adaptive systems to address the challenge of identifying and localizing anomalies in large video datasets. The approach employs deep learning techniques for anomaly detection and localization and suggests a training methodology for the proposed network to improve the network's performance. The proposed model's effectiveness is demonstrated through experimental evaluations, suggesting that the proposed network outperforms other state-of-the-art approaches regarding the task of anomaly detection and localization. Overall, this paper establishes a practical framework for designing anomaly detection systems and suggests potential avenues for future research.\"}\n","{'text': \"Protean malware mutations and premeditated cyber attacks are threatening security of information systems worldwide. There is an urgent need for effective methods to trace the source of code. In this paper, through study of coding behavior, which is a social characteristic of code, we trace the source of code preliminarily. Based on function-calling relation graph, three function-calling features of code are proposed to distinguish different coding patterns of programmers: relative edit distance shows the orderliness of code, semivariogram reveals programmers' coding logic (Breadth First Coding or Depth First Coding) and ODD value suggests different function arrangement styles. Tested in experiments, these features are able to trace the coding behavior patterns of programmers, providing assistance with source tracing as expected.\"}\n","{'text': 'Deep image captioning is an emerging field of research that aims to automatically generate natural language descriptions for images. This overview article summarizes the key components and techniques involved in the task analysis, decoding, feature extraction, visualization, maximum likelihood estimation, neural networks, and training phases of deep image captioning systems. Task analysis involves defining the specific goals and objectives of the system, while decoding involves selecting the most appropriate words and grammar to express the image content. Feature extraction involves identifying relevant visual features from the image and translating them into a suitable format for the caption generation process. Visualization techniques are used to provide insights into the internal workings of the system, while maximum likelihood estimation is a common technique for training deep neural network-based caption generators. Finally, neural network architectures and training strategies are discussed in detail, highlighting recent advances and challenges in the field.'}\n","{'text': \"Combining global user and product characteristics with local review information provides a powerful mechanism for predicting users' sentiment in a review document about a product on online review sites such as Amazon, Yelp and IMDB. However, the user information is not always available in the real scenario, for example, some new-registered users, or some sites allowing users' comments without logging in. To address this issue, we introduce a novel knowledge distillation (KD) learning paradigm, to transfer the user characteristics into the weights of student neural networks that just utilize product and review information. The teacher model transfers its predictive distributions of training data to the student model. Thus, the user profiles are only required during the training stage. Experimental results on several sentiment classification datasets show that the proposed learning framework enables student models to achieve improved performance.\"}\n","{'text': 'Anomaly detection is the first step with a challenging task of securing a communication network, as the anomalies may indicate suspicious behaviors, attacks, network malfunctions, or failures. In this paper, we address the problem of not only detecting different anomalies, such as volume based (e.g., DDoS or Flash crowd) and spatial based (e.g., network scan), that arise simultaneously in the wild but also of attributing the anomalous point to a single-anomaly event causing it. Besides, we also tackle the problem of low-detection accuracy caused by the phenomenon of traffic drift. To this end, a novel adaptive profile-based anomaly detection scheme is proposed. More specifically, a more comprehensive metrics set is defined from the dimensions of temporal, spatial, category, and intensity to compose IP traffic behavior characteristic spectrum for fine-grained traffic characterization. Then, the digital signature matrix obtained by using the ant colony optimization (ACO) algorithm is applied to construct the baseline profile of the normal traffic behavior. Anomalous points are identified and analyzed by using confidence bands and a generic clustering technique, respectively. Finally, a lightweight updating strategy is applied to reduce the number of false positives. Real-world data of China Education Research Network backbone and synthetic data are collected to verify our proposal. The experimental results demonstrate that our approach provides a fine-grained behavior description ability and has significantly increased the detection accuracy compared with other similar alternatives.'}\n","{'text': 'In recent years, a new generation of low-power, neuromorphic, event-based vision sensors has been gaining popularity for their very low latency and data sparsity. Though the conventional frame-based cameras have advanced in a lot of ways, they suffer from data redundancy and temporal latency. The bio-inspired artificial retinas eliminate the data redundancy by capturing only the change in illumination at each pixel and asynchronously communicating in binary spikes. In this work, we propose a system to achieve the task of human activity recognition based on the event-based camera data. We show that such tasks, which generally need high frame rate sensors for accurate predictions, can be achieved by adapting existing computer vision techniques to the spiking domain. We used event memory surfaces to make the sparse event data compatible with deep convolutional neural networks (CNNs). We leverage upon the recent advances in deep convolutional networks based video analysis and adapt such frameworks onto the neuromorphic domain. We also provide the community with a new dataset consisting of five categories of human activities captured in real world without any simulations. We achieved an accuracy of 94.3% using event memory surfaces on our activity recognition dataset.'}\n","{'text': 'In recent years, underwater object detection has become a challenging research area, and the classification of underwater object images plays a vital role in this field. This paper proposes a novel approach for classifying underwater object images based on Convolutional Neural Network (CNN), which has shown remarkable success in image classification tasks. The proposed method combines the processes of training, image segmentation, and feature extraction to improve classification accuracy. Furthermore, we compare the results with a Support Vector Machine (SVM) model, which is commonly used in image classification. The experimental results demonstrate that our proposed method outperforms the SVM approach in terms of classification accuracy, and provide high-quality visualizations of the segmented and classified underwater object images. The proposed approach has potential applications in sonar-based underwater object detection tasks, and can be used by marine researchers and underwater engineers to improve the accuracy and efficiency of object classification in underwater environments.'}\n","{'text': 'Efficient Virtual Network Function Placement (VNF) is a critical issue, especially for Poisson arrived traffic, which can lead to delays and overloading of servers and middleboxes in IP networks. This paper proposes a heuristic algorithm for the efficient placement of VNF, which considers the available resources and the traffic patterns. The algorithm maximizes the utilization of resources and minimizes the delays by placing the VNFs as close as possible to the source of the traffic. The proposed algorithm is evaluated through simulations based on standard traffic patterns and shows significant improvements compared to existing solutions. Furthermore, a programming model for the implementation of the proposed algorithm is presented, which can be easily integrated into the existing network infrastructure. As a result, this paper provides a practical solution for efficient VNF placement in IP networks, which can lead to significant improvements in network performance and user experience.'}\n","{'text': \"Cooperative Intelligent Transport Systems (C-ITS) are expected to play an important role in our lives. They will improve the traffic safety and bring about a revolution on the driving experience. However, these benefits are counterbalanced by possible attacks that threaten not only the vehicle's security, but also passengers' lives. One of the most common attacks is the Sybil attack, which is even more dangerous than others because it could be the starting point of many other attacks in C-ITS. This paper proposes a distributed approach allowing the detection of Sybil attacks by using the traffic flow theory. The key idea here is that each vehicle will monitor its neighbourhood in order to detect an eventual Sybil attack. This is achieved by a comparison between the real accurate speed of the vehicle and the one estimated using the V2V communications with vehicles in the vicinity. The estimated speed is derived by using the traffic flow fundamental diagram of the road's portion where the vehicles are moving. This detection algorithm is validated through some extensive simulations conducted using the well-known NS3 network simulator with SUMO traffic simulator.\"}\n","{'text': 'This paper explores the challenge of producing radiologist-quality reports through interpretable deep learning. Radiologists play a critical role in medical diagnosis and treatment, but their expertise is limited by the sheer volume of imaging data that must be analyzed. By utilizing deep learning algorithms, we aim to automate the process of diagnosing and interpreting images. In this study, we conduct a thorough task analysis and select the hip as our target region for analysis, due to its prevalence in biomedical imaging. We also explore the best practices for training interpretable deep learning models, including the use of transfer learning and data augmentation. Ultimately, our goal is to produce high-quality, automated reports that can assist radiologists in their diagnoses of X-rays and other medical images. This study contributes to the growing field of deep learning in biomedical imaging and highlights the need for collaboration between radiologists and data scientists to develop accurate and reliable automated diagnostic tools.'}\n","{'text': 'Vehicular ad hoc Network (VANET) are a class of ad hoc systems work to guarantee the safety and security of traffic. An important point in VANET is the manner by which to believe the data transmitted when the neighboring vehicles are quickly changing and moving all through range. The fundamental point of this paper is to distinguish Sybil attack in VANET. A two phase security based mechanism is proposed to give reliable solution in identifying and blocking the Sybil attacked nodes to secure the information and providing safety and trust on the application. In the first phase Public Key Infrastructure (PKI) is taken and in the second phase hash function is considered. In this way to defeat Sybil attack we can easily recognizing Sybil attacks in VANET with much accurate.'}\n","{'text': 'This paper describes a multi-session monocular SLAM approach addressed to underwater environments. It has three main blocks: a) visual odometry, b) loop-closing detection; loop closings inside each individual session are found applying feature matching with RANSAC, and since no geometric relation between images of different sessions is available, multi-session loop closings are detected via an image hash matching procedure, alleviating also the computational cost of the image comparisons, and c) an Iterated Extended Kalman Filter (IEKF) based optimization process used to refine the different individual trajectories and to join the different maps; the global optimization process (map joining) can be delayed until certain number of loop closings are found, reducing the global running time. Several experiments using marine imagery in areas colonized with Posidonia Oceanica show the robustness of this approach.'}\n","{'text': 'Finding recurrent patterns within a data stream is important for fields as diverse as cybersecurity or e-commerce. This requires to use pattern mining techniques. However, pattern mining suffers from two issues. The first one, known as \"pattern explosion\", comes from the large combinatorial space explored and is the result of too many patterns outputed to be analyzed. Recent techniques called output space sampling solve this problem by outputing only a sampled set of all the results, with a target size provided by the user. The second issue is that most algorithms are designed to operate on static datasets or low throughput streams. In this paper, we propose a contribution to tackle both issues, by designing an FPGA accelerator for pattern mining with output space sampling. We show that our accelerator can outperform a state-of-the-art implementation on a server class CPU using a modest FPGA product.'}\n","{'text': 'In this paper we present the multi-year collaboration between Rupprecht-Gymnasium MÃ¼nchen, a preuniversity school (K-12) in Bavaria, Germany, and MathWorks, an international scientific computing company. The school is STEM-focused and a member of the German national STEM school excellence network MINT-EC; they prepare students aged 10 to 18 for university careers. We highlight the starting motivation for the partners and describe several building blocks and initiatives including curricular and extracurricular activities for students as well as teacher training that became part of the collaboration. We also discuss future steps for the partners and how this project could be transferred to other schools.'}\n","{'text': \"Feature extraction and classification is a subject of broad and current interest in the brain-computer interfaces (BCIs) community, and remains a challenging task when working with Electroencephalogram (EEG) data, with no agreed upon optimum features set and classifier algorithm. In this 75-participant lab study, we compare different feature extraction methods and classifiers as we investigate the relationship between users' perceptions of the memorability of a number of passwords and the users' EEG data collected using BCIs when presented with these passwords. We asked the participants to rank the comparative memorability of 15 blocks of 5 passwords each, while recording their EEG data. Features from the EEG signals are extracted in three domains, power spectrum from the frequency domain, statistics from the time domain, and wavelet coefficients from the time-frequency domain. The feature subsets are submitted for classification with two classes, most memorable and least memorable, based on the user's perceived memorability of the passwords. Classification performance of Neural Networks and Support Vector Machine algorithms are compared. Results show distinctive features of EEG signals in the two different classes, achieving a classification accuracy of 89%. Our results indicate that features extracted in the time-frequency domain using wavelet transform, and classified using neural networks, resulted in the highest classification performance.\"}\n","{'text': 'WaDang recognition can provide valuable information for digital protection of cultural relics. However, WaDang recognition is challenging due to a great number of variations, such as different characters, different background pattern, and different scale and rotation. In this paper, we try to solve these problems by using hand-crafted and deep features and integrate them into multiple instance learning, in which the features of instances are divided into two parts and their similarity is computed by multiple kernel learning. The experiments on our collected WaDang images, MUSK, and COREL datasets show that the proposed algorithm is effective and its performance is compared with other state-of-art algorithms.'}\n","{'text': 'The Internet of Things (IoT) is penetrating almost all sectors of the global economy, addressing a wide range of opportunities by applying different Artificial Intelligence (AI) tools to IoT data. Due to the diversity in challenges and applications, IoT solutions are often bespoke and highly domain specific. With the surge of IoT applications, this approach to solutions becomes very costly and time consuming if there is a lack of reusability and replicability across different IoT sectors. This work presents a step towards reusability of IoT solution components applied to Industrial IoT (IIoT). We start from the challenging position of two unique AI-driven applications stemming from two separate IIoT verticals - applications which may be realized using the same components. We identify a set of application independent reusable AI-centric components and show how they can be orchestrated into the unique IoT applications. Our approach shortens the time to market and reduces costs for developing IIoT solutions, and opens a path towards reusability and replicability of IIoT components, thus accelerating the IoT market uptake.'}\n","{'text': 'This paper presents a simple method to extract the damping ratio of bilayer cantilevers using the static deflection profile of the released cantilevers. The extracted damping ratio is used to build a second order dynamical model of the cantilever. The model is validated by comparing the measured step response with the response predicted by the second order dynamical model.'}\n","{'text': 'In the context of the 5G mobile communication network, it is crucial to effectively manage the multiplexing of enhanced mobile broadband (eMBB) and ultra-reliable and low-latency communications (URLLC) traffics. To achieve this, a dynamic resource management scheme is proposed in this paper, based on a chance constrained optimization formulation. The scheme aims to ensure that the quality of service requirements for the URLLC traffics are met while maximizing the resource utilization for eMBB traffics. The proposed approach is inspired by the job shop scheduling problem and biological neural networks, and exploits the dynamic nature of 5G networks to adapt to changes in traffic demands. The results of the simulations demonstrate the effectiveness and robustness of the proposed scheme, which can improve the reliability of 5G communication systems.'}\n","{'text': 'Product unit neural networks (PUNNs) are powerful models that are difficult to train with gradient-based optimizers. We present windowed product unit neural networks (WPUNNs), a simple method of leveraging product as a nonlinearity in a neural network. Windowing the product tames the complex gradient surface and enables WPUNNs to learn effectively, solving the problems faced by PUNNs. WPUNNs use product layers between traditional sum layers, capturing the representational power of product units and using the product itself as a nonlinearity. We find the result that this method works as well as traditional nonlinearities like ReLU on the MNIST dataset. We demonstrate that WPUNNs can also generalize gated units in recurrent neural networks, yielding results comparable to LSTM networks.'}\n","{'text': 'The BIW OCMM Online Measurement Data is widely used in the process control of manufacturing industries. The measurement data collected from the process is complex, which makes it difficult to accurately understand the actual status of the system. To address the issue of data complexity, Artificial Neural Networks (ANNs) are commonly used. ANN is a computational model inspired by the human brain, which has the ability to recognize patterns and perform complex functions. In this study, the focus is on using the Long Short-Term Memory (LSTM) Neural Network, a type of ANN, for recognizing the variation patterns of the BIW OCMM Online Measurement Data for process control. The logic gates in the LSTM neurons enable the network to maintain temporal relationships between measurements, which is essential for recognizing the variation pattern. Furthermore, Optical Variables Measurement is used to obtain accurate data and Speech Recognition is used to reduce human intervention. The results show that the LSTM NN model can effectively recognize the variation patterns in the BIW OCMM Online Measurement Data, which facilitates the process of manufacturing control.'}\n","{'text': 'In this paper, a cooperative distributed optimization method via sliding mode extremum seeking (ES) control for a class of large-scale interconnected systems is presented. In this approach, a consensus algorithm is exploited to communicate the value of the global cost function to the ES controllers. Then, each sliding mode ES controller is designed such that a multivariable cost function is optimized in a cooperative fashion. The stability and convergence conditions for the ES controllers are determined and sufficient conditions for the distributed scheme to converge to the vicinity of the optimal points are driven. The application of the proposed scheme to a real-world example is investigated and simulations are provided to illustrate the theoretical results and demonstrate their potential use.'}\n","{'text': 'High-speed optical imaging is used in conjunction with fast electrical measurements to advance the understanding of the development of short circuit failures in silicon carbide power MOSFETs. Special samples are manufactured, which are compatible and comparable to TO-247 packages, but do not have any encapsulation. This allows optical observation of die surface during the test. The information on visible processes on the die allows for a better understanding of the sequence of events leading up to a failure. Imagery of destructive drain-source failures is also obtained, as well as post-failure images of surface and cross-sections. Aluminum metal melting is observed even for very short tests, before electrical indications of damage. The onset and completion of melting are used as information on the temperature of the die surface. Using this data for calibration, a detailed electro-thermal model is then used to simulate the temperature distribution and evolution during the short circuit.'}\n","{'text': 'Advances in digital technology have increased event recognition capabilities through the development of devices with high resolution, small physical dimensions and high sampling rates. The recognition of complex events in videos has several relevant applications, particularly due to the large availability of digital cameras in environments such as airports, banks, roads, among others. The large amount of data produced is the ideal scenario for the development of automatic methods based on deep learning. Despite the significant progress achieved through image-based deep networks, video understanding still faces challenges in modeling spatio-temporal relations. In this work, we address the problem of human action recognition in videos. A multi-stream network is our architecture of choice to incorporate temporal information, since it may benefit from pre-trained deep networks for images and from handcrafted features for initialization. Furthermore, its training cost is usually lower than video-based networks. We explore visual rhythm images since they encode longer-term information when compared to still frames and optical flow. We propose a novel method based on point tracking for deciding the best visual rhythm direction for each video. Experiments conducted on the challenging UCF101 and HMDB51 data sets indicate that our proposed stream improves network performance, achieving accuracy rates comparable to the state-of-the-art approaches.'}\n","{'text': \"This paper presents a novel method to estimate the instantaneous fundamental frequency (IFF) of speech signals using tunable-Q wavelet transform (TQWT). The proposed method uses a TQWT based filter-bank which has common or nearly uniform bandwidth for all sub-bands. This filter-bank is used to decompose the speech signal. The fundamental frequency component (FFC) of speech signal may be present in many subbands at different time intervals. The time interval at where FFC is present, in a sub-band, is identified using time-domain segmentation (TDS) section. In the similar way, the harmonic of FFC can also be present in different sub-bands at different time durations. The proposed method extracts FFC from different sub-bands and constructs a FFC for entire speech signal. Then, Hilbert transform is applied on constructed FFC to obtain IFF of speech signal. In order to show the efficacy of proposed method, it's performance has been compared with performance of other existing methods in terms of gross error in percentage.\"}\n","{'text': 'This paper presents the development of a real-time two-wheeled inverted pendulum robot using fuzzy logic-based intelligent control. The robot is designed with two wheels, DC motors, and sensor fusion to enable smooth and stable motion. The fuzzy logic-based controller is used to generate appropriate commands to control the movement of the robot. The proposed system was tested and evaluated under various scenarios, and the results demonstrate the effectiveness of the fuzzy logic-based controller for real-time systems. The use of fuzzy logic enables the controller to handle uncertainties and non-linearities in the system, resulting in accurate and efficient control performance. Overall, the presented system can be used in various applications that require robust and accurate control of two-wheeled inverted pendulum robots.'}\n","{'text': \"The manufacturing industry is rapidly evolving, and it's becoming increasingly important to adopt smart technologies to improve efficiency and productivity. AI is one such technology that has become popular in recent years. This paper discusses the use of AI in the manufacturing sector to create smarter systems. The article highlights the importance of software and data models in creating efficient computational models. The lead discusses the various applications of AI in manufacturing, such as predictive maintenance and quality control. Additionally, the article highlights the importance of machine learning in the development of smarter systems. By adopting these technologies, manufacturers can streamline and optimize their production processes, increasing efficiency, and profitability. Overall, this paper emphasizes the importance of embracing AI as a valuable asset in the manufacturing industry to build smarter systems.\"}\n","{'text': \"Humans can fluidly adapt their interest in complex environments in ways that machines cannot. Here, we lay the groundwork for a real-world system that passively monitors and merges neural correlates of visual interest across team members via Collaborative Brain Computer Interface (cBCI). When group interest is detected and co-registered in time and space, it can be used to model the task relevance of items in a dynamic, natural environment. Previous work in cBCIs focuses on static stimuli, stimulus-or response-locked analyses, and often within-subject and experiment model training. The contributions of this work are twofold. First, we test the utility of cBCI on a scenario that more closely resembles natural conditions, where subjects visually scanned a video for target items in a virtual environment. Second, we use an experiment-agnostic deep learning model to account for the real-world use case where no training set exists that exactly matches the end-users' task and circumstances. With our approach we show improved performance as the number of subjects in the cBCI ensemble grows, and the potential to reconstruct ground-truth target occurrence in an otherwise noisy and complex environment.\"}\n","{'text': 'This paper proposes a method of analyzing and classifying traffic congestion information from two sources, Twitter and Waze Map, using artificial neural networks. The approach to mining the data involves the identification of correlation between keywords extracted from Twitter and Waze Map that are related to traffic congestion. The use of artificial neural networks helps to effectively categorize and classify the data, enabling the extraction of valuable information from these sources. The application of this method has potential benefits for traffic management and information systems, as it provides a more comprehensive understanding of traffic congestion patterns and can facilitate proactive traffic management strategies. Overall, this study demonstrates the effectiveness of using artificial neural networks for traffic data analysis and classification, and highlights the potential of social media data sources for enhancing traffic management systems.'}\n","{'text': 'Despite having one of the most efficient transportation systems in the world, Singapore is still faced with congestion issues regularly, especially during peak hour periods, due to a number of reasons. We investigate some of the factors contributing to this issue and propose a simulator supplied with predictive travel times through congestion prediction, in order to evaluate and improve bus utilization through effective scheduling. We introduced a conceptual framework to integrate neural network models into simulation so as to improve real-time supply based on several possibilities of demands. This paper will delineate the steps taken to produce the simulator and discuss the evaluation of these models.'}\n","{'text': \"Spatial databases have become a popular research topic due to the increasing amount of location-based data. Data mining is an effective way to extract valuable information from such databases. Clustering algorithms are widely used in data mining to group similar data together. DBSCAN is a widely used clustering algorithm that has been applied to many fields including the medical field. In this paper, we introduce a new framework for location prediction by designing and developing a Spatial DBSCAN Clustering framework. Our framework incorporates an optimization approach to enhance the accuracy of location prediction. We conducted experiments on hospital and river data to evaluate our framework's performance, and the results show that our framework outperforms existing methods. We also present our framework at several conferences to gather feedback from experts in the field. The framework has a wide range of applications in prediction algorithms and can be used to forecast future data trends.\"}\n","{'text': 'Aiming at the irrational size of LEACH protocol cluster and the imbalance of network energy consumption, an energy-equalized unequal clustering routing protocol is proposed. By introducing the energy decision factor and the density decision factor of node, the proposed method improves a threshold calculation formula of candidate cluster heads, and it is more likely that the nodes with more residual energy and more neighbor nodes become candidate nodes. The candidate cluster heads are elected to become the real cluster heads according to a certain competition radius. Since we consider the influence of the number of cluster heads and the distance between the nodes and the base station on the network energy consumption when determining the competition radius, then, the algorithm can divide the nodes into clusters of different sizes and make the size of the cluster close to the base station smaller, thereby effectively solving the â\\x80\\x9chot spotsâ\\x80?problem. Finally, the number of cluster heads and the cluster head distribution are more reasonable. The simulation results show that the improved algorithm can effectively balance the network consumption and prolong the network life cycle.'}\n","{'text': 'This paper proposes a novel approach to decision fusion for wideband cooperative sensing using artificial neural networks. The proposed method utilizes multiple receivers to enhance the signal to noise ratio of the sensed signal, which is then processed by a neural network composed of multiple neurons. The network employs shadow mapping to eliminate redundant and irrelevant information and make efficient use of computational resources. The system is designed for real-time applications, with low computational complexity and fast convergence. Results show that the proposed approach outperforms traditional methods in terms of accuracy and efficiency. Overall, this study demonstrates the potential of neural network-based decision fusion techniques in improving wideband cooperative sensing systems.'}\n","{'text': 'Forecasting time series data is a crucial subject in economics, business, and finance. Traditionally, there are several techniques to effectively forecast the next lag of time series data such as univariate Autoregressive (AR), univariate Moving Average (MA), Simple Exponential Smoothing (SES), and more notably Autoregressive Integrated Moving Average (ARIMA) with its many variations. However, with the advancements in computational power and machine learning, newly developed deep learning-based algorithms, such as Long Short-Term Memory (LSTM), have emerged. This article investigates whether and how deep learning-based algorithms are superior to traditional algorithms for time series data forecasting. The research question investigated in this article is that whether and how the newly developed deep learning-based algorithms for forecasting time series data, such as \"Long Short-Term Memory (LSTM)\", are superior to the traditional algorithms. The average reduction in error rates obtained by LSTM was found to be between 84-87 percent when compared to ARIMA, indicating the superiority of LSTM to ARIMA. More specifically, the average reduction in error rates obtained by LSTM was between 84 - 87 percent when compared to ARIMA indicating the superiority of LSTM to ARIMA. In conclusion, the developments in deep learning algorithms have provided a promising approach for time series data forecasting, surpassing the traditional techniques in accuracy and precision.'}\n","{'text': 'To manufacture high-quality electrical machinery, the accurate estimation of magnetization is required before the practical design. The early diagnosis of magnetization distribution with high accuracy decreases the number of inferior electrical machineries. Diagnosis methods to identify the magnetization distribution in a permanent magnet are classified into two types. The first method is based on destructive testing (e.g., electron backscatter diffraction patterns, X-ray diffraction). The second method is based on nondestructive testing using measurement data on magnetic flux density in the surrounding region of the magnet. While destructive testing takes several days, the measurement time for nondestructive testing using outside magnetic flux density is much shorter. However, one drawback of the nondestructive testing is that because the number of combinations of magnetization distribution to reconstruct the outside flux is infinite, the measurement error of the measured flux density in the outside leads to infeasible magnetization distribution. Thus, to overcome this difficulty, a diagnosis method for magnetization distribution based on the Fourier series expansion is proposed. The validity of the proposed method is demonstrated in a permanent magnet with multipole orientation.'}\n","{'text': 'In this paper, we investigate the outage performance of a general dual-hop multiple-input multiple-output (MIMO) amplify-and-forward (AF) relay network, where the source, relay and destination are all equipped with multiple antennas. By considering maximal-ratio-transmission (MRT) and maximal-ratio combining (MRC) for the transmitter and receiver, respectively, we first obtain the output signal-to-interference-plus-noise ratio (SINR) of the dual-hop AF relay system with multiple co-channel interferences (CCIs) and noise at the relay. Then, we derive closed-form expressions of the outage probability (OP) for both the fixed-gain and variable-gain multi-antenna relaying systems. Finally, computer simulations are carried out to validate the performance analysis. Our new analytical expressions not only provide a fast and efficient method to evaluate the outage performance of the system, but also enable us to gain valuable insights into the effects of key parameters on the performance of the dual-hop AF relaying system benefit from implementing multiple antennas at each of the three nodes in the relaying network.'}\n","{'text': \"This paper presents the design and real-time implementation of an Adaptive Neuro-Fuzzy Inference System (ANFIS) controller for greenhouse climate. The ANFIS controller utilizes fuzzy logic to control temperature dynamically and improve the greenhouse's performance. The implementation of the controller uses sensors to measure temperature, humidity, and other meteorological parameters. The proposed ANFIS controller adapts in real-time to the changes in the underlying system parameters and provides appropriate control outputs to maintain the targeted temperature regime. The paper also discusses the importance of green products and how the proposed ANFIS controller contributes to green technology. The study concludes that the ANFIS controller is an effective solution that can achieve precise temperature control in greenhouses, improving the yield and quality of crops, reducing energy consumption, and promoting sustainable agriculture practices.\"}\n","{'text': 'This paper proposes the use of a hybrid neural algorithm to process active infrared thermography data for the evaluation of thermal barrier coating thicknesses. The proposed algorithm combines genetic algorithms and biological neural networks to optimize the training of the neural network for accurate evaluation of coating thickness. This approach can help improve the accuracy and efficiency of the evaluation process and reduce the need for extensive physical testing. The results show that the hybrid neural algorithm can effectively process the infrared data and provide accurate evaluations of the coating thickness. This approach can have important applications in the optimization of heating systems and in the development and testing of new coatings. Overall, this study highlights the potential of hybrid neural algorithms for the processing of active infrared thermography data in the evaluation of thermal barrier coating thicknesses.'}\n","{'text': 'In this paper, we present a finite-time adaptive synchronization scheme for the drive-response two-layer networks with unknown parameters and unknown network topology. The proposed synchronization scheme can ensure that the response network tracks the state of the drive network in finite time, regardless of the network topology and parameter uncertainties. The scheme is based on perturbation methods and artificial neural networks, and is designed to adaptively adjust the coupling strengths and the network parameters online. Simulation results demonstrate the effectiveness and robustness of the proposed scheme. This work contributes to the field of adaptive systems and network synchronization, and has potential applications in various fields, such as robotics and control systems.'}\n","{'text': 'Computer sciences and related disciplines evolve around developing, evaluating, and applying algorithms. Typically, an algorithm is not developed from scratch, but uses and builds upon existing ones, which often are proposed and published in scholarly articles. The ability to capture this evolution relationship among these algorithms in scientific literature would not only allow us to understand how a particular algorithm is composed, but also shed light on large-scale analysis of algorithmic evolution through different temporal spans and thematic scales. We propose to capture such evolution relationship between two algorithms by investigating the knowledge represented in citation contexts, where authors explain how cited algorithms are used in their works. A set of heterogeneous ensemble machine-learning methods is proposed, where the combination of two base classifiers trained with heterogeneous feature types is used to automatically identify the algorithm usage relationship. The proposed heterogeneous ensemble methods achieve the best average F1 of 0.749 and 0.905 for fine-grained and binary algorithm citation function classification, respectively. The success of this study will allow us to generate a large-scale algorithm citation network from a collection of scholarly documents representing multiple time spans, venues, and fields of study. Such a network will be used as an instrument not only to answer critical questions in algorithm search, such as identifying the most influential and generalizable algorithms, but also to study the evolution of algorithmic development and trends over time.'}\n","{'text': 'Aiming at the problems of the complex modeling, large amount and variety of data in the 3D modeling of viaducts and underpass tunnels in digital city, a novel approach is proposed for the rapid construction of 3D urban road network based on the two-dimensional raster map. Extract the centerlines of roads from the two dimensional raster map of different layers, then the rapid three-dimensional solid modeling of the viaducts and underpass tunnels could be realized through the parametric modeling and texture mapping. The experimental results show that the proposed parametric modeling approach of the urban road network could greatly reduce the modeling time, and improve the design efficiency with better flexibility and interactivity.'}\n","{'text': 'Vehicle autonomy definitionally is the act of processing information gathered from the environment and acting on the decisions formed based on this information. Therefore, any autonomous paradigm can only perform as good as the quality of the information it can understand. Lane identification forms the foundation of many of the autonomous drive and driver-assist technologies. However, current methods are not always reliable, especially under the edge-cases. In this paper, we have experimentally evaluated and extended the state-of-the-art deterministic lane detection methods. Our evaluation provides experimental evidence towards their efficacy in extreme cases: real-data with sharp shadows and varying lighting that is recorded through a camera that has a limited field of view. Experimental results suggest that a method that builds similarly to human perception performs better-with an increase of 32% in its accuracy. Our hypothesis is that autonomous vehicles that can perform even under these extreme conditions will play an important role on the fully autonomous systems.'}\n","{'text': 'With the development of fingerprinting-based visual localization technology, a problem with this method is standing out, which is it takes great expenses in fingerprint collection. Recently, a few studies proposed some methods to alleviate this problem. However, the accuracy of the existing method is relatively low under some scenarios such as wide field of vision. In this paper, we propose a novel automatic visual fingerprinting (AVF) method for an indoor visual localization system. We consider the performance of AVF greatly hinges on visual odometry (VO) and ego-motion estimation (EME) block, which are two different ways of estimating fingerprint coordinates. Since both visual odometry and ego-motion estimation model are inaccurate, we build the least square model by second-order cone programming (SOCP). Our SOCP-based method is proposed to deal with the serious cumulative error and the random error introduced by VO and EME model, respectively. The purpose of this paper is improving the accuracy of the database generated by the AVF method under wide field of vision scenarios. Although the time costs are relatively higher than our compared method, fortunately, it is only on the off-line stage. The simulation results show that our method can provide a reliable image-location database with the consumer-grade smartphone camera.'}\n","{'text': 'Deception detection is a critical issue in various fields such as criminal justice, national security, and business. This paper presents a research study on identifying deception using phase synchrony in brain network. The study uses Electroencephalography and indexes for detecting deception. The research focuses on the feature extraction process using graph theory and wavelet analysis to extract features from the brain network. The brain probes are used to collect the data required for the study. The study aims to investigate the practicality of using the brain network for deception detection, and whether the extracted features can lead to accurate detection of deception. This research provides valuable insights into the potential use of phase synchrony in brain network analysis for detecting deception. The study has the potential to improve current methods used in various fields for deception detection, and contribute to a better understanding of the brain mechanisms involved in deception.'}\n","{'text': \"With the emergence of the Internet-of-Things (IoT) and seamless Internet connectivity, the need to process streaming data on real-time basis has become essential. However, the existing data stream management systems are not efficient in analyzing the network log big data for real-time anomaly detection. Further, the existing anomaly detection approaches are not proficient because they cannot be applied to networks, are computationally complex, and suffer from high false positives. Thus, in this paper a hybrid data processing model for network anomaly detection is proposed that leverages grey wolf optimization (GWO) and convolutional neural network (CNN). To enhance the capabilities of the proposed model, GWO and CNN learning approaches were enhanced with: 1) improved exploration, exploitation, and initial population generation abilities and 2) revamped dropout functionality, respectively. These extended variants are referred to as Improved-GWO (ImGWO) and Improved-CNN (ImCNN). The proposed model works in two phases for efficient network anomaly detection. In the first phase, ImGWO is used for feature selection in order to obtain an optimal trade-off between two objectives, i.e., reduced error rate and feature-set minimization. In the second phase, ImCNN is used for network anomaly classification. The efficacy of the proposed model is validated on benchmark (DARPA'98 and KDD'99) and synthetic datasets. The results obtained demonstrate that the proposed cloud-based anomaly detection model is superior in comparison to the other state-of-the-art models (used for network anomaly detection), in terms of accuracy, detection rate, false positive rate, and F-score. In average, the proposed model exhibits an overall improvement of 8.25%, 4.08%, and 3.62% in terms of detection rate, false positives, and accuracy, respectively; relative to standard GWO with CNN.\"}\n","{'text': \"This project transplants the deep learning framework to the android platform. It combines Deep learning based on Tensor Flow (TF) with Android software to recognize people's activities. Provided by android sensors, dataset is in the form of float arrays. And then we used them to train TF model with the data that was tagged by the different actions. Then we transplant the model into android to achieve activity recognition in mobile phone. In this project, six activities are recognized, including downstairs, upstairs, jogging, walking, sitting and standing. Finally, the probability of each activity will be seen in an android mobile phone. According to the results of experiments, almost all of six types of activities can be recognized successfully.\"}\n","{'text': 'Cross-media retrieval (CMR) is an attractive networked application where a server responds to queries with retrieval results of different modalities. Different from traditional information retrieval, CMR relies on a more enriched set of machine learning techniques to produce semantic models projecting multimodal data into a common space. A larger training dataset usually gives more accurate models, leading to a better retrieval result. Despite very promising with potential underpinnings in network analytics and multimedia applications, applying CMR in such contexts also faces severe privacy challenges, due to the fact that various data scattering among multiple parties may be sensitive and not allowed to be shared publicly. Studies jointly considering cross-media analytics, privacy protection, collaborative learning, and distributed networking contexts, are relatively sparse. In this work, we propose the first practical system for privacy-preserving cross-media retrieval by utilizing trusted processors. Our scheme enables secure aggregation of the data from distinct parties, and secure canonical correlation analysis (CCA) over collaborated data to obtain semantic models. Verification mechanisms are designed to defend against active attacks from a malicious adversary. Furthermore, to deal with large data sets, we provide a set of optimization methods to accomodate to limited trusted memory and improve the efficiency of training process in CMR. We consider issues such as data block splitting to manage memory overhead, ordering of operations as well as parameters reuse and release to simplify I/O, and parallel computation to speed up dual operations. Our experiments over both synthetic and real datasets show that our solution is very efficient in practice, outperforms the existing solutions, and performs comparably with the original CMR system.'}\n","{'text': 'Feature extraction and selection are crucial tasks in order to enhance the accuracy of facial expression systems. The distribution of geometric features and their quantity play a vital role in the quality of the image matching process, particularly for databases that pose more challenges for system accuracy. In this paper, we exploit a robust system to mitigate these challenges as this is essential for real-time applications. Our approach focuses on automatic geometric feature extraction from raw data using the popular method of deep learning for classification in neural networks. Our improved system consists of the following: solving the misalignment problem of the training images, lower complexity for geometric feature extraction, and finally, auto-encoder deep learning. We evaluate the performance of image-based expression recognition for the first time on three spontaneous databases with varying levels of challenges, using geometric and appearance-based features for comparison. These three spontaneous databases are VDMFP, MMI facial expression database, and BINED, each with diverse challenges in terms of system accuracy. Deep learning with a high-level feature representation, clearly outperforms state-of-the-art techniques.'}\n","{'text': 'Supervised deep learning depends on labeled datasets to define objective categorization of subject matter, but annotation is typically quite expensive for specialized domains. The ISIC 2017 skin lesion and BCCD blood cell image datasets are used to represent complex medical annotation scenarios, where domain knowledge is not permitted in either preprocessing or feature extraction. A low complexity supervision method is proposed, based on an iterative machine learning algorithm that fulfills the requirements for cognitive-assisted labeling. The visualization and editing of feature spaces is demanded where new label information must be integrated to improve the embedding quality as feedback mechanism. The annotators ability for fast local homogeneity assessment is leveraged through compound labeling prospects, which is the basis for achieving efficient labeling. Improved unsupervised feature extraction is hypothesized to reduce the labeling burden so the best feature extractors are empirically located at the various depths in ImageNet-pretrained convolutional neural networks, including VGG-16, Inception-v4 and Inception-Resnet-v2. Annotator emulation is performed to simulate upper bounds of achievable labeling efficiency and to explore active learning dynamics. A two-fold increase in efficiency is shown in the case of partial labeling, despite the complexity of the skin lesion data and the marginal improvement with pretrained features.'}\n","{'text': \"In this study was to present our framework of the new equipment development as called `Automatic Ladder Training'. The equipment was improved from an ordinary agility ladder training via image processing technique. The training with the ladder was the most significant to the athletes and some perspectives to improve their physical fitness. Traditional ladder training was necessary to have an instructor or a coach to record the athletes' training results, as it was important for their skill developments. As it costs and wasted times to make the record of training results. Therefore, we develop this equipment which can perform 3stepsof its working processes. First step, it will extract features of binary images and detect objective pixels from the trainees' feet. Second step, its alignment will be adjusted in the right position by using perspective transform to visualize a real ladder. Last step is time evaluation of athletes training. The start and the end of training time will be recorded through the pixels of athletes' feet entering and leaving the area of the ladder. To assure the reliability of our framework, we have tested our equipment with 240videos which contained 400Thai youths. From our experiment, the results which are compared to human can confirm our accuracy and achievement.\"}\n","{'text': 'Being able to describe a specific network as consistent is a large step towards resiliency. Next to the importance of security lies the necessity of consistency verification. Attackers are currently focusing on targeting small and crutial goals such as network configurations or flow tables. These types of attacks would defy the whole purpose of a security system when built on top of an inconsistent network. Advances in Artificial Intelligence (AI) are playing a key role in ensuring a fast responce to the large number of evolving threats. Software Defined Networking (SDN), being centralized by design, offers a global overview of the network. Robustness and adaptability are part of a package offered by programmable networking, which drove us to consider the integration between both AI and SDN. The general goal of our series is to achieve an Artificial Intelligence Resiliency System (ARS). The aim of this paper is to propose a new AI-based consistency verification system, which will be part of ARS in our future work. The comparison of different deep learning architectures shows that Convolutional Neural Networks (CNN) give the best results with an accuracy of 99.39% on our dataset and 96% on our consistency test scenario.'}\n","{'text': 'This article presents the prototype design and testing of a long-range, self-powered IoT devices for use in precision agriculture and aquaponics. The devices are designed using the ultra-low power nRF52840 microcontroller with Bluetooth 5 support and ambient energy harvesting. A power of 942Î¼W is harvested in an indoor environment. The devices are therefore suitable for both indoor and outdoor use, as natural sunlight will provide far more energy compared to artificial indoor lights. A line-of-sight range of up to 1.8km is achieved with the use of coded transmissions. However, the coverage area and range can be extended significantly by deploying the devices in multi-hop network topology. The custom multi-hop protocol provides energy efficient communication from any device in a wireless sensor network to a gateway while consuming an average of 267Î¼W with a transmission interval of 5 minutes. The sensor data is transmitted to a gateway, which then forwards it to a local server or cloud service, where the data can be analyzed to optimize the production in agriculture and aquaponics.'}\n","{'text': 'This paper presents a system applied in the automatic driving train using Case Based Reasoning (CBR) with Differential Evolution (DE). CBR was used to retrieve, reuse and revise experiences from real data during the journey. The DE was used to adapt the cases retrieved and optimize then considering multi-objective optimization. For this purpose, a train driving simulator used and the results compared the data of real train driving scenarios. Multi-objective optimization was used to reduce fuel consumption and also travel time. The results obtained concerning fuel consumption was entirely satisfactory because in some cases average savings of 45% in fuel consumption about the results obtained by human drivers. Adapting cases using the Differential Evolution approach led to a 5% gain in consumption over an adaptation of cases using Genetic Algorithm. It should also note that the time required for case adaptation was lower using Differential Evolution Algorithm than using Genetic Algorithm.'}\n","{'text': 'A key challenge in renal diagnosis using digital pathology has been the scarcity of reliable annotated datasets that can act as a benchmark for histological investigations. This paper uses a novel medical image dataset, titled Glomeruli Classification Database (GCDB), consisting of renal glomeruli images bifurcated into binary classes of normal and abnormal morphology. Based on this dataset, we direct our pioneering efforts to explore suitable deep neural network techniques related to kidney tissue slide imaging so as to establish a state of the art in this relatively unexplored domain. The paper focuses on classifying normal and abnormal categories of glomeruli which are the vital blood filtration units of the kidney. The results obtained using publicly available transfer learning models are held in comparison with supervised classifiers configured with image features extracted from the last layers of pre-trained image classifiers. Contrary to popular belief, transfer learning models such as ResNet50 and InceptionV3 are empirically proved to under-perform for this particular task whereas the Logistic Regression model augmented with features from the InceptionResNetV2 show the most promising results on the GCDB dataset.'}\n","{'text': 'The spiking neural network (SNN) is considered to be the third generation of neural networks featured by its low power consumption and high computing capability, which has great application potential in robotics. However, the present SNN has two limitations: 1) the neuronâ\\x80\\x99s spike firing time is calculated based on the iterative approach, which dramatically slows down the calculation rate of the SNN and 2) the existing learning algorithm is more suitable for the single-layer structure, which can hardly train the network with â\\x80\\x9cdeep structure.â\\x80?To this end, this paper proposes a novel spike firing time search algorithm that can narrow the search interval. In addition, a pretrained subnet SNN is designed, which makes the SNN have more hidden layers. This setting of the SNN can effectively improve its performance in pattern recognition tasks. Furthermore, by using the surface electromyography signal (sEMG), the proposed SNN is used to recognize the hand gestures. The experimental results show that: 1) the spike firing time search algorithm can significantly increase the forward propagation rate of the SNN and 2) the proposed SNN can reach a satisfactory recognition accuracy ratio 97.4%, which is 0.9% higher than that of the fully connected SNN.'}\n","{'text': 'This paper presents a classical constraint satisfaction problem and its solution using artificial intelligence. The problem involves finding a solution that satisfies a set of constraints. To solve this problem, the authors propose using genetic algorithms, a technique inspired by genetics and evolution. Cryptography is used to ensure the security and privacy of the data being processed. Artificial intelligence is used to optimize the solution and improve efficiency. Genetics provides a framework for understanding the behavior of the algorithm and making improvements. Additionally, fuzzy logic is used to handle uncertainty and incomplete information. The solution has implications for sociology, as it can be applied to a variety of real-world problems involving constraint satisfaction. Overall, the paper highlights the interdisciplinary nature of research in artificial intelligence and its potential for solving complex problems.'}\n","{'text': 'Autonomous mobile robot navigation is a very interesting problem to researchers. The electric wheelchair is a mobile robot for the disabled. The electrical wheelchair offers the possibility of outdoor or indoor autonomy navigation for a disabled person. Trajectory Tracking is a current topic in mobile robotics. In this paper a control strategy is developed. This strategy enables the electric wheelchair to follow a desired trajectory. A fuzzy logic controller is adopted in this approach. Also, a mathematical model is proposed as a kinematic model of the electric wheelchair. Then, a simulation results is presented to justify the efficiency of the method.'}\n","{'text': 'This paper introduces an innovative stochastic cascading failure (CF) model for analyzing power grid vulnerability utilizing the unscented transform (UT) and full ac power flow. The quasi-steady state (QSS) model is built upon previous dc power flow model by incorporating several enhancements. Our analysis shows that dc power flow does not provide an accurate estimation of the flow process under highly variable generation thus may underestimate the severity of the cascades. The incorporation of full ac power flow constraints allows us to access voltage profiles dynamics during CF in order to simulate voltage-related failures in the grid. To more accurately simulate protective system responses, we modeled undervoltage load shedding relays and a stochastic time-inverse overload relay. In addition, more realistic assumptions are considered in the modeling of wind power penetration using geographical information of grid topology and wind potential map for a given geographical area. The accuracy of the estimated flow process based on UT method is examined under different operating conditions in a 500-bus synthetic network. The proposed model was benchmarked against historical blackout data and widely used models in the literature, and displayed similar statistical patterns of blackout size.'}\n","{'text': 'We study distributed algorithms for seeking a Nash equilibrium in a class of non-cooperative games with strongly monotone mappings. Each player has access to her own smooth local cost function and can communicate to her neighbors in some undirected graph. We first consider a distributed gradient play algorithm, which we call GRANE, for determining a Nash equilibrium. The algorithm involves every player performing a gradient step to minimize her own cost function while sharing and retrieving information locally among her neighbors in the network. We prove the convergence of this algorithm to a Nash equilibrium with a geometric rate. Further, we introduce the Nesterov type acceleration for the gradient play algorithm. We demonstrate that, similarly to the accelerated algorithms in centralized optimization and variational inequality problems, our accelerated algorithm outperforms GRANE in the convergence rate.'}\n","{'text': 'Dictionary learning has emerged as a powerful tool for a range of image processing applications and a proper dictionary always plays a key issue to the final achievable performance. In this paper, a class-oriented discriminative dictionary learning (CODDL) method is presented for image classification applications. It takes a comprehensive consideration of multiple optimization objectives, emphasizing class discrimination of both dictionary atoms and representation coefficients. The atoms of the learned dictionary should be grouped into class level sub-dictionaries. Meanwhile, the sparse representation coefficients of an input sample should be concentrated on the sub-dictionary of the class it belongs to. Then, based on the learned class-oriented discriminative dictionary, the structured representation coefficients can thus be used for image classification with a simple and efficient classification scheme. The superior performance of the proposed algorithm is demonstrated through extensive experiments.'}\n","{'text': 'Phoneme lattices have been shown to be a good choice to encode in a compact way alternative decoding hypotheses from a speech recognition system. However the optimal phoneme sequence is produced by tracing all the phoneme identities in the lattice. This not only makes the search space of the decoder huge but also the final phoneme sequence may be prone to have false substitutions or insertion errors. In this paper, we introduce the split lattice structures that is generated by splitting the speech frames based on the manner of articulation. Spectral flatness measure (SFM) is exploited to detect the two broad manner of articulation sonorants and non-sonorants. The manner of sonorants includes broadly the vowels, the semivowels and the nasals whereas the fricatives, stop consonants and closures belong to non-sonorants. The conventional way of speech decoder produces one lattice for one test utterance. In our work, we split the speech frames into sonorants and non-sonorants based on SFM knowledge and generate split lattices. The split lattice generated are modified according to the manner of articulation in each split so as to remove the irrelevant phoneme identities in the lattice. For instance, the sonorant lattice is forced to exclude the non-sonorant phoneme identities and hence minimizing false substitutions or insertion errors. The proposed split lattice structure based on sonority detection decreased the phone error rates by nearly 0.9 % when evaluated on core TIMIT test corpus as compared to the conventional decoding involved in the state-of-the-art Deep Neural Networks (DNN).'}\n","{'text': 'As researches on robots and robotic arms going further, human portrait painting robot appears as a typical art creation application. Traditional ways to achieve this goal mainly depend on the geometric and texture features with no semantic information. In this system, to enrich the portrait, key points of human faces are fused with gray scale information. During the process of drawing, different components of the portrait can be distinguished such as hair or eyes by strokes. Besides, sketch pattern is added to line drawing model using cluster algorithm and presents a unique style. The painted results combine outline and sketch characters different from preceding work and each costs less than two minutes to finish an outline portrait and 4-6 minutes with sketch pattern.'}\n","{'text': 'In computer vision, feature extraction plays a critical role in the successful implementation of object detection and recognition systems. One of the significant challenges in feature extraction is removing the effects of variable orientations and lighting conditions on the images. To overcome this problem, researchers have proposed a new 2D-feature descriptor that is free from orientation compensation. This descriptor, called \"histograms,\" is based on the idea of utilizing local intensity gradients. This method calculates gradients for image patches in multiple directions and then construct histograms of the gradient magnitudes. The descriptor is unique in that it can be used without the need for a prior orientation estimation step. The histograms descriptor is tested on a dataset containing images of dogs, and it is shown to achieve excellent results in terms of both resistance to variable orientations and lighting conditions and detection accuracy. The new feature descriptor is promising and represents a significant improvement over traditional methods that require orientation compensation. Therefore, it has enormous potential for use in object recognition and detection systems.'}\n","{'text': 'Mathematical word problems have been consistently considered one of the most difficult obstacles in mathematics education. Semantic parsing, as a natural language processing technique, has demonstrated a huge potential in tackling mathematical word problems by converting text to formal mathematical expressions. This survey seeks to provide a thorough understanding of the state-of-the-art in automatic math word problem solvers based on semantic parsing. It examines the challenges and limitations of existing methods and highlights the importance of feature extraction and mathematical modeling in successful problem solving. Moreover, this survey presents a comprehensive review of current approaches that employ deep learning techniques to improve the accuracy of semantic parsing. Although the development of automatic math word problem solvers is still in its early stages, this survey offers a promising path for future research and advancements in the field of cognition and natural language processing.'}\n","{'text': 'High-capacity TDM-PONs, TWDM PONs, and WDM PONs have great potential to be used as next-generation PONs in emerging broadband services for various applications. As PONs typically use direct detection techniques and low-cost components, transmission impairments become one of the main limiting factors. Various transmission impairment compensation techniques, including both optical and digital signal processing (DSP) based techniques, are proposed and demonstrated for high-speed TDM-, TWDM-, and WDM-PONs. In this article, we describe the next-generation PON schemes and principles of different compensation techniques. We propose filter type optical compensation and Volterra type electrical compensation techniques to compensate nonlinear inter-symbol interference caused by vestigial sideband, limited modulation bandwidth, in-phase and quadrature imbalance, dispersion, and square-law detection. In addition, analyses and comparison of the equilibrium performances, features, characteristics, and applicability of the various optical- and electrical-domain compensation schemes are presented.'}\n","{'text': 'Modern convolutional neural network (CNN) models offer significant performance improvement over previous methods, but suffer from high computational complexity and are not able to adapt to different run-time needs. To solve above problem, this paper proposes an inference-stage pruning method that offers multiple operation points in a single model, which can provide computational power-accuracy modulation during run time. This method can perform on shallow CNN models as well as very deep networks such as Resnet101. Experimental results show that up to 50% savings in the FLOP are available by trading away less than 10% of the top-1 accuracy.'}\n","{'text': 'The advent of Cloud Native Microservices [1] has brought new challenges. Among them, the need to understand and monitor the complex and dynamic distributed systems that have become web applications. This demonstration present presents observability framework for microservices orchestration. The developed observability framework provides the means to understand the internal behavior of microservices at different layers, lifetime and abstraction levels. This demonstration utilizes a cloud-based infrastructure for observability framework and need an only a web-browser for a front-end.'}\n","{'text': 'In recent years, object detection and image segmentation have been active research fields in computer vision. However, these techniques are vulnerable to adversarial attacks that can compromise their performance. This research aims to tackle this issue by proposing a new method called ROSA â\\x80?Robust Salient Object Detection Against Adversarial Attacks. ROSA is designed to improve the robustness of object detection by exploiting the properties of image labeling, feature extraction, and neural networks. The training methodology of ROSA involves using adaptation models to teach the neural network to recognize and handle adversarial attacks by adjusting its internal parameters. Experimental results show that ROSA achieves better performance than existing methods in detecting salient objects in images under various adversarial scenarios.'}\n","{'text': 'Mobile Edge Cloud Computing Architecture (MEC-CA) presents key opportunities in performance improvement and energy saving for resource constrained mobile device. The mobile applications such as healthcare application, Augmented Reality can be modeled by task graphs. This work investigates the problem of dynamic application and scheduling tasks (which belong to the same or possibly different applications) in the MCCA environment. Nevertheless, the existing offloading system algorithms did not consider network failure and cloud resource in their MCCA paradigm. More specilically, we suggest the dynamic application partitioning and task scheduling (DAPTS) algorithm such that the application completion time constraint are satisfied while the total energy dissipation of the mobile device and cloud resources is minimized. Performance evaluations result demonstrates that proposed DAPTS outperform minimize the objective function in context of completion time and energy use as compared to the baseline approaches.'}\n","{'text': 'In this paper, a novel algorithm based on convolutional neural network (CNN) and support vector machine (SVM) for fire detection in infrared (IR) video surveillance is proposed. To improve the performance of IR fire detection, we develop a 9-layer convolutional neural network named IRCNN instead of traditional empirically handcrafted methods to extract IR image features. Then, a linear support vector machine is trained with extracted features to achieve fire detection. Our network adopts data augmentation technique and Adam optimization to deal with problems caused by the insufficient dataset, and accelerate the training process. Experimental results show that our method achieved both high precision (98.82%) and high recall (98.58%) on our IR flame dataset and real-time detection on the ordinary infrared surveillance cameras.'}\n","{'text': 'This paper addresses the problem of optimal sampling of multiple linear processes that share a common communication medium. The objective is to estimate the processes while minimizing the resource utilization. The authors propose an optimization framework that takes into account stochastic processes and capacitive sensors to achieve efficient resource management. The proposed method is evaluated on a sensor system experiment and shows significant improvement in terms of estimation accuracy and resource utilization compared to other strategies. This work contributes to the development of efficient and effective sampling methods for sensor networks, which can have applications in many fields such as environmental monitoring and industrial control.'}\n","{'text': 'Educational-support robots are being increasingly used to support learning among students. In previous studies, robots have taught only how to solve questions. Using such robots, it is difficult for learners to improve their applied skills and creativity, because these robots were not able to prompt learners to think. Thus, in this research, we develops a robot that supports learning by using the cognitive apprenticeship theory. Previous studies have reported that the pedagogy based on cognitive apprenticeship theory can prompt learners to think through the problems. Therefore, using the cognitive apprenticeship theory method for teaching can improve the applied skills and curiosity of the learner. In this paper, we investigates the effects of educational support robots based on the cognitive apprenticeship theory in collaborative learning with junior high-school students.'}\n","{'text': 'We consider the problem of estimating the elevation angle in the presence of multipath. The proposed method belongs to the class of maximum-likelihood-like estimators and employs a modified specular reflection model that accounts for the uncertainty of the steering vector by assuming that they are subject to unknown deterministic perturbations with bounded norms. The analysis, performed using convex optimization methods, allows us to obtain computationally efficient implementations of the approach. Real-world results and computer simulations confirm the improved behavior of the proposed robustified estimators.'}\n","{'text': 'Parameter estimation is an essential task in software reliability growth modeling (SRGM) for predicting the reliability of software. This research proposes a Crow Search Optimization (CSO) based approach for parameter estimation of SRGMs. This approach is based on the optimization algorithm of the social crow search behavior. The CSO algorithm is used to optimize the parameters of the SRGMs, which can provide better fitting of the data models. The proposed approach is compared with the existing optimization algorithms, such as Genetic Algorithm (GA) and Particle Swarm Optimization (PSO). The experimental results demonstrate that the proposed approach can achieve better results than the traditional optimization algorithms in terms of the accuracy and efficiency of parameter estimation. The proposed approach is also evaluated using real-world software reliability data sets. The results show that our proposed approach can effectively estimate the parameters of the SRGMs and improve the prediction accuracy. This research provides a new perspective for researchers in the field of software reliability testing and is of great significance for practical applications.'}\n","{'text': 'Direction-of-arrival (DOA) estimation is an essential technique in array signal processing. This paper proposes a new approach to DOA estimation using multi-level prime array with compression. The method is based on linear antenna arrays with multiple apertures, where the prime elements are arranged in multiple levels to form the array. The structure of the array allows for higher sparsity in the incoming signals, which in turn enables better estimation accuracy. Additionally, the compression technique is used to reduce the dimensionality of the received data, improving the computational efficiency. This paper analyzes the performance of the proposed method using the multiple signal classification (MUSIC) algorithm. Simulation results indicate that the proposed method provides superior DOA estimation accuracy compared to existing methods, particularly in scenarios where the number of sources is small and the signals are highly sparse. Therefore, the proposed method is expected to be particularly useful in applications such as wireless communication systems, radar, and sonar.'}\n","{'text': 'This paper investigates the improvement in accuracy and efficiency of the ray-launching geometrical optics method, as implemented in different versions of FEKO, and shooting-and-bouncing-rays with physical optics method, as implemented in SigmaHat, to calculate the radar cross section (RCS) of a large complex model airframe. A scale model Boeing 707 (106Î») and accurately scanned CAD model is utilized for this study. The investigation is conducted by comparing the calculated RCS to measured data, obtained in a compact range, using angular RCS graphs and ISAR imaging. Interesting results are obtained and some clear improvements can be observed in the accuracy as well as efficiency of the methods.'}\n","{'text': 'Finding recurrent patterns within a data stream is important for fields as diverse as cybersecurity or e-commerce. This requires to use pattern mining techniques. However, pattern mining suffers from two issues. The first one, known as \"pattern explosion\", comes from the large combinatorial space explored and is the result of too many patterns outputed to be analyzed. Recent techniques called output space sampling solve this problem by outputing only a sampled set of all the results, with a target size provided by the user. The second issue is that most algorithms are designed to operate on static datasets or low throughput streams. In this paper, we propose a contribution to tackle both issues, by designing an FPGA accelerator for pattern mining with output space sampling. We show that our accelerator can outperform a state-of-the-art implementation on a server class CPU using a modest FPGA product.'}\n","{'text': 'This paper focuses on the development of a deep gender classification and visualization system for near-infra-red periocular-iris images. The system utilizes feature extraction methods such as iris recognition and database retrieval to accurately classify genders in visualization results. To effectively train the system, various task analysis and load modeling techniques were employed. Results show that the system achieves high classification accuracy and robustness. The proposed methods and techniques can potentially be extended to other periocular-iris recognition tasks.'}\n","{'text': \"This paper introduces an ultra low-power drowsiness detection system known as BioWolf. The system is designed for biomedical monitoring using electroencephalography (EEG) to detect drowsy states. The feature extraction algorithm is optimized for monitoring the head's EEG signals, which are then processed by the hardware before being transmitted to Microsoft Windows software. By utilizing low-power components, this system can operate for extended periods of time without requiring frequent battery replacement. The BioWolf system is a promising solution for monitoring drowsiness levels in situations where the detection of tiredness is critical, such as driving or operating heavy machinery.\"}\n","{'text': 'An analysis was conducted on the use of light emitting diodes (LEDs) and printed electroluminescent elements for the manufacturing of flexible displays that can be seamlessly integrated into textile items. The comparative investigation focused on the necessary manufacturing processes, on the architecture of driver electronics, on achievable display brightness, on lifetime expectations and reliability aspects of the systems. This comparative study led to the development of printed electroluminescent display demonstrators, which were integrated into jackets for a field test. The systems produced were described in detail, and the results of the analysis were presented.'}\n","{'text': 'This article provides a novel continuous-time state feedback control strategy to stabilize an eigenstate of the Hermitian measurement operator of a two-level quantum system. In open loop, such system converges stochastically to one of the eigenstates of the measurement operator. Previous work has proposed state feedback that destabilizes the undesired eigenstates and relies on a probabilistic analysis to prove convergence. In contrast, we here associate the state observer to an adaptive version of so-called Markovian feedback (essentially, proportional control) and we show that this leads to a global exponential convergence property with a strict Lyapunov function. Furthermore, besides the instantaneous measurement output, our controller only depends on the single coordinate along the measurement axis, which opens the way to replacing the full state observer by lower-complexity filters in the future.'}\n","{'text': 'In this paper, the authors design a controller for a robot-trailer system to solve the path following problem. A kinematic state-space model is derived using tractor steering angle rate as system input so that undesirable effects of input disturbances can be reduced. A tracking error of the trailer position may exist when there are biases on the measurements of heading angles. An improved integral separation combined with linear quadratic regulator (LQR) is designed for the system to remove the trailer position error. The tractor relative location is used to estimate whether the system is under steady state. The controller with integral action can be difficult to tune, so a genetic algorithm (GA) is then used to find optimal LQR controller parameters. Simulation results verify the approaches above.'}\n","{'text': 'This paper proposes a novel time-varying nonsingular terminal sliding mode (TVNTSMC) control algorithm for the attitude control of a rigid spacecraft, which gives the user the ability to select convergence time in advance and also ensures global robustness to undesired external disturbances. The satellite dynamics are represented using minimal (three dimensional) Modified Rodrigues Parameters (MRP) description, which is then transformed into Lagrangian form and is used to formulate the state-space representation. A new non-linear sliding surface is designed in terms of the MRP parameters and a piecewise continuous time-varying function which is then used for expressing the attitude control algorithm. The expressions for settling time and convergence time to the origin of the system are calculated using Lyapunov theory. The design parameters of the time-varying function are derived from the user-specified convergence time, which ensures that the system states converge to the origin at the pre-specified time. The global finite-time stability of the overall system in the presence of external disturbances is shown using the Lyapunov method. The simulations are carried out for different user chosen convergence times to elucidate the efficacy of the proposed control.'}\n","{'text': 'The classic objective in a reinforcement learning (RL) problem is to find a policy that minimizes, in expectation, a long-run cost objective such as the infinite horizon discounted or average cost. In many practical applications, optimizing the expected value alone is not sufficient and it may be necessary to include a risk measure in the optimization process either as the objective or a constraint. Various risk measures have been proposed in the literature, e.g., mean-variance tradeoff, exponential utility, the percentile performance, value at risk, conditional value at risk, prospect theory and its later enhancement, cumulative prospect theory. In this two-part article, we are primarily concerned with the combination of risk criteria and reinforcement learning in a constrained optimization framework, i.e., a setting where the goal to find a policy that minimizes the usual objective of infinite horizon discounted/average cost, while ensuring that an explicit risk constraint is satisfied. In this part, we introduce the risk-constrained RL framework, cover popular risk measures based on variance, conditional value-at-risk and cumulative prospect theory and present a template for a risk-sensitive RL algorithm. In a companion paper, we survey some of our recent works on this topic, covering problems encompassing discounted, average and stochastic shortest path settings, together with the aforementioned risk measures in a constrained framework. This non-exhaustive survey is aimed at giving a flavor of the challenges involved in solving a risk-sensitive RL problem, and outlining a few challenging future research directions.'}\n","{'text': 'As IOT is a coming out as an emerging technology from the last few decades and the demand for the devices based on IOT are also increasing. Encryption methods that are cost-effective, reliable, and size-effective, with small key sizes are essential for IoT devices. This calls for the proper encryption method which is cost effective, reliable, size effective and also uses small key size. Many of the encryption methods are proposed till now for the same but still we always have a room for improvement, in this paper we analyzed an effective algorithm which provides security for the IOT based devices as well as meet the specifications which are mentioned above. Simulation and results shows that the proposed algorithm is effective to provide security with cost and size effective design.'}\n","{'text': 'Device-to-device (D2D) communications have been proposed as a promising technology to improve system capacity and user experiences. In moving D2D-enabled heterogeneous ultra-dense networks (H-UDNs), it will cause heavy system overhead from the frequent mode selection between D2D mode and cellular mode, which is also belong to handover strategies. Thus, the optimization of mode selection strategy is needed urgently. In this paper, for the mode selection occurring from cellular communication mode to D2D communication mode (C2D), we propose a feed-forward neural network (FFNN) based multi-attribute D2D transmitter choosing strategy. Our proposed strategy seamlessly integrates the FFNN model with stochastic geometry based long-term analytical results, along with instant parameters involved in the mode selection process. As a result, our proposed strategy brings improvements to the mode selection performance, which can be observed in reducing the mode selection probability and increasing the D2D mode dwell time. Additionally, we have successfully achieved full-spectrum reuse, which has further reduced system overhead.'}\n","Processing batch 50/63\n","{'text': 'A statistical model for predicting the output power and energy of Solar Photovoltaics (PV) has been developed. The multiple input single output (MISO) system is based on Jackknife regression and generates PV power in kilo-watts in response to inputs that include irradiance, precipitation, ozone, ambient temperature and atmospheric aerosol components. The model is trained and tested on data from National Renewable Energy Laboratory and residual statistical tests are applied to validate the estimation results. An absolute error of less than 1 kW is observed for 90.6 % of the predicted values that corresponds to a percentage error of less than 8.33 % for the 12 kW system under study.'}\n","{'text': 'Underwater sensor networks have received significant attention due to their potential to support a range of applications, including environmental monitoring, oceanographic research, and defense operations. One of the key challenges faced by these networks is the evolution of temporal mobility patterns, particularly in freely floating scenarios. This study investigates the role of force and protocols in shaping the mobility patterns of underwater sensor networks using a combination of numerical models and differential equations. We focus on the use of underwater acoustics as a means of communication between sensors and consider the impact of various wireless sensor network configurations on temporal mobility. The results suggest that incorporating force and protocol design in the shape of underwater sensor networks is essential for improving their temporal mobility. Overall, this study highlights the importance of considering both the physical and communication aspects of underwater sensor networks in their design and operation.'}\n","{'text': 'Neuromorphic systems aim to mimic the structure and function of the human brain to perform tasks that traditional computers struggle to solve. This paper proposes a multilayer-learning current-mode neuromorphic system with analog-error compensation. The hardware architecture uses pulse width modulation to convert digital input signals to analog signals for more efficient computation. The neural networks are modeled using synapses with analog weights for improved energy efficiency. The system demonstrated successful approximation of various functions and exhibited better performance compared to traditional computing methods. The proposed architecture has potential applications in artificial intelligence and can pave the way for developing more advanced neuromorphic systems.'}\n","{'text': \"Power system stability is an essential aspect that must be accurately analyzed in order to ensure reliable and efficient operations of power systems. This study proposes a transient stability analysis approach utilizing the Adaptive Neuro Fuzzy Inference System (ANFIS) and Sobol Sequence. The proposed method combines fuzzy logic and artificial neural networks to effectively model and predict power system transients. The ANFIS-based model is trained using Sobol Sequence which incorporates global sensitivity analysis to enhance the model's accuracy and efficiency. The proposed methodology is tested on a sample power system, and the results demonstrate that the ANFIS-based approach outperforms conventional analytical methods in terms of accuracy and speed. The study concludes that the proposed approach can effectively contribute to the development of mathematical models for power system stability analysis.\"}\n","{'text': \"This paper presents a robust nonlinear tracking control approach for a 2-DOF helicopter system under uncertainty. The study focuses on the control of helicopters, which are complex and nonlinear systems that require precise control for stable flight. The proposed control strategy incorporates a computational modeling technique using aerodynamics to compute the torque and force on the propellers. Additionally, observers are integrated with the control strategy to estimate the helicopter's velocity and displacement, which are essential for precise control. The system's uncertainty is handled by designing a robust control law that can track the desired trajectory even in the presence of uncertainties. The effectiveness of the proposed control approach is verified through simulations, which show good performance even for highly uncertain conditions. This study provides a valuable contribution towards developing robust control strategies for complex nonlinear systems like helicopters.\"}\n","{'text': 'Incorporating Human Visual System (HVS) models into building of classifiers has become an intensively researched field in visual content mining. In the variety of models of HVS we are interested in so-called visual saliency maps. Contrarily to scan-paths they model instantaneous attention assigning the degree of interestingness/saliency for humans to each pixel in the image plane. In various tasks of visual content understanding, these maps proved to be efficient stressing contribution of the areas of interest in image plane to classifiers models. In previous works saliency layers have been introduced in Deep CNNs, showing that they allow reducing training time getting similar accuracy and loss values in optimal models. In case of large image collections efficient building of saliency maps is based on predictive models of visual attention. They are generally bottom-up and are not adapted to specific visual tasks. Unless they are built for specific content, such as \"urban images\"-targeted saliency maps we also compare in this paper. In present research we propose a \"bootstrap\" strategy of building visual saliency maps for particular tasks of visual data mining. A small collection of images relevant to the visual understanding problem is annotated with gaze fixations. Then the propagation to a large training dataset is ensured and compared with the classical GBVS model and a recent method of saliency for urban image content. The classification results within Deep CNN framework are promising compared to the purely automatic visual saliency prediction.'}\n","{'text': 'Channel estimation is a crucial aspect of wireless communication systems, particularly for vehicular communications. This paper investigates the performance of IEEE 802.11-based channel estimators under the non-WSSUS (wide-sense stationary uncorrelated scattering) condition. The study utilizes OFDM (orthogonal frequency-division multiplexing) modulation scheme, and leverages training sequences for channel estimation. Furthermore, time-frequency analysis and interpolation techniques are applied for enhancing the accuracy of the channel estimates. The results demonstrate that the non-WSSUS condition has a significant impact on the performance of the channel estimators, as it leads to weaker correlation among the channel taps. However, with the proposed techniques, the accuracy of the estimates could be improved, even under the non-WSSUS condition. These findings illustrate the importance of implementing efficient channel estimation schemes for reliable and efficient vehicular communication systems.'}\n","{'text': 'In this paper, we present a technique for representing behavioral dynamical systems as Generalized Synchronization Trees (GSTs). Our proposed representation method involves unrolling Labeled Transition Systems (LTSs) into bisimilar Synchronization Trees (STs), providing a similar analog to the LTS unrolling process. By establishing conditions under which bisimilar behavioral systems result in bisimilar GST representations, we can ensure that bisimulation equivalence is preserved. Preservation of bisimulation equivalence is critical to future study of composition operators for behavioral systems and GSTs. In addition to the representation method, we define a composition operator for GSTs created using behavioral systems and demonstrate a congruence result for strong bisimulation.'}\n","{'text': 'Fine-grained visual categorization is to recognize hundreds of subcategories belonging to the same basic-level category, which is a highly challenging task due to the quite subtle and local visual distinctions among similar subcategories. Most existing methods generally learn part detectors to discover discriminative regions for better categorization performance. However, not all parts are beneficial and indispensable for visual categorization, and the setting of part detector number heavily relies on prior knowledge as well as experimental validation. As is known to all, when we describe the object of an image via textual descriptions, we mainly focus on the pivotal characteristics and rarely pay attention to common characteristics as well as the background areas. This is an involuntary transfer from human visual attention to textual attention, which leads to the fact that textual attention tells us how many and which parts are discriminative and significant to categorization. So, textual attention could help us to discover visual attention in the image. Inspired by this, we propose a fine-grained visual-textual representation learning (VTRL) approach, and its main contributions are: 1) fine-grained visual-textual pattern mining devotes to discovering discriminative visual-textual pairwise information for boosting categorization performance through jointly modeling vision and text with generative adversarial networks, which automatically and adaptively discovers discriminative parts and 2) VTRL jointly combines visual and textual information, which preserves the intra-modality and inter-modality information to generate complementary fine-grained representation, as well as further improves categorization performance. Comprehensive experimental results on the widely used CUB-200-2011 and Oxford Flowers-102 datasets demonstrate the effectiveness of our VTRL approach, which achieves the best categorization accuracy compared with the state-of-the-art methods.'}\n","{'text': 'The interpretation of scintillation Doppler and intensity spectra requires the estimation of the irregularity parameter, which characterizes the strength of small-scale ionospheric irregularities. This parameter is essential for the analysis of the Doppler effect and other fitting indexes in the data. In this paper, we present a mathematical model and methods for parameter estimation based on the measurements performed by receivers. We propose a yield estimation technique that combines multiple measurements to increase the accuracy of the estimated irregularity parameter. Our results demonstrate the effectiveness of our approach in estimating the irregularity parameter and improving the interpretation of scintillation Doppler and intensity spectra.'}\n","{'text': 'Whether the performance of speech system is good or not is closely related to its characteristic parameters. An excellent feature extraction method is a key step in forming a good recognition system. A good feature extraction method can improve the design and performance of the acoustic classifier. In this paper, a feature extraction algorithm based on human-ear perceptual characteristics is presented, which differs from the traditional Mel Frequency Cepstrum Coefficients (MFCC). This paper presents and studies the method of extracting feature parameters from Wavelet packet transform applied to bark-scale filter, and the feature extraction method based on Gammatone filter. Finally, it is proved that the Wavelet packet transform and the feature extraction method based on Gammatone filter can greatly improve the recognition rate through simulation and experiment.'}\n","{'text': \"In today's Era of Cybersecurity, hardware and cryptography have become increasingly important in the field of computer security. Cryptographic hardware and embedded systems have been developed to ensure the confidentiality, integrity, and authenticity of data. With the rise of the Internet of Things (IoT), more emphasis has been placed on hardware security and cryptography to prevent potential attacks on IoT devices. Computer architecture plays a critical role in the design and implementation of secure hardware and cryptographic systems. Many conferences have been held to discuss the latest advancements in hardware and cryptography, as well as to address the ongoing challenges in computer security. As security threats continue to evolve, it is essential to continue researching and developing new hardware and cryptographic systems to ensure the safety and protection of sensitive information.\"}\n","{'text': 'Recommender systems have gained immense attention in recent years due to their ability to predict user preferences and recommend relevant items to users. However, challenges still exist in developing more accurate and effective recommender systems. This paper explores the use of word embedding models to improve context-aware recommender systems through data mining techniques, context modeling, and feature extraction. The proposed approach involves developing data models that take into account contextual factors such as time, location, and user behavior. Additionally, the cleaning of data is also a crucial step in the proposed methodology to remove irrelevant information and obtain reliable recommendations. Overall, this paper proposes a novel approach to improve context-aware recommender systems, which can enhance usersâ\\x80?online experience and help businesses increase their revenue.'}\n","{'text': 'CNN methods for image super-resolution consume a large number of training-time memory, due to the feature size will not decrease as the network goes deeper. To reduce the memory consumption during training, we propose a memory optimized deep dense network for image super-resolution. We first reduce redundant features learning, by rationally designing the skip connection and dense connection in the network. Then we adopt share memory allocations to store concatenated features and Batch Normalization intermediate feature maps. The memory optimized network consumes less memory than normal dense network. We also evaluate our proposed architecture on highly competitive super-resolution benchmark datasets. Our deep dense network outperforms some existing methods, and requires relatively less computation.'}\n","{'text': 'This paper designs a smart urban environment monitoring system based on the wireless network of ZigBee to complete the real-time collection of urban environment information. The system consists of the basic monitoring network and the remote receiving terminal. The basic monitoring network connects the streetlights as routes and the taxis as nodes. After dynamically organizing the network, each node is assigned with an address as the only identity in the network. Then, the system designed conducts the simulation experiment to prove that it could meet the needs and send the collected information to the designated terminal in the form of message according to the setting. The sensor organized through the wireless network of ZigBee could inspire the infrastructure construction of the smart city. With the network, a smarter and more comfortable society could be well offered to people.'}\n","{'text': 'Internet of Things (IoT) technologies are quickly entering in every aspect of our life, definitely changing the way we interact with smart objects. Such technologies allows to set-up solutions that can be used not just for practical activities, but also for didactic and research. This paper presents the development of an IoT-based environmental monitoring system for indoor workplaces. The remotely accessible monitoring system allows the students to add/remove sensors to the network, configure the nodes and the network, deal with different kind of sensors and controllers, analyze and postprocess the collected data. It also allows to compare the energy consumptions for environmental control with the real environmental wellness. The implemented network and the available didactic scenarios are discussed.'}\n","{'text': 'This paper proposes a localized deep norm-CNN structure for face verification, which focuses on the feature extraction and training based on deep learning. The proposed method takes a holistic approach, as it integrates the skin color information with task analysis to build an effective and robust face verification system. The proposed structure utilizes a novel combination of 3D convolutions and 2D convolutions to encode both the spatial and temporal features of the face. Experimental results demonstrate the efficacy of the proposed method in achieving high accuracy in face verification tasks. Additionally, the proposed method is highly efficient, which indicates that it can be used in a wide variety of applications such as three-dimensional displays. Overall, the proposed localized deep norm-CNN structure is an innovative and powerful tool for face verification and deep learning research.'}\n","{'text': 'Real-time quality prediction in continuous casting process is of great significance to the increase of production and the improvement of casting billet quality. The process parameters have a great influence on the quality of the billet in the continuous casting process, and the quantity distribution of the superior and inferior products in the casting billet is extremely unbalanced. Therefore, this paper proposes an intelligent prediction method for casting billet quality based on multi-process parameters. Based on the analysis of the relationship between multiple process parameters and casting billet quality, a casting quality prediction model based on weighted random forest (WRF) algorithm was established. This algorithm solves the sample imbalance problem by weighting the decision tree results effectively, and can correctly identify negative samples. Based on real-time casting billet data in the production process, results of the case prove the effectiveness of the proposed method.'}\n","{'text': 'This paper proposes a Bayesian estimator based weather forecasting approach using Wireless Sensor Networks (WSN). The estimation process utilizes Bayes methods to predict weather conditions. The focus is on the use of support vector machines (SVMs) to establish data models. The proposed method has the advantage of being battery-powered, which reduces maintenance efforts. Moreover, it employs sensors for data collection, enabling accurate predictions. The research demonstrates that with the deployment of WSNs, the weather forecasting accuracy can be improved, which can have significant implications in various fields, such as agriculture, transportation, and construction.'}\n","{'text': 'Hybrid beamforming (BF) is a promising solution for massive MIMO with limited RF chains. To reduce the amount of pilot overhead for channel estimation, compressed sensing techniques that exploit channel sparsity have been proposed. One key issue is how to design the RF (analog) training vectors to achieve higher BF gain with fewer pilots. Specifically, narrow-beam RF training requires large pilot overhead for finding strongest paths, and random RF training suffers from low BF gain. We propose to use a mixture of narrow-beam and random RF training vectors, and optimize the fraction of the two sets of RF training vectors based on channel support side information (CSSI) at the BS. We show that this optimized fraction exhibits a phase transition: when the CSSI accuracy exceeds a certain threshold, the maximum number of narrow-beam RF training vectors should be used to focus beams in all directions indicated by the CSSI. Otherwise, only random RF training vectors should be used to explore the unknown channel support. Moreover, we derive closed-form bounds on the channel estimation error. Both the analysis and simulations show that the proposed method can achieve substantial gains over various baseline methods.'}\n","{'text': 'Collaboration has been an integral part of software development history, with merging being a crucial task. In order to optimize the merging process, it is important to recommend suitable participants for collaborative merge sessions. This can be achieved through task analysis and data mining techniques which can help identify individuals with the necessary skills and experience to contribute effectively to the merging process. Software tools can play a key role in facilitating the collaborative merging process by providing features such as version control and real-time collaboration. By implementing effective participant recommendation strategies, software development teams can improve the efficiency and quality of their merging process.'}\n","{'text': 'The current work emphasizes on a Taxi rental company which possess 30 cars. In an effort to benchmark the company\\'s performance and functionality/usability system, the owner of the company decided to utilize the cars as much as possible in such a way to avoid any Taxi remaining in an idle/inactive status. The company\\'s system typically was consisted of the following steps as follows: a Taxi car is usually used by a pair of two different drivers within 24 hours so as the first driver takes care of the morning half-day, while the other one takes care of the night half-day. Doing this can help the company to maximum its monetization process leading to optimum revenue and profits. However, one of the problems associated with the current system is that, in case any of the driver pairs will not be able to come to work punctually, then this is going to affect the overall time scheduling of the driving plan for that day leading to time conflict and loss of money for the company. Accordingly, the selection of the appropriate pair of drivers is crucial for the owner of the company. To solve these issues and in order to address the above-mentioned problems, a Process Mining technique based on the Social Network Analysis algorithm was applied and used with the intention of better analyzing and investigating the behavior of the drivers so as to select the best \"pair\" of drivers for the relevant working days. Subsequently, by using the resulting/generated Social Network graphs/models, the owner of the company was capable of simulating and illustrating the relationships and communicational dependencies amongst the drivers. Due to the fact that the company was using a very traditional way of data collection, therefore, the data was captured and stored manually within a paper-based approach. Nevertheless, this work can provide groundwork for further and future studies and research in such a way that several Process Mining techniques (including Social Network Mining methods) can be applied in versatile scenarios and situations whereas the data is typically captured, gathered and stored manually.'}\n","{'text': 'The work herein demonstrates how hybrid mesh network reliability can be improved by leveraging the channel diversity enabled by a compact, tripolar antenna. Specifically, through simulation, we show that a tripolar antenna can reduce packet drops to a third of that of when a single element antenna is used. These results were achieved assuming a slowly-varying, but highly-multipath, propagation environment such as those that may he exnected in industrial IoT settings.'}\n","{'text': 'Processor array architectures have been employed, as an accelerator, to compute similarity distance found in a variety of data mining algorithms. However, most of the proposed architectures in existing literature are designed in an ad hoc manner. Furthermore, data dependencies have not been analyzed and often only one design choice is considered for the scheduling and mapping of computational tasks. In this work, we present a systematic technique to design linear processor arrays for the computation of similarity distance matrices. The technique employed is used to define the computation domain of the algorithm, with time restrictions on input and output variables. Six scheduling vectors and their associated projection matrices are generated to illustrate our systematic technique. The six possible design options obtained are analyzed in terms of area and time complexities. We are also able to derive a previously existing processor array in the literature by modifying the scheduling vector for one of the proposed architectures. Field Programmable Gate Array (FPGA) Implementations show that our proposed architecture achieves better performance in both speed and area.'}\n","{'text': \"Humans can fluidly adapt their interest in complex environments in ways that machines cannot. Here, we lay the groundwork for a real-world system that passively monitors and merges neural correlates of visual interest across team members via Collaborative Brain Computer Interface (cBCI). When group interest is detected and co-registered in time and space, it can be used to model the task relevance of items in a dynamic, natural environment. Previous work in cBCIs focuses on static stimuli, stimulus-or response-locked analyses, and often within-subject and experiment model training. The contributions of this work are twofold. First, we test the utility of cBCI on a scenario that more closely resembles natural conditions, where subjects visually scanned a video for target items in a virtual environment. Second, we use an experiment-agnostic deep learning model to account for the real-world use case where no training set exists that exactly matches the end-users' task and circumstances. With our approach we show improved performance as the number of subjects in the cBCI ensemble grows, and the potential to reconstruct ground-truth target occurrence in an otherwise noisy and complex environment.\"}\n","{'text': 'Real-world data processing problems often involve various image modalities associated with a certain scene, including RGB images, infrared images, or multispectral images. The fact that different image modalities often share certain attributes, such as edges, textures, and other structure primitives, represents an opportunity to enhance various image processing tasks. This paper proposes a new approach to construct a high-resolution (HR) version of a low-resolution (LR) image, given another HR image modality as guidance, based on joint sparse representations induced by coupled dictionaries. The proposed approach captures complex dependency correlations, including similarities and disparities, between different image modalities in a learned sparse feature domain in lieu of the original image domain. It consists of two phases: coupled dictionary learning phase and coupled superresolution phase. The learning phase learns a set of dictionaries from the training dataset to couple different image modalities together in the sparse feature domain. In turn, the super-resolution phase leverages such dictionaries to construct an HR version of the LR target image with another related image modality for guidance. In the advanced version of our approach, multistage strategy and neighbourhood regression concept are introduced to further improve the model capacity and performance. Extensive guided image super-resolution experiments on real multimodal images demonstrate that the proposed approach admits distinctive advantages with respect to the state-of-the-art approaches, for example, overcoming the texture copying artifacts commonly resulting from inconsistency between the guidance and target images. Of particular relevance, the proposed model demonstrates much better robustness than competing deep models in a range of noisy scenarios.'}\n","{'text': \"In this paper, a real-time adaptive parameter estimation approach is proposed for a Polymer Electrolyte Membrane Fuel Cell (PEMFC). The aim of the proposed approach is to estimate the values of the unknown parameters of the PEMFC without interrupting the system's operation. The parameters include the transport and kinetic parameters of the PEMFC, which have a significant impact on its performance. The estimation process is performed using adaptation models that are designed to dynamically adjust the parameters based on the measured data. The approach is implemented in a real-time system, which enables the estimation process to be performed continuously during the operation of the PEMFC. The proposed approach is based on the use of polymer electrolytes, which play a key role in the PEMFC's operation. The results of the experiments demonstrate that the proposed approach is effective in accurately estimating the parameters of the PEMFC, and can improve its overall performance.\"}\n","{'text': 'The potential of interferometric synthetic aperture radar (InSAR) heights from TanDEM-X for vegetation canopy height and aboveground biomass (AGB) estimation has long been recognized. Penetration of X-band into the canopy affects these estimations. Thus, the canopy height and AGB retrieval from InSAR are typically biased and cannot be compared directly to estimates from other data sources. The objective of this letter was to apply a penetration depth model to compensate for height biases in TanDEM-X InSAR heights. The resulting canopy height estimates are subsequently converted to AGB estimates using regression models. The uncorrected InSAR heights of the forest canopy are biased due to the penetration of the signal into the canopy and differ substantially to light detection and ranging (LiDAR) canopy height estimates. The application of the penetration depth compensation results in unbiased forest canopy height estimates and AGB regression models that are comparable between InSAR and LiDAR. These results indicate that TanDEM-X InSAR and LiDAR technologies can be used to estimate AGB in complex tropical forests suggesting a synergistic use of these fundamentally different observation concepts.'}\n","{'text': 'This paper proposes a novel frequency offset estimation scheme for reliable wireless communication using modified K-means clustering. The scheme is mainly focused on orthogonal frequency-division multiplexing (OFDM) systems and clustering algorithms. Phase shift keying (PSK) modulation is used in the scheme, and constellation diagrams are utilized to determine frequency estimation. The frequency offset estimation is crucial for reliable wireless communication as it is affected by various factors such as Doppler shift. The modified K-means clustering algorithm improves the accuracy and robustness of frequency offset estimation. The proposed scheme is applicable to various types of wireless communication systems and can significantly enhance communication performance.'}\n","{'text': 'We aim for a robot capable to learn sequences of motor policies to achieve a field of complex tasks. In this paper, we consider a set of interrelated complex tasks hierarchically organized. To address this high-dimensional mapping between a continuous high-dimensional space of tasks and an infinite dimensional space of sequences of policies, we introduce a framework called \"procedure\", which enables the creation of sequences of policies by combining previously learned skills. We propose an active learning algorithmic architecture, capable of organizing its learning process in order to achieve a field of complex tasks by learning sequences of primitive motor policies. Based on heuristics of goal-babbling, social guidance, strategic learning guided by intrinsic motivation, and the \"procedure\" framework, our algorithm can actively decide on which outcome to focus and which exploration strategy to apply. We show that a simulation industrial robot can tackle the learning of complex motor policies and adapt this complexity to that of the task at hand. Owing to its exploration strategies, it can discover the levels of difficulty of the tasks, and learn the hierarchy between tasks so as to combine simple tasks to complete a complex task.'}\n","{'text': 'Aiming at the shortcomings of the current classification models of distribution lines, such as low classification accuracy and poor robustness, a rating classification model of distribution network based on dynamic classification is proposed. Based on K-PAM, the model dynamically combines the decision tree classification method C4.5 to efficiently use the prediction information of base classifier to achieve higher classification accuracy. Finally, the real data of the three distribution networks were used to conduct the experimental analysis, and the classification efficiency, classification accuracy and robustness of the three methods were compared.'}\n","{'text': 'A language model (LM) is an important part of a speech recognition system. Language model adaptation techniques use a large amount of source domain data and limited target domain data to improve the performance of language models in target domain. Even though text datasets are easy to obtain, there is no public Chinese text dataset for language model adaptation tasks. This paper presents a language model adaptation dataset which consists of four different domains of news data, i.e., sport, stock, fashion, finance. The discrepancy between the domains of data is evaluated. Model combination based adaptation of n-gram is evaluated on the dataset. Three different fine-tuning adaptation methods of recurrent neural network language models (RNNLMs) are evaluated. WER results on AIShell speech data with the language models trained on this dataset are also provided. The absolute WER reduction of lattice rescoring with adapted RNNLM is 4.74%.'}\n","{'text': 'Vision-based simultaneous localization and mapping (VSLAM) which uses visual sensor to make a robot locate itself in an unknown environment while simultaneously construct a map of the environment. With the continuous development of computer vision and robotics, VSLAM has become a supporting technology for popular fields such as unmanned aerial vehicle, virtual reality and unmanned driving. In this paper, the classical framework of visual SLAM is introduced briefly. On this basis, the key technologies and latest research progress of VSLAM from indirect and direct methods are surveyed. Then the research progress of deep learning techniques applied to VSLAM is reviewed. Finally, the development tendency of VSLAM is discussed.'}\n","{'text': 'This paper proposes an automatic traffic sign detection and recognition system using SegU-Net and a modified Tversky loss function with L1-constraint. The proposed method utilizes image segmentation and color analysis to extract the important features of the traffic signs. Task analysis is then used to classify the detected signs. The system was trained using a deep learning approach, and benchmark testing showed promising results, with an accuracy rate of 97%. The modified Tversky loss function with L1-constraint further improved the performance of the system by enhancing the shape and overall recognition of the traffic signs. This study showcases the effectiveness of deep learning and image processing techniques in developing automated traffic sign detection and recognition systems.'}\n","{'text': 'In this paper, we propose a novel approach to improve boundary level calculation in quantized iterative learning control (ILC) with encoding and decoding mechanism. The main objective of this work is to enhance the convergence performance of iterative decoding in control systems. The proposed method utilizes the quantization signal to perform the encoding and decoding of control signals. The encoding mechanism reduces the number of bits required to encode the control signal, resulting in a compressed representation of the signal. The decoding mechanism, on the other hand, contains a boundary level calculation algorithm that maps the quantized signal back to the original control signal. The proposed method is tested on a benchmark ILC problem, and the simulation results show that the convergence performance is significantly improved compared to the conventional method. The proposed approach can also be extended to address more complex control problems in a wide range of applications. Overall, this work highlights the potential benefits of incorporating encoding and decoding mechanisms in quantized ILC for enhanced control system performance.'}\n","{'text': 'This paper proposes the design of an optimized CMOS ELM accelerator which can efficiently train nonvolatile memory and simulate the behavior of neurons in neural networks. The hardware architecture of the accelerator is detailed, including its parallel processing units and inference algorithms. The proposed accelerator can achieve high-speed training and inference of neural networks through its advanced parallel processing capabilities, and can effectively reduce the computational load on the main processor. The optimized CMOS ELM accelerator provides a solution for efficient neural network training and inference, which is of great significance in the field of artificial intelligence and computer architecture.'}\n","{'text': 'As new services and business models are being associated with the power distribution network, it becomes of great importance to include load uncertainty in predictive computational tools. In this paper, an efficient uncertainty-aware load flow analysis is described which relies on generalized polynomial chaos and stochastic testing methods. It is described how the method can be implemented in order to account for real data-based load profiles due to two different usage models: residential loads and electrical vehicle charging profiles. Hence, it is shown how some relevant information affecting the quality of service can be deduced by means of non-elementary post-processing computations. The proposed technique is tested by using a benchmark scenario for typical European low voltage networks, considering the variation of both residential loads and EV charging profiles. The results are compared with the same simulation done by means of the Monte Carlo methodology. The consideration done during the analysis will be useful to clarify the application of the methodology but also to understand the effect of load variations on the grid characteristic quantities.'}\n","{'text': 'Pulmonary and respiratory diseases comprise a large proportion of the global disease burden, responsible for both mortality and disability. This burden is especially concentrated in the developing world, where air pollution levels are generally high and resources for diagnosing these diseases are very limited. Health workers and many general practitioner doctors in developing countries are not trained to diagnose pulmonary diseases, leading to high rates of misdiagnosis and underdiagnosis. Motivated by this need, we have developed a mobile toolkit that can be used for screening and diagnostic guidance for three of the most common pulmonary and respiratory diseases (Asthma, Chronic Obstructive Pulmonary Disease (COPD) and Allergic Rhinitis (AR)). The toolkit consists of a mobile phone app, known as Pulmonary Screener, which is used in conjunction with a low-cost (<;US$10) peak flow meter. Machine vision software enables the phone camera to automatically track and capture the reading from the peak flow meter without the need for any electronics, Bluetooth radio, or batteries. Using the peak flow meter reading as well as an integrated clinical questionnaire, a machine learning model is then used to calculate the individual probabilities of a patient having a specific pulmonary disease (Asthma, COPD, AR, other) or comorbidities (Asthma + AR, COPD + AR). The machine learning models used in the application were trained using diagnostic data from 325 patients collected at a pulmonary clinic over the past 3 years. Based on 50 iterations of a held-out test set, the Pulmonary Screener achieves accuracy (AUC) values above 0.90 for all diseases and combinations, with the exception of Asthma with AUC = 0.84. Sensitivity and specificity values were for all diseases was also greater than 0.90. To our knowledge, this is the first clinically validated mobile tool that is capable of diagnosing multiple pulmonary diseases in a single app. Future versions of the Pulmonary Screener will make use of ongoing data collection to expand support for infectious diseases as well, including pneumonia and tuberculosis, and include features extracted from auscultation and cough sounds.'}\n","{'text': 'This paper presents a cloud computing platform that is designed to cater to the holistic needs of children and families during natural disasters incidents. With the use of social network services, games, and cloud computing technology, this platform aims to provide education and support for children and their families in the aftermath of earthquakes and other disasters. The platform is also designed to address the specific needs of pediatrics and biomedical engineering. By utilizing cloud computing, this platform allows for scalability, accessibility, and a more efficient use of resources during disaster relief efforts. Overall, this platform offers a comprehensive approach to disaster relief that considers the needs of children and their families in a holistic manner.'}\n","{'text': \"The evolution of the smart cities' research and the relevant discussion on well-being is challenging the design of policies, information systems, and computational methods toward the alignment to Sustainable Development Goals (SDG) of the United Nations. Sustainable GOAL 7-Affordable and Clean Energy-is the focus of this paper. The requirement to integrate certain levels of renewable energy sources into the electricity grids to meet sustainability measures creates unfavorable variability in the entire electricity supply chain and delays the integration of renewable energy sources into the energy systems. This paper introduces a methodology and an optimization model for the electricity supply chain that allows reducing the variability of the renewable energy sources supply by optimal planning of the supply chain operations. The methodology supports electricity decision makers to identify the optimal operation of the electricity supply chain, taking into account multiple objectives and supply chain designs, including innovative architectures. The multi-objective linearized optimization model allows regulating the flow rates of energy and water for the electricity supply chain. The methodology was evaluated, considering three possible integration architectures for the loads and real-time electricity pricing. For each of the studied architectures, the analysis showed the optimal dispatching to reduce the energy variation due to the increasing renewable energy penetration into the grid. The results show how the methodology can present decision makers with optimal operation of the supply chain, such that a minimum energy variation is achieved at a minimum cost. The key contribution of this paper to the agenda of the special section entitled â\\x80\\x9cUrban Computing & Well-being in Smart Cities: Services, Applications, Policymaking Considerationsâ\\x80?is multifold: It sets a scientific framework for the promotion of the SDG #7 and innovates in the design and deliverable of a fully functional eco-system for the optimization of the electricity supply chain. It also defines well-being as an affordable and clean energy primer.\"}\n","{'text': 'This paper presents a novel approach for monitoring the degradation of low-voltage electromagnetic coil insulation using a microscopic machine vision system. The proposed method leverages the capabilities of ensemble learning and feature extraction techniques within a membrane computing framework to accurately identify patterns of insulation degradation. The approach is based on a combination of image processing and microscopy, which allows for a high degree of precision in the detection and analysis of degradation. The proposed framework is capable of detecting degradation in low-voltage electromagnetic coils with a high degree of accuracy, and is capable of identifying patterns of degradation that are not readily apparent to human operators. The results of this study demonstrate the potential of this approach for improving the reliability and safety of low-voltage electromagnetic coils.'}\n","{'text': \"Smart contracts and blockchain technology have shown promise in creating secure and reliable systems for various applications. In this paper, we propose an Ethereum-based emergency service for smart home systems, where smart contracts are used to ensure privacy and security in emergency situations. The Internet of Things (IoT) devices in smart homes are integrated with our system, allowing for automatic detection of emergencies and triggering the smart contract. We employ different cryptographic techniques, such as encryption and hash functions, to protect users' privacy and prevent unauthorized access to their data. Our implementation offers a decentralized, tamper-proof, and transparent emergency service for smart homes, providing a more reliable and efficient way of handling critical situations. Overall, our proposed system offers a practical solution for emergency services with the use of smart contracts, blockchain, and cryptography.\"}\n","{'text': 'Deep learning models, especially deep convolutional neural networks (CNNs), have been intensively investigated for hyperspectral image (HSI) classification due to their powerful feature extraction ability. In the same manner, ensemble-based learning systems have demonstrated high potential to effectively perform supervised classification. In order to boost the performance of deep learning-based HSI classification, the idea of deep learning ensemble framework is proposed here, which is loosely based on the integration of deep learning model and random subspace-based ensemble learning. Specifically, two deep learning ensemble-based classification methods (i.e., CNN ensemble and deep residual network ensemble) are proposed. CNNs or deep residual networks are used as individual classifiers and random subspaces contribute to diversify the ensemble system in a simple yet effective manner. Moreover, to further improve the classification accuracy, transfer learning is investigated in this study to transfer the learnt weights from one individual classifier to another (i.e., CNNs). This mechanism speeds up the learning stage. Experimental results with widely used hyperspectral datasets indicate that the proposed deep learning ensemble system provides competitive results compared with state-of-the-art methods in terms of classification accuracy. The combination of deep learning and ensemble learning provides a significant potential for reliable HSI classification.'}\n","{'text': \"This note presents a novel control framework based on disturbance estimation information to exploit the potential performance improvement. Disturbances in the hypersonic reentry vehicles are revisited, and a disturbance effect indicator (DEI) is defined to demonstrate the pros and cons of disturbances' influence on the system. Based on the disturbance estimation, a disturbance estimation-triggered control scheme for the attitude tracking is established. Furthermore, the ultimately bounded stability of the closed-loop system is guaranteed. Distinguished from eliminating the disturbance directly in the state-of-the-art disturbance observer-based control, the proposed control switches its structure to counteract or retain the disturbance according to the DEI, and thus is capable of improving the transient performance. Simulation results verify the effectiveness and superiority of the proposed approach.\"}\n","{'text': 'The purpose of this paper is to study the short-term demand prediction for online car-hailing services problem. Prediction of short-term network car demand can provide many benefits such as an increase in the income of network car drivers. In addition, demand prediction is an important resource for recommendation systems, carpooling systems, and network car scheduling; and therefore, predicting the demand for network cars has great significance. In the last few decades, scholars have studied various problems related to short-term demand prediction for online car-hailing services based on clustering algorithms and regression algorithms. However, these studies are still problematic because the accuracy of demand prediction is not high enough. Therefore, this paper studies a method of improving the accuracy and the efficiency of demand prediction. Due to the high prediction accuracy and the fast training efficiency of least squares support vector machine (LS-SVM), a short-term demand prediction method for online car-hailing services based on LS-SVM is proposed. The modeling process involves selecting the dependent and independent variables, the basic principles of the LS-SVM, the kernel function and superparameter, model training, and prediction. In a numerical experiment, we use network car order data as the network car demand data to test the model. We show that the experimental results with the LS-SVM method implemented in this paper and then compare the model with lasso linear regression, nearest neighbor regression, decision tree regression, and neural network. The experimental results show that the short-term demand prediction model for online car-hailing services based on LS-SVM performs better than the other methods.'}\n","{'text': 'In recent years, Generative adversarial networks (GANs) have become increasingly popular for realistic image synthesis. However, training GANs can be a computationally expensive and time-consuming process. In this paper, we propose DepthwiseGANs, a novel fast training method for GANs that utilizes depthwise separable convolutions to reduce the computational cost of training generators. Our approach has been evaluated on face synthesis tasks, with promising results compared to state-of-the-art methods. Additionally, we analyze the impact of different configurations on training time and quality of the generated images. Overall, our results suggest that DepthwiseGANs represent a promising approach for efficient and effective generative adversarial networks, with potential applications in computational modeling and computer architecture.'}\n","{'text': 'Many unsupervised learning algorithms have been proposed to avoid the inconvenience of data labeling. The nature of neural networks is also gradually being explored by unsupervised learning. In this paper, we focus on the sampling strategy for unsupervised images embedding learning via instance discrimination. A new sampling method is proposed based on the observation that different samples contribute unequally to training, which pays more attention to the neighbours. The proposed sampling method is beneficial and efficient for images embedding learning. The results on benchmark data show that the proposed sampling method is robust and outperforms the compared method.'}\n","{'text': 'This paper proposes a method for detecting fraudulent credit card transactions by combining auto encoders and one class support vector machines. The proposed approach depends on machine learning techniques and utilizes anomaly detection methods to identify unusual transaction patterns. In this method, auto encoders are used to construct a data model for normal credit card transactions, while one class support vector machines are utilized to classify incoming transactions as either normal or fraudulent. The system employs training data to train the models, which it then uses to detect fraudulent transactions. The proposed method provides a promising solution for detecting this type of fraud with high accuracy.'}\n","{'text': 'This paper proposes the use of Temporal Convolutional Memory Networks (TCMNs) for the remaining useful life estimation of industrial machinery. The authors first discuss the importance of accurately estimating the remaining useful life of such machinery to avoid costly downtime and maintenance. They then introduce TCMNs as a potential solution due to their ability to handle sequential data and learn long-term dependencies. The authors further detail the training process of the TCMNs, including data preprocessing and hyperparameter tuning. They also discuss the trajectory-based approach to remaining useful life estimation, which involves predicting the future paths of degradation. Additionally, the authors compare the TCMNs to other methods such as Hidden Markov models and highlight the superior performance of the TCMNs. Feature extraction is addressed as an important step in accurately capturing meaningful information from the raw data. Finally, the authors present a systems architecture for integrating the TCMNs into industrial machinery maintenance systems for real-time monitoring and prediction of remaining useful life.'}\n","{'text': 'This paper provides theoretical analysis of existing optical distribution network (ODN) that integrates mobile backhaul network with already existing passive optical network (PON). The need to reduce the cost of laying down new fibres for mobile backhaul networks drives the need for such an integrated architecture that allows sharing of ODN. In this paper, analysis has been done for the two arms of architecture, i.e. the mobile backhaul system and passive optical network arm. A wavelength division multiplexing (WDM) combiner is used to stream data from the two arms of the architecture. The PON ODN is considered to have 10 Gbps data rate downstream and 2.5 Gbps rate upstream and a bit error rate (BER) less than $10^{-9}$. The power budget analysis is used in both arms to determine the maximum reach possible. Rise time analysis in PON arm makes sure that the rise time stays within limits for DS and US. Delay analysis for mobile backhaul is done to make sure that the end to end delay in mobile backhaul is not more than 1 ms so as to meet 5G specifications. The analysis shows that a distance of 20 km is possible for carrying 5G mobile backhaul traffic in the existing ODN.'}\n","{'text': 'Decision trees are an extremely popular machine learning technique. Unfortunately, overfitting in decision trees still remains an open issue that sometimes prevents achieving good performance. In this paper, we present a novel approach for the construction of decision trees that avoids the overfitting by design, without losing accuracy. A distinctive feature of our algorithm is that it requires neither the optimization of any hyperparameters, nor the use of regularization techniques, thus significantly reducing the decision tree training time. Moreover, our algorithm produces much smaller and shallower trees than traditional algorithms, facilitating the interpretability of the resulting models. For reproducibility, we provide an open source version of the algorithm.'}\n","{'text': 'This paper proposes a novel solution for regular expression matching using memristor-based ternary content-addressable memory (TCAMs) in network security applications. The use of memristors offers a promising solution for hardware-based matching engines due to their non-volatile, high density, and low power consumption. The proposed approach uses automata-based techniques to map regular expressions into TCAM rules, which are then stored in memristor-based TCAMs. The experimental results show that the proposed memristor-based TCAM approach significantly improves the matching throughput compared to traditional Random Access Memory (RAM) based solutions. This work presents an important contribution to the field of network security and opens up promising opportunities for the use of memristors in future hardware designs.'}\n","{'text': \"This paper presents an alternative computer access communication tool for cerebral palsy people with preserved cognitive ability. The device consists of a portable computerized system containing a special keyboard activated manually by means of mechanical keys or remotely via infrared signal by head movement. An infrared signal emitter module is attached externally to the user's forehead in a cap-type holder. Tests indicated that a receiver could be operated at a maximum distance of 40 cm, with an angulation of up to 15Â°. The device has quality features, short response time, ease of use, and it is easily transported.\"}\n","{'text': 'This paper presents an approach to adaptive dynamic programming using Lyapunov function constraints, specifically incorporating Lyapunov methods and cost functions for stability analysis and convergence. The use of Lyapunov functions allows for the identification of stability conditions and constraints that can be used to ensure optimal control. The proposed approach is based on dynamic programming and is designed to achieve optimal control while maintaining stability and achieving convergence. The use of Lyapunov function constraints also enables the integration of online learning and adaptation into the optimization process, allowing for the system to adapt to changing environments or objectives. Overall, this approach presents a promising method for achieving optimal control in dynamic systems that is both robust and adaptive, making it useful in a wide range of applications.'}\n","{'text': 'In the recent past, we have witnessed steep growth in mobile data consumption. To address the capacity requirements resulting from the huge growth in mobile data traffic, the mobile network operators (MNOs) are adding more base stations and allocating more spectrum layers including outdoor and indoor small cells. Since the capacity requirement of the network varies over time, the scaling up of the network may increase the energy consumption of the Radio Access Network (RAN). Hence, we need to optimize the network to reduce the overall power consumption through Cloud based models, and deployment of power-efficient radio nodes. In this paper, we analyze the network evolution towards Cloud based Radio Access Network (CRAN) for a heterogeneous set of base stations such as those with Macro RRUs, Micro RRUs and Pico radio units. We derive the computational complexity using a flexible and â\\x80\\x98future-proofâ\\x80?power model and apply it for the network. We also compare the computation complexity for various cases of User Equipment (UE) channel conditions, different sub-components within the given base station type and provide the results. We further use the Bin-Packing algorithm to analyze the number of base station cloud servers needed for this network and the power consumption of the base station cloud. We further evaluate whether the newer cloud servers with higher CPU cores are power efficient for a given load. We observe from the simulations, that the currently available base station cloud servers have more capacity and still are more power efficient than the baseline Compute Node servers used with the earlier power model.'}\n","{'text': 'The high impedance fault (HIF) has random, irregular, and unsymmetrical characteristics, making such a fault difficult to detect in distribution grids via conventional relay measurements with relatively low resolution and accuracy. This paper proposes a stochastic HIF monitoring and location scheme using high-resolution time-synchronized data in Î¼-PMUs for distribution network protection. Specifically, we systematically design a process based on feature selections, semi-supervised learning (SSL), and probabilistic learning for fault detection and location. For example, a wrapper method is proposed to leverage output data in feature selection to avoid overfitting and reduce communication demand. To utilize unlabeled data and quantify uncertainties, an SSL-based method is proposed using the information theory for fault detection. For location, a probabilistic analysis is proposed via moving window total least square based on the probability distribution of the fault impedance. For numerical validation, we set up an experiment platform based on the real-time simulator, so that the real-time property of Î¼-PMU can be examined. Such experiment shows enhanced HIF detection and location, when compared to the traditional methods.'}\n","{'text': 'The aim of this paper is to explore the use of emojis and natural language processing techniques in predicting the best emoji to use for a given picture. The study employs task analysis and visualization to identify the relationship between pictures and emojis. The analysis is carried out using a dataset sourced from Twitter, where users tweet pictures along with their corresponding emojis. The study uses semantics and predictive models to predict the most appropriate emoji for a given picture based on its visual attributes. The results show that natural language processing is an effective approach for predicting the best emoji for a picture. This study provides insights into the use of computer vision and natural language processing in developing intelligent systems that can interpret visual data and generate appropriate responses. The findings have practical applications in social media marketing and communication, where the use of emojis has become increasingly popular in recent years.'}\n","{'text': 'Breast cancer is the most frequent type of cancer among women. Since early diagnosis provides a better prognosis, different techniques have been developed by researchers all over the world. Several studies proved the efficiency of infrared image as a breast cancer screening technique. This paper proposes a methodology for analyzing infrared thermography of breast, considering distinct protocols, in order to classify patients images as healthy or non-healthy due to anomalies such as cancer. The major contribution of this work is to provide accurate classification using Convolutional Neural Networks, which were not exploited in previous works. Many methods relies on handcrafted features and traditional classificators, such as Support Vector Machines. We obtained competitive results compared to other works and we design an appropriate modelling which takes advantage of this type of deep learning architecture. Our proposal obtained 98% of accuracy for static protocol and 95% for dynamic protocol.'}\n","{'text': \"In this paper, an intuitive neuro-rehabilitation video game has been developed employing the fusion of artificial neural networks (ANNs), inverse kinematics (IK), and fuzzy logic (FL) algorithms. The embedded algorithms automatically adjust the game difficulty level based on the player's interaction with the game. Moreover, it is manifested as an alternative approach for possible movements to improve incorrect positioning through real-time visual feedback on the screen; 52 participants volunteered to engage in the program. Motor assessment scale (MAS) was determined to assess the participants' functional ability pre- and post-treatments. The system input is received via the Microsoft Kinect, a foot Pedal (Saitek), and the Thalmic Myo armband. The ANN classifier integrates the limb joints orientation, angular velocity, lower arms' muscle activity, hand gestures, feet sole (plantar) pressure parameters, and the MAS scores to learn from data and predict the improvement following the intervention. The fuzzy input generates a crisp output and provides a personalized rehabilitation program with the potential to be integrated into clinical protocols. Experiments to obtain the input signals and desired outputs were conducted for the learning and validation of the network. The networks pattern recognition, self-organizing map, and non-linear auto-regression analysis performed using feed-forward and Levenberg-Marquardt backpropagation (LMBP) procedure. The results showed the effectiveness of the non-linear auto-regression using the optimized LMBP algorithm to classify and visualize the target categories. Furthermore, the state of the network demonstrates the prediction accuracy exceeding 94%. Clustering algorithm grouped the data based on the similarity. Self-organizing map trained the network to learn the topology of samples with high correlation, presented outputs with high achievement.\"}\n","{'text': 'Soft robotic end-effectors with inherent compliance have excellent grasping adaptability and ensure safe human-robot interaction. The inherent compliance also limits structural dexterity in soft robotic systems and makes mathematical modeling difficult, therefore resulting in control challenges for existing soft robotic hands. To tackle these problems, we propose a general and intuitive control approach for various soft end-effectors with different kinematic structures. A grasping component based mapping approach is presented. This approach maps the essential human hand grasping components to robotic hand grasping components, without requiring a specific kinematic model per end-effector. A LMC-based human hand motion capturing system and multi-channel pneumatic actuation platform are accompanied to realize the intuitive control. The proposed intuitive control strategy does not require the human operator to wear any equipment or modify their natural hand behavior to match different end-effector structures. We demonstrate the efficacy of our control strategy with two, three, and four-fingered soft end-effectors. All static performances are depicted by photos in the experimental section and dynamic processes are in our accompanying video. The proposed approach provides an efficient solution to control various soft robotic hands and enhances the performance dexterity of soft robotic end-effectors.'}\n","{'text': 'To address the limited speed and scale of the simulation of modular multilevel converter (MMC) in electromagnetic transient simulation program (EMTP), this paper put forward a MMC fast electromagnetic transient model based on rotation transformation. The crucial advantage of the rotation transformation is to reduce the fundamental frequency of the original signal via the rotation transformation of coordinate system. With proposed method implemented in the EMTP of MMC, the simulation step size can be relatively increased, and the fast electromagnetic transient simulation can be achieved. In this paper, the equivalent model of MMC switch function model expressed by the state equation is derived. Based on this, the novel MMC model based on rotation transformation is further derived combined with the concept of rotation transformation. The state equation of the proposed MMC model is calculated in MATLAB, and simulation results and time-consuming are compared to those of a 51-level topological MMC electromagnetic transient model established in PSCAD/EMTDC. The results of comparative analysis show that the simulation duration of the MMC model based on rotation transformation is far less than the traditional MMC electromagnetic transient model without sacrificing accuracy.'}\n","{'text': 'Autonomous robots are critical components of factories of futures. In this era, autonomous transfer vehicles are expected to play important role for flexible manufacturing. But the system should detect abnormal events itself. In this study, anomaly detection approach is proposed for autonomous transfer vehicles in the smart factories. Decision trees are used to detect stopping and slow down anomalies in internal transportation of the factories. The proposed approach is tested in simulation environment.'}\n","{'text': 'This study has the primary goal to analyze the growth of data science through the main search trends. This study was conducted by defining in high level the concept of data science as well as its main components. Supported in those elements, we identified the main trends. We used mainly data from google trends to determine the evolution of search by topics., research area, or simple expressions. It allowed us to reckon that artificial intelligence (AI)suffered a lack of interest until 2012. Then it became an increasingly popular field since 2014. This is due to the progression of machine learning and data science. Results show a cumulative search of data science since 2012.'}\n","{'text': 'Clustering algorithms have been a topic of interest in the field of machine learning algorithms as they play a crucial role in identifying patterns and structures within data. Fuzzy co-clustering has gained popularity in recent times, especially in text analysis, due to its ability to capture the overlapping nature of data. MMMs-induced fuzzy co-clustering has shown promising results in various applications, but its computational complexity poses a challenge. In this paper, we discuss the basic considerations of online and mini-batch algorithms for MMMs-induced fuzzy co-clustering. We explore the use of linear programming techniques and mixture models to develop efficient algorithms for this clustering method. We also discuss the historical development of clustering methods to provide insights into the current state of this field. Our findings suggest that online and mini-batch algorithms have the potential to significantly reduce the computational burden associated with MMMs-induced fuzzy co-clustering, thereby making it practical for real-world applications.'}\n","{'text': 'Localization and identification of vertebrae in 3D MR volumes is a crucial first step for diagnosis and management of spinal conditions. Automating this process can save radiologists significant time and clicks. In this paper, we propose a novel learning-based approach consisting of two cascaded networks that perform simultaneous identification and localization of vertebrae. The first network performs slice-based level detection of full 3D sagittal volumes using an adaptive loss function that adjusts the weights of its loss terms during training, and outputs estimated center slices of each vertebrae. The sagittal slice is then divided into sub-volumes each containing a single vertebra. These sub-volumes are inputted into the second network for binary classification and localization of the vertebrae. Our method only requires centroid annotation (performed manually), a statistical model then provides an approximation of the volumetric segmentation for ground truth data. With this method, a vertebra identification rate of 82% was achieved.'}\n","{'text': \"Motion estimation is a crucial task in modern image and video processing applications such as streaming media, motion tracking, and image registration. In this work, we propose a new method for object-based motion estimation using the Estimated Point Density (EPD) similarity measure and Demons algorithm. The EPD similarity measure is used to detect image edges which are critical for accurate motion measurement. Prediction algorithms are used to estimate the object's motion. The optimization process is based on the Demons algorithm, which allows for efficient motion estimation. The proposed method is compared with other state-of-the-art algorithms, and it is shown to be more accurate and reliable. The results of the experiments demonstrate the effectiveness of the proposed approach for object-based motion estimation. This work presents a valuable contribution to image and video processing research and has practical applications in many areas.\"}\n","{'text': 'Bags are not isolated in the Multiple-Instance Active Learning process, especially for image as bag, because each picture has its inherent background or metainformation, such as its taken time, taken place, the topic, and they have possible associations. With context associations, we can build the annotation tool providing more interactively user experience and thus increase the annotation efficiency. In this paper, we propose a context aware images annotation framework that selects the images that are context related to query in the multiple-instance active learning with batch mode. Experiments show that it takes less time for annotation with the proposed framework compared to traditional ones, and improve the labeling efficiency.'}\n","{'text': 'The adaptive command-filtered backstepping controller (ACFBC) is proposed to deal with the consensus problem of two chaotic dynamic systems. The proposed ACFBC system is designed based on the finite-time stability theorem in combination with backstepping technique and command filtered compensation. Moreover, a neural network (NN) approximation technique is utilized to approximate the unknown nonlinear function in this paper. Stability of the closed-loop system is analyzed via Lyapunov direct method. Finally, simulation results have shown the validity the proposed ACFBC system for the chaotic systems regarding unknown dynamic function.'}\n","{'text': 'The development of an automatic mackerel sorting machine is discussed in this paper. The machine utilizes both global and local features for feature extraction in order to improve the accuracy and efficiency of sorting. The sorting process relies on shape recognition, which is done using lasers to create point clouds of the fish. The machine also addresses challenges related to detecting and sorting mackerel with varying abdominal shapes. The sorting proposals are based on object detection algorithms, which help to accurately identify and sort the fish based on their unique features. Overall, this paper presents an innovative and effective solution for mackerel sorting, which could have significant implications for the fishing industry.'}\n","{'text': 'Since the rise of biometrics and their application in authentication systems, the risks of identity theft and fraud are steadily increasing. Hence, biometric template protection has become a real challenge for the research community. Various solutions have been proposed to address these issues and minimize the risk of attacks, but only a few have managed to achieve both performance and security. In this context, we propose a fingerprint template protection method that utilizes the minutiae structure of fingerprints, including their positions and orientations, to generate cancellable templates through a one-way transformation function. We proved that the proposal perfectly meets the properties of revocability, diversity, as well as accuracy performance. Our technique was evaluated on the FVC2002 DB1 database, and we obtained promising results that demonstrate the feasibility of our proposal.'}\n","{'text': 'An important field of application of Forward Scatter Radar systems (both single-node and multi-node) consists in the estimation of the target kinematic parameters. In the past different studies have shown the possibility to extract these parameters by estimating the main target signal parameters (i.e. Doppler rate, derivative of the Doppler rate) and the time instant at which the target crosses the baseline. The estimation accuracy of the motion parameters depends on the estimation accuracy of the target signal parameters and on the FSR geometry. In this frame, the main goal of this paper is to provide a simple tool which can be used to (i) optimize the receivers position in a dual baseline FSR configuration and (ii) evaluate the minimum angular separation between the two baselines that guarantees the estimation of all the kinematic parameters with a desired accuracy. To this aim, for a target following a linear trajectory, the motion parameters are estimated by jointly exploiting the time delay between the signals acquired at the two different receivers and the estimates of their Doppler rates.'}\n","{'text': 'This paper presents a geometrical interpretation of joint diagonalization for symmetric matrices. The method involves an optimization approach that takes into account convergence and noise measurement to calculate the signal to noise ratio in biomedical engineering. The joint diagonalization technique is applied to develop a biological system model that accurately represents the interactions between the components of the system. The approach has been shown to be effective in improving noise reduction and signal detection in a variety of applications, making it a valuable tool for researchers working in biomedical engineering and related fields.'}\n","{'text': 'The increasing use of wireless communication networks has enhanced the need for security protocols to protect against jamming attacks. In this paper, we propose a game of one/two strategic friendly jammers against a malicious strategic node, using the Nash equilibrium as the objective for both sides. The game is modeled as a zero-sum game, where the friendly jammers aim to reduce the interference caused by the malicious node. The proposed strategy involves the use of multiple radio transmitters and the manipulation of packet transmissions to counteract the jamming attack. We demonstrate the effectiveness of the proposed strategy through simulation results, highlighting the benefits of cooperation among the friendly jammers. The proposed game provides a practical approach to jamming attacks in wireless LAN networks, enhancing the overall security of communication networks.'}\n","{'text': 'This paper explores the utility of supervised machine learning algorithms in predicting the tensile strength of high density polyethylene film produced by extrusion-blown molding process. Three algorithms were used: Artificial Neural Networks, Decision Tree, and k-Nearest Neighbors. Specifically, these algorithms were modeled using five materials-related input parameters and six process-related input parameters. The application of algorithms demonstrated their capability in predicting the intended property of the extrusion-blown process products.'}\n","{'text': 'In recent years, robot technology has seen tremendous advancements, enabling them to perform a wider range of tasks than ever before. One crucial aspect of these technological advancements is the development of robot sensing systems which allow robots to detect and classify objects in their environments. A key challenge in designing such systems is to extract useful information from the sensory input. It is here that the synapses in the brain have provided inspiration for an effective feature extraction algorithm that utilizes multimodal sensory information. This new neocortically-inspired algorithm provides an interdisciplinary solution to the challenge by incorporating techniques from task analysis, neuroscience, and engineering. By utilizing a variety of sensory input, the algorithm is able to accurately identify and classify objects with a high degree of accuracy similar to how the human brain processes sensory information. In summary, the research is a significant contribution to the field of robotics and has potential applications in a myriad of settings from autonomous vehicles to manufacturing industries.'}\n","{'text': 'Hyperspectral image (HSI) classification is an important technology for hyperspectral data analysis, which has the challenge of high dimensionality and limited training samples. Moreover, due to the spatial continuity of material distribution, it is reasonable to improve the performance of HSI classification from the local similarity viewpoint, i.e., pixels in the same local region have a high probability to share similar features. Therefore, in this paper, a novel method based on local similarity and kernel low-rank representation is proposed to improve the classification accuracy for HSI. First, taking into consideration that pixels in the same homogeneous region share similar spectral features (termed local similarity), the HSI is segmented by the superpixel segmentation algorithm to obtain the homogeneous regions. Then, a model of kernel low-rank representation based on local similarity (KLRRLS) is proposed for HSI classification. In the model of KLRRLS, the nonlinear structure characteristics of HSI are extracted by employing the kernel trick, and the low-rank constraint is used as a prior to restrict the recovery coefficient matrix in each segmentation region, thus efficiently solving the linear non-separable problem and exploiting the contextual information of HSI. Finally, the classification results are generated by fusing the result of each segmented map via the maximum voting mechanism. Experimental results on three real HSI datasets demonstrate that the proposed method can effectively improve the classification accuracy.'}\n","{'text': 'This paper proposes a new super-resolution method for degraded images of documents, captured in low resolution by mobile device. This is an improvement of a non-linear existed method but limited by its high complexity and low quality on degraded images, caused in general by the JPEG compression. On this category of images, it is necessary to increase the perimeter of the local analysis in order to obtain a better visual rendering with a reduced complexity. These constraints have been the target of our contribution, which aims at the linearization of the existed approach by the use of a bio-inspired approach based on multilayer perceptron neural networks. We have demonstrated that they are able to learn the mechanism of a super-resolution approach and make it possible to extend it, essential for its quality. This is a new alternative to the conventional use of neural approaches in image magnification.'}\n","{'text': 'This article discusses the use of Marginalized Particle Filtering and related filtering techniques as message passing in graphical models. The authors explore the use of covariance matrices, hidden Markov models, and Bayes methods in computational modeling and filtering. The effectiveness of these techniques in filtering is highlighted, as they provide a way to update probability distributions and account for uncertainty in the measurement process. The authors conclude that message passing using marginalized particle filtering is a powerful tool for filtering in graphical models, and can be extended to other domains as well.'}\n","{'text': 'Steganalysis is the process of detecting hidden messages within digital media, such as images or videos. In recent years, mesh steganalysis has become an important research topic within this field. This paper proposes a feature-preserving tensor voting model for mesh steganalysis. The key feature extraction method used in this model is based on Laplace equations, which are used to calculate the curvature of faces in three-dimensional displays. The proposed model utilizes tensors to represent the local shape of the mesh, allowing for efficient analysis of correlations between adjacent vertices. The model is designed to preserve the important features of the original mesh, making it a more reliable tool for steganalysis. Experimental results demonstrate that the proposed model outperforms existing mesh steganalysis methods in terms of detection accuracy and efficiency. In conclusion, the feature-preserving tensor voting model offers a promising approach for the detection of hidden messages within mesh media.'}\n","{'text': 'This paper proposes a novel method for trend identification in fluid flow data sets based on switching models. The technique, referred to as Moving Horizon Trend Identification, relies on the use of mathematical models to decompose complex flows into simpler components. The authors demonstrate how this approach can be used to improve the accuracy of trend estimation, and highlight the potential advantages of switching models over traditional linear approaches. The paper also discusses some of the key challenges associated with this approach, including estimation error and numerical stability in the context of nonlinear dynamical systems. Overall, this research provides valuable insights into how switching models can be used in the context of data-driven decomposition of fluid flows, and highlights the potential role of mathematical models in improving our understanding of these complex systems. The proposed technique has broad implications for market research and other areas where trend identification is critical, offering a powerful new tool for analyzing complex data sets. '}\n","{'text': 'Face restoration from low resolution and noise is important for applications of face analysis recognition. However, most existing face restoration models omit the multiple scale issues in the face restoration problem, which is still not well solved in the research area. In this paper, we propose a sequential gating ensemble network (SGEN) for a multiscale noise robust face restoration issue. To endow the network with multiscale representation ability, we first employ the principle of ensemble learning for SGEN network architecture design. The SGEN aggregates multilevel base-encoders and base-decoders into the network, which enables the network to contain multiple scales of receptive field. Instead of combining these base-en/decoders directly with nonsequential operations, the SGEN takes base-en/decoders from different levels as sequential data. Specifically, it is visualized that SGEN learns to sequentially extract high-level information from base-encoders in a bottom-up manner and restore low-level information from base-decoders in a top-down manner. Besides, we propose realizing bottom-up and top-down information combination and selection with a sequential gating unit (SGU). The SGU sequentially takes information from two different levels as inputs and decides the output based on one active input. Experimental results on the benchmark dataset demonstrate that our SGEN is more effective at multiscale human face restoration with more image details and less noise than state-of-the-art image restoration models. Further utilizing an adversarial training scheme, SGEN also produces more visually preferred results than other models under subjective evaluation.'}\n","{'text': 'The V2V system, short for vehicle-to-vehicle communication, is a promising technology that is expected to revolutionize transportation safety and efficiency. One of the critical challenges in this field is ensuring that the V2V systems can effectively manage congestion and maintain optimal performance. In this paper, we present a comprehensive study on the validation and performance evaluation of V2V congestion control protocols. We integrate safety and standards considerations into the design of V2V systems and evaluate their effectiveness using real-world accident data. Our results demonstrate the effectiveness of using V2V technology to prevent accidents and minimize their severity. Furthermore, we propose a set of tools and metrics to assess the performance of V2V protocols, which can aid in the development of effective communication protocols for vehicular ad hoc networks. Finally, we discuss the potential of using global navigation satellite systems to enhance the accuracy and reliability of V2V communication. Our findings provide valuable insights into the design and implementation of such systems and their potential impact on transportation safety.'}\n","{'text': 'Fiber lasers and amplifiers have significant applications in optoelectronic communication and sensing systems. Optical fiber amplifiers are essential components in optical fiber networks as they boost the optical signal strength without the need for conversion to the electrical domain. Fiber lasers are widely used due to their advantages such as high efficiency, narrow linewidth, and long coherence lengths. Optical fiber cables are critical components of fiber optic communication systems, and they are characterized by low attenuation, broad bandwidth, and immunity to electromagnetic interference. Optical fiber networks employ dense wavelength division multiplexing (DWDM) techniques to transmit data at high speeds over a single optical fiber. Pump lasers facilitate the amplification of optical signals in fiber amplifiers and fiber lasers. Optical fiber theory provides a fundamental understanding of the optical properties of fibers, and it is essential for designing and optimizing fiber-based devices and systems. This paper provides a comprehensive review of fiber lasers and amplifiers, optical fiber cables, optical fiber networks, pump lasers, and optical fiber theory. The objective is to highlight the technical principles, design considerations, and key applications of these optical fiber-based technologies.'}\n","{'text': 'Analysis and interpretation of stained histopathology sections is one of the main tools in cancer diagnosis and prognosis. In addition to the information which is typically extracted by trained pathologists, there is also information that is not yet exploited, simply because we do not yet understand the impact of all cellular and tissular features that could be predictive of outcome. In this paper, we address a question that can currently not be solved by pathologists: the prediction of treatment efficiency for Triple Negative Breast Cancer (TNBC) patients from biopsy data.'}\n","{'text': 'Producing depth maps of a scene is essential in many light field applications. Numerous algorithms have been developed to obtain an accurate depth map on public datasets. However, real-world light field images obtained by cameras have noises produced by hardware limitations. Existing methods do not perform well on noisy scenes. In this paper, we propose a noise-aware light field depth estimation algorithm which is insensitive to noise. First, an optical flow approach is used to compute disparities between the central view and each of the remaining views, then a weighted integration method is used to reduce calculation errors. Second, a refinement framework, which is measured using the refocus image and angular patch, is proposed to handle occlusion and texture-less parts. Third, a K-means clustering-based strategy is used to improve noise capability. Finally, a depth map is regularized by a Markov random field (MRF). Extensive experiments are conducted on synthetic datasets and real-world datasets. Both quantitative and qualitative results have demonstrated the superiority and robustness of our method.'}\n","{'text': 'Modelling three-dimensional virtual objects in the context of architectural, product and game design requires elaborate skill in handling the respective CAD software and is often tedious. We explore the potentials of Kohonen networks, also called self-organizing maps (SOM) as a concept for intuitive 3D modelling aided through mixed reality. We effectively provide a computational \"clay\" that can be pulled, pushed and shaped by picking and placing control objects with an augmented reality headset. Our approach benefits from combining state of the art CAD software with GPU computation and mixed reality hardware as well as the introduction of custom SOM network topologies and arbitrary data dimensionality. The approach is demonstrated in three case studies.'}\n","{'text': 'This paper proposes an adaptive transform domain image super-resolution method, utilizing orthogonally regularized deep networks. The method employs discrete cosine transforms, which are applied to input images in order to obtain their transform domain representations. The transformed images then undergo a training process using a deep learning model, which utilizes spatial resolution information to generate high-resolution images. The proposed method is able to adaptively learn the characteristics of input images, thus enabling it to achieve superior performance compared to traditional methods that employ fixed dictionaries. Overall, the results of this study demonstrate that the proposed method is a promising approach to address the problem of image super-resolution in real-world applications.'}\n","{'text': 'In this paper, a performance guaranteed control algorithm is presented for the consensus control of a class of unknown nonlinear multi-agent systems (MASs) with unknown control directions. It is shown that the states of agents stay within prescribed time-varying restrictions for all time. To attain these new results, an equivalent unconstrained MAS is generated from the original constrained one via a state transformation technique. Stabilization and consensus of the transformed agent states ensure both the consensus of the original agent states as well as the satisfaction of the prescribed restrictions. Based on the Nussbaum gain technique, the unknown control direction problem is solved. Consensus task is achieved theoretically via using Lyapunov synthesis, along with all the closed-loop signals being bounded. Additionally, in the proposed control design, each agent only exchanges the information with its neighbours. Hence, the proposed consensus protocol is distributed. Finally, simulation results demonstrate the effectiveness of the developed controller.'}\n","{'text': 'A novel quadrature phase shift keying (QPSK) carrier tracking method used in coherent demodulation is proposed for satellite communications. Frequency ambiguity is always ignored by the traditional ones which results in that the maximum pull-in range of the carrier tracking loop is limited to one eighth of the symbol rate. A novel low complexity QPSK frequency/phase discriminator and a frequency estimation and compensation (FEC) module are presented in this paper to enlarge the frequency pull-in range, which can resolve the phase jump and frequency ambiguity problem in carrier tracking process and also has the few calculation complexity comparing with the traditional QPSK detector. A parallel FLL-assisted-PLL is adopted to simplify the design structure through the module reuse. Comparing with the state-of-the-arts, this method has lower complexity, smaller variance and larger pull-in range.'}\n","{'text': 'This paper presents a Multi-View Saliency-Guided Clustering approach for Image Cosegmentation, which incorporates multiple views from different perspectives to identify salient objects in images. One of the main focuses of this study is on developing clustering algorithms that are robust and effective in grouping similar objects together. The proposed approach involves task analysis to identify the key features of objects and partitioning algorithms for grouping objects into clusters. The model is optimized to improve the overall performance of the clustering algorithm, and visualization techniques are used to provide a clear representation of the groupings. The paper demonstrates the effectiveness of this approach on various datasets and benchmarks, and provides a comparative analysis with existing methods. The results show that the proposed approach outperforms existing methods with higher accuracy and better robustness. This study highlights the importance of incorporating saliency-guided clustering techniques in image cosegmentation to achieve better results.'}\n","{'text': 'This paper proposes a novel approach to improve automated lane change detection while driving by removing electroencephalography (EEG) artifacts. The proposed method adopts reservoirs and support vector machines (SVMs) to remove EEG artifacts in real-time. Magnetic heads are utilized to capture EEG signals to be used as inputs for machine learning algorithms. The proposed approach leverages the power of neurons by using recurrent neural networks (RNNs) to capture the temporal dynamics of EEG data. Finally, SVMs are trained on the preprocessed EEG data to classify lane changes. The experimental results show that the proposed method outperforms existing methods in terms of accuracy and efficiency. This system can potentially improve the safety and comfort of driving by providing early warning of lane changes to the driver.'}\n","{'text': 'The forming of flocks from birds is a well-known example of emergent behaviors. With the rise of the Internet of Things (loT), where multiple independent devices are interconnected, emergence of behaviors is also plausible. One example is the formation of platoons from independent and autonomous vehicles. Efforts are underway to engineer IoT applications with emergent behaviors, while ensuring the preservation of quality attributes such as elasticity and resilience. However, to the best of our knowledge, a process which guides teams in designing, developing and operating emergent IoT applications with the focus on elasticity and resilience is missing. Therefore, in this paper, we deduce heuristically an initial process model which consists of steps and processes to be established in the design, development and operation of emergent IoT applications for elasticity and resilience. Furthermore, through a running example, we identify four aspects which characterize emergent behaviors: unpredictability, detectability, affinity and optimization opportunity. The proposed process model aligns with the identified characteristics.'}\n","{'text': 'The Sybil attack poses a serious threat to the smooth functioning of vehicular ad hoc networks (VANET). This type of attack involves an intruder claiming or stealing multiple identities and using them to disseminate false information, thereby disrupting the VANET network. Many solutions have been proposed in order to defense the VANET network against the Sybil attack. The hybrid detection scheme will be implemented using the ns2 simulator, and it will leverage the strengths of both the P2DAP and footprint algorithms. P2DAP offers superior performance when the number of vehicles increases, while the footprint algorithm is more effective when the speed of vehicles increases. P2DAP acting better than footprint when the number of vehicles increases. To generate scenarios for our simulation, we will use SUMO and MOVE tools. A new hybrid algorithm will be performed that depends on the encrypted, authentication and on the trajectory of the vehicle. By combining the strengths of multiple algorithms and leveraging sophisticated simulation tools, we hope to contribute to the development of effective strategies to secure these critical networks.'}\n","{'text': 'In this letter, we consider a team of robots that cooperatively transport a payload with an unknown mass in the presence of unknown drag forces. We develop a concurrent learning-based adaptive control algorithm that estimates the drag forces and the unknown mass and drives the agents and the payload to a common desired velocity. The algorithm also regulates the contact forces on the payload. We prove that the estimated parameters, including the mass of the payload, converge to their true values. We validate the effectiveness of the proposed algorithm using two simulation examples.'}\n","{'text': 'The control of bipedal locomotion is often considered to arise from the optimization of variables related to energetic cost and stability. However, developing model-based predictions of optimal strategies can be challenging due to the high-dimensionality of the control space and challenges associated with optimizing potentially conflicting objectives. Here, we present a framework for simulating bipedal gait which can ultimately be used predictive simulations of optimal gait patterns. We modeled a human-like biped and a treadmill in Matlab Simscape and used Dynamical Movement Primitives (DMP) to generate control joint-level controllers from demonstrations of human walking. DMPs facilitate the optimization of gait patterns through a small number of free parameters, such as the amplitude and timing of the patterns. We also implemented a simple feedback controller that variated the amplitude of the DMPs to stabilize the biped based on the deviation from a reference point on the treadmill. Optimizing of this controller allowed us to generate a human-like gait and ultimately contributed to the development of a platform with which we can explore optimization principles during locomotion.'}\n","{'text': 'Image stitching is an important part of computer vision, and how to do it more efficiently with high quality is a heated topic. In this paper, the authors propose a new method called TMGA for image stitching to get an improved performance in calculating Transform Matrix by using Genetic Algorithm. The proposed TMGA not only counts the number of interior points, but also takes standard error and degree of dispersion into consideration compared the traditional methods. The results demonstrate that the proposed algorithm can gain a high-quality transform matrix and improves the result of the stitching.'}\n","{'text': 'To handle the customer distribution in the certain areas, crowd counting is necessary for such applications, which is a labor-intensive work for human. Therefore, an automatic crowd counting system is in great demand, but it is still a challenging problem since the human heads and bodies are usually highly overlapping in crowd images. In this paper, a counting-by-regression framework is employed. The human head is modeled as a Guassian distribution. With a crowd density map estimator, the head count can be obtained by integrating over the density map. Most existing approaches only apply density map regression for training a density map estimator, but it is hard to find a suitable training parameters to train a good one; actually, the head count is overestimated easily. To mitigate this problem, counting regression is combined with density map regression. A deeper and lighter fully convolutional network (FCN) is designed to be a crowd density map estimator. The input and output size of the FCN are the same. After training by the proposed method, our model is more competitive comparing with others. The parameter quantity of the model is the lowest, and it needs the least inference time.'}\n","{'text': \"The internet has created a platform where people can exchange ideas, learn new things, and have meaningful conversations. For online interactions to be productive, it is necessary for users to feel comfortable sharing information without the fear of online hate, which includes insults, personal attacks, identity hate, threats, and more. To address this issue, the first step is to identify such online behavior. Framing the problem as text classification, we present a novel and versatile model in this paper which employs Recurrent Neural Network and Capsule network as its backbone and captures contextual information to a larger extent when learning word representations in the text. A series of experiments are conducted on Wikipedia's talk page edits provided by Jigsaw in Kaggle's toxic comment classification challenge. The results show that our proposed model outperforms other traditional state-of-the-art models on the dataset, proving the effectiveness of capsule networks for multi-label text classification. The superior performance of architecture is also confirmed by results obtained on traditional benchmark datasets such as AG News, IMDB Large Movie Review and Yelp Reviews data.\"}\n","{'text': 'Mauritius suffers from chronic water shortages that can severely impact its economy and the well-being of its population. Both surface and groundwater availability are determined by rainfall, which is in turn influenced by large-scale circulation patterns such as the El NiÃ±o Southern Oscillation (ENSO) and the Indian Ocean Dipole (IOD). Here we report on the influence of these two teleconnection patterns and present the result of a simple neural network for precipitation forecasting, based on the state of ENSO and IOD. Data from the Vacaos station, for the period 1961 to 2012 is used. We found statistically significant correlation between average winter rainfall and ENSO and IOD indices. The correlation for summer was negligible. The prediction of summer precipitation was less accurate than that of winter precipitation. The findings from this study can help in more efficient planning and management of water resources on the island.'}\n","{'text': \"Computer Vision has become the poster child for Deep Learning. The image classification accuracy of convolutional neural nets on benchmark data sets has increased every year since their inception. This has been aided with advances in feature fusion. The increase in the availability of imagetext occurrence has lead to text augmented feature spaces that have lead to higher accuracy in in image classification tasks. However, these works are limited to instances where text is readily available. This study presents an approach to featurize text within natural images with the goal of augmenting image features for image classification tasks. Text extraction and featurization in natural images is a challenging task due to challenges in reliable text localization and OCR results, both being impeded by the variability in image text and errors in OCR. We overcome these challenges by implementing a novel bounding box concatenation algorithm and a novel feature boosting algorithm. The result is a pipeline that encodes an image into a text feature space. Classifiers trained on the text based feature space have comparable accuracy to the state of the art Convolutional Neural Nets (CNN's) while being significantly inexpensive computationally. Moreover, the augmentation of text features to image features generates a hybrid feature space with a higher information content for a classification problem when compared to a feature space comprised exclusively of image features. Thus, we see a rise in classification accuracy across all state of the art machine learning algorithms.\"}\n","{'text': 'Underground strata are reflected in various information sources in petroleum exploration, including good logging and drilling data. Real-time measurement parameters obtained from mud logging can provide data support for the early discovery of oil and gas resources and the prevention of safety accidents. It plays a forward-looking role in the drilling process. In this paper, we aim at the defection of fuzzy and random characteristics of the big data of drilling element parameters in the current drilling process. A new method named grey wolf optimization-support vector machine (GWO-SVM) is proposed by analyzing the relationship between logging data and formation to solve the serious problem of formation misjudgment. Using element content and Gamma-ray value, data mining is performed by a large number of real-time data obtained from the drilling site. The obtained information is used for comprehensive estimation and prediction of strata. First, the data is normalized, and then, the best Î¶ and Ï\\x83 values are found through the optimization of gray wolf algorithm, next the SVM training is carried out, finally, the formation prediction model is established, and the error analysis of the results was conducted. In the paper, the algorithm model is subsequently applied to three actual wells. The GWO-SVM model based on drilling data is used to predict the formation, and the error analysis showed that the error range of the GWO-SVM algorithm is within 10%. Compared with the GWO-SVM, the model accuracy of SVM, Particle Swarm OptimizationSupport Vector Machine (PSO-SVM) algorithm is lower 53% and 23%, respectively. The GWO-SVM has higher robustness, reliability, and achieves faster convergence speed, stronger generalization effect, and improves the identification accuracy of elements for the formation. The average accuracy of the GWOSVM in stratum dynamic identification is 93.5%. This model is implemented to support the logging system to improve application strength.'}\n","{'text': 'Sentence embedding has become an important task in natural language processing, with applications in document summarization, sentiment analysis, and machine translation. In this paper, we propose a jointly learning topic model for sentence embedding to improve document summarization. The model uses semantic information to predict the topic of a document, and then uses that information to extract relevant features. We also introduce a novel approach to context modeling that incorporates the topic information into the training process. Experimental results show that our model outperforms state-of-the-art models on the DUC benchmark dataset. Our approach can be easily extended to other tasks that require feature extraction and computational modeling, and has the potential to improve task analysis and predictive models in natural language processing.'}\n","{'text': 'With the wide applications of wireless sensor networks (WSNs) in various fields, such as environment monitoring, battlefield surveillance, healthcare, and intrusion detection, trust establishment among sensor nodes becomes a vital requirement to improve security, reliability, and successful cooperation. The existing trust management approaches for large-scale WSN are failed due to their low dependability (i.e., cooperation), higher communication, and memory overheads (i.e., resource inefficient). In this paper, we propose a novel and comprehensive trust estimation approach (LTS) for large-scale WSN that employs clustering to improve cooperation, trustworthiness, and security by detecting malicious (faulty or selfish) sensor nodes with reduced resource (memory and power) consumption. The proposed scheme (LTS) operates on two levels, namely, intra-cluster and inter-cluster along with distributed approach and centralized approach, respectively, to make accurate trust decision of sensor nodes with minimum overheads. LTS consists of unique features, such as robust trust estimation function, attack resistant, and efficient trust aggregation at the cluster, head to obtain the global feedback trust value. Data trust along with communication trust plays a significant role to cope with malicious nodes. In LTS, punishment and trust severity can be tuned according to the application requirement, which makes it an innovative LTS. Moreover, dishonest recommendations (outliers) are eliminated before aggregation at the base station by observing the statistical dispersion. The theoretical and mathematical validations along with simulation results exhibit the great performance of our proposed approach in terms of trust evaluation cost, prevention, and detection of malicious nodes as well as communication overhead.'}\n","{'text': 'State-dependent networked dynamic systems are ones where the interconnections between agents change as a function of the states of the agents. Such systems are highly nonlinear, and a cohesive strategy for their control is lacking in the literature. In this paper, we present two techniques pertaining to the density control of such systems. Agent states are initially distributed according to some density, and a feedback law is designed to move the agents to a target density profile. We use optimal mass transport to design a feedforward control law propelling the agents towards this target density. Kernel density estimation, with constraints imposed by the state-dependent dynamics, is then used to allow each agent to estimate the local density of the agents.'}\n","{'text': 'The efficiency of data collection in the water column is a major challenge in oceanographic field studies. We propose an AUV system based on wireless mesh network to cope with it. The investigated field for water column sampling mission is structured in several areas. Multiple AUVs collect data in the water simultaneously. After the data collection, AUVs can access to the wireless mesh network for data consolidation and mission allocation. The design of the AUV System also pays attention to the endurance and the cost of AUVs. The introduction of the wireless mesh network and the proposed scenario give a new way for data collection in the water column.'}\n","{'text': 'Video summarization (VSUMM) has become a popular method in processing massive video data. The key point of VSUMM is to select the key frames to represent the effective contents of a video sequence. The existing methods can only extract the static images of videos as the content summarization, but they ignore the representation of motion information. To cope with these issues, a novel framework for an efficient video content summarization as well as video motion summarization is proposed. Initially, Capsules Net is trained as a spatiotemporal information extractor, and an inter-frames motion curve is generated based on those spatiotemporal features. Subsequently, a transition effects detection method is proposed to automatically segment the video streams into shots. Finally, a self-attention model is introduced to select key-frames sequences inside the shots; thus, key static images are selected as video content summarization, and optical flows can be calculated as video motion summarization. The ultimate experimental results demonstrate that our method is competitive on VSUMM, TvSum, SumMe, and RAI datasets about shot segmentation and video content summarization, and can also represent a good motion summarization result.'}\n","{'text': 'This study aims to investigate the differences in the Electromyography (EMG) Feature Space between Able-Bodied and Amputee Subjects for Myoelectric Control. Feature extraction and Time-frequency analysis techniques were utilized to determine complexities in the EMG signals. The research involved a cross-sectional study design with a sample of able-bodied individuals and amputee subjects. The results revealed that the EMG feature space of the amputee subjects was significantly different from that of the able-bodied individuals regarding muscle activation. This study provides valuable insight into the field of Myoelectric Control, and the findings can be used to improve the design of prosthetic devices for better functionality. Furthermore, the research demonstrated the use of Complexity theory in understanding the EMG signals, and the importance of utilizing statistical and data analysis to draw meaningful conclusions. The study contributes both to the fields of engineering and sociology, emphasizing the importance of socio-technical studies in understanding the dynamics of technological interventions.'}\n","{'text': 'A new approach for designing a decentralized observer to estimate the un-measurable states of a discrete-time large-scale Takagi-Sugeno (T-S) fuzzy system is considered in this paper. The interconnection terms of the large-scale system in this study is with an arbitrary nonlinear form and unnecessary to satisfy the bounded constraints. On the basis of the Lyapunov theory, the conditions for observer design which are expressed under the framework of LMIs are derived in the main theorems. Finally, an example is introduced to show the effectiveness of the proposed method.'}\n","{'text': 'This paper focuses on the sentiment analysis of music lyrics using supervised learning algorithms. The objective of the study is to classify the music lyrics according to mood using machine learning techniques. The study employs classification algorithms for data mining and sentiment analysis. The study uses a large dataset of music lyrics for training and testing the model. The results show that the supervised learning algorithm outperforms traditional techniques for sentiment analysis. The findings suggest that the use of machine learning algorithms in sentiment analysis of music lyrics can be effective for classifying music according to mood. The research provides a valuable contribution to the field of music analysis and has potential applications in different fields including music recommendation systems and emotion recognition.'}\n","{'text': 'With the continuous progress of the space station project, the rotary mechanism is widely used in the space station. Serious failure of rotating mechanism can cause motor burnout and then safety problems. Therefore, it is necessary to monitor and diagnose rotating mechanism. The vibration signal of the rotating mechanism is nonlinear and non-stationary. Therefore, the acceleration sensor vibration signal is decomposed by CEEMD method to get the intrinsic mode function. Next, Fourier transform is used to obtain time-frequency information according to the obvious components of fault characteristics, and the information entropy of time-frequency information is calculated. The degree of dimensionality reduction about fault feature is determined by selecting the number of principal components through adaptive cumulative contribution. Finally, the fault feature is trained by support vector machine and tested with data. Experimental results show that the optimized method is less computational and can accurately extract fault feature information.'}\n","{'text': \"This paper introduces a Bayesian approach to actively exploring a planar shape with both localization and shape uncertainty. The goal is to dock the robot's end-effector against the shape-reaching a point of contact that resists a desired load-with as few probing actions as possible. The proposed method involves several steps, including inference, planning, and execution. Given a prior probability distribution over object shape and sensor readings from previously executed motions, the posterior distribution is inferred using a novel and efficient Hamiltonian Monte Carlo method. The optimal docking site is chosen to maximize docking probability, using a closed-form probabilistic simulation that accepts rigid and compliant motion models under Coulomb friction. Numerical experiments show that this approach requires fewer exploration actions to reach the docking stage than comparable heuristics and information-gain strategies.\"}\n","{'text': 'The problem on loss free burst transmission has been well studied in Burst Switching Networks (BSN). There are number of approaches discussed for the performance development, but suffers to achieve higher performance. To overcome the issue, an burst rate based dynamic IO Queue management scheme has been presented. The method monitors the incoming burst traffic from more number of nodes and according to the rate of burst coming, the input output queue systems has been modified for their size. The burst in the queue system has been routed through available routes whenever identified. The method is capable of triggering the IO queue systems up and down according to the burst traffic. The proposed method improves the performance of burst switching networks.'}\n","{'text': \"The arc fault occurs frequently in aircrafts due to the poor working environment of the cable which needs to be diagnosed and excluded promptly. Currently, the AC fault characteristics studies and the detection algorithms studies are dependent on the experimental data. However, the AC arc fault experimental data has randomness, so it is necessary to do some research on AC arc modeling. This paper researches AC arc modeling based on the simplified Schavemaker model. Since model parameters' values vary with different working conditions and parameter calculation methods are inaccurate, complex to operate and dependent on experimental data, this paper firstly proposes a calculation method based on experimental data which is easy to operate with high accuracy. Then, this paper proposes another calculation method based on neural network using the first calculation method to obtain training samples. Next, the neural network between the model parameters and the working conditions is constructed. Finally, the accuracy of the proposed calculating method for the model's parameters and the accuracy of the AC arc model are verified by comparing the arc characteristics' values of the experimental data and the simulation results.\"}\n","{'text': 'In this paper, we present a new load balancing algorithm based on multi-criterion decision making (MCDM) to select efficient relay UAV. For MCDM operation, buffer occupancy, remaining energy and link quality given by number of retransmission are consider. Through simulation result, we demonstrate that the proposed scheme can improving packet delivery ratio and end-to-end delay by reducing the congestion significantly.'}\n","{'text': 'Fraud detection methods are continuously being developed to defend against criminals. They allow us to identify quickly and easily the frauds. In this work, we will focus on the problem of fraud detection in banking transactions. As not a single algorithm may be suitable for every problem, it is crucial to select an algorithm that performs best in a given situation. We therefore present a comparative analysis of four algorithms: Simple Anomaly detection algorithm, Decision Tree algorithm, Random Forest algorithm, and NaÃ¯ve Bayes algorithm. In this work, we give a comparative analysis of four algorithms: Simple Anomaly detection algorithm, Decision Tree algorithm, Random Forest algorithm and NaÃ¯ve Bayes algorithm. We use the machine learning library (MLlib) of Apache Spark to handle credit card fraud detection. The data used in our simulation is generated randomly following a normal distribution, this data includes two features Price and Distance that allow us to distinguish anomalies and valid transactions. Performance analysis is based on the parameters of Total Running Time and Accuracy. Our results show that the Random Forest algorithm provided the best results, whereas the Simple Anomaly detection algorithm produced the worst results.'}\n","{'text': 'In the report, physical and media-access level of wireless ultra-wideband sensor network are considered. The physical level of discussed network is based on chaotic radio pulses. It allows to achieve two contradictory goals: fast establishment of links between network nodes, and realization of energy saving modes. This network belongs to the class of wireless personal area networks. It consists of short-range transceivers with radio links up to 100 m in free space, average emission power ~ 0.1 mW and physical data rate up to 12 Mbps.'}\n","{'text': 'Message Queue Telemetry Transport (MQTT) is widely accepted as a data exchange protocol in Internet of Things (IoT) environment. For security, MQTT supports Transport Layer Security (MQTT-TLS). However, MQTT-TLS provides thing-to-broker channel encryption only because data can still be exposed after MQTT broker. In addition, ACL becomes impractical due to the increasing number of rules for authorizing massive IoT devices. For solving these problems, we propose MQTT Thing-to-Thing Security (MQTT-TTS) which provides thing-to-thing security which prevents data leak. MQTT-TTS also provides the extensibility to include demanded security mechanisms for various security requirements. Moreover, the transparency of MQTT-TTS lets IoT application developers implementing secure data exchange with less programming efforts. Our MQTT-TTS implementation is available on https://github.com/beebit-sec/beebit-mqttc-sdk for evaluation.'}\n","{'text': 'Cloud computing is a new model that gives appropriate, on-demand access to a shared pool configurable computing resources. In cloud computing, IT-related abilities are given as services, available without requiring a deep knowledge of the underlying technologies, also, with insignificant administration exertion. The security issue turns out to be more complex under the cloud model as new measurements have gone into the issue scope related to the model architecture, multi-tenancy, elasticity, and layers dependency stack. In this paper, a survey on communication security issues over cloud computing is presented along with their solution.'}\n","{'text': 'Higher education is faced nowadays with great challenges related to preservation and improvement of quality in teaching, the use of new technologies and new pedagogical approaches, equal access to studies, improving staff and student mobility, and employability of graduates. Therefore, it is the aim of many existing or future projects to provide solutions to these challenges. In this paper two European projects: CARIBU (Erasmus Mundus Action 2) and IMPROPAL (Erasmus KA2-Cooperation for Innovation and Exchange of Good practices Strategic partnerships for higher Education) in which the Technical University of Cluj-Napoca, Romania was involved as partner will be presented as examples of best practice for increasing student and academic mobility exchanges and for learning enhancement through innovative pedagogical approaches.'}\n","{'text': \"Virtualized software-defined networking (SDN) has been drawing increasing attention in data centers. SDN enables the creation of arbitrary and flexible virtual networks. However, given that the physical network is shared among multiple tenants, the throughput of a tenant can interfere with that of the other tenants, and the throughput requirement on each tenant cannot be met. To solve this problem, we propose TALON, a throughput allocation scheme based on traffic load-balancing. TALON allocates a throughput per tenant flow by calculating multiple paths to fulfill the traffic requirement. We design and implement TALON using an open-source network hypervisor. The evaluation results show that each tenant's throughput requirements are nearly met. In addition, the throughput increases by up to 2.29 times compared to that of a non-load-balancing network.\"}\n","{'text': 'This paper focuses on the FE simulation and motion tracking of a soft ring-shaped actuator used in soft robotics. The actuator is capable of generating strain and is inspired by the contraction of the stomach. Computational modeling is used to simulate the behavior of the actuator and track its motion. By accurately predicting the motion of the actuator, it can be further optimized for various applications in soft robotics. This research provides valuable insights into the design and development of soft actuators, which can potentially revolutionize the field of robotics.'}\n","{'text': \"This paper describes our automatic cell image classification algorithm that explores expert's eye tracking data combined to convolutional neural networks. Our methodology involves selecting regions of interest that catch the attention of cytologists and focusing computation on cell classification of these specific sub-images. Our novel contribution is the integration of deep learning and saliency maps from eye-tracking to detect abnormal cells in Pap smear microscopy under real-world conditions such as noise, artifacts, and occlusion, thereby bypassing the need for segmentation. Our preliminary results demonstrate a high classification accuracy of approximately 90% for identifying critical cells within three levels: normal, low-risk disease, and high-risk disease. To validate our findings, we tested our algorithm on 111 images containing 3,183 cells, and acquired an average runtime of 4.5 seconds per image.\"}\n","{'text': 'Project-based learning (PBL) is an important component of the practical based assessment of software engineering courses. The success of PBL relies on team composition where all necessary skills to execute the project is needed. Conventionally, facilitators assign the students to the group randomly which results in biased groups where all the necessary skills to complete the project lacks in some of the groups. Most computational tools solve the group assignment problem (GAP) by assigning students to relevant groups based on some general criterion. However, there is a need for a system which allows taking skill preference as a parameter in a limited or unevenly distributed skill set. The system needs to have more or less same strength with the presence of all the skills required to complete the project. In this paper, a method is proposed that uses the canonical genetic algorithm to generate evenly balanced groups by minimizing the intergroup difference. We have employed penalty function to rank the skills and incur a penalty for the non-presence of required skills for proof of concept. Due to unavailability of benchmark datasets, we have used the real data of software engineering courses of our university where good results have been observed.'}\n","{'text': 'Social network websites have become important marketing platforms for studying business models. When impressive advertisements are posted on the platforms, social network users like to comment or post their experiences as part of feedback about the products. Those interesting opinions will exert influences on other users buying decisions but some may remain commented. This invokes peoples interests to dig out interesting relationship between sentiment of social network users and the volume of product sales. Then, they can apply the discovered patterns of sentiment and sales to predict users buying behaviors. This study proposes a framework based on data mining method to find interesting patterns of sentiment and sales. The proposed model starts by defining sentiment topics with their corresponding terms and then follows by a fuzzy model to infer the sentiment scores for user opinions. Each transaction in the database is transformed to attach with public sentiment scores, influential users sentiment scores and volume of product sales. To better obtain the relationship among public sentiment, users sentiment and volume of product sales, a mining method of inter-transaction association rules is considered to extract the interesting patterns of sentiment and sales. Two case studies are given to verify the effectiveness of the proposed method.'}\n","{'text': 'Image dehazing has been a great challenge in the process of adjusting haze images. In this paper, an effective and accurate dehazing method based on atmospheric scattering model is proposed. Since the dark channel is not applicable to sky areas, single-threshold segmentation combined with quad-tree partition technique is adopted to position and estimate the ambient light A* rapidly and accurately. In order to optimize transmittance, we employ a new convolutional network architecture, multi-feature-based bilinear CNN, which can mitigate the halo effect around the abrupt edges and restrain image noise, and the whole transmittance estimation process can be divided into three main parts: feature extraction, nonlinear mapping, and image reconstruction. A large number of outdoor haze image test results show that our optimized method has better experimental results than the existing methods.'}\n","{'text': 'Advances in IoT and cloud computing are revolutionizing the architecture of industrial control systems by changing them from isolated architectures to decentralized ones. This leads to increased complexity that exposes these systems to cyber threats from both the cloud and the control environment. Different cyber security standards have been proposed for securing these systems based on a set of security requirements. However, these requirements are often specified in natural language, which makes formal verification of security properties against the standards challenging. In this paper we propose a framework for modeling cloud-connected SCADA systems and formally verify their compliance with the IEC-62443-3-3 standard. We model the system and the security requirements from the standards using the formal modeling language TLA+ in order to formally verify compliance with the standard using the TLC model checker. The applicability of our technique is demonstrated using an industrial case study.'}\n","{'text': 'In this paper, we propose a modeling approach for trajectory-based I2V message delivery over VANETs with vehicle detours. The proposed approach includes both numerical models and analytical models, which can effectively predict the message delivery performance over a wide range of scenario settings. Specifically, we focus on the trajectory of vehicles and design corresponding protocols to facilitate message delivery. Vehicular ad hoc networks are employed as the communication platform, which can effectively support the transmission of messages between vehicles. Our experimental results demonstrate that the proposed approach can effectively improve the message delivery performance in scenarios with vehicle detours, and achieve a higher success rate compared to traditional approaches. These findings can provide practical guidance for the design of efficient and reliable trajectory-based message delivery protocols, which can ultimately benefit the development of VANETs.'}\n","{'text': 'A post convolutional neural networks (CNN) method is proposed to extract ships from high resolution optical remotely sensed images. It consist of two parts: ship proposal detection and ship extraction based on CNN. The first part aims to locate possible ships through classification of water and no-water, seawater area extraction using mathematical morphology, and ship proposal extraction. Ships are extracted in the second part by implementing a trained CNN on the ship proposals. Experimental results on a high resolution optical image of San Francisco Bay show the efficiency and robustness of the proposed post CNN method.'}\n","{'text': 'In the field of polymers, testing and predicting the mechanical properties of various materials are essential for optimizing products and processes. The aim of this study is to develop predictive models using machine learning algorithms to estimate the tensile strength of extrusion-blown high-density polyethylene film. Several prediction algorithms including decision trees were used for training and testing. The results show that the developed models can accurately predict the tensile strength of the film. The proposed methodology could be helpful in improving the efficiency of product design and process optimization in the polymer industry. Moreover, this approach shows considerable potential for future work in the prediction of other mechanical properties of polymers by using machine learning algorithms.'}\n","{'text': 'In this paper, we propose an ensemble learning scheme for indoor-outdoor classification based on key performance indicators (KPIs) of LTE network, global positioning system (GPS), and frequency measurement. The proposed scheme utilizes big data to classify indoor and outdoor areas in urban regions. Decision trees and machine learning algorithms are employed to improve the accuracy of the classification. The experimental results demonstrate that our proposed scheme achieves a high level of accuracy for indoor and outdoor area classification. The proposed scheme can be applied to various applications, such as urban planning and management, location-based services, and marketing. Overall, the proposed scheme can aid decision-making processes in urban areas and allow for the creation of more effective solutions for urban problems.'}\n","{'text': 'Most traditional supervised classification methods for polarimetric synthetic aperture radar (PolSAR) imagery require abundant manually selected samples, and the classification results are affected by the size and quality of the samples. In this paper, we propose an improved deep Q-network (DQN) method for PolSAR image classification, which can generate amounts of valid data by interacting with the agent using the Îµ-greedy strategy. The PolSAR data are first preprocessed to reduce the influence of speckle noise and extract the multi-dimensional features. The multi-dimensional feature image and corresponding training image are then fed into a deep reinforcement learning model tailored for PolSAR image classification. After many epochs of training, the method was applied to identify different land cover types in two PolSAR images acquired by different sensors. The experimental results demonstrate that the proposed method has a better classification performance compared with traditional supervised classification methods, such as convolutional neural network (CNN), random forest (RF), and L2-loss linear support vector machine (L2-SVM), and also has a good performance compared with the deep learning method CNN-SVM, which integrates the synergy of the SVM and CNN methods, especially in small sample sizes. This study also provides a toolset for the DQN (kiwi.server) on the GitHub development platform for training and visualization.'}\n","{'text': \"Wireless sensor networks (WSNs) have become crucial in monitoring environments and collecting data. However, the information collected by WSNs is vulnerable to privacy breaches such as source location tracking. CPSLP, a cloud-based scheme, is proposed to protect the source location privacy of WSNs. The scheme uses multi-sinks, which act as phantoms, to confuse adversaries from associating the source with the sensors. The scheme also employs a routing algorithm that optimizes cloud utilization and minimizes energy consumption. Cloud computing is utilized to offload computational tasks from the resource-constrained sensors, ensuring the scheme's scalability. Simulation results show that CPSLP outperforms existing schemes in terms of privacy preservation, energy efficiency, and delay. CPSLP provides an effective solution to address the source location privacy issue in WSNs, making it ideal for application scenarios that require privacy protection.\"}\n","{'text': \"To offer high quality services to patients, hospitals try to get a perception of patients' processes. This research work aims at identifying a type of processes known as patients' pathways and to devise a framework which could support the task of discovering patients' pathways. Existing modeling languages for discovering patients' processes fail at extracting the value and nature of each activity relevant to the whole process. To fill the identified gap, this paper uses a new approach for visualizing patients' pathways as Operational Process Charts (OPC). To do so, Real-Time Location Systems (RTLS) have been used to extract the primary event logs which contain the data related to movements of patients. Next, we have designed a meta-model which can filter and analyze the RTLS event logs and identify the different elements for the construction of OPC's. This paper focuses on presenting the DIAG meta-model for interpretation of event logs and the transformation of these data into opc's.\"}\n","{'text': 'Deploying neural networks models over embedded devices have an increased interest and many works is ongoing on that topic. Energy consumption, model sizes and inference time are critical issues as explained in the literature. In the context of IoT and edge computing, tradeoff have been studied in order to get a low cost but rapid answer, robust to connection issue exploiting early exiting or distributing deep neural networks. Those approaches exploits the cloud as an endpoint, balancing the load with respect to different computing capabilities. In this paper, we propose to extend those approaches to networks of embedded devices such as a swarm of drones, where every device has the same computing capabilities (in terms of energy and speed). Computing load may be balanced among the whole swarm in order to maximise either the lifetime of specific devices or lifetime of the whole swarm. We develop criteria to best cut and distribute those networks, validate them through power measurement and express the different tradeoffs we have to address.'}\n","{'text': 'In this paper, we propose a survival factorization framework that models information cascades by tying together social influence patterns, topical structure, and temporal dynamics. This is achieved through the introduction of a latent space which encodes: (a) the relevance of an information cascade on a topic; (b) the topical authoritativeness and the susceptibility of each individual involved in the information cascade, and (c) temporal topical patterns. By exploiting the cumulative properties of the survival function and of the likelihood of the model on a given adoption log, which records the observed activation times of users and side-information for each cascade, we show that the inference phase is linear in the number of users and in the number of adoptions. The evaluation on both synthetic and real-world data shows the effectiveness of the model in detecting the interplay between topics and social influence patterns, which ultimately provides high accuracy in predicting users activation times.'}\n","{'text': 'Wireless Sensor Networks (WSNs) find varied applications because of their unique features, such as low power consumption, small size, self-organization, and deployment flexibility. The localization of nodes in WSNs is essential for most of the applications, which demands accurate spatial information. The adaptive localization algorithm presented in this paper is based on range, clocks, and distance measurement. A mathematical model of the attenuation effects due to signal delays is utilized to calculate the range between nodes. This algorithm adjusts the weights according to the number of communicating nodes to improve the accuracy of localization. The proposed algorithm is compared with other localization algorithms and is found to be more accurate. Moreover, the implementation and evaluation of the algorithm are validated using standard experiments, showing that it can effectively localize nodes in WSNs.'}\n","{'text': 'In order for robots to learn more complex behaviors, recognizing primitive behaviors plays a fundamental role. Research has shown that the recognition of primitive behaviors such as basic gestures enables robots to learn more complex behaviors as combinations of these simple, primitive behaviors. The focus of this study is to investigate the tolerance of neural network models to noisy inputs. We compare and evaluate several neural network architectures including the multilayer perceptron (MLP), time-delay neural network (TDNN), recurrent neural network (RNN) and the Long Short-Term Memory (LSTM). We show that the LSTM is superior to other models in terms of its robustness noisy inputs subjected to Gaussian noise.'}\n","{'text': \"Smart cities have become an essential and global need; they enhance the infrastructure to mitigate the problems caused by the rapid pace of the urbanization. The main goal is not only achieving a smart city but to realize a smart sustainable city, to achieve the balance of the environment alongside the balance of the city's technology evolution. The Internet of Things (IoT) technology is the most popular technology used in smart cities due to its efficiency in wide varieties of applications. Although the IoT is yet to fully emerge, the energy demand has proven to be significantly increased and will keep on increasing over the upcoming years, that's why it's crucial to investigate the Green IoT. One of the most challenging issues in cities is pollution especially air pollution. Air pollution will become a catastrophe with technological advancement if cities turned a blind eye to it. It has a direct effect on people's health as well as the ecosystem. From this point, this paper suggests a green IoT based efficient system that detects and monitor the outdoor air pollution level; the system is powered by renewable energy. The system monitors the pollution level; if the pollution level exceeds the acceptable pollution level, it takes a decision to notify the authorities who can use this data in planning preventive actions and take measures to stop the continuous harmful air pollution effects and prevent the evolution of this phenomenon.\"}\n","{'text': 'The proportion of the stock range that is devoted to spare parts is often considerable in industrial context. As such, even minor enhancements in spare parts demand forecasting can result in significant cost reductions. Time series analysis has been the most popularly applied method in the prior spare part demand forecasting models. However, these approaches need to be improved in terms of prediction accuracy. In this study, we gathered component consumption data including structured and unstructured data from a spare part management information system in military logistics. Our approach yielded superior prediction performance compared to traditional approaches. Overall, our results suggest that this method has great potential for improving spare parts demand forecasting in industrial settings.'}\n","{'text': 'This paper proposes an improved image high fidelity compression algorithm based on the generative adversarial networks (GANs) to deal with the problem that the UAV image has a large amount of data which is not conducive to post-processing. By adding an encoder in front of the generator, the disaster area image transmitted by UAV is compressed to meet the requirements of the generator. After the compressed image is trained together with the real image through the discriminator, the quality of the compressed image is constantly improved. This image compression algorithm can fully synthesize the codes of non-major areas such as trees and rivers in the image, and try to retain the codes of important areas such as houses and roads. The experimental results show that the proposed compression method in this paper has a higher compression ratio than the traditional compression method for the disaster area image, and can obtain images with strong sense of hierarchy.'}\n","{'text': 'This paper proposes an optimal VM coalition scheme for multi-tier applications over multi-cloud broker environments. The main focus is on enhancing the quality of service and optimizing the pricing of cloud services through the collaboration among multiple cloud brokers. An aggregate of resources is considered, leading to a better resource management with a focus on game theory. The proposed approach identifies the best VM coalition that optimizes pricing and guarantees the necessary quality of service. The experimental results show that the proposed scheme is efficient and effective in terms of cloud service pricing, resource allocation, and overall performance. Overall, this paper presents a viable solution for multi-cloud broker environments that can lead to improved quality of service and pricing while optimizing resource management.'}\n","{'text': 'This paper proposes a novel Channel-Wise and Spatial Feature Modulation Network (CSFM-Net) for Single Image Super-Resolution. The CSFM-Net focuses on both spatial resolution and modulation, combining feature extraction and image reconstruction through a neural network architecture. The proposed model utilizes a channel-wise attention mechanism to extract relevant spatial features, which are then modulated to enhance the overall resolution of the image. Furthermore, the proposed CSFM-Net incorporates a blockchain approach to enhance the security and privacy of image data. Experimental results demonstrate that the proposed CSFM-Net achieves superior performance compared to existing state-of-the-art methods in terms of both quantitative and qualitative evaluations, showing its effectiveness in single image super-resolution tasks. Overall, the proposed CSFM-Net represents a promising development in the field of image processing and neural networks.'}\n","{'text': 'Wireless sensor networks (WSNs) are becoming increasingly popular in various domains including healthcare, environmental monitoring, and military applications. However, security remains a significant concern due to the limited resources of sensor nodes. In this paper, we propose a low power cryptography solution based on chaos theory for WSNs. The proposed solution utilizes chaos-based encryption algorithms to provide secure communication while minimizing power consumption. We demonstrate the feasibility and effectiveness of our approach through simulations and experiments. Our results show that our approach achieves satisfactory security levels with significantly reduced power consumption compared to conventional ciphers. This work provides a promising direction for the development of low-power cryptography solutions for resource-constrained WSNs.'}\n","{'text': 'As renewable wind energy penetration rates continue to increase, one of the major challenges facing grid operators is the question of how to control transmission grids in a reliable and a cost-efficient manner. The stochastic nature of wind forces an alteration of traditional methods for solving day-ahead and look-ahead unit commitment and dispatch. In particular, the variability of wind generation increases the risk of unexpected overloads and cascading events. To address these questions, we present an N-1 security and chance-constrained unit commitment (SCCUC) that includes models of generation reserves that respond to wind fluctuations and component outages. We formulate the SCCUC as a mixed-integer, second-order cone problem that limits the probability of failure. We develop a modified Benders decomposition algorithm to solve the problem to optimality and present detailed case studies on the IEEE RTS-96 three area and the IEEE 300 NESTA test systems. The case studies assess the economic impacts of contingencies and various degrees of wind power penetration and demonstrate the effectiveness and scalability of the algorithm.'}\n","{'text': \"Vehicular Ad hoc Network (VANET) is an advanced style and subcategory of a Mobile Ad hoc Network (MANET), the main objective of VANET's is to create an Intelligent Transport System (ITS). The routing in VANET has attracted many attentions during the last few years. Highly mobility of vehicles, irregular communication between the vehicles and the necessities of real time applications are some of the major challenges of multi-hop message delivery in VANETs. Because of the frequent changing topology of VANET it becomes difficult to route the packets effectively. In this research, we are focusing on the routing concept for the VANET i.e. principles for routing, decomposition of the routing function and requirement for Forwarding protocols unicast (Geographic based, Trajectory based and Link Stability based) and Probabilistic (Distance based) routing protocols in VANETs, To analyse the performance of the most suitable routing protocols and to determine the best efficient protocol for VANET environment.\"}\n","{'text': 'The concept of fairness has long been an integral part of economic and social systems. In recent years, with the growth of cloud computing and the need for efficient multi-resource allocation, fairness has also become a critical concern in computer science. Dominant Resource Fairness (DRF) is one approach that aims to achieve fairness in multi-resource allocation without sacrificing efficiency. This paper explores the fairness-efficiency trade-offs inherent in DRF and investigates its properties using computational modeling. The authors analyze several task scenarios to demonstrate the effectiveness and efficiency of DRF in resource management. Conferences and publications in the field of cloud computing and resource management have eagerly discussed DRF as a promising solution to the problem of efficient and fair resource allocation.'}\n","{'text': 'This paper discusses the application of data analytics and machine learning technologies in the field of wide area surveillance systems. Specifically, the focus is on trajectory analysis using machine learning algorithms to improve surveillance effectiveness. Radar tracking data is collected and analyzed to build predictive models that can identify potential threats, such as aircraft in restricted airspace. Additionally, the use of heating systems in surveillance applications is explored, as they can be used to create a temperature contrast that enhances object detection. Overall, this paper demonstrates the potential of data analytics and machine learning in enhancing the capabilities of surveillance systems, making them more effective and reliable.'}\n","{'text': \"Lane detection and tracking is essential concern in vision based autonomous vehicle navigation. This paper proposes a novel method based on probabilistic Hough transform and motion vector based analysis for detecting and tracking lane and lane departures. It addresses drawbacks of current systems under hazy situations with learning method based on previous tracking records of the system. In this method relevant lane mark features are extracted based on color variations. Therefore used HSL color model which gives higher color contrast of road surface and the markings. In order to reduce computation, processing algorithms are applied only to the region of interest (ROI). Edges of the selected regions are extracted with Canny Edge Detection. Since lane markings are made with set of straight lines, straight lines are extracted with Probabilistic Hough Transform. Extracted lines are analyzed to detect lane. To monitor lane departures vehicle's motion is detected and tracked based on motion vector analysis with Lucas Kanade Optical Flow algorithm. Previous detection records are used to track the lane continuously in hazy situations and provide prediction on approximate lane for the roads without lane markings. Experiments were performed on set of videos taken from vehicles' front camera mounted on dashboard. According to the experiments the proposed algorithm has 81.9% of sensitivity in lane detection and 63.5% in approximate lane predictions for the roads without lane markings. Lane detection algorithm has 83% precision, 68% recall and 0.75 F1 score with threshold brightness value 140. Algorithm can further improved to guide the autonomous vehicles to take accurate decisions on selecting safety lane to drive ahead in different situations.\"}\n","{'text': 'Defocus region detection (DRD) problem aims to assign per-pixel predictions of focus clear areas and defocus blur areas. One of the challenges in this problem is to accurately detect the boundary of the transition region between the focus and defocus regions. To address this issue, the paper proposes a direction-context-inspiration network (DCINet), which can take advantage of the directional context effectively. First, we extract directional context by recurrent neural networks initialized with the identity matrix (IRNN) to weight the feature maps and integrate them in the two-group integration method, which can produce the coarse DRD maps. Second, the maps are level-integrated with the source image guiding and the coarse maps are refined gradually. The overall DCINet can integrate low-level details and high-level semantics efficiently. The Experimental results demonstrate that the network can detect the boundary of the transition region precisely, achieving the state-of-the-art performance.'}\n","{'text': \"Pre-trained DCNN trained on a large-scale image database can be used as a universal feature representation for image classification, which has achieved significant progress in some image recognition tasks. Compared with other image recognition tasks, directly utilizing a single convolutional feature as feature representation for vein recognition task cannot achieve the impressive result due to the sparse distribution of vein information. Therefore, to obtain more representative and discriminative convolutional feature for vein recognition, a novel multi-layer convolutional features' concatenation with semantic feature selector is proposed in this paper. In the pre-trained DCNN, different convolutional layers can encode different-level feature information. High-level convolutional features with vein information cover more semantic information and low-level convolutional features with vein information cover more detail information. However, low-level convolutional features also contain some background information. Therefore, in order to remove the background information of low-level convolutional features, a novel semantic feature selector is presented. First, the proposed local max-pooling of preserving spatial position (LMP-PSP) information is applied on activation map obtained by adding up all feature maps of the high-level convolutional layer to generate the semantic weighting map, which reflects key vein information of high-level convolutional features. Then, semantic weighting map is regarded as a feature selector to discard the background information of the low-level convolutional features and preserve the detail information of low level convolutional features. Finally, low-level convolutional features with vein information are selectively linked to high-level convolutional features with vein information based on the proposed semantic feature selector. A series of rigorous experiments on two lab-made vein databases named CUMT-Hand-Dorsa Vein database and CUMT-Palm Vein database is conducted to verify the effectiveness and feasibility of the proposed model. Besides, additional experiments with PUT Palm Vein database and the subset of PolyU database illustrate its generalization ability and robustness.\"}\n","{'text': \"As industrial communication systems continue to evolve, they face various future challenges that need to be addressed in order to achieve optimal performance. Next-generation Ethernet, IIoT, and 5G are among the most critical issues that require attention. In addition, wireless sensor networks and real-time systems are also factors that will influence the future of industrial communication. One significant challenge lies in the selection of appropriate protocols that can support the demanding requirements of industrial communication. Ethernet is widely used as a backbone for industrial communication, but next-generation Ethernet is required to support the rapidly expanding information transfer needs. In contrast, wireless communication is fast becoming an essential part of industrial automation, particularly in manufacturing automation. Hence, future industrial communication systems need to be designed to support both wired and wireless communication. Overall, sustainable and scalable industrial communication systems are in high demand and must be developed to meet the changing needs of today's industries.\"}\n","{'text': 'This paper presents a generic Coq proof for the typical worst-case analysis of real-time systems. The analysis is based on analytical models and computational modeling techniques that take into account the time factors involved in the runtime of tasks. The paper discusses the task analysis process and the relevance of the analysis for real-world systems, using Microsoft Windows as an example. The proof is designed to be generic, allowing for the analysis of a wide range of real-time systems. The authors highlight the importance of formal verification techniques for ensuring the reliability and correctness of real-time systems, and stress the potential benefits of generic Coq proofs for improving the efficiency and effectiveness of worst-case analysis.'}\n","{'text': 'This paper proposes a measurement-based study on the usage of discrete wavelet transforms for generating secret keys in wireless communication. The method uses the noise reduction capability of wavelets to extract a channel estimate from the received signal. This channel estimate is further transformed using wavelets to generate a set of indexes, which can be used as a secret key for encryption. The proposed method is evaluated using simulations, and the results show that it provides a secure and efficient way of key generation. Additionally, the proposed method is compared with other key generation techniques, and it is observed that the proposed method performs better in terms of security and computational complexity. The study highlights the potential of wavelet-based methods in wireless communication and encourages further research in this area.'}\n","{'text': 'This paper presents predictive analytical and simulation approaches to reliability worth/cost assessments conducted on a test system and a typical Cape Town real system. Feeder 3 of bus 6 of the RBTS was utilized to illustrate various cases of switch configurations and for each arrangement the reliability indices were evaluated analytically as well as in Monte Carlo Simulation and results found to be similar. In this paper three scenarios were investigated in the Waterkloof Farmers-1 11 kV network (real system); Reliability assessment was firstly performed without automation devices (Scenario 1), secondly with automation devices in the current or existing positions (Scenario 2) and lastly, with optimal placement of the automation devices on the feeder using analytical and evolutionary algorithms methodologies (Scenario 3). The objective function behind placement can either be based on SAIDI or the ECOST and the best switch position for SAIDI might be worst position for the ECOST.'}\n","{'text': 'Rinjani Mountain in West Nusa Tenggara is famous destination for travelling which has Instagram able for tourism photos. Its popularity because many social media tolls which easy to uploading photos. Instagram is a digital media for sharing photos and videos to others. This paper aimed are (a) develop a sentiment classifier required method based on Lexicon-Based method of conducting a dictionary-based sentiment analysis and (b) Identifying the sentiments of each opinion words contained in the response and hashtag data. The results are posting photo or picture in Instagram make positive comment from visitor and the impact is increasing visitor to Rinjani Mountain. The trial and evaluations system created be able to provide information about positive, negative and neutral opinion of the community on tourism in Mount Rinjani.'}\n","{'text': 'This paper presents a comparative study of various clustering algorithms for electronic learning (e-learning) systems using Weka tools. The clustering algorithms discussed include partitioning, classification, and filtering algorithms. The purpose of this study is to evaluate the effectiveness of these algorithms in clustering e-learning data. Data mining techniques are applied to analyze the data and evaluate the clustering results. The paper discusses the advantages and disadvantages of each algorithm and provides recommendations for selecting the most appropriate algorithm for specific e-learning applications. The study shows that the choice of algorithm largely depends on the nature of the data and the intended use of the clustering results. Overall, the paper highlights the importance of careful algorithm selection in achieving optimal e-learning clustering performance.'}\n","{'text': 'This paper proposes a data distillation approach to train a region selector for limited data on Gram stained slides. The task analysis was performed on microscopy images to select only relevant regions. The training data was then distilled to reduce noise and improve the training of predictive models. The proposed approach uses deep learning techniques to identify relevant regions and train the model with a limited amount of data. The resulting model achieved high accuracy on the test data, indicating the effectiveness of the proposed approach. This study addresses a crucial issue in medical image analysis, where limited data sets are common. The proposed approach can be extended for various microscopy tasks and can benefit image analysis in medical diagnosis and research.'}\n","{'text': 'This paper presents an analysis of vehicle handling through the use of a simple track model of an automobile. The mathematical model developed in this study takes into account the behavior of the tires, which play a crucial role in determining the stability and dynamics of the vehicle. Computational modeling techniques were employed to investigate the behavior of the vehicle under different driving scenarios, and stability analysis was used to assess the performance of the analytical models developed. In addition, control systems were implemented to optimize vehicle handling and improve driving performance. Overall, this study provides valuable insights into the dynamics of vehicle handling and identifies ways in which control systems can be designed to enhance the driving experience.'}\n","{'text': 'This paper focuses on the application of Machine Learning for Error Detection and Design Optimization in Signal Integrity Applications. The primary focus of this investigation includes Feature Extraction, Training, Data Models, Anomaly Detection, Integrated Circuit Modeling, and Packaging. To optimize signal integrity, feature extraction is carried out to identify the characteristics of the system. Further, training the data models is performed to assess the accuracy and efficiency of the utilized machine learning algorithm. To improve the performance of signal integrity and, subsequently, optimize the design of the system, anomaly detection is performed to identify deviations from the expected behavior of the system. Moreover, integrated circuit modeling is performed to link the physical aspects of the system with the mathematical model. Finally, packaging is analyzed to ensure that signal integrity is maintained throughout the entire circuit. Through the utilization of these tools and techniques, the performance of signal integrity applications can be significantly improved, and optimal design can be achieved.'}\n","{'text': 'This paper presents a consensus-based data statistics approach for distributed network systems. The proposed method is based on a consensus algorithm that allows multiple nodes to agree on statistical data in a distributed manner. The approach leverages distributed databases to store and manage data, and models the data using probability density functions. Computational modeling is also used to analyze the collected data, which allows for the prediction of future trends. The proposed approach takes into consideration the network topology and the protocols used, which ensures the accuracy and reliability of the collected data. The results show that the consensus-based approach provides better accuracy and efficiency than traditional approaches for data statistics in distributed network systems. This research has implications for a wide range of applications, including sensor networks, Internet of Things, and distributed data processing.'}\n","Processing batch 60/63\n","{'text': 'A fast and accurate non-iterative direction-of-arrival (DOA) estimation algorithm for multiple targets in additive white Gaussian noise is devised in this paper. The proposed estimator makes use of the two highest magnitudes discrete Fourier transform (DFT) coefficients of the input data and two of their associated neighboring bins, resulting in a deterministic complexity of O(N(1 + log(N))) with N being the number of sensors. The bias and mean squares error of the DOA estimates are analyzed. The simulation results are presented to validate the correctness of theoretical derivation and demonstrate the superiority of the devised estimator over several conventional DOA estimators.'}\n","{'text': 'Interference has become a critical issue in modern wireless communication systems, particularly in macrocell networks, where multiple base stations are used to cover a large area. Resource management, particularly in the downlink direction, is crucial to mitigate such interferences. In this regard, several heuristic algorithms have been proposed to effectively allocate resources, with the aim of lowering the interference level. However, most of these algorithms only consider user-centric factors, which cannot effectively control interference between adjacent base stations. In this paper, we propose a sleep-based resource allocation algorithm for inter-femto interference mitigation, which leverages the nickel-hydrogen battery technology to mitigate adjacent channel interferences. The proposed algorithm not only considers user-centric factors but also takes into account the interference between adjacent base stations, effectively mitigating interference in the network. The simulation results illustrate the effectiveness of the proposed algorithm, demonstrating significant improvement in terms of reducing interference and resource allocation efficiency.'}\n","{'text': 'In the future Fifth-Generation networks, the eavesdropping is a critical threat due to their broadcast-based transmission. This problem can be addressed with the cryptographic protocols. However, this method is complex and difficult because of the dynamic topology of wireless networks, which does not allow an efficient management of security keys. As a complement solution, Physical-layer security (PLS) is integrated to enhance secrecy in wireless networks. The PLS exploits the schemes features of this layer, namely the modulation, Massive Multi-Input Multi-Output(m-MiMo) and channel coding. The fountain code is one of those systems where the secrecy is provided when the destination retrieves packets encoded before the intruder. Nevertheless, the secrecy can not be guaranteed when eavesdropper uses large number of the antennas as in the m-MiMo. The feature of m-MiMo should be considered to secure main channel with fountain codes. Therefore, we propose to use Raptor code which is a class of fountain code, aided by an Artificial noise (AN) and the punctuated data to reduce the efficient of intruder channel. This allows the main channel to retrieve the signal before eavesdropper. The numerical results show that using Raptor code in massive MiMo enhances the reliability and the security on the channel of legitimate user, while minimizes the abilities of intruders to spy on data.'}\n","{'text': 'This paper provides an overview of tourist information distribution system that sends information corresponding to places and times. We completed the system successfully, although it is difficult to clearly extract information of the date, time, place, and event name from non-structured data written in natural language such as the language used on the SNS. We evaluated how many pieces of information are collected.'}\n","{'text': 'In this paper cubic splines are designed as tone correction functions applied to the achromatic component of a spherical color model. Compared with the commonly used color models HSV and HSL, an advantage of the spherical color model is that color changes more perceptually smoothly along its coordinates. However, the spherical color model contains more color points than what can be displayed with the RGB color model, so a tone correction function might cause a gamut issue. The paper demonstrates the gamut issue can be avoided when tone correction functions are well designed and the general tone correction techniques still work well in the spherical color model. A particular type of cubic splines is designed to serve the purpose, and these splines can be adopted by the general tone correction techniques including those for low-key, middle-key and high-key images with correspondingly selected parameters. Experimental results demonstrate that these cubic splines work well for tone correction under the spherical color model.'}\n","{'text': 'Sentiment analysis of Twitter data has recently become an important research topic due to the explosive growth of social media use. Twitter, being one of the most popular social media platforms, provides an ideal source of data for sentiment analysis. In order to analyze these large volumes of data, data models and mining techniques are employed. Machine learning algorithms and classification algorithms are the most commonly used techniques in sentiment analysis. Among these algorithms, Support Vector Machines (SVMs) have been found to be highly effective in accurately classifying the sentiment of Twitter data. This paper explores the different data models and mining techniques that have been developed for analyzing Twitter data along with a comparison of various machine learning and classification algorithms used in sentiment analysis, highlighting the effectiveness of SVMs in this context. The paper also discusses the challenges faced in sentiment analysis of Twitter data and outlines some future directions for research in this field.'}\n","{'text': 'Speaker recognition or voice detection is a state-of-art in the field of signal processing which includes human as well as animal. This paper proposes a naive approach to build a predictor model to detect the Houston Toad mating call signature in an audio file which can be paraphrased as toad voice activity detection. To accomplish that, several ideal toad call voice frames of unique characteristics in audio files have been experienced. The audio file is bandpass filtered, and then preprocessed by multiplying every frame with the hamming window to break into segments. Next, the Mel-Filterbank and Mel-Frequency Spectral Coefficient (MFCC) are used for feature extraction, while the Support Vector Machine (SVM) and Multi-layer Perceptron (MLP) neural networks are utilized as classifiers to determine the best fit. This experimental result reflects the higher accuracy of the MLP neural network over SVM showing the best potential of classification.'}\n","{'text': 'This paper proposes a novel approach for multivariable support vector regression with multi-sensor network data fusion, aiming to optimize the performance of support vector machines in the context of wireless sensor networks. By integrating multiple data models and conducting task analysis on urban areas, the proposed system is capable of capturing the complex dynamics of smart devices and accurately predicting their behaviors. The optimization process is implemented through a series of iterative steps that aim to minimize the error rate and maximize the prediction accuracy. The results show that the proposed approach outperforms existing methods and is suitable for a wide range of applications such as smart city planning and intelligent transportation systems. Overall, this study presents an innovative solution for optimizing support vector machines in the context of multi-sensor network data fusion, which has great potential for future research and development.'}\n","{'text': 'This research presents a new approach to increasing the bandwidth of airborne capacitive micromachined ultrasonic transducers (CMUTs). This method introduces a gaseous squeeze film as a damping mechanism, which induces a stiffening effect that lowers the pull-in voltage and improves the sensitivity. Optimized fluidic trenches of different heights are created within the gap to control the behavior of the stiffness effect versus the damping mechanism. The fractional BW can be controlled from 0.89% to 8.1% by adjusting the trench height while lowering the pull-in voltage to less than 54 V at the gap height of 1.0 Î¼m. To optimize the sensitivity and reduce pull-in voltage at a given bandwidth, a multi-parameter optimization method has been developed to adjust all combinations of design parameters. Additionally, a novel multiple hard-mask process flow has been developed to allow for the fabrication of CMUTs with varying cavity and trench heights on the same wafer. The developed devices exhibit an equivalent noise pressure level of 4.77 Î¼Pa/â\\x88\\x9aHz with 6.24-kHz bandwidth for 7.6-Î¼m deep fluidic trenches, and 4.88 Î¼Pa/â\\x88\\x9aHz with 7.48-kHz bandwidth for 14.3-Î¼m deep fluidic trenches. This demonstration of the wide-BW CMUTs with high sensitivity and low pull-in voltage makes them applicable to medical and thermoacoustic imaging, nondestructive testing, and ultrasonic flow metering.'}\n","{'text': 'Predicting real-time spatial information from data collected by the mobile Internet of Things (IoT) devices is one solution to the social problems related to road traffic. The mobile IoT devices for real-time spatial information prediction generate an extremely high volume of data, making it impossible to collect all of it through mobile networks. Although some previous works have reduced the volume of transmitted data, the prediction accuracy of real-time spatial information is still not ensured. Therefore, this paper proposes an IoT device control system that reduces the amount of transmitted data used as input for real-time prediction while maintaining the prediction accuracy. The main contribution of this paper is that the proposed system controls data transmission from the mobile IoT devices based on the importance of data extracted from the machine learning model used for the prediction. Feature selection has been widely used for extracting the importance of data from the machine learning model. Feature selection methods were also used to reduce communication overhead in distributed learning. Unlike the conventional usage of feature selection methods, the proposed system uses them to control the data transmission of the mobile IoT devices with priority. In this paper, the proposed system is evaluated with a real-world vehicle mobility dataset in two practical scenarios using the random forest model, which is an extensively used machine learning model. The evaluation results show that the proposed system reduces the amount of transmitted input data for real-time prediction while achieving the same level of prediction accuracy as benchmark methods.'}\n","{'text': 'Content Based Image Retrieval (CBIR) systems retrieve relevant images from a database based on the content of the query. Most CBIR systems take a query image as input and retrieve similar images from a gallery, based on the global features (such as texture, shape, and color) extracted from an image. There are several ways of querying from an image database for retrieval purpose. Some of which are text, image, and sketch. However, the traditional methodologies support only one of the domains at a time. There is a need of bridging the gap between different domains (sketch and image) for enabling a Multi-Modal CBIR system. In this work, we propose a novel bimodal query based retrieval framework, which can take inputs from both sketch and image domains. The proposed framework aims at reducing the domain gap by learning a mapping function using Generative Adversarial Networks (GANs) and supervised deep domain adaptation techniques. Extensive experimentation and comparison with several baselines on two popular sketch datasets (Sketchy and TU-Berlin) show the effectiveness of our proposed framework.'}\n","{'text': 'In recent years, fault prognostics has gained increasing attention due to its critical role in ensuring the safety and reliability of complex systems. This paper proposes an online fault prognostics method based on degradation-oriented slow feature analysis and temporal smoothness analysis. A degradation model is first constructed to describe the degradation process of the system. Feature extraction is then applied to capture the most relevant information from the degradation data. Both analytical models and hidden Markov models are used to identify the underlying degradation patterns and predict the remaining useful life of the system. In addition, market research and data mining techniques are employed to optimize the prognostic model and improve its accuracy. The proposed approach is demonstrated on a real-world electrical insulation system and achieves superior prognostic performance compared to existing methods. Overall, the results show that the proposed approach is a promising solution for online fault prognostics and has practical applications in various industry sectors.'}\n","{'text': 'The purpose of this article is to analyze the power of WeChat and question ourselves on the hypothetical expansion. We discovered WeChat by living in China. For us, it is an application which gather everything. It is Instagram, Facebook, Twitter in just one app. But since we are living in a world with so many differences and different laws, we want to know if this app can really encounter the same success in different countries. WeChat has a big place in the life of Chinese people and this is something which is very interesting. Everything is around this app. The payment method, the social life and the way of interacting with people in general. We decided to split our study in three parts in order to answer the problematic.'}\n","{'text': \"This paper proposes an approach to adjust the difficulty level of a wobble board-based game using the Monte Carlo tree search algorithm. The application of artificial intelligence techniques, specifically prediction algorithms and heuristic algorithms, enables the creation of a mathematical model that can predict a player's ability to complete the game. The Monte Carlo method is then used to simulate game outcomes and adjust the difficulty level accordingly. This approach has the potential to improve training outcomes in physical therapy and athletic settings, where personalized and adaptive training regimes are key. The proposed method is expected to be a valuable contribution to the field of human-AI interaction in both gaming and training contexts.\"}\n","{'text': 'The traditional two-way (2W) parabolic equation (PE) (2W-PE) method has been applied for modeling groundwave propagation over irregular terrain. However, based on a staircase terrain model (STM), the method is not sufficient in sloping facets modeling. Although more accurate one-way PE method based on conformal mapping model (CMM) is available, it handles only forward-propagating waves and neglects the backward-propagating waves, which become significant especially for steep terrain. In this paper, a hybrid 2W-PE method is presented to model the low-frequency (LF) groundwave propagation over irregular terrain. The method combines the STM and CMM to improve the prediction accuracy of both forward and backward propagations. The numerical results are compared with those of the conventional 2W-PE and finite-difference time-domain (FDTD) methods. While calibrated against the FDTD method, the proposed hybrid 2W-PE method has higher accuracy than the traditional 2W-PE method at the same computational cost.'}\n","{'text': 'According to the new Law of Electricity Market of Ukraine, photoelectric stations will be obliged to declare their generation graphic one day ahead. Proceeding from this, the task of hourly prediction of generation of PV arises a day ahead. Since such a graph significantly depends on the change of meteorological parameters, in the work it was investigated which of them most influence generation. On the basis of the analysis it was determined that this is solar radiation, cloudiness, humidity, wind speed and temperature. The determined meteorological parameters included the construction of the neural network for forecast the hourly generation of PV on day ahead. Neural networks which proposed that is capable of predicting the generation of photovoltaic stations with a fairly high accuracy.'}\n","{'text': 'The recent surge of interest in Deep Neural Networks (DNNs) has led to increasingly complex networks that tax computational and memory resources. Many DNNs presently use 16-bit or 32-bit floating point operations. Significant performance and power gains can be obtained when DNN accelerators support low-precision numerical formats. Despite considerable research, there is still a knowledge gap on how low-precision operations can be realized for both DNN training and inference. In this work, we propose a DNN architecture, Deep Positron, with posit numerical format operating successfully at â\\x89? bits for inference. We propose a precision-adaptable FPGA soft core for exact multiply-and-accumulate for uniform comparison across three numerical formats, fixed, floating-point and posit. Preliminary results demonstrate that 8-bit posit has better accuracy than 8-bit fixed or floating-point for three different low-dimensional datasets. Moreover, the accuracy is comparable to 32-bit floating-point on a Xilinx Virtex-7 FPGA device. The trade-offs between DNN performance and hardware resources, i.e. latency, power, and resource utilization, show that posit outperforms in accuracy and latency at 8-bit and below.'}\n","{'text': 'In this paper, we present an optimization method for improving the transmission rates of simultaneous wireless information and power transfer (SWIPT) networks through relay power allocation ratio. The decode-and-forward (DF) relay strategy is first adopted in the relay interference channels (IFC) when the single source communicates with destination nodes through dedicated EH relays. Then a successive convex approximation (SCA) algorithm is introduced to transform the original NP-hard problem into a concave optimization problem in order to guarantee the normal operation of all EH relays, maximize the data transmission rates and improve the communication quality of the whole network. Finally, the Lagrangian multiplier method based on the Karush-Kuhn-Tucker(KKT) condition is applied to achieve the optimal power allocation for each relay. Numerical results demonstrate that the proposed algorithm can improve the transmission rates, has a fast convergence and high accuracy.'}\n","{'text': 'We describe a new vision of joint computation and communication resource management that goes beyond the end-to-end and client-server model of the current Internet. Enabled by a growing trend toward embedding processing and networking capabilities into \"smart\" network nodes and devices, for example, smartphones, watches, appliances, and automobiles, Dispersed Computing describes a new resource-centric architecture that leverages the diversity of networked computation points within the network, and the heterogeneity of network links and protocol stacks that connect them. We describe this new, resource-centric architecture as an evolution of both fog/edge networking and active networks. We illustrate the fundamental principles and the advantages over the current Internet architecture, and highlight several commercial use cases enabled by a dispersed computing architecture.'}\n","{'text': 'Many Higher Education Institutions are shifting to Cloud-Based E-Iearning (CBEL) due to its benefits. These benefits include reduced costs of accessing IT services, pooling of resources, scalability, and mobility as well as consumer satisfaction among others. However, some institutions especially in developing countries in general and Gulf Cooperation Council (GCC) in particular still reluctant to adopt CBEL due to many factors. There is necessity to find out the factors that drive the adoption of CBEL in higher education institutions. This study was carried out to find out the factors that determine whether these institutions in GCC would adopt the CBEL or not. The study involved a group of respondents from the GCC who provided with an On-line survey sent to identify the factors they thought played a role in determining whether institutions would adopt the CBEL or not. The base for this study was TOE and DOI adoption theories. The following factors were recommended by researchers; Technological Factors such as Relative advantage, Complexity, Compatibility which derived from DOI theory and Organizational factors such as Fit, Decision maker, Cost reduction, and IT readiness which derived from TOE framework, and Information culture behavioral such as Information Integrity, Information Formality, Information Control and Information Pro-activeness which derived from Information culture factors.'}\n","{'text': 'Visual saliency is an important component of attention. It helps animals survive and can also be used by computer vision applications to filter out irrelevant information from high volumes of data. Our network features an architecture and pre-processing methods optimized for the detection task, and experiments using the MIT300 benchmark have demonstrated state-of-the-art performance. Compared to similar models, our network has a 75% parameter reduction, making it more efficient and practical for real-world applications.'}\n","{'text': 'Surface defect detection is challenging due to varying defect types and their novelties. Because of this, it is hard for algorithms to implement across datasets. Moreover, current automated optical inspection (AOI) machines cannot handle this novelty effectively. In this work, we develop a new method for surface defect detection based on generative models, which can detect novelty according to learned distributions. Experimental results on real industrial datasets show that the proposed method can successfully construct the surface texture pattern generator. By transforming the image through the generator to the corresponding latent space, the defects can be separated effectively without a tedious effort of annotation in a large amount of training data.'}\n","{'text': 'In this paper, we propose a method for reducing the approximation time of cluster workload by using simplified hypergamma distribution. The proposed method utilizes solid modeling and mathematical and computational modeling techniques to construct a probability distribution model of cluster workload. Random variables are used to represent the variations in the workload of different clusters. Our proposed method can be applied in various domains such as industrial engineering, manufacturing, and computers to optimize the usage of computational resources. We demonstrate the effectiveness of our proposed method through empirical experiments, which show that it outperforms existing methods in terms of approximation time reduction. Finally, we discuss the implications of our work and propose directions for future research.'}\n","{'text': 'Feature selection (FS) is becoming critical in this data era. Selecting effective features from datasets is a particularly important part in text classification, data mining, pattern recognition and artificial intelligence. FS excludes irrelevant features from the classification task, reduces the dimensionality of a dataset, allows us to better understand data, improves the performance of machine learning techniques, and minimizes the computation requirement. Thus far, a large number of FS methods have been proposed, however the most effective one in practice remains unclear. Though it is conceivable that different categories of FS methods have different evaluation criteria for variables, there are few studies fixating on evaluating various categories of FS methods. This article gathers ten superior FS methods under four different categories, and fixates on evaluating and comparing them in general versatility (constant ability to select out the useful features) regarding authorship attribution problems. Besides, this article tries to identify which method is most effective. SVM (support vector machine) serves as the classifier. Different categories of features, different numbers of top variables in feature rankings, and different performance measures are employed to measure the effectiveness and general versatility of these methods together. Finally, rank aggregation method Schulze (SSD) is employed to make a ranking of the ten FS methods. The analysis results suggest that Mahalanobis distance is the best method on the whole.'}\n","{'text': 'Tracking targets with bearings-only measurement is a great challenge caused by poor observability and highly nonlinear estimation. In this brief, a novel augmented ensemble Kalman filter (AEnKF) is presented to address this bearings-only tracking problem. Different from the conventional ensemble Kalman filter (EnKF), the AEnKF overcomes the limitation of the linear measurement update rule in the linear minimum mean-square error (LMMSE) framework. The AEnKF utilizes a nonlinear transform of the measurement, called uncorrelated conversion (UC), to augment the measurement space. This conversion serves as a pseudomeasurement and is uncorrelated with the original measurement statistically. Unlike other UC filters based on the Gaussian assumption in the existing literature, the AEnKF does not impose any assumption on the probability density of the measurement by using generalized orthogonal polynomials to construct the UCs in a systematic way. The simulation results show that the AEnKF outperforms the conventional EnKF and other UC filters in the bearings-only tracking problem.'}\n","{'text': 'In the field of computer science, the advent of big data has led to an enormous demand for prediction algorithms to make sense of the vast amounts of information available. One technique that has been developed to deal with high-dimensional data is tensor decomposition, with the tensor train decomposition being a recent development that has proven to be highly effective. In this paper, we propose a tensor-train based high-order dominant eigen decomposition method for multimodal prediction services. Specifically, we apply the method to Markov processes and see how it performs against other computational modeling techniques. Our results suggest that the proposed method is superior in predicting the future states of Markov processes, and thus holds great promise for building more accurate predictive models in the future.'}\n","{'text': 'Internet of Things (IoT) has gained tremendous attention in recent years due to its potential to revolutionize various sectors. IoT is essentially an ecosystem that interconnects various sensors, devices, and networks to gather and transmit data to facilitate efficient decision-making. One of the critical components of the IoT ecosystem is protocols. Protocols govern the way in which devices communicate with each other and exchange information. Another essential element of IoT is web pages, which serve as an interface for users to access and monitor IoT devices. These web pages are hosted on computers and servers and can be accessed using Uniform Resource Locators (URLs). Understanding the IoT ecosystem and its various components is crucial for developing efficient and sustainable IoT solutions.'}\n","{'text': 'In recent years, the use of Learning Management Systems (LMS) has become increasingly widespread in educational institutions, providing an abundance of learning data. The challenge is how to efficiently analyze this data to understand student performance and behavior, and ultimately enhance the learning experience. This paper proposes the use of interpretable neural networks to mine LMS data and develop predictive models for student performance and engagement. The artificial neural networks are designed to be highly interpretable, allowing educators to understand the features and weights used in the prediction algorithms. The paper also discusses the use of various data models and analysis techniques in combination with data mining to extract valuable insights from LMS data. Overall, the proposed approach has the potential to aid educators in developing effective teaching strategies and providing targeted interventions to better support student success.'}\n","{'text': 'Tasks involving the analysis of geometric (graph-and manifold-structured) data have recently gained prominence in the machine learning community, giving birth to a rapidly developing field of geometric deep learning. In this work, we leverage graph neural networks to improve signal detection in the IceCube neutrino observatory. The IceCube detector array is modeled as a graph, where vertices are sensors and edges are a learned function of the sensors spatial coordinates. As only a subset of IceCubes sensors is active during a given observation, we note the adaptive nature of our GNN, wherein computation is restricted to the input signal support. We demonstrate the effectiveness of our GNN architecture on a task classifying IceCube events, where it outperforms both a traditional physics-based method as well as classical 3D convolution neural networks.'}\n","{'text': 'This study focuses on Ultrawideband (UWB) network channel models and their application in next-generation wireless avionic systems. Aerospace electronics, aircraft, relays, wireless sensor networks, switches, and wireless communication are areas that can benefit from UWB technology. This research has examined different UWB channel models and their characteristics to determine their suitability for wireless communication in avionics systems. The study also considers the limitations of traditional narrowband communication systems and emphasizes the importance of UWB in achieving high data rates and improved reliability for aircraft operations. The results suggest that UWB technology can improve the performance of wireless communication systems in avionics applications, and that the proposed channel models will be useful in optimizing wireless communication links in future avionic systems.'}\n","{'text': 'Memristive devices can be exploited for memory as well as logic operation paving the way for non von-Neumann Computation-In-Memory architectures. To validate the potential of such architectures accurate compact models for the memristive devices are required. As a standard device is not available, evaluating the performance of such an architecture is ambiguous. This paper proposes a flexible model for bipolar, filamentary switching, redox-based memristive devices. The model does catch both the device resistance ratio as well as the nonlinearity of the switching kinetics. It is used to perform design exploration for three memristive based circuit design (IMPLY, MAGIC and CRS) for computation-in-memory architectures.'}\n","{'text': \"This paper presents a live demonstration of an intelligent stethoscope that can simultaneously display electrocardiography (ECG) and heart sounds. This device is designed to provide real-time atmospheric measurements and biomedical measurements for doctors and healthcare professionals. The stethoscope is capable of detecting particle measurements that can aid in the diagnosis of certain conditions. Furthermore, the device utilizes cloud computing, which enables the storage and analysis of the data collected, making it easy for doctors to access and use the information gathered by the stethoscope. Overall, this intelligent stethoscope is a promising tool that can provide accurate and comprehensive information about a patient's heart and respiratory health.\"}\n","{'text': \"This paper proposes a unified smart Chinese medicine framework for healthcare and medical services, focusing on the integration of tongue inspection, computational modeling, and deep learning to improve the accuracy of disease diagnosis and treatment, particularly for hypertension. Through the use of advanced techniques such as image recognition and machine learning algorithms, the framework enables automated tongue diagnosis and provides personalized treatment recommendations based on the individual patient's symptoms and medical history. It also allows for continuous monitoring of the patient's condition, assisting physicians in making informed decisions about treatment options. Overall, this framework offers an innovative and effective approach to incorporating traditional Chinese medicine into modern healthcare and medical services, providing improved outcomes for patients with hypertension and other diseases.\"}\n","{'text': 'Though large-scale datasets are essential for training deep learning systems, it is expensive to scale up the collection of medical imaging datasets. Synthesizing the objects of interests, such as lung nodules, in medical images based on the distribution of annotated datasets can be helpful for improving the supervised learning tasks, especially when the datasets are limited by size and class balance. In this paper, we propose the class-aware adversarial synthesis framework to synthesize lung nodules in CT images. The framework is built with a coarse-to-fine patch in-painter (generator) and two class-aware discriminators. By conditioning on the random latent variables and the target nodule labels, the trained networks are able to generate diverse nodules given the same context. By evaluating on the public LIDC-IDRI dataset, we demonstrate an example application of the proposed framework for improving the accuracy of the lung nodule malignancy estimation as a binary classification problem, which is important in the lung screening scenario. We show that combining the real image patches and the synthetic lung nodules in the training set can improve the mean AUC classification score across different network architectures by 2%.'}\n","{'text': 'NB-IoT technology has been considered as the most promising solution for Low Power Wide Area Networks (LPWAN) catering to the requirements of Internet of Things (IoT) applications. In NB-IoT, random access procedure is an important entity that supports delay sensitive and delay-tolerant IoT applications by providing appropriate response probability and delays. This paper presents an analysis of the NB-IoT random access procedure, with a focus on the prioritization of delay-sensitive and delay-tolerant applications. The probability of random access success is calculated based on the number of contention slots, which is shown to be inversely proportional to the number of devices contending. Moreover, the impact of synchronization mechanism on random access procedure is analyzed. The proposed analysis provides insights into the potential delays and response probabilities of the NB-IoT random access procedure, which can aid in the design and optimization of NB-IoT networks for IoT applications.'}\n","{'text': 'The clustering methods have a good application in many aspects, in which the density peak (DP) clustering can effectively cluster similar neighboring pixels so that the features can be extracted well for hyperspectral images (HSIs) classification. In this work, a DP based covariance matrix (DPCM) method is proposed for the feature extraction of HSIs, which not only can effectively extract features but also can reduce the within-class variations and the between-class interference. The proposed method consists of the following steps: First, maximum noise fraction is employed on the original HSI to reduce the computational complexity and eliminate noise. Second, the local densities of the sample are calculated by the DP clustering. Therefore, a reconstructed image can be obtained in which each pixel has a density feature vector. Then, the covariance matrix between each density pixel in the density map is calculated. Last, the extracted covariance matrices are fed back to the support vector machine based on the logarithm Euclidean kernel for label assignment. Experiments are conducted on the Indian pine data set, in which each of the five randomly selected marker data are selected as the training sample. The experimental results show that the method can effectively improve the classification accuracy and is superior to other classification methods.'}\n","{'text': 'Fingerprint Indexing allows filtering databases for samples most similar to a query fingerprint. Fixed-length feature vectors invariant to the count of minutiae allow fast comparison. This is the first approach, which uses Deep Convolutional Neural Networks to generate fixed-length index vectors from minutia neighbourhoods. It is also invariant to any sorting of minutiae with respect to their vicinity. No fingerprint image data is required. Usage of only standardized ISO/IEC minutia templates allows even to deploy to legacy systems. Our approach is therefore called Deep ISO Minutiae Indexing (DIMI). Index vectors can be as short as 16 float values per sample. DIMI was evaluated at the independent benchmark framework FVCongoing. In the incremental search scenario, DIMI achieves an average penetration ratio of 0.747% for test FIDX-50K and 0.723% for test FIDX-10K respectively. These are the best results reported so far.'}\n","{'text': 'mHealth4Afrika is a collaborative research and innovation project, focused on supporting Horizon 2020 Societal challenges and Sustainable Development Goal 3. It is researching and evaluating the potential impact of co-designing and developing an open source, multilingual enabled mHealth platform to support quality community-based primary maternal healthcare delivery at semi-urban, rural and deep rural clinics, based on end-user requirements in Southern Africa (Malawi, South Africa), East Africa (Kenya) & Horn of Africa (Ethiopia). This paper aims to share the co-design process applied to develop and validate Beta platform v1, and the implications this had on the design of subsequent iterations of the beta platform. The Beta platform v1 validation was undertaken with 36 participants from 11 healthcare clinics across Northern Ethiopia, Western Kenya, Southern Malawi and Eastern Cape, South Africa during November - December 2017, using a mix of ethnographic observation and semi-structured interviews. These findings have informed the co-design of the subsequent iterations of the mHealth4Afrika beta platform, which is being used in the participating clinics on a phased basis during Q3 - Q4 2018. This platform integrates Electronic Medical Records, Electronic Health Records, medical sensors, visualisation and automatically generate monthly health indicators, thus supporting better clinical care and decision making, and freeing up time for clinical care and continuous professional medical education, thus reducing mortality rates. The expected outcome is a multi-region proof of concept that can make a significant contribution in accelerating exploitation of mHealth across Africa to improve health outcomes and stregthen health systems.'}\n","{'text': 'This paper investigates distributed control and incentive mechanisms to coordinate distributed energy resources (DERs) with both continuous and discrete decision variables as well as device dynamics in distribution grids. We formulate a multiperiod social welfare maximization problem, and based on its convex relaxation propose a distributed stochastic dual gradient algorithm for managing DERs. We further extend it to an online real-time setting with time-varying operating conditions, asynchronous updates by devices, and feedback being leveraged to account for nonlinear power flows as well as reduce communication overhead. The resulting algorithm provides a general online stochastic optimization algorithm for coordinating networked DERs with discrete power setpoints and dynamics to meet operational and economic objectives and constraints. We characterize the convergence of the algorithm analytically and evaluate its performance numerically.'}\n","{'text': \"Cognitive impairment is a growing concern in the aging population worldwide. Alzheimer's disease is among the most common type of cognitive impairment and its early detection is crucial for effective treatment. In this paper, we propose an evaluation system for cognitive impairment based on brain functional network links. The system utilizes both artificial and biological neural networks, correlating the extracted features to correlate the network links. Correlation coefficients are then calculated to determine the cognitive impairment level. The proposed system also includes a training phase to optimize the network's performance in detecting cognitive impairment. We demonstrate the effectiveness of our system by conducting experiments on a dataset of patients with Alzheimer's disease. The results show that our system can detect cognitive impairment with high accuracy, making it a promising approach for early detection of Alzheimer's disease.\"}\n","Total predictions: 1000\n","Generated predictions: 1000\n","Submission DataFrame shape: (1000, 2)\n","Submission saved to /content/drive/MyDrive/ai_detection_model/submission.csv\n","Saved file shape: (1000, 2)\n","Training pipeline completed successfully!\n","\n","GPU Memory Usage:\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","\n","Detailed GPU Memory Info:\n","Allocated: 6722.65 MB\n","Cached: 6836.00 MB\n","Max Allocated: 8987.55 MB\n"]}],"source":["def main(data_dir):\n","    \"\"\"\n","    Main training and evaluation pipeline.\n","    Args:\n","       data_dir (str): Path to data directory.\n","    \"\"\"\n","    try:\n","        set_seeds()\n","        print(\"Starting training pipeline...\")\n","\n","        # Initialize and run trainer\n","        trainer = AIGenerationDetector(data_dir=data_dir)  # set data directory path\n","        trainer.download_data()\n","        trainer.setup_model()\n","        trainer.prepare_datasets(max_samples=5000)\n","        trainer.train()\n","        trainer.create_submission()\n","\n","        print(\"Training pipeline completed successfully!\")\n","\n","    except Exception as e:\n","        print(f\"Fatal error in main: {str(e)}\")\n","        raise\n","    finally:\n","        clear_memory()\n","        print_gpu_utilization()\n","        print_detailed_gpu_info()\n","\n","# Main execution block\n","if __name__ == \"__main__\":\n","    data_dir = \"/content/drive/MyDrive/ai_dataset\"  # Set the Google Drive path to save data\n","\n","    # Run the final training using main()\n","    main(data_dir)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["uIWN2AazbCtN","6MyPxv-EImbL"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f68e1b61bd304214b6a52f80fc37faf3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ef03292b2a2142d1b37c01e1684258a1","IPY_MODEL_bd945d8684e94a9db712f7cd5291c89c","IPY_MODEL_3cfd3ba6e0bf41c0adb6c7f649a3f1d1"],"layout":"IPY_MODEL_b951e46369324e80bc0a501ed8c383dd"}},"ef03292b2a2142d1b37c01e1684258a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39416d60de274bd8b269ab71a2de6c25","placeholder":"​","style":"IPY_MODEL_2a528ef78b1b453283ed9b7c8dbb1810","value":"Map (num_proc=2): 100%"}},"bd945d8684e94a9db712f7cd5291c89c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6f7e5b33c4a43e787f8234da7f73913","max":3500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29ab1fe4f92c4c83adfb624031d064bf","value":3500}},"3cfd3ba6e0bf41c0adb6c7f649a3f1d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ce850ea4fe645d3ace5361f452077d2","placeholder":"​","style":"IPY_MODEL_1a8f9c9abb574e15bc182c7f4276f56e","value":" 3500/3500 [00:04&lt;00:00, 970.73 examples/s]"}},"b951e46369324e80bc0a501ed8c383dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39416d60de274bd8b269ab71a2de6c25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a528ef78b1b453283ed9b7c8dbb1810":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6f7e5b33c4a43e787f8234da7f73913":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29ab1fe4f92c4c83adfb624031d064bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ce850ea4fe645d3ace5361f452077d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a8f9c9abb574e15bc182c7f4276f56e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6944b9463ec64dfe96f51569adfd6c4b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a1154a7e9d02419d82b097955360c73d","IPY_MODEL_a1c75d42776342f4a7b6fe5c4ffd292c","IPY_MODEL_45e9be17b1e449e5b86e3d276ea25c13"],"layout":"IPY_MODEL_e20ff4b6dd154cc39536f99d485d22cb"}},"a1154a7e9d02419d82b097955360c73d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd2d1b75abc34531b92d24a37d374d1b","placeholder":"​","style":"IPY_MODEL_8cb8654249854752adffc8c11becb002","value":"Map (num_proc=2): 100%"}},"a1c75d42776342f4a7b6fe5c4ffd292c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_075678c9c4714a2fbc9b4f1f9d3ff78d","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b89f172e16c489eb477755b1c83a24c","value":500}},"45e9be17b1e449e5b86e3d276ea25c13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_414330f0171f4a3abb56a52e3eb92412","placeholder":"​","style":"IPY_MODEL_bd17beae41094bab89ed49df440ab7f9","value":" 500/500 [00:03&lt;00:00, 162.00 examples/s]"}},"e20ff4b6dd154cc39536f99d485d22cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd2d1b75abc34531b92d24a37d374d1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cb8654249854752adffc8c11becb002":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"075678c9c4714a2fbc9b4f1f9d3ff78d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b89f172e16c489eb477755b1c83a24c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"414330f0171f4a3abb56a52e3eb92412":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd17beae41094bab89ed49df440ab7f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}